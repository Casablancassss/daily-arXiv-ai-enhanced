<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 61]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.AI](#cs.AI) [Total: 67]
- [cs.CG](#cs.CG) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training](https://arxiv.org/abs/2602.11239)
*Samanta Ghosh,Jannatul Adan Mahi,Shayan Abrar,Md Parvez Mia,Asaduzzaman Rayhan,Abdul Awal Yasir,Asaduzzaman Hridoy*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的自动化茶树叶病分类方法，利用茶LeafBD数据集（含5278张高分辨率图像，分为7类），结合DenseNet201和EfficientNetB3模型、对抗训练与Grad-CAM可视化技术，实现了最高93%的准确率，为农业病害管理提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 茶树对孟加拉国经济至关重要，但易受多种叶部病害影响，导致产量和品质下降；传统人工检测效率低且易出错，因此亟需一种自动、准确的病害识别方法。

Method: 研究构建了一个包含数据预处理、划分、对抗训练、数据增强、模型训练与评估的完整流程，并采用DenseNet201和EfficientNetB3进行分类；通过对抗训练提升模型鲁棒性，并利用Grad-CAM实现可解释性分析。

Result: 实验结果显示，EfficientNetB3在茶LeafBD数据集上达到93%的分类准确率，DenseNet201达到91%，表明所提方法能有效识别茶树叶病。

Conclusion: 该研究证明了深度学习结合对抗训练与可解释AI技术在茶树叶病自动识别中的有效性，为智能农业管理提供了实用工具。

Abstract: Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.

</details>


### [2] [Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration](https://arxiv.org/abs/2602.11241)
*Jinghan He,Junfeng Fang,Feng Xiong,Zijun Yao,Fei Shen,Haiyun Guo,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出Active-Zero框架，通过主动探索视觉环境实现视觉语言模型的自进化学习，在多个基准上显著优于现有自博弈方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的自博弈方法依赖静态图像集，缺乏主动获取适配其能力水平数据的能力，导致学习效率低下且受初始数据集限制。

Method: Active-Zero引入三个协同演化的智能体：Searcher从开放世界中检索符合模型能力前沿的图像，Questioner生成校准后的推理任务，Solver通过准确率奖励进行优化，形成闭环自课程学习机制。

Result: 在Qwen2.5-VL-7B-Instruct模型上，Active-Zero在12个基准测试中推理任务平均准确率达53.97%（提升5.7%），通用理解达59.77%（提升3.9%），均优于现有自博弈基线。

Conclusion: 主动探索是构建可扩展、自适应的自进化视觉语言系统的关键要素。

Abstract: Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.

</details>


### [3] [ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems](https://arxiv.org/abs/2602.11242)
*Yitong Wang,Yue Yao*

Main category: cs.CV

TL;DR: ReTracing 是一个多智能体具身表演艺术项目，通过考古学方法探索人工智能如何塑造、限制并生成身体动作，并揭示生成系统在编舞中所编码的社会文化偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能如何影响人类身体动作，并通过人机互动的编舞形式揭示生成式AI中隐含的社会文化偏见。

Method: 从科幻小说中提取描述人机交互的句子，利用大语言模型生成“应做”与“不应做”的动作提示，再通过扩散式文本到视频模型将其转化为人类表演者和四足机器人的动作指令；两者在镜面地板上执行动作，由多摄像头运动捕捉系统记录，并重建为3D点云与运动轨迹，形成数字动作档案。

Result: 成功构建了一个融合人类、机器人与AI的沉浸式表演系统，生成了可分析的数字运动痕迹档案，并揭示了AI编舞中蕴含的规范性与偏见。

Conclusion: ReTracing 提供了一种新颖的方法论，通过具身实践反思AI对人类行为的塑造作用，并引发对“在能动、思考并留下痕迹的AI环境中，何以为人”这一当代核心问题的深入思考。

Abstract: We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts "what to do" and "what not to do" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?

</details>


### [4] [Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models](https://arxiv.org/abs/2602.11244)
*Sethuraman T,Savya Khosla,Aditi Tiwari,Vidya Ganesh,Rakshana Jayaprakash,Aditya Jain,Vignesh Srinivasakumar,Onkar Kishor Susladkar,Srinidhi Sunkara,Aditya Shanmugham,Rakesh Vaideeswaran,Abbaas Alif Mohamed Nishar,Simon Jenni,Derek Hoiem*

Main category: cs.CV

TL;DR: 本文提出REVEAL基准，揭示当前视频-语言模型（VidLMs）在处理视频内容、时序和运动方面存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 探究当前VidLMs是否真正理解视频中的内容、时间顺序和运动信息，发现其存在对视频信号依赖不足的问题。

Method: 构建REVEAL诊断基准，包含五个受控压力测试：时间预期偏差、仅依赖语言的捷径、视频逢迎行为、摄像机运动敏感性、时空遮挡鲁棒性；并提供自动生成诊断样本的数据管道。

Result: 主流开源与闭源VidLMs在这些测试中表现不佳，例如将倒放视频误认为正放、忽略视频内容作答、认同错误陈述、难以应对基本摄像机运动、无法在遮挡下整合时序信息；而人类轻松完成这些任务。

Conclusion: 当前VidLMs对视频信号的理解远未达到可靠水平，REVEAL基准和数据管道有助于推动更全面、可扩展的评估与改进。

Abstract: This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.

</details>


### [5] [Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking](https://arxiv.org/abs/2602.11314)
*Jacob Rubinstein,Avi Donaty,Don Engel*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过高质量3D模型和程序生成的相机姿态生成合成图像，以支持可重复、可量化的数字孪生重建实验。


<details>
  <summary>Details</summary>
Motivation: 现有基于摄影测量的3D建模方法在生成数字孪生时存在多种设计选择，但其效果多依赖主观评价，缺乏可量化、可重复的评估手段。

Method: 构建一个新流程，利用高保真3D模型与程序化生成的虚拟相机位姿生成合成图像，并将重建结果与已知的虚拟相机参数和物体真值进行对比。

Result: 该方法支持对不同重建策略进行系统性、可重复且可量化的性能评估。

Conclusion: 所提出的合成图像生成流程为数字孪生和3D重建研究提供了可靠的基准测试平台。

Abstract: The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.

</details>


### [6] [MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors](https://arxiv.org/abs/2602.11323)
*Arda Alniak,Sinan Kalkan,Mustafa Mert Ankarali,Afsar Saranli,Abdullah Aydin Alatan*

Main category: cs.CV

TL;DR: 本文提出一种将基于Vision Transformer的深度估计先验融入VINS-Mono后端的新框架，在边缘设备上实现实时、鲁棒且具有度量尺度的单目视觉惯性里程计。


<details>
  <summary>Details</summary>
Motivation: 传统单目VIO在低纹理环境中因视觉特征稀疏而性能下降，而现有基于ViT的稠密深度估计算法虽能提供几何一致的深度信息，但计算开销大，难以部署于边缘设备。

Method: 将学习得到的深度先验集成到VINS-Mono优化后端中，引入仿射不变深度一致性约束和成对序数约束，并通过基于方差的门控机制滤除不稳定伪影。

Result: 在TartanGround和M3ED数据集上的实验表明，该方法在挑战性场景中有效防止轨迹发散，绝对轨迹误差（ATE）最多降低28.3%。

Conclusion: 所提方法在满足边缘设备计算限制的同时，显著提升了单目VIO在低纹理环境下的精度与鲁棒性。

Abstract: Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.

</details>


### [7] [Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content](https://arxiv.org/abs/2602.11339)
*Evgeney Bogatyrev,Khaled Abud,Ivan Molodetskikh,Nikita Alutis,Dmitry Vatolin*

Main category: cs.CV

TL;DR: 本文提出了一个面向真实流媒体场景的超分辨率数据集StreamSR，并引入了一个高效实时超分模型EfRLFN，该模型结合了高效通道注意力机制与双曲正切激活函数，在视觉质量和运行效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有实时超分辨率方法在压缩视频内容上表现不佳，且常用数据集无法准确反映流媒体视频的真实特性，导致现有基准缺乏实际应用相关性。

Method: 构建了源自YouTube、涵盖多类型和分辨率的StreamSR数据集；提出EfRLFN模型，整合高效通道注意力机制与tanh激活函数，并设计复合损失函数以优化训练；对11种先进模型进行基准测试，并在新数据集上进行微调实验。

Result: EfRLFN在视觉质量和推理速度上均优于现有实时超分模型；在StreamSR上微调其他模型可显著提升其在多个标准基准上的泛化性能。

Conclusion: StreamSR数据集更贴近真实流媒体场景，能有效提升模型泛化能力；EfRLFN通过结构与损失函数的协同优化，实现了高效且高质量的实时超分辨率，为流媒体应用提供了实用解决方案。

Abstract: Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.
  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.
  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.

</details>


### [8] [ArtContext: Contextualizing Artworks with Open-Access Art History Articles and Wikidata Knowledge through a LoRA-Tuned CLIP Model](https://arxiv.org/abs/2602.11349)
*Samuel Waugh,Stuart James*

Main category: cs.CV

TL;DR: 本文提出ArtContext，一个结合开放获取艺术史文章与Wikidata知识的流程，通过构建新语料库并微调CLIP模型（命名为PaintingCLIP），实现对艺术作品的上下文注释，提升模型在艺术领域的表现。


<details>
  <summary>Details</summary>
Motivation: 艺术史文献常讨论艺术品及其特定方面（如构图、图像志、物质文化），但读者难以快速了解不同文献对某件作品的具体观点。因此，亟需一种自动方法将文献知识与具体艺术品关联起来。

Method: 作者构建了一个新颖的语料收集流程，整合开放获取的艺术史文章和Wikidata知识；随后采用低秩适应（LoRA）技术对CLIP模型进行领域适配，训练出弱监督的PaintingCLIP模型，用于为艺术品提供上下文注释。

Result: 实验表明，所提出的PaintingCLIP模型在艺术相关任务上优于原始CLIP模型，能有效为给定艺术品提供上下文信息。

Conclusion: ArtContext流程具有通用性，不仅适用于艺术史，还可推广至其他人文学科领域，为跨模态人文研究提供新工具。

Abstract: Many Art History articles discuss artworks in general as well as specific parts of works, such as layout, iconography, or material culture. However, when viewing an artwork, it is not trivial to identify what different articles have said about the piece. Therefore, we propose ArtContext, a pipeline for taking a corpus of Open-Access Art History articles and Wikidata Knowledge and annotating Artworks with this information. We do this using a novel corpus collection pipeline, then learn a bespoke CLIP model adapted using Low-Rank Adaptation (LoRA) to make it domain-specific. We show that the new model, PaintingCLIP, which is weakly supervised by the collected corpus, outperforms CLIP and provides context for a given artwork. The proposed pipeline is generalisable and can be readily applied to numerous humanities areas.

</details>


### [9] [Latent Forcing: Reordering the Diffusion Trajectory for Pixel-Space Image Generation](https://arxiv.org/abs/2602.11401)
*Alan Baade,Eric Ryan Chan,Kyle Sargent,Changan Chen,Justin Johnson,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: 本文提出Latent Forcing方法，在保持潜在扩散模型效率的同时直接在原始像素图像上进行生成，通过联合处理潜在表示与像素并采用独立调优的噪声调度，实现高质量图像生成，并在ImageNet上达到当前扩散Transformer模型的新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有潜在扩散模型虽能高效生成高质量图像，但存在信息丢失、需单独训练解码器、建模辅助分布等问题，无法端到端地处理原始图像数据。作者旨在保留潜在扩散效率优势的同时，直接在原始像素空间中建模。

Method: 提出Latent Forcing方法：在去噪过程中联合处理潜在变量和像素，使用各自调优的噪声调度，使潜在变量作为中间计算的“草稿板”，在高频像素特征生成前提供引导；强调条件信号顺序的重要性，并分析其对多种生成设置的影响。

Result: 在ImageNet上，该方法在相同计算规模下实现了基于扩散Transformer的像素级生成新SOTA性能。

Conclusion: Latent Forcing成功结合了潜在扩散的效率与原始像素生成的端到端优势，揭示了条件信号顺序对生成质量的关键作用，为高效高质量图像生成提供了新思路。

Abstract: Latent diffusion models excel at generating high-quality images but lose the benefits of end-to-end modeling. They discard information during image encoding, require a separately trained decoder, and model an auxiliary distribution to the raw data. In this paper, we propose Latent Forcing, a simple modification to existing architectures that achieves the efficiency of latent diffusion while operating on raw natural images. Our approach orders the denoising trajectory by jointly processing latents and pixels with separately tuned noise schedules. This allows the latents to act as a scratchpad for intermediate computation before high-frequency pixel features are generated. We find that the order of conditioning signals is critical, and we analyze this to explain differences between REPA distillation in the tokenizer and the diffusion model, conditional versus unconditional generation, and how tokenizer reconstruction quality relates to diffusability. Applied to ImageNet, Latent Forcing achieves a new state-of-the-art for diffusion transformer-based pixel generation at our compute scale.

</details>


### [10] [Fighting MRI Anisotropy: Learning Multiple Cardiac Shapes From a Single Implicit Neural Representation](https://arxiv.org/abs/2602.11436)
*Carolina Brás,Soufiane Ben Haddou,Thijs P. Kuipers,Laura Alvarez-Florez,R. Nils Planken,Fleur V. Y. Tjong,Connie Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 该论文提出利用高分辨率、近各向同性的CTA数据训练一个神经隐式函数，以重建CMRI中右心室（RV）和心肌（MYO）的三维形状，并在4腔切面评估其准确性。


<details>
  <summary>Details</summary>
Motivation: 短轴心血管磁共振成像（CMRI）具有各向异性，限制了心脏形状分析的精度，因此需要一种方法来提升重建质量。

Method: 使用高分辨率CTA数据训练单一神经隐式函数，联合表示任意分辨率下的CMRI心脏形状；通过从重建形状中提取4腔切面并与CMRI参考分割进行比较来评估性能。

Result: 在4CH切面上，RV和MYO的Dice系数分别为0.91±0.07和0.75±0.13，Hausdorff距离分别为6.21±3.97 mm和7.53±5.13 mm；重建结果在定量和定性上均表现良好。

Conclusion: 所提方法能够重建准确、平滑且解剖学上合理的三维心脏形状，有助于提升心脏形状分析能力。

Abstract: The anisotropic nature of short-axis (SAX) cardiovascular magnetic resonance imaging (CMRI) limits cardiac shape analysis. To address this, we propose to leverage near-isotropic, higher resolution computed tomography angiography (CTA) data of the heart. We use this data to train a single neural implicit function to jointly represent cardiac shapes from CMRI at any resolution. We evaluate the method for the reconstruction of right ventricle (RV) and myocardium (MYO), where MYO simultaneously models endocardial and epicardial left-ventricle surfaces. Since high-resolution SAX reference segmentations are unavailable, we evaluate performance by extracting a 4-chamber (4CH) slice of RV and MYO from their reconstructed shapes. When compared with the reference 4CH segmentation masks from CMRI, our method achieved a Dice similarity coefficient of 0.91 $\pm$ 0.07 and 0.75 $\pm$ 0.13, and a Hausdorff distance of 6.21 $\pm$ 3.97 mm and 7.53 $\pm$ 5.13 mm for RV and MYO, respectively. Quantitative and qualitative assessment demonstrate the model's ability to reconstruct accurate, smooth and anatomically plausible shapes, supporting improvements in cardiac shape analysis.

</details>


### [11] [Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation](https://arxiv.org/abs/2602.11440)
*Penghui Ruan,Bojia Zi,Xianbiao Qi,Youze Huang,Rong Xiao,Pichao Wang,Jiannong Cao,Yuhui Shi*

Main category: cs.CV

TL;DR: Ctrl&Shift 是一个端到端扩散框架，可在不依赖显式3D建模的情况下实现几何一致且用户可控的物体级图像/视频编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时满足背景保留、视角变换下的几何一致性以及用户可控性三大目标，几何方法控制精确但泛化差，扩散方法泛化好但缺乏几何控制。

Method: 将物体操作分解为物体移除与参考引导的修复两个阶段，并在统一的扩散过程中结合显式相机姿态控制；采用多任务、多阶段训练策略分离背景、身份和姿态信号；构建可扩展的真实世界数据集，包含带估计相对相机姿态的图像-视频对。

Result: 实验表明 Ctrl&Shift 在保真度、视角一致性和可控性方面达到最先进水平。

Conclusion: 该框架首次在无需显式3D建模的前提下，统一了细粒度几何控制与真实场景泛化能力，适用于电影后期、AR和创意编辑等任务。

Abstract: Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.

</details>


### [12] [Arbitrary Ratio Feature Compression via Next Token Prediction](https://arxiv.org/abs/2602.11494)
*Yufan Liu,Daoyuan Ren,Zhipeng Zhang,Wenyang Luo,Bing Li,Weiming Hu,Stephen Maybank*

Main category: cs.CV

TL;DR: 本文提出了一种任意比率特征压缩（ARFC）框架，通过单一模型支持任意压缩比，无需为不同压缩比重新训练模型，并在多个任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有特征压缩方法通常依赖专用模型实现特定压缩比，缺乏灵活性和泛化能力，且在适应新压缩比时需重新训练。为解决这一问题，作者提出一种更灵活的通用压缩框架。

Method: 提出任意比率压缩器（ARC），基于自回归模型通过下一令牌预测实现压缩，压缩比由推理时生成的令牌数量控制。引入混合解（MoS）模块融合多个压缩结果以提升鲁棒性，并在训练中加入实体关系图约束（ERGC）以保留语义与结构信息。

Result: 在跨模态检索、图像分类和图像检索等多个数据集和任务上，ARFC在各种压缩比下均优于现有方法，某些情况下甚至超越原始未压缩特征的性能。

Conclusion: ARFC框架具有高度灵活性和实用性，在资源受限场景下展现出优越的压缩效果与泛化能力。

Abstract: Feature compression is increasingly important for improving the efficiency of downstream tasks, especially in applications involving large-scale or multi-modal data. While existing methods typically rely on dedicated models for achieving specific compression ratios, they are often limited in flexibility and generalization. In particular, retraining is necessary when adapting to a new compression ratio. To address this limitation, we propose a novel and flexible Arbitrary Ratio Feature Compression (ARFC) framework, which supports any compression ratio with a single model, eliminating the need for multiple specialized models. At its core, the Arbitrary Ratio Compressor (ARC) is an auto-regressive model that performs compression via next-token prediction. This allows the compression ratio to be controlled at inference simply by adjusting the number of generated tokens. To enhance the quality of the compressed features, two key modules are introduced. The Mixture of Solutions (MoS) module refines the compressed tokens by utilizing multiple compression results (solutions), reducing uncertainty and improving robustness. The Entity Relation Graph Constraint (ERGC) is integrated into the training process to preserve semantic and structural relationships during compression. Extensive experiments on cross-modal retrieval, image classification, and image retrieval tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches at various compression ratios. Notably, in some cases, it even surpasses the performance of the original, uncompressed features. These results validate the effectiveness and versatility of ARFC for practical, resource-constrained scenarios.

</details>


### [13] [What if Agents Could Imagine? Reinforcing Open-Vocabulary HOI Comprehension through Generation](https://arxiv.org/abs/2602.11499)
*Zhenlong Yuan,Xiangyan Qu,Jing Tang,Rui Chen,Lei Sun,Ruidong Chen,Hongwei Yu,Chengxuan Qian,Xiangxiang Chu,Shuo Li,Yuyin Zhou*

Main category: cs.CV

TL;DR: 本文提出ImagineAgent，一种结合认知推理与生成式想象的智能体框架，用于提升开放词汇人-物交互（OV-HOI）任务中的跨模态对齐能力，在减少训练数据的同时取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在OV-HOI任务中受限于跨模态幻觉和遮挡引起的歧义，难以实现鲁棒的视觉理解。

Method: 构建显式建模实体与动作关系的认知图谱，并动态调用检索增强、图像裁剪和扩散模型等工具获取领域知识与视觉证据，辅以兼顾预测准确率与工具效率的复合奖励机制。

Result: 在SWIG-HOI和HICO-DET数据集上达到SOTA性能，仅需约20%的训练数据即可超越现有方法。

Conclusion: ImagineAgent通过融合认知推理与生成式想象，有效缓解了跨模态幻觉与遮挡问题，显著提升了OV-HOI任务的鲁棒性与数据效率。

Abstract: Multimodal Large Language Models have shown promising capabilities in bridging visual and textual reasoning, yet their reasoning capabilities in Open-Vocabulary Human-Object Interaction (OV-HOI) are limited by cross-modal hallucinations and occlusion-induced ambiguity. To address this, we propose \textbf{ImagineAgent}, an agentic framework that harmonizes cognitive reasoning with generative imagination for robust visual understanding. Specifically, our method innovatively constructs cognitive maps that explicitly model plausible relationships between detected entities and candidate actions. Subsequently, it dynamically invokes tools including retrieval augmentation, image cropping, and diffusion models to gather domain-specific knowledge and enriched visual evidence, thereby achieving cross-modal alignment in ambiguous scenarios. Moreover, we propose a composite reward that balances prediction accuracy and tool efficiency. Evaluations on SWIG-HOI and HICO-DET datasets demonstrate our SOTA performance, requiring approximately 20\% of training data compared to existing methods, validating our robustness and efficiency.

</details>


### [14] [Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis](https://arxiv.org/abs/2602.11536)
*De-Xing Huang,Chaohui Yu,Xiao-Hu Zhou,Tian-Yu Xiang,Qin-Yi Zhang,Mei-Jiang Gui,Rui-Ze Ma,Chen-Yu Wang,Nu-Fang Xiao,Fan Wang,Zeng-Guang Hou*

Main category: cs.CV

TL;DR: 本文提出了一种血管解剖结构感知的掩码图像建模方法（VasoMIM），结合大规模X射线血管造影数据集XA-170K，在多个下游任务中实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前X射线血管造影图像分析受限于标注数据稀缺，而现有自监督学习方法在该领域缺乏有效的框架和大规模数据集支持。

Method: VasoMIM包含两个核心设计：基于解剖结构引导的掩码策略和解剖一致性损失。前者通过遮盖含血管区域迫使模型学习鲁棒的血管语义，后者则保持原始与重建图像间血管结构的一致性，提升表征判别能力。同时构建了目前最大的X射线血管造影预训练数据集XA-170K。

Result: 在六个数据集上的四个下游任务中，VasoMIM展现出优异的迁移能力和最先进的性能。

Conclusion: VasoMIM有望作为基础模型推动X射线血管造影图像分析任务的发展，相关代码和数据集已开源。

Abstract: X-ray angiography is the gold standard imaging modality for cardiovascular diseases. However, current deep learning approaches for X-ray angiogram analysis are severely constrained by the scarcity of annotated data. While large-scale self-supervised learning (SSL) has emerged as a promising solution, its potential in this domain remains largely unexplored, primarily due to the lack of effective SSL frameworks and large-scale datasets. To bridge this gap, we introduce a vascular anatomy-aware masked image modeling (VasoMIM) framework that explicitly integrates domain-specific anatomical knowledge. Specifically, VasoMIM comprises two key designs: an anatomy-guided masking strategy and an anatomical consistency loss. The former strategically masks vessel-containing patches to compel the model to learn robust vascular semantics, while the latter preserves structural consistency of vessels between original and reconstructed images, enhancing the discriminability of the learned representations. In conjunction with VasoMIM, we curate XA-170K, the largest X-ray angiogram pre-training dataset to date. We validate VasoMIM on four downstream tasks across six datasets, where it demonstrates superior transferability and achieves state-of-the-art performance compared to existing methods. These findings highlight the significant potential of VasoMIM as a foundation model for advancing a wide range of X-ray angiogram analysis tasks. VasoMIM and XA-170K will be available at https://github.com/Dxhuang-CASIA/XA-SSL.

</details>


### [15] [Supervise-assisted Multi-modality Fusion Diffusion Model for PET Restoration](https://arxiv.org/abs/2602.11545)
*Yingkai Zhang,Shuang Chen,Ye Tian,Yunyi Gao,Jianyong Jiang,Ying Fu*

Main category: cs.CV

TL;DR: 本文提出了一种监督辅助的多模态融合扩散模型（MFdiff），用于从低剂量PET和MR图像中高质量地恢复标准剂量PET图像，有效解决了多模态融合中的结构纹理不一致及分布外数据不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 降低PET成像中的辐射剂量会导致图像质量下降，而利用MR图像辅助恢复标准剂量PET图像面临多模态融合不一致和分布外数据不匹配等挑战。

Method: 提出MFdiff模型：1）设计多模态特征融合模块以优化融合特征，避免引入无关细节；2）以融合特征为条件，基于扩散模型迭代生成高质量SPET图像；3）采用两阶段监督辅助学习策略，结合模拟分布内数据的通用先验和真实分布外数据的特定先验。

Result: 实验表明，MFdiff在定性和定量指标上均优于当前最先进的方法，能有效从多模态输入中恢复高质量SPET图像。

Conclusion: 所提出的MFdiff模型通过创新的多模态融合机制和监督辅助学习策略，显著提升了低剂量PET图像的恢复质量，具有良好的临床应用前景。

Abstract: Positron emission tomography (PET) offers powerful functional imaging but involves radiation exposure. Efforts to reduce this exposure by lowering the radiotracer dose or scan time can degrade image quality. While using magnetic resonance (MR) images with clearer anatomical information to restore standard-dose PET (SPET) from low-dose PET (LPET) is a promising approach, it faces challenges with the inconsistencies in the structure and texture of multi-modality fusion, as well as the mismatch in out-of-distribution (OOD) data. In this paper, we propose a supervise-assisted multi-modality fusion diffusion model (MFdiff) for addressing these challenges for high-quality PET restoration. Firstly, to fully utilize auxiliary MR images without introducing extraneous details in the restored image, a multi-modality feature fusion module is designed to learn an optimized fusion feature. Secondly, using the fusion feature as an additional condition, high-quality SPET images are iteratively generated based on the diffusion model. Furthermore, we introduce a two-stage supervise-assisted learning strategy that harnesses both generalized priors from simulated in-distribution datasets and specific priors tailored to in-vivo OOD data. Experiments demonstrate that the proposed MFdiff effectively restores high-quality SPET images from multi-modality inputs and outperforms state-of-the-art methods both qualitatively and quantitatively.

</details>


### [16] [Perception-based Image Denoising via Generative Compression](https://arxiv.org/abs/2602.11553)
*Nam Nguyen,Thinh Nguyen,Bella Bose*

Main category: cs.CV

TL;DR: 本文提出一种基于生成压缩的图像去噪框架，在保留结构细节的同时提升感知真实性，通过熵编码潜在表示和生成解码器实现，并引入WGAN与扩散模型两种实现方式。


<details>
  <summary>Details</summary>
Motivation: 传统失真驱动的去噪方法在强噪声或分布偏移下易产生过度平滑结果，难以兼顾感知质量和结构保真度。

Method: 构建生成压缩框架：利用熵编码的低复杂度潜在表示进行重建，结合生成解码器（如条件WGAN和条件扩散模型）并通过LPIPS损失与Wasserstein距离优化感知质量；同时提供高斯噪声下最大似然去噪器的非渐近理论保证。

Result: 在合成与真实噪声数据集上，该方法在保持竞争性失真性能的同时，显著提升了感知质量。

Conclusion: 所提框架有效平衡了率-失真-感知三者之间的权衡，为感知导向的图像去噪提供了新思路与理论支持。

Abstract: Image denoising aims to remove noise while preserving structural details and perceptual realism, yet distortion-driven methods often produce over-smoothed reconstructions, especially under strong noise and distribution shift. This paper proposes a generative compression framework for perception-based denoising, where restoration is achieved by reconstructing from entropy-coded latent representations that enforce low-complexity structure, while generative decoders recover realistic textures via perceptual measures such as learned perceptual image patch similarity (LPIPS) loss and Wasserstein distance. Two complementary instantiations are introduced: (i) a conditional Wasserstein GAN (WGAN)-based compression denoiser that explicitly controls the rate-distortion-perception (RDP) trade-off, and (ii) a conditional diffusion-based reconstruction strategy that performs iterative denoising guided by compressed latents. We further establish non-asymptotic guarantees for the compression-based maximum-likelihood denoiser under additive Gaussian noise, including bounds on reconstruction error and decoding error probability. Experiments on synthetic and real-noise benchmarks demonstrate consistent perceptual improvements while maintaining competitive distortion performance.

</details>


### [17] [LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts](https://arxiv.org/abs/2602.11564)
*Chen Zhao,Jiawei Chen,Hongyu Li,Zhuoliang Kang,Shilin Lu,Xiaoming Wei,Kai Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 本文提出了LUVE，一种基于双频专家的潜空间级联超高清（UHR）视频生成框架，通过三阶段架构实现高质量、高保真度的UHR视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在视觉质量上虽有提升，但在超高清视频生成方面仍面临运动建模、语义规划和细节合成等多重挑战。

Method: LUVE采用三阶段架构：1）低分辨率运动生成以获得运动一致的潜在表示；2）在潜在空间中直接进行视频潜在上采样以降低计算和内存开销；3）结合低频与高频专家模块，联合优化语义一致性和细粒度细节生成。

Result: 实验表明，LUVE在UHR视频生成中实现了优越的逼真度和内容保真度，消融研究也验证了各组件的有效性。

Conclusion: LUVE有效解决了UHR视频生成中的关键难题，为高质量视频生成提供了新思路。

Abstract: Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \textbf{LUVE}, a \textbf{L}atent-cascaded \textbf{U}HR \textbf{V}ideo generation framework built upon dual frequency \textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.

</details>


### [18] [Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception](https://arxiv.org/abs/2602.11565)
*Zesheng Jia,Jin Wang,Siao Liu,Lingzhi Li,Ziyao Huang,Yunjiang Xu,Jianping Wang*

Main category: cs.CV

TL;DR: 本文提出FlowAdapt，一种基于最优传输理论的参数高效域自适应框架，通过Wasserstein贪心采样和渐进知识迁移，在仅1%可训练参数下实现V2X多智能体感知中的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在V2X协同感知中，将参数高效微调（PEFT）直接应用于多智能体系统会导致性能显著下降和训练不稳定，主要源于异构感知流中的帧间冗余和深层表征中细粒度语义的退化。

Method: 提出FlowAdapt框架：1）利用Wasserstein贪心采样策略，通过有界覆盖半径筛选冗余样本；2）设计渐进知识迁移模块，通过可学习路径将压缩的早期表征逐步注入后期阶段，缓解语义退化。

Result: 在三个基准上的实验表明，FlowAdapt仅用1%的可训练参数即达到领先性能，具有优异的样本效率和泛化能力。

Conclusion: FlowAdapt有效解决了多智能体V2X感知中PEFT应用的关键瓶颈，为快速域自适应提供了高效且稳定的解决方案。

Abstract: Fast domain adaptation remains a fundamental challenge for deploying multi-agent systems across diverse environments in Vehicle-to-Everything (V2X) collaborative perception. Despite the success of Parameter-Efficient Fine-Tuning (PEFT) in natural language processing and conventional vision tasks, directly applying PEFT to multi-agent settings leads to significant performance degradation and training instability. In this work, we conduct a detailed analysis and identify two key factors: (i) inter-frame redundancy in heterogeneous sensory streams, and (ii) erosion of fine-grained semantics in deep-layer representations under PEFT adaptation. To address these issues, we propose FlowAdapt, a parameter-efficient framework grounded in optimal transport theory, which minimizes information transport costs across both data distributions and network hierarchies. Specifically, we introduce a Wasserstein Greedy Sampling strategy to selectively filter redundant samples via a bounded covering radius. Furthermore, Progressive Knowledge Transfer module is designed to progressively inject compressed early-stage representations into later stages through learnable pathways, alleviating semantic degradation in late-stage adaptation. Extensive experiments on three benchmarks demonstrate that FlowAdapt achieves state-of-the-art performance with only 1% of trainable parameters, effectively bridging domain gaps with superior sample efficiency and generalization.

</details>


### [19] [PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction](https://arxiv.org/abs/2602.11625)
*Bin Huang,Xun Yu,Yikun Zhang,Yi Zhang,Yang Chen,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PLOT-CT的新框架，通过在预对数（pre-log）域中使用Voronoi分解来提升低剂量CT重建的精度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT重建面临严重噪声和数据保真度下降的问题。现有方法多在图像域或对数后投影域操作，无法充分利用预对数测量中的结构信息，且对噪声敏感；对数变换会放大噪声，对重建精度提出更高要求。

Method: 提出PLOT-CT框架，在预对数正弦图上应用Voronoi分解，将数据解耦为多个底层成分并映射到不同的潜在空间，从而增强模型学习判别性特征的能力，有效抑制噪声并保留预对数域中的信息。

Result: 在1e4入射光子水平下，PLOT-CT在预对数域中比传统方法PSNR提升2.36dB，达到当前最优性能。

Conclusion: PLOT-CT通过在预对数域中引入Voronoi分解，有效提升了低剂量CT重建的准确性和鲁棒性，为该领域提供了新的技术路径。

Abstract: Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.

</details>


### [20] [PLESS: Pseudo-Label Enhancement with Spreading Scribbles for Weakly Supervised Segmentation](https://arxiv.org/abs/2602.11628)
*Yeva Gabrielyan,Varduhi Yeghiazaryan,Irina Voiculescu*

Main category: cs.CV

TL;DR: 提出了一种通用的伪标签增强策略PLESS，通过图像层次分割和语义一致区域内的标注传播，提升scribble弱监督医学图像分割中伪标签的可靠性和空间一致性。


<details>
  <summary>Details</summary>
Motivation: Scribble标注虽能降低标注成本，但存在监督信息稀疏、噪声大和不完整的问题；现有基于伪标签的方法受限于伪标签质量，亟需提升其可靠性与一致性。

Method: PLESS方法基于图像的层次化空间一致区域划分，将scribble标注信息在语义一致区域内传播，从而优化伪标签；该方法模型无关，可嵌入现有伪标签流程。

Result: 在ACDC和MSCMRseg两个公开心脏MRI数据集上，结合四种scribble监督算法，PLESS均显著提升了分割精度。

Conclusion: PLESS是一种有效且通用的伪标签增强策略，能显著改善scribble弱监督医学图像分割性能，具有良好的实用性和可扩展性。

Abstract: Weakly supervised learning with scribble annotations uses sparse user-drawn strokes to indicate segmentation labels on a small subset of pixels. This annotation reduces the cost of dense pixel-wise labeling, but suffers inherently from noisy and incomplete supervision. Recent scribble-based approaches in medical image segmentation address this limitation using pseudo-label-based training; however, the quality of the pseudo-labels remains a key performance limit. We propose PLESS, a generic pseudo-label enhancement strategy which improves reliability and spatial consistency. It builds on a hierarchical partitioning of the image into a hierarchy of spatially coherent regions. PLESS propagates scribble information to refine pseudo-labels within semantically coherent regions. The framework is model-agnostic and easily integrates into existing pseudo-label methods. Experiments on two public cardiac MRI datasets (ACDC and MSCMRseg) across four scribble-supervised algorithms show consistent improvements in segmentation accuracy. Code will be made available on GitHub upon acceptance.

</details>


### [21] [GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction](https://arxiv.org/abs/2602.11653)
*Mengxiao Geng,Zijie Chen,Ran Hong,Bingxuan Li,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出GR-Diffusion框架，结合离散高斯表示（GR）与扩散模型，用于低剂量三维全身PET图像重建，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PET重建面临噪声放大、结构模糊和细节丢失等问题，尤其在稀疏采样和低剂量条件下。传统点基或体素基方法存在低通滤波限制，难以保留精细结构。

Method: GR-Diffusion利用GR从投影数据生成具有物理依据和结构明确的参考3D PET图像，并以此作为扩散过程中的双重引导：细粒度引导优化局部细节，粗粒度引导通过多尺度差异图校正全局偏差，从而融合几何先验并恢复亚体素信息。

Result: 在UDPET和临床数据集上的实验表明，GR-Diffusion在不同剂量水平下均能显著提升3D全身PET图像质量，优于当前最先进方法。

Conclusion: GR-Diffusion通过将离散高斯表示与扩散模型有机结合，有效提升了低剂量PET重建的结构保真度与细节还原能力，为分子影像提供了一种新范式。

Abstract: Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.

</details>


### [22] [SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving](https://arxiv.org/abs/2602.11656)
*Seo Hyun Kim,Jin Bok Park,Do Yeon Koo,Ho Gun Park,Il Yong Chun*

Main category: cs.CV

TL;DR: 本文提出了一种名为SToRM的监督式视觉token压缩框架，用于多模态大语言模型驱动的端到端自动驾驶系统，在大幅降低计算开销（最高达30倍）的同时保持与使用全部token相当的性能。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统在应对突发场景时可借助人类自然语言指令提升安全性，但融合多模态大语言模型（MLLM）会带来高昂的计算成本，尤其受限于车载资源。现有视觉token压缩方法常导致任务性能下降，因此亟需一种高效且性能无损的token压缩方案。

Method: 提出SToRM框架，包含三个核心组件：1）轻量级重要性预测器，利用短期滑动窗口估计各视觉token的重要性；2）监督训练策略，通过辅助路径从全token LLM前向传播中获取伪监督信号；3）锚点-上下文合并模块，将token划分为锚点与上下文，并将上下文合并至相关锚点以减少冗余并保留关键信息。

Result: 在LangAuto基准上的实验表明，SToRM在相同压缩token预算下优于当前最先进的端到端驾驶MLLM方法，能够在计算成本降低最高30倍的同时维持与使用全部token相当的性能。

Conclusion: SToRM是首个面向多模态大语言模型的监督式token压缩框架，有效解决了端到端自动驾驶中计算效率与任务性能之间的权衡问题，为资源受限的车载部署提供了可行方案。

Abstract: In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.
  To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.

</details>


### [23] [EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation](https://arxiv.org/abs/2602.11658)
*Bingyuan Wang,Xingbei Chen,Zongyang Qiu,Linping Yuan,Zeyu Wang*

Main category: cs.CV

TL;DR: 本文提出EmoSpace，一种用于情感感知内容生成的新框架，通过视觉-语言对齐学习动态可解释的情感原型，实现细粒度情感控制，适用于VR等沉浸式环境。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以捕捉细腻的情感语义，且缺乏对情感的精细控制，限制了虚拟现实（VR）中沉浸式内容的创作。

Method: 提出EmoSpace框架，采用层次化情感表示和可学习的情感原型，结合多原型引导、时间混合与注意力重加权机制，在无需显式情感标签的情况下实现可控生成。

Result: 实验表明EmoSpace在定性和定量评估中均优于现有方法，并通过用户研究揭示VR环境对情感感知的影响。

Conclusion: 该工作支持具有细粒度情感控制的沉浸式视觉内容生成，可应用于治疗、教育、叙事、艺术创作和文化保护等领域。

Abstract: Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.

</details>


### [24] [Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes](https://arxiv.org/abs/2602.11660)
*Jeongho Noh,Tai Hyoung Rhee,Eunho Lee,Jeongyun Kim,Sunwoo Lee,Ayoung Kim*

Main category: cs.CV

TL;DR: 本文提出Clutt3R-Seg，一种用于语言引导机器人在杂乱场景中进行3D实例分割的零样本方法，通过构建语义线索的层次化实例树，有效处理遮挡、视角有限和掩码噪声等问题，在合成与真实数据集及真实机器人上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在语言引导的机器人操作中，杂乱环境下的可靠3D实例分割面临遮挡、视角受限和掩码噪声等挑战，现有方法难以生成一致且鲁棒的实例分割结果，亟需一种能在稀疏视角和动态场景中保持高精度的解决方案。

Method: Clutt3R-Seg利用噪声掩码作为信息线索，通过跨视角分组和条件替换构建层次化实例树，抑制过分割与欠分割；结合开放词汇语义嵌入支持自然语言指令的目标选择，并引入一致性感知更新机制，仅用单张交互后图像即可维持实例对应关系。

Result: 在合成与真实数据集及真实机器人实验中，Clutt3R-Seg在杂乱和稀疏视角场景下均优于SOTA方法：在重度杂乱序列中AP@25达61.66，是基线的2.2倍以上；仅用4个视角即超越使用8个视角的MaskClustering两倍以上。

Conclusion: Clutt3R-Seg通过创新性地利用噪声掩码并结合层次化语义结构与一致性更新机制，实现了在复杂、动态杂乱环境中高效、鲁棒的语言引导3D实例分割，为实际机器人应用提供了可行方案。

Abstract: Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.

</details>


### [25] [Egocentric Gaze Estimation via Neck-Mounted Camera](https://arxiv.org/abs/2602.11669)
*Haoyu Huang,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出了一种新的任务——颈部摄像头视角下的视线估计，并构建了首个相关数据集，评估了基于Transformer的模型GLC及其两种改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有以自我为中心的视线估计研究主要集中在头戴式摄像头，而其他视角（如颈部视角）尚未被充分探索。为填补这一空白，作者引入并研究颈部摄像头视角下的视线估计任务。

Method: 作者收集了包含8名参与者在日常活动中约4小时视频的首个颈部视角视线估计数据集；采用基于Transformer的GLC模型进行评估，并提出两种扩展方法：一是增加视线是否超出视野范围的辅助分类任务，二是结合头戴与颈部视角的多视角协同学习方法，使用几何感知辅助损失进行联合训练。

Result: 实验表明，引入视线越界分类任务能提升模型性能，优于标准微调；但多视角协同学习方法未带来性能增益。

Conclusion: 颈部摄像头视角下的视线估计具有可行性，辅助越界分类有助于提升性能，而多视角协同学习在此任务中效果有限，需进一步研究其适用条件和优化策略。

Abstract: This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.

</details>


### [26] [U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction](https://arxiv.org/abs/2602.11672)
*Yingyi Luo,Shuaiang Rong,Adam Watts,Ahmet Enis Cetin*

Main category: cs.CV

TL;DR: 提出了一种轻量级深度学习模型TD-FusionUNet，用于次日野火蔓延预测，在保持低参数量的同时取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有野火预测模型往往计算复杂、参数量大，难以部署在资源受限的实时应用场景中，因此需要开发一种兼顾精度与效率的轻量级预测工具。

Method: 提出TD-FusionUNet模型，引入可训练的Hadamard变换和离散余弦变换层以在正交化潜在空间中捕捉关键“频率”成分；同时采用随机边缘裁剪和高斯混合模型等自定义预处理技术，增强稀疏火灾前掩码的表示能力。

Result: 在Google Research的Next-Day Wildfire Spread数据集和WildfireSpreadTS数据集上评估，TD-FusionUNet以仅370k参数达到0.591的F1分数，优于使用ResNet18编码器的UNet基线模型。

Conclusion: 所提出的TD-FusionUNet在轻量级设置下有效平衡了预测精度与计算效率，适用于资源受限环境下的实时野火预测。

Abstract: We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential "frequency" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.

</details>


### [27] [RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval](https://arxiv.org/abs/2602.11673)
*Khanh Nguyen,Dasith de Silva Edirimuni,Ghulam Mubashar Hassan,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出RI-Mamba，首个用于点云的旋转不变状态空间模型，在任意姿态下实现高效、鲁棒的文本到3D形状检索。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D形状检索方法依赖规范姿态且支持类别有限，难以应对真实场景中多类别、任意朝向的3D对象。

Method: RI-Mamba通过构建全局与局部参考系解耦姿态与几何，利用Hilbert排序生成具有几何结构的旋转不变token序列，并引入方向嵌入与特征线性调制以恢复空间上下文；结合跨模态对比学习与自动三元组生成进行大规模训练。

Result: 在OmniObject3D基准上，RI-Mamba在200多个类别、任意姿态条件下达到最先进的检索性能，展现出卓越的表达能力和鲁棒性。

Conclusion: RI-Mamba有效解决了3D对象在任意姿态下的文本检索难题，为大规模、多类别3D资产库提供了实用且高效的解决方案。

Abstract: 3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.

</details>


### [28] [Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis](https://arxiv.org/abs/2602.11703)
*Qiwen Xu,David Rügamer,Holger Wenz,Johann Fontana,Nora Meggyeshazi,Andreas Bender,Máté E. Maros*

Main category: cs.CV

TL;DR: 本文提出了一种语义条件控制的潜在扩散模型（LDM），用于生成具有解剖结构和成像角度控制的脑血管数字减影血管造影（DSA）图像，所生成图像在临床真实性和分布相似性方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 由于DSA检查具有侵入性和高成本，限制了大规模数据收集与公开共享，因此需要一种能够生成逼真且可控的合成DSA图像的方法，以支持医学研究、算法开发和培训。

Method: 作者构建了一个包含99,349帧的单中心DSA数据集，并利用编码了解剖区域（前循环/后循环）和C臂标准位置的文本嵌入，训练了一个语义条件控制的潜在扩散模型（LDM）。

Result: 四位医学专家对400张合成图像进行Likert评分（1–5分），整体得分在3.1–3.3之间，组内相关系数（ICC）为0.80–0.87；与真实DSA图像的Fréchet Inception Distance（FID）中位数为15.27，表明分布高度相似。

Conclusion: 语义条件控制的LDM能生成具有临床可信度的合成DSA图像，适用于下游医学图像算法开发、科研及教学用途。

Abstract: Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.

</details>


### [29] [LLM-Driven 3D Scene Generation of Agricultural Simulation Environments](https://arxiv.org/abs/2602.11706)
*Arafa Yoncalik,Wouter Jansen,Nico Huebel,Mohammad Hasan Rahmani,Jan Steckel*

Main category: cs.CV

TL;DR: 本文提出一种模块化的多大语言模型（LLM）流水线，用于从自然语言生成农业仿真3D场景，通过结合领域知识、资产检索与代码生成，在Unreal引擎中实现高真实感、可验证且可扩展的环境构建。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的3D场景生成方法缺乏领域特定推理、验证机制和模块化设计，导致控制力弱、可扩展性差；本文旨在解决这些问题，特别是在农业仿真环境中。

Method: 开发了一个模块化多LLM流水线，整合3D资产检索、领域知识注入和基于Unreal引擎API的代码生成，并采用少样本提示、检索增强生成（RAG）、微调和验证等混合优化策略。

Result: 系统能根据自然语言提示生成具有真实种植布局和环境上下文的3D场景；评估显示其在语义准确性、用户感知真实感方面表现良好，并显著节省专家手动建模时间。

Conclusion: 多LLM模块化架构有效提升了领域特定3D场景生成的可靠性、精确性和可扩展性，未来可拓展至其他仿真领域并支持实时生成。

Abstract: Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.

</details>


### [30] [GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry](https://arxiv.org/abs/2602.11714)
*Jiung Yeon,Seongbo Ha,Hyeonwoo Yu*

Main category: cs.CV

TL;DR: GSO-SLAM 是一种实时单目稠密SLAM系统，通过高斯场景表示和双向耦合视觉里程计（VO）与高斯点阵（GS），在不增加计算开销的情况下实现高精度重建与跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM方法要么将跟踪与建图耦合于统一场景导致计算成本高，要么松散集成引入冗余。本文旨在设计一种高效、精确且实时的单目稠密SLAM系统。

Method: 提出GSO-SLAM，采用期望最大化（EM）框架对VO提供的半稠密深度估计与高斯点阵表示进行联合优化，并设计高斯点初始化策略，利用图像信息、关键帧位姿和VO像素关联快速生成高质量初始高斯场景。

Result: 实验表明，该方法可实现实时运行，在几何/光度保真度和跟踪精度方面达到当前最优水平。

Conclusion: GSO-SLAM通过双向耦合VO与GS并结合EM优化与高效初始化策略，有效解决了现有SLAM系统在效率与精度之间的权衡问题。

Abstract: We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.

</details>


### [31] [STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning](https://arxiv.org/abs/2602.11730)
*Xiaowen Zhang,Zhi Gao,Licheng Jiao,Lingling Li,Qing Li*

Main category: cs.CV

TL;DR: 本文提出一种新的视觉提示范式STVG-R1，通过将坐标预测转化为实例级ID识别问题，并结合强化学习优化时序准确性、空间一致性和结构格式，显著提升密集预测任务如时空视频定位（STVG）的性能，并在多个基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在密集预测任务中常因文本描述与视觉坐标对齐困难而产生幻觉，且已有方法依赖额外可训练模块，带来高标注成本和计算开销。

Method: 将每帧坐标预测重构为实例级唯一ID识别问题，将ID作为视觉提示嵌入视频输入；并提出首个用于STVG的强化学习框架STVG-R1，采用任务驱动奖励联合优化时序、空间和结构目标。

Result: 在六个基准上验证有效性，在HCSTVG-v2上m_IoU比Qwen2.5-VL-7B提升20.9%，并在MeViS多目标指代视频分割任务中以47.3% J&F实现零样本SOTA。

Conclusion: 所提方法有效缓解了跨模态坐标对齐难题，无需额外标注即可实现高性能和强泛化能力，为VLM在密集预测任务中的应用提供了新思路。

Abstract: In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.

</details>


### [32] [Adapting Vision-Language Models for E-commerce Understanding at Scale](https://arxiv.org/abs/2602.11733)
*Matteo Nulli,Vladimir Orshulevich,Tala Bazazo,Christian Herold,Michael Kozielski,Marcin Mazur,Szymon Tuzel,Cees G. M. Snoek,Seyyed Hadi Hashemi,Omar Javed,Yannick Versley,Shahram Khadivi*

Main category: cs.CV

TL;DR: 本文通过大规模实验研究，展示了如何有针对性地调整通用视觉语言模型（VLMs），以显著提升其在电商场景中的表现，同时保留其广泛的多模态能力，并提出了一套涵盖深度商品理解、严格指令遵循和动态属性提取的新型综合评估体系。


<details>
  <summary>Details</summary>
Motivation: 电商产品理解天然需要对文本、图像和结构化属性进行强大的多模态理解。尽管通用视觉语言模型（VLMs）具备可泛化的多模态建模能力，但目前尚无明确策略能在不牺牲通用性能的前提下，将其有效适配到以属性为中心、多图像且噪声较多的电商数据中。

Method: 开展大规模实验研究，对通用VLM进行针对性适配；同时构建一套新的综合评估体系，覆盖深度产品理解、严格指令遵循和动态属性提取三个方面。

Result: 针对性适配显著提升了VLM在电商任务中的性能，同时保持了其通用多模态能力。

Conclusion: 通过合理调整通用VLM并辅以全面评估体系，可以在电商场景中实现高效且鲁棒的多模态产品理解，为后续相关研究和应用提供方法论支持。

Abstract: E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.

</details>


### [33] [Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding](https://arxiv.org/abs/2602.11737)
*Boqi Chen,Xudong Liu,Jianing Qiu*

Main category: cs.CV

TL;DR: 本文通过构建对象对齐的辅助视图改进视觉对比解码（VCD），以缓解多模态大语言模型中的对象幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在生成文本时容易产生对象幻觉，即生成图像中不存在的对象。现有方法如VCD虽有效，但仍有提升空间。

Method: 利用自监督视觉Transformer中的对象中心注意力机制，移除最显著的视觉证据以构建辅助视图，从而破坏无支持的生成token并增强对比信号。该方法无需修改提示或模型，可无缝集成到现有VCD流程中，仅需一次可缓存的前向传播。

Result: 在两个主流对象幻觉评测基准上，对两种MLLM进行了实验，结果表明该方法始终优于基线。

Conclusion: 所提方法是一种高效、通用且即插即用的策略，能有效缓解MLLM中的对象幻觉问题。

Abstract: We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.

</details>


### [34] [Code2Worlds: Empowering Coding LLMs for 4D World Generation](https://arxiv.org/abs/2602.11757)
*Yi Zhang,Yunshuang Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出Code2Worlds框架，通过语言到仿真代码的生成方式实现具有物理真实性的4D动态场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在4D动态场景生成中面临多尺度上下文纠缠和语义-物理执行鸿沟两大挑战，难以兼顾局部物体结构与全局环境布局，并常产生缺乏动态真实性的物理幻觉。

Method: 提出双流架构，将检索增强的物体生成与分层环境编排解耦；并引入物理感知的闭环机制，由PostProcess Agent编写动力学脚本，配合VLM-Motion Critic进行自反思以迭代优化仿真代码。

Result: 在Code4D基准上，Code2Worlds相比基线方法SGS提升41%，Richness提高49%，并首次实现了静态方法所不具备的物理感知动态生成。

Conclusion: Code2Worlds有效解决了4D场景生成中的关键挑战，为构建基于物理规律的世界模拟器提供了新路径。

Abstract: Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.

</details>


### [35] [Light4D: Training-Free Extreme Viewpoint 4D Video Relighting](https://arxiv.org/abs/2602.11769)
*Zhenghuang Wu,Kang Chen,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出Light4D，一种无需训练的4D重光照框架，通过解耦光流引导和时序一致性注意力机制，在极端视角变化下实现高质量、时序一致的4D视频重光照。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的重光照方法难以扩展到4D场景，主要受限于配对4D重光照训练数据稀缺以及时序一致性在极端视角下难以维持。

Method: 提出Light4D框架：1）引入解耦光流引导策略，在潜在空间中注入光照控制同时保持几何完整性；2）在IC-Light架构中设计时序一致性注意力机制，并加入确定性正则化以消除闪烁。

Result: 实验表明，该方法在时序一致性和光照保真度方面表现优异，可稳健处理-90°至90°的相机旋转。

Conclusion: Light4D在无需训练的前提下，有效解决了4D视频重光照中的视角变化与时序一致性难题，为动态场景光照编辑提供了新思路。

Abstract: Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.

</details>


### [36] [Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data](https://arxiv.org/abs/2602.11804)
*Yiming Zhou,Xuenjie Xie,Panfeng Li,Albrecht Kunz,Ahmad Osman,Xavier Maldague*

Main category: cs.CV

TL;DR: 本文提出一种轻量级RGB-D融合框架，在仅使用11.2k样本训练的情况下，通过引入单目深度先验显著提升分割精度，优于EfficientViT-SAM。


<details>
  <summary>Details</summary>
Motivation: 现有Segment Anything Model（SAM）虽性能强大，但依赖大规模RGB数据集（如11M图像），计算成本高；尽管已有高效变体降低计算开销，但仍需大量训练数据。因此，作者希望探索如何在极小训练样本下提升分割性能。

Method: 将预训练的单目深度估计器生成的深度图与RGB特征在中间层融合，通过专用深度编码器嵌入到EfficientViT-SAM中，构建轻量级RGB-D融合框架。

Result: 在仅使用11.2k训练样本（不到SA-1B数据集的0.1%）的情况下，该方法在分割准确率上优于EfficientViT-SAM。

Conclusion: 深度信息提供了强有力的几何先验，能显著增强通用分割模型的性能，即使在极低数据量下也能实现高效准确的分割。

Abstract: Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.

</details>


### [37] [How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?](https://arxiv.org/abs/2602.11810)
*Marko Putak,Thomas B. Moeslund,Joakim Bruslund Haurum*

Main category: cs.CV

TL;DR: 本文提出一种名为“定向智能过滤”（Targeted Smart Filtering）的新方法，用于高效生成多样化的3D分形视频，以用于动作识别模型的预训练，显著提升生成速度（约100倍）和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D分形生成方法速度慢且生成的分形退化，限制了其在预训练中的应用；同时，过于追求美学效果的生成策略会损害下游任务性能。

Method: 利用3D迭代函数系统（IFS）生成3D分形，并通过时间变换构建视频数据；提出“定向智能过滤”方法，在保证分形多样性的同时大幅提升采样速度。

Result: 所提方法比现有3D分形过滤方法快约100倍，并在动作识别下游任务中取得更优性能。

Conclusion: 为FDSL框架下的3D分形生成提供了一种高效且实用的解决方案，证明了在合成数据预训练中兼顾生成效率与任务相关多样性的重要性。

Abstract: Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.

</details>


### [38] [JEPA-VLA: Video Predictive Embedding is Needed for VLA Models](https://arxiv.org/abs/2602.11832)
*Shangchen Miao,Ningya Feng,Jialong Wu,Ye Lin,Xu He,Dong Li,Mingsheng Long*

Main category: cs.CV

TL;DR: 本文提出JEPA-VLA，通过引入基于视频预训练的预测性嵌入（如V-JEPA 2）来增强现有视觉-语言-动作（VLA）模型的环境理解与策略先验能力，显著提升样本效率和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型受限于视觉表征的不足，难以有效捕捉任务相关的环境信息和策略先验，导致样本效率低和泛化能力有限。

Method: 分析现有VLA中使用的视觉表征（如语言-图像对比学习或自监督学习）的缺陷，引入基于视频预训练的预测性嵌入V-JEPA 2，并将其自适应地融合到现有VLA架构中，形成JEPA-VLA方法。

Result: 在LIBERO、LIBERO-plus、RoboTwin2.0及真实机器人任务等多个基准上，JEPA-VLA均取得显著性能提升。

Conclusion: 利用视频预训练的预测性嵌入能有效弥补现有VLA视觉表征的不足，提升模型对任务相关动态的理解和策略生成能力，为未来高效、泛化的机器人操作提供新思路。

Abstract: Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.

</details>


### [39] [WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains](https://arxiv.org/abs/2602.11845)
*Qisen Wang,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 本文提出WorldTree框架，通过时序划分树（TPT）和空间祖先链（SAC）实现统一的时空分解，在单目动态重建任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有动态重建方法在单目输入下缺乏统一的时空分解框架，难以兼顾高效运动表示与分层优化。

Method: 提出WorldTree框架，包含基于继承结构的时序划分树（TPT）用于分层时序分解，以及递归查询祖先结构的空间祖先链（SAC）以提供互补的空间动态信息。

Result: 在NVIDIA-LS和DyCheck数据集上，LPIPS指标分别提升8.26%和9.09%，优于当前次优方法。

Conclusion: WorldTree通过统一的时空分解机制有效提升了单目动态重建的质量，为实际应用提供了更优解决方案。

Abstract: Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.

</details>


### [40] [Free Lunch for Stabilizing Rectified Flow Inversion](https://arxiv.org/abs/2602.11850)
*Chenru Wang,Beier Zhu,Chi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Proximal-Mean Inversion（PMI）的无训练梯度校正方法，结合轻量级的mimic-CFG速度校正策略，显著提升了Rectified-Flow模型在图像重建与编辑任务中的稳定性、质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于Rectified-Flow的反演方法存在时间步累积的近似误差，导致速度场不稳定，进而影响重建和编辑质量。

Method: 提出PMI方法，通过将速度场引导至历史速度的运行平均值（约束在理论推导的球形高斯内）来稳定反演过程；同时引入mimic-CFG，在编辑任务中对当前速度与其历史投影进行插值，以平衡编辑效果与结构一致性。

Result: 在PIE-Bench上的大量实验表明，所提方法显著提升了反演稳定性、图像重建质量和编辑保真度，并减少了神经函数调用次数。

Conclusion: 该方法在PIE-Bench上达到最先进的性能，兼具更高的效率和理论严谨性。

Abstract: Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.

</details>


### [41] [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858)
*Lai Wei,Liangbo He,Jun Lan,Lingzhong Dong,Yutong Cai,Siyuan Li,Huijia Zhu,Weiqiang Wang,Linghe Kong,Yue Wang,Zhuosheng Zhang,Weiran Huang*

Main category: cs.CV

TL;DR: 本文提出Region-to-Image Distillation方法，将“图像思考”中的迭代缩放机制从推理阶段移至训练阶段，通过蒸馏区域标注的监督信号，使小型多模态大语言模型在单次前向传播中即可实现细粒度感知能力，无需依赖推理时的工具调用。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在细粒度视觉理解任务中表现不佳，因为关键证据区域小且易被全局上下文淹没。虽然“Thinking-with-Images”方法通过迭代缩放提升性能，但带来高延迟。因此，作者希望在不牺牲效率的前提下，将这种能力内化到模型中。

Method: 提出Region-to-Image Distillation框架：首先对微裁剪区域使用强教师模型生成高质量VQA数据，再将这些区域级监督信号蒸馏回完整图像，用于训练学生模型。同时构建ZoomBench评测基准，包含845个涵盖六类细粒度感知维度的VQA样本，并设计双视图协议评估“缩放差距”。

Result: 所提方法在多个细粒度感知基准上取得领先性能，同时在视觉推理和GUI智能体等通用多模态任务上也有所提升，验证了蒸馏策略的有效性。

Conclusion: 通过将“Thinking-with-Images”的能力从推理阶段迁移到训练阶段，可在保持单次前向传播效率的同时显著提升MLLM的细粒度感知能力；论文还探讨了何时仍需显式使用推理时缩放，何时可完全依赖蒸馏。

Abstract: Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves "single-glance" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional "zooming gap". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when "Thinking-with-Images" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.

</details>


### [42] [DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition](https://arxiv.org/abs/2602.11875)
*Ji Li,Zhiwei Li,Shihao Li,Zhenjiang Yu,Boyang Wang,Haiou Liu*

Main category: cs.CV

TL;DR: 本文提出DiffPlace，一种支持地点可控的多视角图像生成框架，通过引入place-ID控制器，在保持背景建筑一致的同时灵活调整前景物体和天气条件，显著提升生成质量和对视觉地点识别任务的训练支持。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本、BEV地图和物体边界框的多视角扩散模型在生成具有地点感知和背景一致性的城市街景方面存在不足，难以满足视觉地点识别任务对真实样本的需求。

Method: 提出DiffPlace框架，其核心是place-ID控制器，该控制器利用线性投影、Perceiver Transformer和对比学习，将地点ID嵌入映射到固定的CLIP空间，从而控制生成图像的地点一致性。

Result: 大量实验表明，DiffPlace在生成质量和对视觉地点识别模型的增强训练效果上均优于现有方法。

Conclusion: DiffPlace展示了生成模型在场景级和地点感知合成方面的潜力，为提升自动驾驶中的地点识别能力提供了有效途径。

Abstract: Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving

</details>


### [43] [DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target](https://arxiv.org/abs/2602.11919)
*BoCheng Hu,Zhonghan Zhao,Kaiyue Zhou,Hongwei Wang,Gaoang Wang*

Main category: cs.CV

TL;DR: 本文提出了DynaHOI-Gym平台和DynaHOI-10M大规模基准数据集，用于评估手部与动态物体交互的运动生成，并引入了一个基于时空注意力的基线模型ObAct。


<details>
  <summary>Details</summary>
Motivation: 现有手-物交互（HOI）的手部运动生成基准主要关注静态物体，缺乏对动态目标和时间敏感协调场景的测试。

Method: 构建统一的在线闭环平台DynaHOI-Gym，包含参数化运动生成器和基于rollout的评估指标；在此基础上发布包含1000万帧、18万条轨迹的DynaHOI-10M基准数据集，并提出ObAct基线方法，通过时空注意力机制融合短期观察与当前帧信息进行动作预测。

Result: ObAct方法在位置成功率上提升了8.1%。

Conclusion: DynaHOI-Gym和DynaHOI-10M填补了动态手-物交互评估的空白，为未来研究提供了有效平台和基准。

Abstract: Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.

</details>


### [44] [Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation](https://arxiv.org/abs/2602.11942)
*Soufiane Ben Haddou,Laura Alvarez-Florez,Erik J. Bekkers,Fleur V. Y. Tjong,Ahmad S. Amin,Connie R. Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 提出一种结合隐式神经表示（INR）与去噪扩散模型的新框架，用于合成带有对应分割掩码的晚期钆增强（LGE）图像，以缓解标注数据稀缺问题，并在心肌纤维化分割任务中提升性能。


<details>
  <summary>Details</summary>
Motivation: 晚期钆增强（LGE）成像是心肌瘢痕评估的临床标准，但缺乏大量标注数据限制了自动化分割方法的发展。因此，需要一种无需额外标注即可生成高质量合成数据的方法来增强训练集。

Method: 首先使用隐式神经表示（INR）对LGE图像及其对应的心肌和纤维化掩码进行连续空间建模；然后将这些INR压缩为紧凑的潜在嵌入，在该潜在空间上训练去噪扩散模型以生成新的表示；最后将生成的表示解码为具有解剖一致性的合成LGE图像及对应分割掩码。

Result: 在133例心脏MRI扫描数据上的实验表明，加入200个合成体积可提升纤维化分割性能，Dice分数从0.509提高到0.524。

Conclusion: 所提方法提供了一种无需人工标注的数据增强策略，有助于缓解医学图像分析中的数据稀缺问题，并提升下游分割任务的性能。

Abstract: Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.

</details>


### [45] [Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion](https://arxiv.org/abs/2602.11960)
*Bruno Rigal,Victor Dupriez,Alexis Mignon,Ronan Le Hy,Nicolas Mery*

Main category: cs.CV

TL;DR: 本文评估了多种视觉语言模型（VLM）在具有挑战性的法语文档上进行PDF到Markdown转换的性能，提出了一种更关注下游任务需求的新型评估方法，并构建了一个以法语为主的困难页面基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析基准多聚焦于英语或中文，且常因对无害的格式差异（如换行、列表分段、表格呈现方式）过度惩罚而无法准确反映模型在下游RAG任务中的实际表现。为解决这一问题，作者构建了一个专注于法语、强调真实困难场景的评估基准。

Method: 作者从6万份法语文档中通过模型分歧采样选出困难页面，构建包含手写表单、复杂布局、密集表格和图文混排页面的基准。评估采用单元测试式检查（检测文本存在性、阅读顺序、局部表格约束）并结合类别特定的归一化策略，以忽略不影响下游任务的格式差异。

Result: 在15个模型上的实验表明，顶尖的闭源模型在处理手写和表单类文档时显著更鲁棒，而部分开源模型在标准印刷体布局上仍具竞争力。

Conclusion: 针对法语复杂文档的PDF解析需考虑下游任务的实际需求，采用更合理的评估方式；当前最强模型在处理非标准输入（如手写）方面优势明显，但开源模型在常规场景下仍有实用价值。

Abstract: This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.
  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.

</details>


### [46] [Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging](https://arxiv.org/abs/2602.11973)
*Hua Xu,Julián D. Arias-Londoño,Juan I. Godino-Llorente*

Main category: cs.CV

TL;DR: 本文提出一种基于贝叶斯深度学习的通用概率优化框架，通过引入置信-不确定性边界损失（CUB-Loss）和双重温度缩放（DTS）策略，提升医学影像AI模型的校准能力与不确定性估计可靠性。


<details>
  <summary>Details</summary>
Motivation: 在基于医学影像的关键决策支持系统中，AI模型不仅需要高预测准确性，还需具备可靠的不确定性量化能力，以避免对错误预测过度自信，从而增强临床医生对AI输出的信任与可审查性。

Method: 提出一种结合训练阶段与后处理阶段的校准方法：训练时使用新型CUB-Loss，惩罚高置信度错误和低置信度正确预测；推理后采用DTS策略进一步优化后验分布。

Result: 在肺炎筛查、糖尿病视网膜病变检测和皮肤病变识别三项任务上验证，该方法在多种模态、数据稀缺及类别严重不平衡场景下均表现出一致且稳健的校准性能提升。

Conclusion: 所提框架有效对齐了预测正确性与不确定性估计，具备良好的泛化能力和临床部署潜力。

Abstract: In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.

</details>


### [47] [Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation](https://arxiv.org/abs/2602.11980)
*Wei Chen,Yancheng Long,Mingqiao Liu,Haojie Ding,Yankai Yang,Hongyang Wei,Yi-Fan Zhang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出一种即插即用的空间思维链（SCoT）框架，将多模态大语言模型的空间推理能力与扩散模型的生成能力相结合，在图像生成和编辑任务中实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在美学图像合成方面表现出色，但在复杂空间理解和推理方面存在不足；现有方法要么计算成本高，要么依赖文本提示导致空间信息丢失。

Method: 首先通过交错的文本-坐标指令格式训练扩散模型以增强其布局感知能力，然后利用先进的多模态大语言模型作为规划器生成完整的布局计划，将空间规划能力直接迁移到生成过程中。

Result: 在图像生成基准上达到当前最优性能，在复杂推理任务中显著优于基线方法，并在图像编辑场景中也展现出强大效果。

Conclusion: 所提出的SCoT框架有效结合了多模态大语言模型的推理能力和扩散模型的生成能力，为提升生成模型的空间理解能力提供了高效且实用的解决方案。

Abstract: While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.

</details>


### [48] [Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation](https://arxiv.org/abs/2602.12002)
*Enrico Guerriero,Kjersti Engan,Øyvind Meinich-Bache*

Main category: cs.CV

TL;DR: 本文探索生成式AI方法（特别是结合局部视觉语言模型与大语言模型）在新生儿复苏视频中识别关键活动的潜力，并在微调后以LoRA方法显著优于传统TimeSformer模型。


<details>
  <summary>Details</summary>
Motivation: 新生儿复苏过程的准确记录对质量改进和遵循临床指南至关重要，但实践中仍不足；现有方法在细粒度活动识别上存在挑战，因此需探索更有效的AI技术。

Method: 使用局部视觉语言模型（VLM）结合大语言模型（LLM），在包含13.26小时模拟新生儿复苏视频的数据集上，评估多种零样本VLM策略及带分类头的微调VLM（包括LoRA方法），并与监督式TimeSformer基线进行比较。

Result: 微调后的局部VLM配合LoRA达到F1分数0.91，显著优于TimeSformer的0.70；但未微调的小型VLM易产生幻觉。

Conclusion: 生成式AI方法，尤其是经LoRA微调的局部VLM，在新生儿复苏活动识别任务中具有显著优势，有望提升临床文档记录的自动化水平。

Abstract: Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.

</details>


### [49] [Projected Representation Conditioning for High-fidelity Novel View Synthesis](https://arxiv.org/abs/2602.12003)
*Min-Seop Kwak,Minkyung Kwon,Jinhyeok Choi,Jiho Park,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReNoV的新型扩散模型框架，通过引入外部表征作为条件，提升新视角合成的几何一致性与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的新视角合成方法在几何一致性和稀疏输入下的鲁棒性方面存在不足，作者希望通过利用外部视觉表征的几何与语义对应特性来改善这些问题。

Method: 作者分析了外部视觉表征在空间注意力中涌现出的对应能力，并设计了专用的表征投影模块，将这些外部表征注入扩散过程中，实现表征引导的新视角合成（ReNoV）。

Result: 实验表明，ReNoV在重建保真度和图像补全质量上显著优于现有扩散模型方法，并能在稀疏、无姿态图像集合上实现稳健的新视角合成。

Conclusion: 引入外部表征作为扩散过程的引导信号，能有效提升新视角合成的几何一致性和整体生成性能，为该任务提供了一种高效可行的新范式。

Abstract: We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.

</details>


### [50] [A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments](https://arxiv.org/abs/2602.12044)
*Banglei Guan,Jing Tao,Liang Xu,Dongcai Tan,Pengju Sun,Jianbing Liu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出一种基于数字微镜器件（DMD）的高动态范围（HDR）成像系统，在强眩光环境下实现127 dB动态范围，显著提升数字图像相关（DIC）测量精度。


<details>
  <summary>Details</summary>
Motivation: 传统CCD/CMOS传感器动态范围不足（通常低于70 dB），在焊接电弧监测和高反光金属表面分析等强光照条件下易饱和，导致细节丢失和DIC测量误差。

Method: 系统结合DMD光学调制单元与自适应计算成像流程，通过空间调制实现区域自动分割与自适应曝光控制，以应对高动态范围场景。

Result: 系统实测动态范围达127 dB，有效消除强眩光下的饱和伪影，实验显示应变误差降低78%，DIC定位精度显著提升。

Conclusion: 该DMD基系统克服了传统传感器的关键局限，为高眩光环境下的光学计量与应力分析提供了高保真自适应HDR成像解决方案。

Abstract: Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.

</details>


### [51] [GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning](https://arxiv.org/abs/2602.12099)
*GigaBrain Team,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Hao Li,Jie Li,Jindi Lv,Jingyu Liu,Lv Feng,Mingming Yu,Peng Li,Qiuping Deng,Tianze Liu,Xinyu Zhou,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yifei Nie,Yilong Li,Yukun Zhou,Yun Ye,Zhichao Liu,Zheng Zhu*

Main category: cs.CV

TL;DR: 本文提出GigaBrain-0.5M*，一种基于世界模型强化学习的视觉-语言-动作（VLA）模型，通过RAMP方法显著提升跨任务适应能力与长视野执行成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在场景理解与未来预测方面存在局限，而视频世界模型具备强大的时空推理能力，因此作者希望利用预训练世界模型增强VLA学习。

Method: 在GigaBrain-0.5基础上，引入基于世界模型的强化学习框架RAMP（Reinforcement leArning via world Model-conditioned Policy），实现多任务鲁棒适应。

Result: RAMP相较RECAP基线在Laundry Folding、Box Packing和Espresso Preparation等任务上性能提升约30%，并在真实环境中实现无失败的长视野操作。

Conclusion: 结合世界模型的强化学习能有效提升VLA模型的泛化能力与复杂任务执行可靠性，GigaBrain-0.5M*在RoboChallenge基准中表现领先。

Abstract: Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\% on challenging tasks including \texttt{Laundry Folding}, \texttt{Box Packing}, and \texttt{Espresso Preparation}. Critically, \textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \href{https://gigabrain05m.github.io}{project page}.

</details>


### [52] [AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer](https://arxiv.org/abs/2602.12100)
*Lingting Zhu,Shengju Qian,Haidi Fan,Jiayu Dong,Zhenchao Jin,Siwei Zhou,Gen Dong,Xin Wang,Lequan Yu*

Main category: cs.CV

TL;DR: AssetFormer 是一个基于自回归 Transformer 的模型，可根据文本描述生成模块化 3D 资产，适用于专业开发和用户生成内容（UGC）场景。


<details>
  <summary>Details</summary>
Motivation: 数字产业对高质量、多样化的模块化 3D 资产有强烈需求，尤其在用户生成内容领域，现有方法难以满足设计约束与多样性要求。

Method: 提出 AssetFormer 模型，借鉴语言模型的模块序列化与解码技术，通过自回归方式建模，从真实世界收集的模块化资产数据中学习生成符合约束条件的 3D 资产。

Result: 初步实验表明 AssetFormer 能有效提升模块化 3D 资产的生成质量，并简化资产创建流程。

Conclusion: 该工作提供了一个可扩展的模块化 3D 资产生成框架，推动了 3D 内容生成领域的发展。

Abstract: The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.

</details>


### [53] [PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback](https://arxiv.org/abs/2602.12127)
*Sixiang Chen,Jianyu Lai,Jialin Gao,Hengyu Shi,Zhongying Liu,Tian Ye,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterOmni 是一个统一的图像到海报生成框架，通过结合局部编辑与全局创作，在多任务设置下显著提升生成海报的语义保真度、构图质量与美学一致性。


<details>
  <summary>Details</summary>
Motivation: 图像到海报生成需同时满足局部细节调整与高层设计理解，现有方法难以兼顾实体保留与概念驱动的创作需求，因此需要一个能整合两种机制的通用框架。

Method: PosterOmni 采用三阶段流程：(i) 构建涵盖六类任务的多场景图像-海报数据集；(ii) 在局部与全局专家模型间进行知识蒸馏以微调基础模型；(iii) 引入统一的 PosterOmni 奖励反馈机制，联合优化视觉实体保留与美学偏好。

Result: 实验表明，PosterOmni 在参考依从性、整体构图质量和美学协调性方面显著优于开源基线，甚至超越部分商用系统。

Conclusion: PosterOmni 成功将局部编辑与全局创作统一于单一框架内，为多任务图像到海报生成提供了高效且通用的解决方案，并通过 PosterOmni-Bench 推动该领域的系统评估。

Abstract: Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.

</details>


### [54] [FAIL: Flow Matching Adversarial Imitation Learning for Image Generation](https://arxiv.org/abs/2602.12155)
*Yeyao Ma,Chen Li,Xiaosong Zhang,Han Hu,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了一种名为 FAIL（Flow Matching Adversarial Imitation Learning）的新方法，通过对抗训练在无需显式奖励或成对比较的情况下对齐策略与专家行为，在图像和视频生成任务中表现优异，并可作为奖励优化中的正则化手段。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法如监督微调无法纠正未见状态下的策略漂移，而基于偏好的优化方法又依赖昂贵的偏好数据或奖励建模。因此，作者希望开发一种无需显式奖励或成对比较、又能有效对齐专家分布的后训练方法。

Method: 提出 FAIL 框架，通过对抗训练最小化策略与专家之间的分布差异。设计了两种算法：FAIL-PD 利用可微 ODE 求解器获得低方差路径梯度；FAIL-PG 为黑盒版本，适用于离散或计算受限场景。

Result: 仅使用 13,000 条 Nano Banana pro 的示范数据对 FLUX 模型进行微调，FAIL 在提示跟随和美学基准上达到有竞争力的性能，并成功泛化到离散图像与视频生成任务，同时能有效缓解奖励优化中的奖励黑客问题。

Conclusion: FAIL 提供了一种高效、通用且无需偏好标签的模仿学习方法，不仅适用于连续和离散生成任务，还能增强基于奖励优化的鲁棒性。

Abstract: Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.

</details>


### [55] [TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation](https://arxiv.org/abs/2602.12157)
*Ziteng Lu,Yushuang Wu,Chongjie Ye,Yuda Qiu,Jing Shao,Xiaoyang Guo,Jiaqing Zhou,Tianlei Hu,Kun Zhou,Xiaoguang Han*

Main category: cs.CV

TL;DR: 本文提出TexSpot，一种基于扩散模型的3D纹理增强框架，通过引入新型纹理表示Texlet，在保持几何一致性和高分辨率的同时显著提升纹理质量。


<details>
  <summary>Details</summary>
Motivation: 当前主流的多视角扩散流程在3D纹理生成中存在视角不一致性问题；现有方法如UV映射易产生扭曲，而基于点的方法则受限于几何密度，难以生成高分辨率纹理。

Method: 提出Texlet表示：结合点基3D纹理的几何表达能力与UV表示的紧凑性。每个Texlet潜变量通过2D编码器编码局部纹理块，并由3D编码器聚合以融入全局形状上下文；再通过级联的3D-to-2D解码器重建高质量纹理块。在此基础上，训练一个以Texlet为条件的扩散Transformer，用于增强多视角扩散方法生成的纹理。

Result: 实验表明，TexSpot在视觉保真度、几何一致性和鲁棒性方面均优于当前最先进的3D纹理生成与增强方法。

Conclusion: TexSpot通过引入Texlet这一新表示和扩散增强机制，有效解决了现有3D纹理生成方法中的关键局限，显著提升了生成质量。

Abstract: High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.

</details>


### [56] [DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation](https://arxiv.org/abs/2602.12160)
*Xu Guo,Fulong Ye,Qichao Sun,Liyang Chen,Bingchuan Li,Pengze Zhang,Jiawei Liu,Songtao Zhao,Qian He,Xiangwang Hou*

Main category: cs.CV

TL;DR: 本文提出DreamID-Omni，一个统一框架用于可控的人类中心音视频生成，在多个任务和指标上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将参考音频视频生成、视频编辑和音频驱动动画等任务孤立处理，且难以在单个框架中实现对多角色身份与声音音色的精准解耦控制。

Method: 提出DreamID-Omni框架，包含：1）对称条件扩散Transformer，通过同步条件注入整合异构条件信号；2）双层级解耦策略（信号层的同步RoPE和语义层的结构化字幕）；3）多任务渐进训练方案，利用弱约束先验正则化强约束任务。

Result: 实验表明DreamID-Omni在视频质量、音频质量和音视频一致性方面均优于现有方法，甚至超越主流商业模型。

Conclusion: DreamID-Omni为人类中心音视频生成提供了一个统一、可控且高性能的解决方案，作者将开源代码以促进学术与工业应用的结合。

Abstract: Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.

</details>


### [57] [DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing](https://arxiv.org/abs/2602.12205)
*Dianyi Wang,Ruihang Li,Feng Han,Chaofan Ma,Wei Song,Siyuan Wang,Yibin Wang,Yi Xin,Hongjian Liu,Zhixiong Zhang,Shengyuan Ding,Tianhang Wang,Zhenglin Cheng,Tao Lin,Cheng Jin,Kaicheng Yu,Jingjing Chen,Wenjie Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出DeepGen 1.0，一个仅5B参数的轻量级统一多模态模型，在图像生成与编辑任务上性能超越多个超大规模模型（如80B的HunyuanImage和27B的Qwen-Image-Edit），并通过开源代码、权重和数据集推动高效多模态研究。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态图像生成与编辑模型通常依赖超大规模参数（>10B），导致训练成本高、部署困难。作者旨在构建一个轻量但能力全面的替代方案，降低资源门槛并提升可及性。

Method: 提出Stacked Channel Bridging（SCB）框架，从多层视觉语言模型（VLM）中提取分层特征，并与可学习的“think tokens”融合，为生成主干提供结构化、富含推理的引导；同时设计三阶段数据驱动训练策略：对齐预训练、联合监督微调、基于MR-GRPO的强化学习。

Result: DeepGen 1.0在仅使用约50M样本训练的情况下，在WISE基准上超越80B的HunyuanImage达28%，在UniREditBench上超越27B的Qwen-Image-Edit达37%，并在多项任务中展现领先性能。

Conclusion: 通过轻量架构、创新对齐机制与高效训练策略，DeepGen 1.0证明小模型也能实现卓越的多模态生成与编辑能力，为社区提供了高性能、低门槛的开源解决方案。

Abstract: Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.

</details>


### [58] [Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching](https://arxiv.org/abs/2602.12221)
*Onkar Susladkar,Tushar Prakash,Gayatri Deshmukh,Kiet A. Nguyen,Jiaxun Zhang,Adheesh Juvekar,Tianshu Bao,Lin Chai,Sparsh Mittal,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: UniDFlow 是一个统一的离散流匹配框架，支持多模态理解、生成与编辑，在无需大规模重训练的情况下实现多项任务的 SOTA 性能和强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态任务中常因目标冲突和表征纠缠而受限，难以同时实现高质量的理解、生成与可控编辑。

Method: 通过任务特定的低秩适配器解耦理解与生成，并引入基于参考的多模态偏好对齐机制，在相同条件下优化相对输出结果。

Result: 在八个基准上达到最先进性能，并在未显式训练的情况下展现出对图像修复、上下文图像生成、参考编辑和组合生成等任务的强大零样本泛化能力。

Conclusion: UniDFlow 有效解决了多模态任务中的目标干扰与表征纠缠问题，显著提升了生成的忠实度与可控性，且具备良好的任务扩展性。

Abstract: We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.

</details>


### [59] [MonarchRT: Efficient Attention for Real-Time Video Generation](https://arxiv.org/abs/2602.12271)
*Krish Agarwal,Zhuoming Chen,Cheng Luo,Yongqi Chen,Haizhong Zheng,Xun Huang,Atri Rudra,Beidi Chen*

Main category: cs.CV

TL;DR: 本文提出Monarch-RT，一种用于实时视频生成的结构化注意力机制，通过Monarch矩阵分解注意力，在保持高表达能力的同时显著提升计算效率，首次实现单卡16 FPS的实时视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法在少步、自回归的实时视频扩散模型中失效，因为视频注意力兼具周期性结构、动态稀疏语义对应和稠密混合，超出传统稀疏近似（如top-k）的表示能力。

Method: 提出Monarch-RT，利用Monarch矩阵对注意力进行结构化分解，结合对齐的块结构与扩展的分块参数化，并通过定制Triton内核和微调策略降低参数化开销。

Result: Monarch-RT在SOTA模型Self-Forcing上实现高达95%的注意力稀疏度且无质量损失；在RTX 5090、H100和B200 GPU上分别超越FlashAttention-2/3/4，内核加速达1.4–11.8倍，首次在单张RTX 5090上实现16 FPS的实时视频生成。

Conclusion: Monarch-RT是首个适用于实时视频生成的高效高容量稀疏注意力参数化方法，解决了现有稀疏注意力在自回归少步场景下的失效问题，为实时视频扩散模型提供了实用解决方案。

Abstract: Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.

</details>


### [60] [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/abs/2602.12279)
*Leon Liangyu Chen,Haoyu Ma,Zhipeng Fan,Ziqi Huang,Animesh Sinha,Xiaoliang Dai,Jialiang Wang,Zecheng He,Jianwei Yang,Chunyuan Li,Junzhe Sun,Chu Wang,Serena Yeung-Levy,Felix Juefei-Xu*

Main category: cs.CV

TL;DR: 本文提出UniT框架，将测试时缩放（TTS）引入统一多模态模型，通过多轮推理、验证与修正提升复杂多模态任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型通常单次前向推理，缺乏迭代优化能力，难以应对涉及空间结构、多对象交互或动态指令的复杂任务；而语言模型中的测试时缩放（TTS）已证明可通过增加推理计算提升性能，但尚未有效扩展至统一多模态模型。

Method: UniT框架结合智能体数据合成、统一模型训练和灵活的测试时推理机制，支持多轮链式思维推理，实现验证、子目标分解和内容记忆等认知行为。

Result: 实验表明：(1) 在短推理轨迹上训练的统一模型可泛化至测试时更长的推理链；(2) 串行链式推理比并行采样更高效且可扩展；(3) 融合生成与编辑轨迹的训练提升分布外视觉推理能力。

Conclusion: 多模态测试时缩放是提升统一模型在理解和生成任务上性能的有效范式。

Abstract: Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.

</details>


### [61] [Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching](https://arxiv.org/abs/2602.12280)
*Huai-Hsun Cheng,Siang-Ling Zhang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“渐进语义幻觉”的新任务，通过在单个矢量草图中逐步添加笔画，使其在不同绘制阶段呈现出截然不同的语义（如从鸭子变为绵羊），并提出了名为“Stroke of Surprise”的生成框架来实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 传统视觉幻觉依赖于空间操作（如多视角一致性），而本文旨在将视觉幻觉从空间维度拓展到时间维度，探索如何通过逐步添加笔画使同一草图在不同阶段表达不同语义，从而创造新型的语义幻觉。

Method: 提出一种序列感知的联合优化框架，采用双分支Score Distillation Sampling（SDS）机制，在优化过程中动态调整前缀笔画，以寻找两个目标概念共享的“公共结构子空间”；同时引入Overlay Loss，确保新增笔画与原始结构互补而非遮挡。

Result: 实验表明，该方法在识别度和幻觉强度方面显著优于现有最先进方法，成功实现了从鸭子到绵羊等跨语义的渐进式矢量草图幻觉。

Conclusion: 本研究成功将视觉字谜（visual anagrams）的概念从空间维度扩展到时间维度，为矢量草图生成和视觉幻觉领域提供了新的思路和有效方法。

Abstract: Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the "dual-constraint": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a "common structural subspace" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [62] [Counterfactual Conditional Likelihood Rewards for Multiagent Exploration](https://arxiv.org/abs/2602.11740)
*Ayhan Alp Aydeniz,Robert Loftin,Kagan Tumer*

Main category: cs.MA

TL;DR: 本文提出了一种名为反事实条件似然（CCL）的奖励机制，通过衡量每个智能体对团队探索的独特贡献，提升多智能体系统在稀疏奖励和高协同需求任务中的探索效率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，仅鼓励个体探索容易导致冗余行为，因为智能体缺乏对队友探索状态的感知。因此，需要一种能促进协同探索的机制，以提升在开放性任务（如搜救、行星勘测）中的策略发现效率。

Method: 作者提出CCL奖励机制，该机制通过反事实分析，评估每个智能体所获取观测对团队整体探索的独特信息量，而非仅基于个体观测的新颖性进行奖励。

Result: 在连续多智能体环境中的实验表明，CCL奖励在团队奖励稀疏（大多数联合动作无奖励）的任务中显著加速学习过程，并在需要高度协同的任务中表现尤为突出。

Conclusion: CCL奖励通过强调个体对团队探索的独特贡献，有效缓解了多智能体探索中的冗余问题，提升了协同策略的学习效率，尤其适用于稀疏奖励和强协同场景。

Abstract: Efficient exploration is critical for multiagent systems to discover coordinated strategies, particularly in open-ended domains such as search and rescue or planetary surveying. However, when exploration is encouraged only at the individual agent level, it often leads to redundancy, as agents act without awareness of how their teammates are exploring. In this work, we introduce Counterfactual Conditional Likelihood (CCL) rewards, which score each agent's exploration by isolating its unique contribution to team exploration. Unlike prior methods that reward agents solely for the novelty of their individual observations, CCL emphasizes observations that are informative with respect to the joint exploration of the team. Experiments in continuous multiagent domains show that CCL rewards accelerate learning for domains with sparse team rewards, where most joint actions yield zero rewards, and are particularly effective in tasks that require tight coordination among agents.

</details>


### [63] [Cooperation Breakdown in LLM Agents Under Communication Delays](https://arxiv.org/abs/2602.11754)
*Keita Nishimoto,Kimitaka Asatani,Ichiro Sakata*

Main category: cs.MA

TL;DR: 本文提出FLCOA框架，强调在基于大语言模型的多智能体系统中，底层因素（如通信延迟和计算资源）对合作与协调具有重要影响，并通过带通信延迟的连续囚徒困境实验揭示了延迟与合作之间的U型关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注多智能体系统中的高层制度设计，忽视了现实世界中计算与通信约束等底层因素对智能体合作行为的影响。为推动LLM-MAS在真实场景中的部署，需系统理解这些底层因素如何影响协作。

Method: 作者提出了FLCOA五层框架用于分析自主智能体间的合作机制，并设计了一个包含通信延迟的连续囚徒困境实验，利用基于LLM的智能体进行模拟，观察不同延迟条件下合作行为的变化。

Result: 实验发现，随着通信延迟增加，智能体会自发利用对方响应慢的特点进行剥削；但当延迟过大时，剥削循环减少，合作水平反而回升，呈现出延迟与合作之间的U型关系。

Conclusion: 促进多智能体系统中的合作不仅需要高层制度设计，还需重视通信延迟、资源分配等底层因素，这为未来MAS研究提供了新方向。

Abstract: LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research.

</details>


### [64] [Multi-Defender Single-Attacker Perimeter Defense Game on a Cylinder: Special Case in which the Attacker Starts at the Boundary](https://arxiv.org/abs/2602.11977)
*Michael Otte,Roderich Groß*

Main category: cs.MA

TL;DR: 本文研究了在圆柱面上进行的多智能体周界防御博弈，分析了当单个高速攻击者从靠近防御边界且已被防守的区域出发时，其获胜所需的条件。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体协同防御系统在特定几何空间（圆柱面）中对抗高速入侵者的策略与可行性，尤其关注攻击者初始位置靠近防御边界时的胜负条件。

Method: 通过建立多智能体周界防御博弈模型，在圆柱面上分析n个低速防御者与单个高速攻击者之间的动态交互，并推导攻击者获胜的必要条件。

Result: 得出了在攻击者起始位置靠近防御边界且处于已防守区域时，其能够成功突破防御的条件。

Conclusion: 该研究为理解多智能体防御系统在受限几何环境中的性能极限提供了理论基础，并揭示了攻击者在特定初始条件下可能突破防御的关键因素。

Abstract: We describe a multi-agent perimeter defense game played on a cylinder. A team of n slow-moving defenders must prevent a single fast-moving attacker from crossing the boundary of a defensive perimeter. We describe the conditions necessary for the attacker to win in the special case that the intruder starts close to the boundary and in a region that is currently defended.

</details>


### [65] [DEpiABS: Differentiable Epidemic Agent-Based Simulator](https://arxiv.org/abs/2602.12102)
*Zhijian Gao,Shuxin Li,Bo An*

Main category: cs.MA

TL;DR: DEpiABS 是一种可扩展、可微分的基于智能体的流行病模型，兼顾机制细节、计算效率与可解释性，在 COVID-19 和流感数据上优于基线模型，且无需辅助数据。


<details>
  <summary>Details</summary>
Motivation: 现有流行病模拟工具难以在保持计算可行性和可解释性的同时捕捉复杂动态，尤其在指导非药物干预（NPIs）方面存在局限。

Method: 提出 DEpiABS 模型，整合个体层面的健康状态、行为和资源约束异质性，并建模病毒突变与再感染等过程；模型完全可微，支持快速仿真与梯度参数校准；引入基于 z 分数的缩放方法，将小规模模拟映射至任意真实人口规模。

Result: 在十个不同规模地区的 COVID-19 与流感数据上验证，DEpiABS 在不依赖辅助数据的情况下，将 COVID-19 死亡率预测的平均标准偏差从 0.97 降至 0.92，流感样疾病预测从 0.41 降至 0.32。

Conclusion: DEpiABS 是一个可靠、通用且数据高效的流行病建模框架，适用于未来疫情响应。

Abstract: The COVID-19 pandemic highlighted the limitations of existing epidemic simulation tools. These tools provide information that guides non-pharmaceutical interventions (NPIs), yet many struggle to capture complex dynamics while remaining computationally practical and interpretable. We introduce DEpiABS, a scalable, differentiable agent-based model (DABM) that balances mechanistic detail, computational efficiency and interpretability. DEpiABS captures individual-level heterogeneity in health status, behaviour, and resource constraints, while also modelling epidemic processes like viral mutation and reinfection dynamics. The model is fully differentiable, enabling fast simulation and gradient-based parameter calibration. Building on this foundation, we introduce a z-score-based scaling method that maps small-scale simulations to any real-world population sizes with negligible loss in output granularity, reducing the computational burden when modelling large populations. We validate DEpiABS through sensitivity analysis and calibration to COVID-19 and flu data from ten regions of varying scales. Compared to the baseline, DEpiABS is more detailed, fully interpretable, and has reduced the average normal deviation in forecasting from 0.97 to 0.92 on COVID-19 mortality data and from 0.41 to 0.32 on influenza-like-illness data. Critically, these improvements are achieved without relying on auxiliary data, making DEpiABS a reliable, generalisable, and data-efficient framework for future epidemic response modelling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [66] [Explaining AI Without Code: A User Study on Explainable AI](https://arxiv.org/abs/2602.11159)
*Natalia Abarca,Andrés Carvallo,Claudia López Moncada,Felipe Bravo-Marquez*

Main category: cs.AI

TL;DR: 本文在开源无代码机器学习平台 DashAI 中集成了一种面向用户的人性化可解释 AI（XAI）模块，结合 PDP、PFI 和 KernelSHAP 三种技术，通过用户研究验证其对新手和专家的可用性与信任影响。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗、金融等敏感领域的广泛应用，模型决策透明性变得至关重要。然而现有可解释 AI 方法通常需要专业技术，难以服务于无代码平台中的非专业用户，因此亟需一种兼顾易用性与解释深度的解决方案。

Method: 在 DashAI 平台中集成 Partial Dependence Plots（PDP）、Permutation Feature Importance（PFI）和 KernelSHAP 三种互补的可解释性技术，并通过包含 20 名参与者（含新手与专家）的用户研究评估其可用性及解释效果。

Result: 研究结果显示：(i) 所有可解释任务的成功率均 ≥80%；(ii) 新手在解释满意度量表（ESS）上给予高分，而专家更关注解释的充分性与完整性；(iii) 解释提升了用户对系统可预测性与信心的感知（TiA 量表），且新手的信任度高于专家。

Conclusion: 该工作揭示了无代码机器学习中 XAI 的核心挑战：如何在保证对新手友好性的同时，为专家提供足够详尽的信息，从而实现真正民主化的可解释 AI。

Abstract: The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying how models generate predictions, yet most methods demand technical expertise, limiting their value for novices. This gap is especially critical in no-code ML platforms, which seek to democratize AI but rarely include explainability. We present a human-centered XAI module in DashAI, an open-source no-code ML platform. The module integrates three complementary techniques, which are Partial Dependence Plots (PDP), Permutation Feature Importance (PFI), and KernelSHAP, into DashAI's workflow for tabular classification. A user study (N = 20; ML novices and experts) evaluated usability and the impact of explanations. Results show: (i) high task success ($\geq80\%$) across all explainability tasks; (ii) novices rated explanations as useful, accurate, and trustworthy on the Explanation Satisfaction Scale (ESS, Cronbach's $α$ = 0.74, a measure of internal consistency), while experts were more critical of sufficiency and completeness; and (iii) explanations improved perceived predictability and confidence on the Trust in Automation scale (TiA, $α$ = 0.60), with novices showing higher trust than experts. These findings highlight a central challenge for XAI in no-code ML, making explanations both accessible to novices and sufficiently detailed for experts.

</details>


### [67] [Latent Generative Solvers for Generalizable Long-Term Physics Simulation](https://arxiv.org/abs/2602.11229)
*Zituo Chen,Haixu Wu,Sili Deng*

Main category: cs.AI

TL;DR: 本文提出Latent Generative Solvers（LGS），一种用于跨异构偏微分方程（PDE）系统的长期替代模拟的两阶段框架，通过在共享潜在物理空间中建模并引入不确定性控制机制，显著提升长期预测稳定性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法在长期PDE模拟中易出现轨迹漂移且计算成本高，缺乏对不确定性的建模能力，难以泛化到分布外或高分辨率场景。

Method: LGS包含两个阶段：(i) 使用预训练VAE将不同PDE状态映射到共享潜在空间；(ii) 采用基于流匹配训练的Transformer学习潜在空间中的概率动力学。引入“不确定性旋钮”扰动潜在输入以校正轨迹漂移，并通过流强制（flow forcing）更新系统描述符以对齐训练与测试条件。

Result: 在包含约250万条轨迹、涵盖12类PDE的预训练数据集上，LGS在短期预测上媲美强基线，长期预测中显著减少漂移，FLOPs降低高达70倍，并能高效迁移到256²分辨率的Kolmogorov流数据集。

Conclusion: LGS为构建可泛化、具备不确定性感知能力的神经PDE求解器提供了实用路径，在长期预测和科学计算下游任务中更具可靠性与可扩展性。

Abstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \textbf{70$\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.

</details>


### [68] [Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization](https://arxiv.org/abs/2602.11437)
*Chengrui Qu,Christopher Yeh,Kishan Panaganti,Eric Mazumdar,Adam Wierman*

Main category: cs.AI

TL;DR: 本文提出Distributionally robust IGM（DrIGM）原则，通过定义鲁棒的个体动作价值函数，在保持去中心化执行的同时提升多智能体强化学习在分布外环境中的鲁棒性，并基于此构建了兼容现有架构（如VDN/QMIX/QTRAN）的鲁棒变体。


<details>
  <summary>Details</summary>
Motivation: 现实世界中存在环境不确定性（如仿真到现实的差距、模型不匹配和系统噪声），使得现有基于IGM原则的值分解方法在实际应用中可靠性不足。

Method: 提出DrIGM原则，定义新的鲁棒个体动作价值函数，确保每个智能体的鲁棒贪心动作与团队整体的鲁棒最优联合动作一致；并据此构建兼容现有值分解架构的鲁棒训练方法，使用鲁棒Q目标进行训练，无需定制奖励设计。

Result: 在SustainGym高保真模拟器和StarCraft游戏环境中，所提方法在分布外场景下表现一致优于基线方法。

Conclusion: DrIGM为多智能体强化学习提供了一种理论上有保证且实践上易部署的鲁棒性增强方案，有效提升了算法在不确定环境下的泛化能力。

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized greedy actions recover the team-optimal joint action. However, the reliability of this recipe in real-world settings remains unreliable due to environmental uncertainties arising from the sim-to-real gap, model mismatch, and system noise. We address this gap by introducing Distributionally robust IGM (DrIGM), a principle that requires each agent's robust greedy action to align with the robust team-optimal joint action. We show that DrIGM holds for a novel definition of robust individual action values, which is compatible with decentralized greedy execution and yields a provable robustness guarantee for the whole system. Building on this foundation, we derive DrIGM-compliant robust variants of existing value-factorization architectures (e.g., VDN/QMIX/QTRAN) that (i) train on robust Q-targets, (ii) preserve scalability, and (iii) integrate seamlessly with existing codebases without bespoke per-agent reward shaping. Empirically, on high-fidelity SustainGym simulators and a StarCraft game environment, our methods consistently improve out-of-distribution performance. Code and data are available at https://github.com/crqu/robust-coMARL.

</details>


### [69] [On Decision-Valued Maps and Representational Dependence](https://arxiv.org/abs/2602.11295)
*Gil Raitses*

Main category: cs.AI

TL;DR: 本文提出决策值映射（decision-valued maps）的概念，并构建DecisionDB系统，用于记录、重放和审计不同数据表示对计算结果的影响。


<details>
  <summary>Details</summary>
Motivation: 同一数据的不同表示形式可能导致计算引擎产生不同的离散结果，有必要系统化地追踪哪些表示保留结果、哪些改变结果。

Method: 形式化定义决策值映射，并通过DecisionDB基础设施以一次性写入方式存储内容标识符与工件，实现确定性重放与审计。

Result: 系统能精确复现已记录的决策标识符，三个识别字段均与持久化值一致，并将表示空间划分为持久化区域与边界。

Conclusion: 决策重用可视为一种可机械验证的条件，为数据表示与计算结果之间的关系提供了可审计、可复现的框架。

Abstract: A computational engine applied to different representations of the same data can produce different discrete outcomes, with some representations preserving the result and others changing it entirely. A decision-valued map records which representations preserve the outcome and which change it, associating each member of a declared representation family with the discrete result it produces. This paper formalizes decision-valued maps and describes DecisionDB, an infrastructure that logs, replays and audits these relationships using identifiers computed from content and artifacts stored in write-once form. Deterministic replay recovers each recorded decision identifier exactly from stored artifacts, with all three identifying fields matching their persisted values. The contribution partitions representation space into persistence regions and boundaries, and treats decision reuse as a mechanically checkable condition.

</details>


### [70] [Multi UAVs Preflight Planning in a Shared and Dynamic Airspace](https://arxiv.org/abs/2602.12055)
*Amath Sow,Mauricio Rodriguez Cesen,Fabiola Martins Campos de Oliveira,Mariusz Wzorek,Daniel de Leng,Mattias Tiger,Fredrik Heintz,Christian Esteve Rothenberg*

Main category: cs.AI

TL;DR: 提出DTAPP-IICR方法，用于大规模无人机机队在动态共享空域中的预飞行规划，通过优先级规划与迭代冲突消解，在含时变禁飞区的城市环境中实现高效、可扩展的路径规划。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF方法在真实城市无人机交通管理（UTM）场景中难以兼顾可扩展性与灵活性，尤其面对时变禁飞区、异构无人机和严格交付时限等挑战。

Method: 提出DTAPP-IICR框架：首先基于任务紧急程度进行优先级排序生成初始解；其次利用新提出的4D单智能体规划器SFIPP-ST计算往返轨迹，该规划器支持异构无人机、强制执行时变禁飞区，并将智能体间冲突建模为软约束；随后通过基于几何冲突图的迭代大邻域搜索消解残余冲突，并引入保完备性的方向剪枝技术加速3D搜索。

Result: 在含时变禁飞区的基准测试中，DTAPP-IICR在多达1000架无人机的机队中实现近100%任务成功率，剪枝技术带来最高50%的运行时间减少，优于批量增强型冲突基搜索方法，并在其他优先级方法失效的中等规模部署下仍能成功扩展至真实城市尺度。

Conclusion: DTAPP-IICR是一种实用且可扩展的预飞行规划方案，适用于高密度、动态变化的城市空域环境。

Abstract: Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.

</details>


### [71] [Voxtral Realtime](https://arxiv.org/abs/2602.11298)
*Alexander H. Liu,Andy Ehrenberg,Andy Lo,Chen-Yo Sun,Guillaume Lample,Jean-Malo Delignon,Khyathi Raghavi Chandu,Patrick von Platen,Pavankumar Reddy Muddireddy,Rohin Arora,Sanchit Gandhi,Sandeep Subramanian,Soham Ghosh,Srijan Mishra,Abhinav Rastogi,Alan Jeffares,Albert Jiang,Alexandre Sablayrolles,Amélie Héliou,Andrew Bai,Angele Lenglemetz,Anmol Agarwal,Anton Eliseev,Antonia Calvi,Arjun Majumdar,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Benjamin Tibi,Clémence Lanfranchi,Connor Chen,Corentin Barreau,Corentin Sautier,Cyprien Courtot,Darius Dabert,Diego de las Casas,Elliot Chane-Sane,Enguerrand Paquin,Faruk Ahmed,Federico Baldassarre,Gabrielle Berrada,Gaëtan Ecrepont,Gauthier Guinet,Genevieve Hayes,Georgii Novikov,Giada Pistilli,Guillaume Martin,Gunjan Dhanuka,Gunshi Gupta,Han Zhou,Indraneel Mukherjee,Irene Zhang,Jaeyoung Kim,Jan Ludziejewski,Jason Rute,Joachim Studnia,John Harvill,Jonas Amar,Josselin Somerville Roberts,Julien Tauran,Karmesh Yadav,Kartik Khandelwal,Kush Jain,Laurence Aitchison,Léonard Blier,Lingxiao Zhao,Louis Martin,Lucile Saulnier,Luyu Gao,Maarten Buyl,Manan Sharma,Margaret Jennings,Marie Pellat,Mark Prins,Mathieu Poirée,Mathilde Guillaumin,Matthieu Dinot,Matthieu Futeral,Maxime Darrin,Maximilian Augustin,Mert Unsal,Mia Chiquier,Nathan Grinsztajn,Neha Gupta,Olivier Bousquet,Olivier Duchenne,Patricia Wang,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Philomène Chagniot,Pierre Stock,Piotr Miłoś,Prateek Gupta,Pravesh Agrawal,Quentin Torroba,Ram Ramrakhya,Rishi Shah,Romain Sauvestre,Roman Soletskyi,Rosalie Millner,Sagar Vaze,Samuel Humeau,Siddharth Gandhi,Sumukh Aithal,Szymon Antoniak,Teven Le Scao,Théo Cachet,Theo Simon Sorg,Thibaut Lavril,Thomas Chabal,Thomas Foubert,Thomas Robert,Thomas Wang,Tim Lawson,Tom Bewley,Tom Edwards,Tyler Wang,Valeriia Nemychnikova,Van Phung,Vedant Nanda,Victor Jouault,Virgile Richard,Vladislav Bataev,Wassim Bouaziz,Wen-Ding Li,William Marshall,Xinghui Li,Xingran Guo,Xinyu Yang,Yannic Neuhaus,Yihan Wang,Zaccharie Ramzi,Zhenlin Xu*

Main category: cs.AI

TL;DR: Voxtral Realtime 是一种原生流式语音识别模型，在480毫秒延迟下达到与离线模型Whisper相当的转录质量，并以Apache 2.0许可证开源。


<details>
  <summary>Details</summary>
Motivation: 现有流式ASR方法多通过分块或滑动窗口改造离线模型，难以兼顾低延迟与高精度；作者旨在设计一个端到端训练、原生支持流式输入且能匹配离线模型性能的系统。

Method: 基于Delayed Streams Modeling框架，引入新型因果音频编码器和Ada RMS-Norm机制，实现音频与文本流的显式对齐；在涵盖13种语言的大规模数据集上进行预训练。

Result: 在480ms延迟条件下，Voxtral Realtime 的转录性能与当前主流离线模型Whisper相当。

Conclusion: Voxtral Realtime 成功实现了低延迟与高精度的平衡，为实时语音识别提供了高效解决方案，并已开源促进社区发展。

Abstract: We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.

</details>


### [72] [The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates](https://arxiv.org/abs/2602.11301)
*John M. Willis*

Main category: cs.AI

TL;DR: 本文提出了一种名为“安全AI实践者蓝图”（PBSAI）的多智能体参考架构，用于保障企业级和超大规模AI系统的安全，填补了现有治理框架在可实施架构方面的空白。


<details>
  <summary>Details</summary>
Motivation: 随着企业广泛部署大语言模型、检索增强生成系统和工具调用智能体，形成了复杂的“AI资产”生态系统，但当前的安全与治理框架缺乏针对此类多智能体AI系统的可落地架构。

Method: 作者设计了PBSAI治理生态系统，包含十二个责任领域、边界明确的智能体家族、共享上下文信封和结构化输出契约，并结合轻量级形式化模型确保可追溯性、来源性和人在环路保障。

Result: 该架构与NIST AI风险管理框架（RMF）功能对齐，并在企业安全运营中心（SOC）和超大规模防御环境中展示了实际应用潜力。

Conclusion: PBSAI为构建开放、可验证的AI安全治理体系提供了结构化、以证据为中心的基础，支持未来生态发展和实证研究。

Abstract: Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and security frameworks, including the NIST AI Risk Management Framework and systems security engineering guidance, articulate principles and risk functions but do not provide implementable architectures for multi agent, AI enabled cyber defense.
  This paper introduces the Practitioners Blueprint for Secure AI (PBSAI) Governance Ecosystem, a multi agent reference architecture for securing enterprise and hyperscale AI estates. PBSAI organizes responsibilities into a twelve domain taxonomy and defines bounded agent families that mediate between tools and policy through shared context envelopes and structured output contracts. The architecture assumes baseline enterprise security capabilities and encodes key systems security techniques, including analytic monitoring, coordinated defense, and adaptive response. A lightweight formal model of agents, context envelopes, and ecosystem level invariants clarifies the traceability, provenance, and human in the loop guarantees enforced across domains. We demonstrate alignment with NIST AI RMF functions and illustrate application in enterprise SOC and hyperscale defensive environments. PBSAI is proposed as a structured, evidence centric foundation for open ecosystem development and future empirical validation.

</details>


### [73] [Dissecting Subjectivity and the "Ground Truth" Illusion in Data Annotation](https://arxiv.org/abs/2602.11318)
*Sheza Munir,Benjamin Mah,Krisha Kalsi,Shivani Kapania,Julian Posada,Edith Law,Ding Wang,Syed Ishtiaque Ahmed*

Main category: cs.AI

TL;DR: 该论文批判了机器学习中将人类标注分歧视为“噪声”的“共识陷阱”，主张将分歧视为反映文化多样性的高保真信号，并提出构建多元标注基础设施的路线图。


<details>
  <summary>Details</summary>
Motivation: 揭示当前机器学习依赖“ground truth”范式所隐含的实证主义谬误，即忽视人类在标注中的合理分歧，将其错误地归为技术噪声，从而掩盖了重要的社会技术信号。

Method: 对2020至2025年间发表于ACL、AIES、CHI等七个顶级会议的文献进行系统性综述，通过关键词筛选从30,897条记录中选出346篇进行反思性主题分析。

Result: 发现标注实践中存在位置可读性缺失、人类角色被降级为模型验证者、模型中介标注引入锚定偏差、地理霸权强加西方规范等问题，导致文化多样性被误判为随机误差。

Conclusion: 应摒弃追求单一“正确答案”的范式，转而构建能映射人类经验多样性的多元标注基础设施，以提升模型的文化胜任力。

Abstract: In machine learning, "ground truth" refers to the assumed correct labels used to train and evaluate models. However, the foundational "ground truth" paradigm rests on a positivistic fallacy that treats human disagreement as technical noise rather than a vital sociotechnical signal. This systematic literature review analyzes research published between 2020 and 2025 across seven premier venues: ACL, AIES, CHI, CSCW, EAAMO, FAccT, and NeurIPS, investigating the mechanisms in data annotation practices that facilitate this "consensus trap". Our identification phase captured 30,897 records, which were refined via a tiered keyword filtration schema to a high-recall corpus of 3,042 records for manual screening, resulting in a final included corpus of 346 papers for qualitative synthesis. Our reflexive thematic analysis reveals that systemic failures in positional legibility, combined with the recent architectural shift toward human-as-verifier models, specifically the reliance on model-mediated annotations, introduce deep-seated anchoring bias and effectively remove human voices from the loop. We further demonstrate how geographic hegemony imposes Western norms as universal benchmarks, often enforced by the performative alignment of precarious data workers who prioritize requester compliance over honest subjectivity to avoid economic penalties. Critiquing the "noisy sensor" fallacy, where statistical models misdiagnose cultural pluralism as random error, we argue for reclaiming disagreement as a high-fidelity signal essential for building culturally competent models. To address these systemic tensions, we propose a roadmap for pluralistic annotation infrastructures that shift the objective from discovering a singular "right" answer to mapping the diversity of human experience.

</details>


### [74] [Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge](https://arxiv.org/abs/2602.11340)
*Bo Pan,Xuan Kan,Kaitai Zhang,Yan Yan,Shunwen Tan,Zihao He,Zixin Ding,Junjie Wu,Liang Zhao*

Main category: cs.AI

TL;DR: 本文提出BLPO，一种用于多模态大语言模型自动评估图像的双层提示优化框架，通过将图像转为文本表示并在有限上下文窗口下联合优化评估提示与图像到文本（I2T）提示，显著提升与人类判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的自动评估方法在多模态场景（如AI生成图像评估）中受限于上下文窗口，难以有效进行提示优化，且监督微调成本高、灵活性差。

Method: 提出BLPO框架，将图像转化为保留评估相关视觉信息的文本表示，并在有限上下文预算下联合优化法官提示（judge prompt）和图像到文本提示（I2T prompt），实现双层提示优化。

Result: 在四个数据集和三种LLM法官上的实验表明，BLPO能有效提升多模态LLM作为评估者与人类判断的一致性。

Conclusion: BLPO为多模态LLM-as-a-judge提供了一种高效、低成本的自动提示优化方案，克服了上下文长度限制，提升了评估质量。

Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and inflexible, requiring new training for each task or dataset. Recent progress in auto prompt optimization (APO) offers a more efficient alternative by automatically improving the instructions that guide LLM judges. However, existing APO methods primarily target text-only evaluations and remain underexplored in multimodal settings. In this work, we study auto prompt optimization for multimodal LLM-as-a-judge, particularly for evaluating AI-generated images. We identify a key bottleneck: multimodal models can only process a limited number of visual examples due to context window constraints, which hinders effective trial-and-error prompt refinement. To overcome this, we propose BLPO, a bi-level prompt optimization framework that converts images into textual representations while preserving evaluation-relevant visual cues. Our bi-level optimization approach jointly refines the judge prompt and the I2T prompt to maintain fidelity under limited context budgets. Experiments on four datasets and three LLM judges demonstrate the effectiveness of our method.

</details>


### [75] [AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition](https://arxiv.org/abs/2602.11348)
*Ruipeng Wang,Yuxin Chen,Yukai Wang,Chang Wu,Junfeng Fang,Xiaodong Cai,Qi Gu,Hui Su,An Zhang,Xiang Wang,Xunliang Cai,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 本文提出了AgentNoiseBench，一个用于系统评估智能体模型在噪声环境下鲁棒性的框架，揭示了当前大语言模型智能体在真实世界复杂和不完美环境中的性能脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体在基准测试中表现优异，但在真实部署中性能显著下降，主要因为训练和评估范式基于理想化假设，忽略了现实交互中的随机性和噪声。

Method: 作者首先分析现实场景中的偏差与不确定性，将环境噪声分为用户噪声和工具噪声两类；随后构建了一个自动化流程，在保留任务可解性的前提下，向现有智能体基准中注入可控噪声，并对多种架构和规模的模型进行广泛评估。

Result: 实验结果表明，不同噪声条件下模型性能存在显著差异，当前智能体模型对现实环境扰动高度敏感。

Conclusion: 为提升智能体在真实世界中的鲁棒性，需在训练与评估中引入更贴近现实的噪声建模，AgentNoiseBench为此提供了有效工具。

Abstract: Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge this gap, we introduce AgentNoiseBench, a framework for systematically evaluating the robustness of agentic models under noisy environments. We first conduct an in-depth analysis of biases and uncertainties in real-world scenarios and categorize environmental noise into two primary types: user-noise and tool-noise. Building on this analysis, we develop an automated pipeline that injects controllable noise into existing agent-centric benchmarks while preserving task solvability. Leveraging this pipeline, we perform extensive evaluations across a wide range of models with diverse architectures and parameter scales. Our results reveal consistent performance variations under different noise conditions, highlighting the sensitivity of current agentic models to realistic environmental perturbations.

</details>


### [76] [Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization](https://arxiv.org/abs/2602.11351)
*Yihang Yao,Zhepeng Cen,Haohong Lin,Shiqi Liu,Zuxin Liu,Jiacheng Zhu,Zhang-Wei Hong,Laixi Shi,Ding Zhao*

Main category: cs.AI

TL;DR: 本文提出BAO框架，通过行为增强与行为正则化，在多轮交互中训练兼具任务性能与用户满意度的主动式大语言模型智能体。


<details>
  <summary>Details</summary>
Motivation: 现有主动式智能体在多轮交互中难以平衡任务完成效率与用户参与体验：过于被动无法适应用户意图，过度依赖人类反馈又会降低用户满意度。

Method: 提出BAO框架，结合行为增强（提升主动推理与信息收集能力）和行为正则化（抑制低效或冗余交互），以对齐用户期望并优化多轮交互策略。

Result: 在UserRL基准测试中，BAO显著优于现有主动式智能体强化学习基线，并在多项任务上达到或超越商用大语言模型智能体的性能。

Conclusion: BAO有效解决了主动式LLM智能体在复杂多轮场景中任务性能与用户对齐之间的权衡问题，为构建高效且用户友好的智能体提供了新路径。

Abstract: Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently emerged as a promising solution for training such agents in multi-turn settings, allowing interaction strategies to be learned from feedback. However, existing pipelines face a critical challenge in balancing task performance with user engagement, as passive agents can not efficiently adapt to users' intentions while overuse of human feedback reduces their satisfaction. To address this trade-off, we propose BAO, an agentic RL framework that combines behavior enhancement to enrich proactive reasoning and information-gathering capabilities with behavior regularization to suppress inefficient or redundant interactions and align agent behavior with user expectations. We evaluate BAO on multiple tasks from the UserRL benchmark suite, and demonstrate that it substantially outperforms proactive agentic RL baselines while achieving comparable or even superior performance to commercial LLM agents, highlighting its effectiveness for training proactive, user-aligned LLM agents in complex multi-turn scenarios. Our website: https://proactive-agentic-rl.github.io/.

</details>


### [77] [Causal-JEPA: Learning World Models through Object-Level Latent Interventions](https://arxiv.org/abs/2602.11389)
*Heejeong Nam,Quentin Le Lidec,Lucas Maes,Yann LeCun,Randall Balestriero*

Main category: cs.AI

TL;DR: C-JEPA 是一种基于对象的新型世界模型，通过对象级掩码机制增强交互推理能力，在视觉问答和智能体控制任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有以对象为中心的世界模型虽能提供抽象表示，但难以捕捉依赖交互的动力学关系；作者旨在通过引入对象级掩码机制，迫使模型学习对象间的因果交互，从而提升预测与推理能力。

Method: C-JEPA 将掩码联合嵌入预测（JEPA）从图像块扩展到对象级表示，通过掩码一个对象并要求其状态由其他对象推断，诱导潜在干预并引入因果归纳偏置。

Result: 在视觉问答任务中，C-JEPA 在反事实推理方面比无对象掩码的相同架构提升约20%；在控制任务中，仅用1%的潜在特征即可达到与基于图像块模型相当的性能。

Conclusion: 对象级掩码能有效诱导因果归纳偏置，使模型更依赖交互推理，从而在多个任务上实现更高效、更鲁棒的性能。

Abstract: World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.

</details>


### [78] [GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection & Truncation](https://arxiv.org/abs/2602.11408)
*Michael Menezes,Anastasios Kyrillidis*

Main category: cs.AI

TL;DR: GHOST 是一种针对 Mamba2 模型的结构化剪枝方法，通过仅使用前向传播统计量近似控制论中的平衡截断，在不进行反向传播的情况下实现高效的状态维度压缩。


<details>
  <summary>Details</summary>
Motivation: Mamba2 虽然通过扩展状态维度提升了时序建模能力，但在自回归生成过程中带来显著的推理开销和带宽饱和问题；现有剪枝方法（非结构化稀疏、基于幅值或梯度的方法）无法有效缓解该瓶颈。

Method: 提出 GHOST（Grouped Hidden-state Output-aware Selection and Truncation）框架，利用前向传播中对可控性和可观性的联合度量，实现无需反向传播的结构化剪枝。

Result: 在 130M 到 2.7B 参数规模的模型上，GHOST 实现了 50% 的状态维度缩减，仅导致 WikiText-2 数据集上约 1 个困惑度点的性能下降。

Conclusion: GHOST 在保持接近梯度方法精度的同时显著降低推理开销，为 Mamba2 类模型提供了一种高效实用的压缩方案。

Abstract: While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck: unstructured sparsity leaves activations dense, magnitude-based selection ignores runtime dynamics, and gradient-based methods impose prohibitive costs. We introduce GHOST (Grouped Hidden-state Output-aware Selection and Truncation), a structured pruning framework that approximates control-theoretic balanced truncation using only forward-pass statistics. By jointly measuring controllability and observability, GHOST rivals the fidelity of gradient-based methods without requiring backpropagation. As a highlight, on models ranging from 130M to 2.7B parameters, our approach achieves a 50\% state-dimension reduction with approximately 1 perplexity point increase on WikiText-2. Code is available at https://anonymous.4open.science/r/mamba2_ghost-7BCB/.

</details>


### [79] [TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning](https://arxiv.org/abs/2602.11409)
*Sina Tayebati,Divake Kumar,Nastaran Darabi,Davide Ettori,Ranganath Krishnan,Amit Ranjan Trivedi*

Main category: cs.AI

TL;DR: 本文提出TRACER，一种面向多轮人机工具交互场景的轨迹级不确定性度量方法，显著优于现有基线，在预测任务失败和选择性执行方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性估计方法主要针对单轮文本生成，难以捕捉多轮工具使用中由稀疏关键事件（如循环、工具使用不连贯或人机协调失败）引发的轨迹级故障信号。

Method: TRACER结合内容感知惊讶度、情境感知信号、语义与词汇重复性以及工具接地的连贯性缺口，并通过尾部聚焦的风险泛函与MAX复合步骤风险进行聚合，以识别关键异常。

Result: 在τ²-bench基准上，TRACER在任务失败预测和选择性任务执行任务中，AUROC最高提升37.1%，AUARC最高提升55%。

Conclusion: TRACER能更早、更准确地检测复杂对话式工具使用中的不确定性，为可靠的人机协作提供支持。

Abstract: Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent miscoordination) even when local generation appears confident. Existing uncertainty proxies focus on single-shot text generation and therefore miss these trajectory-level breakdown signals. We introduce TRACER, a trajectory-level uncertainty metric for dual-control Tool-Agent-User interaction. TRACER combines content-aware surprisal with situational-awareness signals, semantic and lexical repetition, and tool-grounded coherence gaps, and aggregates them using a tail-focused risk functional with a MAX-composite step risk to surface decisive anomalies. We evaluate TRACER on $τ^2$-bench by predicting task failure and selective task execution. To this end, TRACER improves AUROC by up to 37.1% and AUARC by up to 55% over baselines, enabling earlier and more accurate detection of uncertainty in complex conversational tool-use settings. Our code and benchmark are available at https://github.com/sinatayebati/agent-tracer.

</details>


### [80] [Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning](https://arxiv.org/abs/2602.11455)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.AI

TL;DR: 本文提出Anchor-Token强化学习（AT-RL），通过聚焦高跨模态注意力连接的“锚点”token，以极低开销显著提升多模态大语言模型在推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在多模态大语言模型中对视觉证据如何融入推理过程理解不足，作者旨在揭示并利用跨模态注意力中关键的视觉-文本耦合机制。

Method: 通过分析跨模态注意力连接性，识别出约15%的高连接性“锚点”token；在此基础上，提出AT-RL框架，利用基于图聚类的注意力拓扑结构，选择性地对这些锚点token进行强化学习。

Result: AT-RL仅引入1.2%的计算开销，使32B模型在MathVista上达到80.2分，超越72B-Instruct基线，并在STEM、视频和通用任务上均取得一致提升；而仅训练低连接性token则导致性能严重下降。

Conclusion: 多模态强化学习的有效性取决于对视觉锚点token的精准信用分配，推理质量由跨模态锚定的保真度而非token数量决定。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attention connectivity and find that only a small fraction of tokens (approximately 15%) exhibit strong visual-textual coupling. These high-connectivity tokens act as anchors that ground reasoning in the image, while the majority follow linguistic patterns. During RLVR training, credit assignment naturally concentrates on these anchors, sharpening their visual grounding over time. Building on this insight, we propose Anchor-Token Reinforcement Learning (AT-RL), a lightweight framework that selectively reinforces high-connectivity tokens via graph-based clustering of attention topology. Evaluated across the series (3B-32B), AT-RL introduces only 1.2% overhead yet enables the 32B model to surpass the 72B-Instruct baseline on MathVista (80.2), with consistent gains observed across STEM, video and general tasks. Conversely, training solely on low-connectivity tokens causes severe degradation, confirming that effective multimodal RL hinges on precise credit assignment to visual anchors. Our work reveals that reasoning quality is governed not by token quantity but by the fidelity of cross-modal anchoring.

</details>


### [81] [AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems](https://arxiv.org/abs/2602.11510)
*Faouzi El Yagoubi,Ranwa Al Mallah,Godwin Badu-Marfo*

Main category: cs.AI

TL;DR: 本文提出了AgentLeak，首个覆盖多智能体大语言模型系统内部通信渠道的隐私泄露全栈评测基准，发现现有仅审计输出的方法会遗漏大量隐私泄露（高达41.7%），并指出智能体间通信是主要泄露途径。


<details>
  <summary>Details</summary>
Motivation: 当前的隐私评估基准仅关注模型输出，无法检测多智能体系统中通过智能体间消息、共享内存和工具参数等内部渠道发生的隐私泄露，因此亟需一个能全面评估内部通信隐私风险的新基准。

Method: 作者构建了AgentLeak基准，包含横跨医疗、金融、法律和企业领域的1000个场景、32类攻击分类法和三层检测管道，并利用该基准在GPT-4o、Claude 3.5 Sonnet等五个主流大模型上进行了4979次追踪测试，以量化不同渠道（输出、智能体间消息等）的隐私泄露情况。

Result: 实验发现，多智能体配置虽降低了单个输出通道的泄露率（27.2% vs 43.2%），但因引入了未被监控的内部通道，导致系统总泄露率高达68.9%。其中，智能体间消息（C2）的泄露率（68.8%）远高于输出通道（C1, 27.2%）。Claude 3.5 Sonnet在内外部渠道均表现最佳，表明其安全对齐训练可能有效。

Conclusion: 研究证实，仅审计输出会严重低估多智能体系统的隐私风险，智能体间通信是主要漏洞。未来需要设计能保护内部通信渠道的协调框架，并在智能体交互中强制实施隐私控制。

Abstract: Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired with a 32-class attack taxonomy and three-tier detection pipeline. Testing GPT-4o, GPT-4o-mini, Claude 3.5 Sonnet, Mistral Large, and Llama 3.3 70B across 4,979 traces reveals that multi-agent configurations reduce per-channel output leakage (C1: 27.2% vs 43.2% in single-agent) but introduce unmonitored internal channels that raise total system exposure to 68.9% (OR-aggregated across C1, C2, C5). Internal channels account for most of this gap: inter-agent messages (C2) leak at 68.8%, compared to 27.2% on C1 (output channel). This means that output-only audits miss 41.7% of violations. Claude 3.5 Sonnet, which emphasizes safety alignment in its design, achieves the lowest leakage rates on both external (3.3%) and internal (28.1%) channels, suggesting that model-level safety training may transfer to internal channel protection. Across all five models and four domains, the pattern C2 > C1 holds consistently, confirming that inter-agent communication is the primary vulnerability. These findings underscore the need for coordination frameworks that incorporate internal-channel privacy protections and enforce privacy controls on inter-agent communication.

</details>


### [82] [Human-Inspired Continuous Learning of Internal Reasoning Processes: Learning How to Think for Adaptive AI Systems](https://arxiv.org/abs/2602.11516)
*Hong Su*

Main category: cs.AI

TL;DR: 本文提出一种受人类启发的持续学习框架，将内部推理过程作为主要学习对象，通过记录推理轨迹与环境交互，实现推理结构、行动调度和学习机制的协同优化，在温度传感器异常检测任务中使平均运行时间减少23.9%。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注任务特定输出或静态知识表示，忽视了对内部推理结构、行动调度策略及学习机制本身的持续优化，难以支持AI系统在动态环境中的长期适应能力。

Method: 构建一个融合推理、行动、反思与验证的连续学习框架，以内省式序列推理模型为基础，结合并行学习机制，将内部思维过程显式建模为学习对象，系统记录推理轨迹与环境交互数据，用于联合优化任务内容与认知结构，并引入分层“学会学习”机制，支持用习得策略替代预设逻辑。

Result: 在温度传感器异常检测任务中，引入内部过程学习后，系统平均运行时间减少了23.9%，同时保持了运行稳定性。

Conclusion: 将内部推理过程作为核心学习目标，可有效提升AI系统的自适应能力与执行效率，为构建具备持续进化认知架构的智能系统提供新路径。

Abstract: Learning internal reasoning processes is crucial for developing AI systems capable of sustained adaptation in dynamic real-world environments. However, most existing approaches primarily emphasize learning task-specific outputs or static knowledge representations, while overlooking the continuous refinement of internal reasoning structures, action scheduling policies, and learning mechanisms themselves. In this paper, we propose a human-inspired continuous learning framework that unifies reasoning, action, reflection, and verification within a sequential reasoning model enhanced by parallel learning. The framework explicitly treats internal thinking processes as primary learning objects. It systematically records internal reasoning trajectories and environmental interactions as structured learning material, enabling the system to optimize not only task-level content but also the organization, scheduling, and evolution of reasoning activities. This design realizes learning alongside processing, allowing cognitive structures to improve during execution. Furthermore, the framework supports controlled replacement of predefined logic with learned procedures and introduces a hierarchical learning-to-learn mechanism that jointly adapts task-level parameters and learning strategies. As a result, the system progressively evolves its internal cognitive architecture while preserving operational stability. Experimental results on a temperature sensor abnormality detection task show that incorporating internal-process learning reduces average runtime by 23.9%.

</details>


### [83] [CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference](https://arxiv.org/abs/2602.11527)
*Jiawei Zhu,Wei Chen,Ruichu Cai*

Main category: cs.AI

TL;DR: 本文提出CausalAgent，一个基于多智能体的对话系统，通过自然语言交互实现端到端的因果推断，显著降低因果分析的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 传统因果分析流程对研究人员要求高，需同时具备统计学和计算机科学背景，并手动处理算法选择、数据质量问题和结果解释等复杂任务，存在较高技术壁垒。

Method: CausalAgent整合多智能体系统（MAS）、检索增强生成（RAG）和模型上下文协议（MCP），支持从数据清洗、因果结构学习到偏差校正和报告生成的全流程自动化，并通过自然语言交互与可视化提升用户体验。

Result: 用户只需上传数据集并用自然语言提问，即可获得严谨且可交互的因果分析报告，有效降低了因果推断的使用门槛。

Conclusion: CausalAgent作为一种以用户为中心的人机协作新范式，在保证分析严谨性与可解释性的同时，显著提升了因果分析的易用性和可及性。

Abstract: Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The system innovatively integrates Multi-Agent Systems (MAS), Retrieval-Augmented Generation (RAG), and the Model Context Protocol (MCP) to achieve automation from data cleaning and causal structure learning to bias correction and report generation through natural language interaction. Users need only upload a dataset and pose questions in natural language to receive a rigorous, interactive analysis report. As a novel user-centered human-AI collaboration paradigm, CausalAgent explicitly models the analysis workflow. By leveraging interactive visualizations, it significantly lowers the barrier to entry for causal analysis while ensuring the rigor and interpretability of the process.

</details>


### [84] [Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use](https://arxiv.org/abs/2602.11541)
*Hanbing Liu,Chunhao Tian,Nan An,Ziyuan Wang,Pinyan Lu,Changyuan Yu,Qi Qi*

Main category: cs.AI

TL;DR: 本文研究了在严格金钱预算约束下，大语言模型通过调用外部工具完成多步任务的问题，并提出了名为INTENT的推理时规划框架，在保证不超预算的同时显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型智能体在执行多步任务时缺乏对金钱成本的显式建模，而现实场景中工具调用往往具有价格且结果具有随机性，因此需要一种能在严格预算约束下高效决策的方法。

Method: 提出INTENT框架，利用意图感知的分层世界模型，在推理时在线预测未来工具使用、校准风险成本，并据此指导工具调用决策。

Result: 在成本增强版StableToolBench上，INTENT在严格满足硬性预算限制的前提下，显著优于基线方法的任务成功率，并在工具价格变动和预算变化等动态市场条件下保持鲁棒性。

Conclusion: INTENT有效解决了预算受限下工具增强智能体的规划难题，为大语言模型在现实经济约束下的部署提供了可行方案。

Abstract: We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.

</details>


### [85] [The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs](https://arxiv.org/abs/2602.11583)
*Jingdi Chen,Hanqing Yang,Zongjun Liu,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: 本文综述了多智能体通信（MA-Comm）的研究进展，通过“五个W”框架（谁与谁通信、通信内容、通信时机、通信益处等）梳理了从多智能体强化学习（MARL）、涌现语言（EL）到大语言模型（LLM）驱动的通信范式的演进，并总结了设计模式与开放挑战。


<details>
  <summary>Details</summary>
Motivation: 在动态且部分可观测的环境中，多智能体系统依赖通信来降低不确定性并实现协作。现有方法在可解释性、泛化性和可扩展性方面存在不足，亟需系统性梳理与整合。

Method: 采用“五个W”分析框架，对多智能体通信在MARL、EL和LLM三大范式中的发展进行综述，比较不同方法的设计选择、权衡及局限。

Result: 揭示了各范式下通信机制的演进路径：从手工/隐式协议到端到端学习，再到结构化符号语言，最终引入大语言模型以利用自然语言先验；同时提炼出实用设计模式。

Conclusion: 未来方向在于构建融合学习、语言与控制的混合系统，以实现可扩展且可解释的多智能体协作，但仍需解决接地性、泛化性与可扩展性等核心挑战。

Abstract: Multi-agent sequential decision-making powers many real-world systems, from autonomous vehicles and robotics to collaborative AI assistants. In dynamic, partially observable environments, communication is often what reduces uncertainty and makes collaboration possible. This survey reviews multi-agent communication (MA-Comm) through the Five Ws: who communicates with whom, what is communicated, when communication occurs, and why communication is beneficial. This framing offers a clean way to connect ideas across otherwise separate research threads. We trace how communication approaches have evolved across three major paradigms. In Multi-Agent Reinforcement Learning (MARL), early methods used hand-designed or implicit protocols, followed by end-to-end learned communication optimized for reward and control. While successful, these protocols are frequently task-specific and hard to interpret, motivating work on Emergent Language (EL), where agents can develop more structured or symbolic communication through interaction. EL methods, however, still struggle with grounding, generalization, and scalability, which has fueled recent interest in large language models (LLMs) that bring natural language priors for reasoning, planning, and collaboration in more open-ended settings. Across MARL, EL, and LLM-based systems, we highlight how different choices shape communication design, where the main trade-offs lie, and what remains unsolved. We distill practical design patterns and open challenges to support future hybrid systems that combine learning, language, and control for scalable and interpretable multi-agent collaboration.

</details>


### [86] [MAPLE: Modality-Aware Post-training and Learning Ecosystem](https://arxiv.org/abs/2602.11596)
*Nikhil Verma,Minjung Kim,JooYoung Yoo,Kyung-Min Jin,Manasa Bharadwaj,Kevin Ferreira,Ko Keun Kim,Youngjoon Kim*

Main category: cs.AI

TL;DR: 本文提出MAPLE，一个面向多模态语言模型的模态感知强化学习后训练框架，通过构建首个标注任务所需最小信号组合的基准MAPLE-bench、设计模态感知策略优化方法MAPO，并结合自适应加权与课程调度策略，显著提升训练效率、鲁棒性与多模态性能一致性。


<details>
  <summary>Details</summary>
Motivation: 现有RL后训练方法对所有输入模态一视同仁，忽视了不同任务实际所需的模态组合，导致策略梯度方差高、收敛慢，并在真实世界信号缺失或变化时表现不稳定。

Method: MAPLE包含三部分：(1) MAPLE-bench：标注各任务所需最小模态组合的基准；(2) MAPO：按模态需求分层采样以降低梯度方差的策略优化框架；(3) 自适应加权与课程调度机制，优先学习更难的模态组合。系统评估了损失聚合、裁剪、采样和课程设计等策略。

Result: MAPLE将单模态与多模态准确率差距缩小30.24%，收敛速度提升3.18倍，并在信号受限的真实场景下保持所有模态组合下的稳定性能。

Conclusion: MAPLE提供了一套完整的、可部署的多模态RL后训练方案，显著提升了多模态语言模型的训练效率、鲁棒性与泛化能力。

Abstract: Multimodal language models now integrate text, audio, and video for unified reasoning. Yet existing RL post-training pipelines treat all input signals as equally relevant, ignoring which modalities each task actually requires. This modality-blind training inflates policy-gradient variance, slows convergence, and degrades robustness to real-world distribution shifts where signals may be missing, added, or reweighted. We introduce MAPLE, a complete modality-aware post-training and learning ecosystem comprising: (1) MAPLE-bench, the first benchmark explicitly annotating minimal signal combinations required per task; (2) MAPO, a modality-aware policy optimization framework that stratifies batches by modality requirement to reduce gradient variance from heterogeneous group advantages; (3) Adaptive weighting and curriculum scheduling that balances and prioritizes harder signal combinations. Systematic analysis across loss aggregation, clipping, sampling, and curriculum design establishes MAPO's optimal training strategy. Adaptive weighting and curriculum focused learning further boost performance across signal combinations. MAPLE narrows uni/multi-modal accuracy gaps by 30.24%, converges 3.18x faster, and maintains stability across all modality combinations under realistic reduced signal access. MAPLE constitutes a complete recipe for deployment-ready multimodal RL post-training.

</details>


### [87] [scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery](https://arxiv.org/abs/2602.11609)
*Yiming Gao,Zhen Wang,Jefferson Chen,Mark Antkowiak,Mengzhou Hu,JungHo Kong,Dexter Pratt,Jieyuan Liu,Enze Ma,Zhiting Hu,Eric P. Xing*

Main category: cs.AI

TL;DR: scPilot 是首个支持“组学原生推理”的系统框架，使大语言模型（LLM）能在与用户自然语言交互的同时直接分析单细胞 RNA-seq 数据并调用生物信息学工具，将核心单细胞分析任务转化为可解释、可修正的逐步推理过程。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在单细胞组学分析中缺乏对原始数据的直接访问和可解释的推理能力，难以满足生物医学研究对透明性、可审计性和诊断价值的需求。

Method: scPilot 将细胞类型注释、发育轨迹重建和转录因子靶向等任务建模为多步推理问题，引导 LLM 在分析过程中结合原始单细胞数据和按需调用的生物信息学工具进行推理、验证与修正，并生成可追溯的推理轨迹。同时发布 scBench 基准用于评估模型的组学原生推理能力。

Result: 实验表明，采用迭代式组学原生推理可将细胞类型注释准确率平均提升 11%；Gemini-2.5-Pro 在轨迹重建任务中相比一次性提示将图编辑距离降低 30%，并能清晰解释标记基因歧义和调控逻辑。

Conclusion: 通过将 LLM 接地于原始组学数据，scPilot 实现了可审计、可解释且具有诊断价值的单细胞分析，为 AI 驱动的精准生物医学研究提供了新范式。

Abstract: We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence.
  To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses.
  Code, data, and package are available at https://github.com/maitrix-org/scPilot

</details>


### [88] [When Agents Disagree With Themselves: Measuring Behavioral Consistency in LLM-Based Agents](https://arxiv.org/abs/2602.11619)
*Aman Mehta*

Main category: cs.AI

TL;DR: 同一LLM智能体在相同任务上多次运行时行为不一致，且这种不一致性与任务失败高度相关。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLM）智能体在重复执行相同任务时的行为稳定性，并分析其与任务成功率之间的关系。

Method: 对3000次智能体运行（涵盖Llama 3.1 70B、GPT-4o和Claude Sonnet 4.5三种模型）在HotpotQA数据集上进行实验，统计每次运行中ReAct风格智能体产生的不同动作序列数量，并分析行为一致性与准确率的关系，同时追踪分歧发生的时间点。

Result: 平均每10次运行产生2.0–4.2种不同动作序列；行为一致的任务（≤2条路径）准确率达80–92%，而高度不一致任务（≥6条路径）仅达25–60%；69%的分歧出现在第2步（首次搜索查询）。

Conclusion: 行为一致性可作为预测智能体成功与否的重要指标，监控执行过程中的行为变化有助于早期错误检测并提升智能体可靠性。

Abstract: Run the same LLM agent on the same task twice: do you get the same behavior? We find the answer is often no. In a study of 3,000 agent runs across three models (Llama 3.1 70B, GPT-4o, and Claude Sonnet 4.5) on HotpotQA, we observe that ReAct-style agents produce 2.0--4.2 distinct action sequences per 10 runs on average, even with identical inputs. More importantly, this variance predicts failure: tasks with consistent behavior ($\leq$2 unique paths) achieve 80--92% accuracy, while highly inconsistent tasks ($\geq$6 unique paths) achieve only 25--60%, a 32--55 percentage point gap depending on model. We trace variance to early decisions: 69% of divergence occurs at step 2, the first search query. Our results suggest that monitoring behavioral consistency during execution could enable early error detection and improve agent reliability.

</details>


### [89] [Neuro-Symbolic Multitasking: A Unified Framework for Discovering Generalizable Solutions to PDE Families](https://arxiv.org/abs/2602.11630)
*Yipeng Huang,Dejun Xu,Zexin Lin,Zhenzhong Wang,Min Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种名为NMIPS的神经辅助多任务符号偏微分方程（PDE）求解框架，用于高效求解具有相同结构但参数不同的PDE族，通过多因子优化和仿射迁移方法，在提升精度的同时提供可解释的解析解。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在求解PDE族时计算成本高，而现有机器学习PDE求解器虽快但缺乏可解释性，无法提供解析表达式。因此，亟需一种兼顾效率、精度与可解释性的新方法。

Method: 提出NMIPS框架，结合多因子优化同时发现多个PDE的解析解，并设计仿射迁移方法，在PDE族内共享已学习的数学结构，避免重复从头求解。

Result: 在多个实验案例中，NMIPS相比现有基线方法最高提升约35.7%的准确率，同时成功生成可解释的解析解。

Conclusion: NMIPS有效解决了PDE族求解中的效率与可解释性问题，为科学和工程领域提供了兼具高性能与透明度的新工具。

Abstract: Solving Partial Differential Equations (PDEs) is fundamental to numerous scientific and engineering disciplines. A common challenge arises from solving the PDE families, which are characterized by sharing an identical mathematical structure but varying in specific parameters. Traditional numerical methods, such as the finite element method, need to independently solve each instance within a PDE family, which incurs massive computational cost. On the other hand, while recent advancements in machine learning PDE solvers offer impressive computational speed and accuracy, their inherent ``black-box" nature presents a considerable limitation. These methods primarily yield numerical approximations, thereby lacking the crucial interpretability provided by analytical expressions, which are essential for deeper scientific insight. To address these limitations, we propose a neuro-assisted multitasking symbolic PDE solver framework for PDE family solving, dubbed NMIPS. In particular, we employ multifactorial optimization to simultaneously discover the analytical solutions of PDEs. To enhance computational efficiency, we devise an affine transfer method by transferring learned mathematical structures among PDEs in a family, avoiding solving each PDE from scratch. Experimental results across multiple cases demonstrate promising improvements over existing baselines, achieving up to a $\sim$35.7% increase in accuracy while providing interpretable analytical solutions.

</details>


### [90] [Do MLLMs Really Understand Space? A Mathematical Reasoning Evaluation](https://arxiv.org/abs/2602.11635)
*Shuo Lu,Jianjie Cheng,Yinuo Xu,Yongcan Yu,Lijun Sheng,Peijie Wang,Siru Jiang,Yongguan Hu,Run Ling,Yihua Shao,Ao Ma,Wei Feng,Lingxiao He,Meng Wang,Qianlong Xie,Xingxing Wang,Ran He,Jian Liang*

Main category: cs.AI

TL;DR: 本文提出MathSpatial框架，用于评估和提升多模态大语言模型（MLLMs）在数学空间推理任务上的表现，包含评测基准、训练语料和结构化推理方法。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在感知任务上表现优异，但在数学空间推理（如解析和操作二维/三维关系）方面能力明显不足，远低于人类水平，亟需系统性评估与改进。

Method: 构建MathSpatial框架，包含：(i) MathSpatial-Bench（2K问题的评测基准），(ii) MathSpatial-Corpus（8K带解训练数据），(iii) MathSpatial-SRT（基于Correlate、Constrain、Infer三种原子操作的结构化推理轨迹建模）。在Qwen2.5-VL-7B上进行微调验证。

Result: 微调后的模型在保持竞争力的准确率的同时减少了25%的token使用；该框架首次实现了对感知与推理能力的解耦，支持对MLLMs空间推理能力的精准评估。

Conclusion: MathSpatial为MLLMs的空间推理研究提供了首个大规模、结构化的评测与训练资源，揭示了当前模型在此类任务上的根本性短板，并为未来改进指明方向。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on perception-oriented tasks, yet their ability to perform mathematical spatial reasoning, defined as the capacity to parse and manipulate two- and three-dimensional relations, remains unclear. Humans easily solve textbook-style spatial reasoning problems with over 95\% accuracy, but we find that most leading MLLMs fail to reach even 60\% on the same tasks. This striking gap highlights spatial reasoning as a fundamental weakness of current models. To investigate this gap, we present MathSpatial, a unified framework for evaluating and improving spatial reasoning in MLLMs. MathSpatial includes three complementary components: (i) MathSpatial-Bench, a benchmark of 2K problems across three categories and eleven subtypes, designed to isolate reasoning difficulty from perceptual noise; (ii) MathSpatial-Corpus, a training dataset of 8K additional problems with verified solutions; and (iii) MathSpatial-SRT, which models reasoning as structured traces composed of three atomic operations--Correlate, Constrain, and Infer. Experiments show that fine-tuning Qwen2.5-VL-7B on MathSpatial achieves competitive accuracy while reducing tokens by 25\%. MathSpatial provides the first large-scale resource that disentangles perception from reasoning, enabling precise measurement and comprehensive understanding of mathematical spatial reasoning in MLLMs.

</details>


### [91] [Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm](https://arxiv.org/abs/2602.11661)
*Tianxiang Xu,Jiayi Liu,Yixuan Tong,Jialu Xu,Yunqing Wei,Kaiwen Feng,PanPan Hou,Kangping Yin,Jiyuan Hu,Hao Zhou,Zhenxin Ma,Jian Xu,Guanjun Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种面向医疗领域的强化学习对齐新范式，通过构建多维对齐矩阵和统一优化机制，有效解决医疗问答中正确性、安全性和合规性等多目标协同优化难题。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类反馈或可验证奖励的强化学习方法在高风险医疗问答场景中存在根本性不匹配：偏好标注成本高且难以反映医学事实的绝对正确性，自动验证器缺失且难以处理复杂临床语境，同时多目标异构奖励信号易导致尺度不一致与优化冲突。

Method: 作者构建了一个包含基础能力、专家知识、在线反馈和格式规范四维度的医疗对齐矩阵，形成“可观测指标→可归因诊断→可优化奖励”的闭环监督信号；并提出统一优化机制，包括参考冻结归一化（Reference-Frozen Normalization）以对齐奖励尺度，以及三因子自适应动态加权策略（Tri-Factor Adaptive Dynamic Weighting）实现以弱项为导向、风险优先、冗余减少的协同优化。

Result: 在真实医疗场景评估中，所提方法显著提升了模型在正确性、安全性和合规性方面的综合表现，验证了该范式的有效性。

Conclusion: 该研究为垂直领域（如医疗）中的复杂对齐问题提供了一种新的、可扩展的强化学习对齐范式，具有良好的应用前景。

Abstract: While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.

</details>


### [92] [Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs](https://arxiv.org/abs/2602.11674)
*Longyuan Zhu,Hairan Hua,Linlin Miao,Bing Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种名为“基准健康指数（BHI）”的数据驱动框架，用于从能力区分度、抗饱和性和影响力三个维度系统评估大语言模型基准的有效性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前用于评估大语言模型的基准存在分数膨胀和选择性报告等问题，导致其可信度下降，亟需一种客观、系统的方法来评估和管理这些基准的质量。

Method: 作者构建了BHI框架，通过分析2025年91个代表性模型技术报告中使用的106个已验证基准，从能力区分度、抗饱和性和影响力三个正交维度对基准进行量化评估。

Result: BHI首次在宏观层面实现了对基准健康状况的量化，揭示了现有评估体系的问题，并为基准选择和生命周期管理提供了数据支持。

Conclusion: BHI为构建更可靠、可持续的大语言模型评估体系提供了原则性基础，有助于推动下一代评估协议的发展。

Abstract: Large Language Models (LLMs) are advancing rapidly, yet the benchmarks used to measure this progress are becoming increasingly unreliable. Score inflation and selective reporting have eroded the authority of standard benchmarks, leaving the community uncertain about which evaluation results remain trustworthy. We introduce the Benchmark Health Index (BHI), a pure data-driven framework for auditing evaluation sets along three orthogonal and complementary axes: (1) Capability Discrimination, measuring how sharply a benchmark separates model performance beyond noise; (2) Anti-Saturation, estimating remaining headroom before ceiling effects erode resolution and thus the benchmark's expected longevity; and (3) Impact, quantifying influence across academic and industrial ecosystems via adoption breadth and practice-shaping power. By distilling 106 validated benchmarks from the technical reports of 91 representative models in 2025, we systematically characterize the evaluation landscape. BHI is the first framework to quantify benchmark health at a macro level, providing a principled basis for benchmark selection and enabling dynamic lifecycle management for next-generation evaluation protocols.

</details>


### [93] [Right for the Wrong Reasons: Epistemic Regret Minimization for Causal Rung Collapse in LLMs](https://arxiv.org/abs/2602.11675)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 该论文指出大语言模型常因“错误原因得到正确答案”而失败，将其归因于“层级坍缩”（Rung Collapse）和“随机性固化”（Aleatoric Entrenchment），并提出“认知后悔最小化”（ERM）方法，通过因果信念修正机制恢复真实干预分布，在1360个因果陷阱场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习系统在分布偏移下表现不佳，因其依赖关联性而非因果推理，导致即使任务成功也基于错误的因果模型；作者旨在揭示这一问题的因果根源并提出解决机制。

Method: 提出Epistemic Regret Minimization（ERM）目标函数，结合三层架构：(1) 基于执行器独立性的物理接地定理以实现有效do操作；(2) 满足AGM公设的因果信念修正算子；(3) 领域无关的失败模式分类与防护机制。

Result: 在六个前沿大语言模型的1360个因果陷阱场景中，发现Rung Collapse普遍存在（如GPT-5.2仍达3.7%），通用反馈难以纠正高级模型，而ERM针对性反馈可恢复53–59%的固化错误。

Conclusion: 通过将因果推理与信念修正结合，ERM能有效克服因错误因果模型导致的性能脆弱性，实现跨领域鲁棒性，并从理论上保证对真实干预分布的渐近恢复。

Abstract: Machine learning systems that are "right for the wrong reasons" achieve high performance through shortcuts that collapse under distributional shift. We show this pathology has a precise causal origin: autoregressive training provides no gradient signal to distinguish association P(Y|X) from intervention P(Y|do(X)), a failure we formalize as Rung Collapse. When outcome-based learning reinforces correct answers obtained through incorrect causal models, the agent becomes entrenched in flawed reasoning, a phenomenon we term Aleatoric Entrenchment. We propose Epistemic Regret Minimization (ERM), a belief revision objective that penalizes errors in causal reasoning independently of task success, and embed it within a three-layer architecture with three contributions grounded in knowledge representation: (1) a Physical Grounding Theorem proving that actions satisfying actuator independence implement valid do-operations, bridging action languages and do-calculus; (2) ERM as a causal belief revision operator satisfying AGM postulates, preventing entrenchment even when the agent succeeds for the wrong reasons; and (3) a failure mode taxonomy that classifies recurring reasoning errors and injects domain-independent guards, enabling cross-domain transfer. We prove asymptotic recovery of the true interventional distribution with finite-sample bounds. Experiments on 1,360 causal trap scenarios across six frontier LLMs reveal that Rung Collapse persists even in reasoning-enhanced models (3.7% for GPT-5.2), that steerability exhibits inverse scaling where advanced models resist generic correction, and that targeted ERM feedback recovers 53-59% of entrenched errors where outcome-level feedback fails.

</details>


### [94] [Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing](https://arxiv.org/abs/2602.11678)
*Chengwei Ma,Zhen Tian,Zhou Zhou,Zhixian Xu,Xiaowei Zhu,Xia Hua,Si Shi,F. Richard Yu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Vector-to-Graph（V2G）的流程，将CAD图纸转换为属性图，以显式表达工程图纸中的结构依赖关系，从而显著提升多模态大语言模型在电气合规性检查等任务中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在处理工程图纸时存在“结构盲区”，即无法捕捉拓扑结构和符号逻辑，因其基于像素的范式忽略了矢量定义的显式关系，限制了其在工程领域的实际应用。

Method: 作者设计了一个V2G管道，将CAD图纸转化为属性图，其中节点表示组件，边表示连接关系，从而使结构依赖关系显式化并可被机器审计。

Result: 在电气合规性诊断基准测试中，V2G在所有错误类别上均显著提升了准确率，而现有主流MLLM的表现接近随机水平。

Conclusion: 研究表明，基于像素的方法在工程图纸理解任务中存在系统性不足，而引入结构感知的表示（如V2G）是推动多模态AI在工程领域实用化的重要路径。作者同时开源了相关基准和实现代码。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.

</details>


### [95] [ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces](https://arxiv.org/abs/2602.11683)
*Xin Xu,Tong Yu,Xiang Chen,Haoliang Wang,Julian McAuley,Saayan Mitra*

Main category: cs.AI

TL;DR: 本文提出ThinkRouter，一种推理时的置信度感知路由机制，通过在离散token空间与潜在空间之间动态切换，提升推理效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法在不同场景下效果不一，分析发现错误推理路径中低置信度步骤更少，而聚合多个低置信度路径的软嵌入可能引入噪声并导致高置信度但不可靠的推理。为解决此问题，作者提出基于置信度的路由机制。

Method: ThinkRouter在模型置信度低时将推理路由至离散token空间，否则使用潜在空间，从而避免高置信度下的噪声传播。

Result: 在多个STEM推理和代码基准测试中，ThinkRouter在Pass@1上平均提升19.70分，生成长度最多减少15.55%，优于显式CoT、随机路由和潜在推理基线。

Conclusion: ThinkRouter能有效校准显式CoT和潜在推理中的错误，通过全局降低模型置信度加速推理终止，并在准确性和效率上取得显著提升。

Abstract: Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.

</details>


### [96] [Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging](https://arxiv.org/abs/2602.11717)
*Weihong Lin,Lin Sun,Qilong Shi,Aomufei Yuan,Yuxuan Tian,Zhengyang Wang,Guangxiang Zhao,Xiangzheng Zhang,Tong Yang*

Main category: cs.AI

TL;DR: 本文提出了一种名为SCF-RKL的新模型融合方法，通过稀疏且分布感知的更新策略，有效减少模型融合中的功能干扰，在多个基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法依赖参数空间启发式策略，常导致严重干扰，引发泛化能力下降和生成不稳定（如重复、不连贯输出）。

Method: 提出Sparse Complementary Fusion with reverse KL (SCF-RKL)，利用反向KL散度衡量模型间功能差异，并选择性地融合互补参数，实现稀疏、分布感知的更新。

Result: 在24个涵盖推理、知识、指令遵循和安全性的基准上，SCF-RKL在不同模型规模和架构中均优于现有融合方法，同时保持良好的泛化性和生成稳定性。

Conclusion: SCF-RKL通过显式控制功能干扰，提供了一种更稳定、高效的模型融合框架，显著提升了融合模型的性能与可靠性。

Abstract: Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.

</details>


### [97] [Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]](https://arxiv.org/abs/2602.11745)
*Songlin Lyu,Lujie Ban,Zihang Wu,Tianqi Luo,Jirong Liu,Chenhao Ma,Yuyu Luo,Nan Tang,Shipeng Qi,Heng Lin,Yongchao Liu,Chuntao Hong*

Main category: cs.AI

TL;DR: 本文提出了Text2GQL-Bench，一个统一的Text-to-GQL基准，包含覆盖13个领域的178,184个（问题，查询）对，并引入多维度评估方法，揭示了当前大语言模型在ISO-GQL生成中的“方言鸿沟”问题。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-GQL系统缺乏高质量、跨领域、支持多种图查询语言的基准数据集和系统性评估方法，限制了该领域的发展。

Method: 构建了一个名为Text2GQL-Bench的统一基准，包括一个大规模多GQL数据集和一个可扩展的数据集构建框架；同时提出了一种综合评估方法，涵盖语法有效性、相似性、语义对齐和执行准确率四个维度。

Result: 评估发现，在零样本设置下，即使是强大的LLM在ISO-GQL上的执行准确率也仅有4%；通过3-shot提示可提升至约50%，但语法有效性仍低于70%；而经过微调的8B开源模型可达到45.1%的执行准确率和90.8%的语法有效性。

Conclusion: 充分暴露于目标GQL（如ISO-GQL）的示例对提升模型性能至关重要，Text2GQL-Bench为Text-to-GQL系统的开发与评估提供了有效工具和深刻洞见。

Abstract: Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and manipulate graph data, posi-tioning them as powerful agent infrastructures for Graph Database Management System (GDBMS). Despite recent progress, existing datasets are often limited in domain coverage, supported graph query languages, or evaluation scope. The advancement of Text-to-GQL systems is hindered by the lack of high-quality benchmark datasets and evaluation methods to systematically compare model capabilities across different graph query languages and domains. In this work, we present Text2GQL-Bench, a unified Text-to-GQL benchmark designed to address these limitations. Text2GQL-Bench couples a multi-GQL dataset that has 178,184 (Question, Query) pairs spanning 13 domains, with a scalable construction framework that generates datasets in different domains, question abstraction levels, and GQLs with heterogeneous resources. To support compre-hensive assessment, we introduce an evaluation method that goes beyond a single end-to-end metric by jointly reporting grammatical validity, similarity, semantic alignment, and execution accuracy. Our evaluation uncovers a stark dialect gap in ISO-GQL generation: even strong LLMs achieve only at most 4% execution accuracy (EX) in zero-shot settings, though a fixed 3-shot prompt raises accuracy to around 50%, the grammatical validity remains lower than 70%. Moreover, a fine-tuned 8B open-weight model reaches 45.1% EX, and 90.8% grammatical validity, demonstrating that most of the performance jump is unlocked by exposure to sufficient ISO-GQL examples.

</details>


### [98] [AIR: Improving Agent Safety through Incident Response](https://arxiv.org/abs/2602.11749)
*Zibo Xiao,Jun Sun,Junjie Chen*

Main category: cs.AI

TL;DR: 本文提出了AIR，首个面向大语言模型（LLM）智能体系统的事件响应框架，通过在智能体执行循环中集成领域特定语言，实现对事件的自动检测、遏制、恢复和根除，显著提升智能体安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体的安全机制主要集中在事前预防，缺乏对事件发生后的响应、遏制和恢复能力。为弥补这一空白，作者提出将事件响应作为提升智能体安全性的核心机制。

Method: AIR框架定义了一种领域特定语言，嵌入到智能体执行循环中，用于：(1) 基于环境状态和上下文进行语义检查以检测事件；(2) 引导智能体使用工具执行遏制与恢复操作；(3) 在根除阶段自动生成防护规则以防止类似事件再次发生。

Result: 在三类代表性智能体上的实验表明，AIR在事件检测、修复和根除方面的成功率均超过90%；消融实验验证了关键设计组件的必要性，且系统开销适中、响应及时；自动生成的规则效果接近人工编写规则。

Conclusion: 事件响应是提升LLM智能体安全性的可行且必要的机制，应被视为智能体安全体系中的一等公民。

Abstract: Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incident response lifecycle autonomously in LLM agent systems, and integrates it into the agent's execution loop to (1) detect incidents via semantic checks grounded in the current environment state and recent context, (2) guide the agent to execute containment and recovery actions via its tools, and (3) synthesize guardrail rules during eradication to block similar incidents in future executions. We evaluate AIR on three representative agent types. Results show that AIR achieves detection, remediation, and eradication success rates all exceeding 90%. Extensive experiments further confirm the necessity of AIR's key design components, show the timeliness and moderate overhead of AIR, and demonstrate that LLM-generated rules can approach the effectiveness of developer-authored rules across domains. These results show that incident response is both feasible and essential as a first-class mechanism for improving agent safety.

</details>


### [99] [TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents](https://arxiv.org/abs/2602.11767)
*Aladin Djuhera,Swanand Ravindra Kadhe,Farhan Ahmed,Holger Boche*

Main category: cs.AI

TL;DR: 本文提出 TSR（Trajectory-Search Rollouts）方法，在训练阶段通过轻量级树状搜索生成高质量轨迹，提升多轮强化学习中智能体的性能与稳定性。


<details>
  <summary>Details</summary>
Motivation: 多轮强化学习面临奖励稀疏、延迟以及环境随机性等问题，导致简单轨迹采样难以有效利用信息并易引发模式崩溃。

Method: TSR 在训练阶段引入测试时扩展思想，通过任务特定反馈在每一步选择高分动作，构建高质量轨迹；支持 best-of-N、束搜索和浅层前瞻等策略，并兼容 PPO 与 GRPO 等优化器。

Result: 在 Sokoban、FrozenLake 和 WebShop 任务上，TSR 实现最高 15% 的性能提升，并带来更稳定的训练过程，仅需一次性增加训练计算开销。

Conclusion: TSR 将搜索从推理阶段移至训练的 rollout 阶段，提供了一种通用、简洁且与现有框架兼容的多轮智能体训练增强机制。

Abstract: Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.

</details>


### [100] [How to Optimize Multispecies Set Predictions in Presence-Absence Modeling ?](https://arxiv.org/abs/2602.11771)
*Sébastien Gigot--Léandri,Gaétan Morand,Alexis Joly,François Munoz,David Mouillot,Christophe Botella,Maximilien Servajean*

Main category: cs.AI

TL;DR: 本文提出MaxExp和SSE两种新方法，用于将物种分布模型（SDM）的概率预测转化为二元存在-缺失图，以更准确地估计物种丰度和群落组成。


<details>
  <summary>Details</summary>
Motivation: 传统SDM二值化方法多为启发式，易扭曲物种丰度与群落组成的估计，尤其在类别不平衡和稀有物种情况下表现不佳，亟需更稳健、可复现的替代方案。

Method: 提出MaxExp框架，通过直接最大化选定评估指标来选择最可能的物种组合，无需校准数据；同时引入计算高效的SSE方法，基于预期物种丰富度预测群落组成。

Result: 在三个涵盖不同类群、物种数量和评估指标的案例研究中，MaxExp在匹配或超越现有阈值与校准方法方面表现优异，尤其在强类别不平衡和高稀有性条件下；SSE则提供了简单而具竞争力的替代方案。

Conclusion: MaxExp与SSE为多物种SDM的二值化提供了稳健、可复现的新工具，有助于提升生态推断与保护规划的准确性。

Abstract: Species distribution models (SDMs) commonly produce probabilistic occurrence predictions that must be converted into binary presence-absence maps for ecological inference and conservation planning. However, this binarization step is typically heuristic and can substantially distort estimates of species prevalence and community composition. We present MaxExp, a decision-driven binarization framework that selects the most probable species assemblage by directly maximizing a chosen evaluation metric. MaxExp requires no calibration data and is flexible across several scores. We also introduce the Set Size Expectation (SSE) method, a computationally efficient alternative that predicts assemblages based on expected species richness. Using three case studies spanning diverse taxa, species counts, and performance metrics, we show that MaxExp consistently matches or surpasses widely used thresholding and calibration methods, especially under strong class imbalance and high rarity. SSE offers a simpler yet competitive option. Together, these methods provide robust, reproducible tools for multispecies SDM binarization.

</details>


### [101] [RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation](https://arxiv.org/abs/2602.11780)
*Jinfang Wang,Jiajie Liu,Jianwei Wu,Ziqin Luo,Zhen Chen,Chunlei Li,Biao Han,Tao Deng,Yi Li,Shuanglong Li,Lin Liu*

Main category: cs.AI

TL;DR: 本文提出RELATE，一种基于强化学习的端到端广告文案生成框架，将文案生成与广告效果指标（如点击率和转化率）及合规约束统一建模，显著提升线上转化效果。


<details>
  <summary>Details</summary>
Motivation: 现有广告文案生成系统通常采用两阶段范式，先生成候选文案再对齐线上效果指标，导致优化目标不一致、漏斗效率低，难以实现全局最优。

Method: RELATE通过强化学习将性能指标（特别是转化导向指标）和合规约束作为多维奖励直接融入生成过程，实现端到端联合优化。

Result: 在大规模工业数据集上，RELATE显著优于基线模型；在线上生产环境中，在严格合规约束下显著提升了点击后转化率（CTCVR）。

Conclusion: RELATE有效解决了传统两阶段方法的优化目标割裂问题，验证了端到端强化学习框架在广告文案生成中的实际价值与鲁棒性。

Abstract: In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.
  To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.
  Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.

</details>


### [102] [FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning](https://arxiv.org/abs/2602.11782)
*Yihao Liu,Ziyun Zhang,Zile He,Huaqian Cai*

Main category: cs.AI

TL;DR: 本文提出Execute-Summarize（ES）框架，通过将任务执行与工作流构建解耦，显著提升大语言模型生成结构化工作流的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在任务执行过程中同步构建工作流，容易因两个过程相互干扰而导致工作流不准确；因此需要一种能同时有效完成任务并可靠构建结构化工作流的新机制。

Method: 提出Execute-Summarize框架：首先让模型使用工具完成任务，然后基于执行轨迹独立重构结构化工作流；并通过新构建的FlowBench基准进行评估。

Result: 大量实验表明，该方法在工作流准确性与鲁棒性方面优于现有方法，并能有效将自由形式的大模型推理结果转化为结构化工作流。

Conclusion: Execute-Summarize框架为将大语言模型的推理能力可靠地落地为结构化工作流提供了一种有效范式。

Abstract: LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.

</details>


### [103] [Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation](https://arxiv.org/abs/2602.11790)
*Lingyong Yan,Jiulong Wu,Dong Xie,Weixian Shi,Deguo Xia,Jizhou Huang*

Main category: cs.AI

TL;DR: LAVES is a hierarchical LLM-based multi-agent system that automatically generates high-quality, logically rigorous instructional videos with precise audio-visual alignment, achieving high throughput and low cost.


<details>
  <summary>Details</summary>
Motivation: Existing end-to-end video generation models lack logical rigor and precise knowledge representation needed for educational content, suffering from low procedural fidelity, high cost, and poor controllability.

Method: LAVES employs a central Orchestrating Agent coordinating specialized agents (Solution, Illustration, Narration) with iterative critique, rule-based constraints, and tool-based checks; it produces structured executable scripts compiled via template-driven rules instead of direct pixel synthesis.

Result: LAVES achieves over 95% cost reduction versus industry standards, supports over one million videos per day, and maintains high acceptance rates in large-scale deployments.

Conclusion: By integrating multi-agent collaboration, explicit quality control, and deterministic script compilation, LAVES enables scalable, accurate, and cost-effective automated production of instructional videos.

Abstract: Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.

</details>


### [104] [Detecting RLVR Training Data via Structural Convergence of Reasoning](https://arxiv.org/abs/2602.11792)
*Hongbo Zhang,Yue Yang,Jianhao Yan,Guangsheng Bao,Yue Zhang,Yue Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Min-$k$NN Distance的黑盒检测方法，用于识别在强化学习带可验证奖励（RLVR）训练中见过的提示。该方法通过计算同一提示下多个生成结果之间最小的k个编辑距离均值，有效检测因RLVR训练导致的输出多样性下降现象，在多个模型上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 由于RLVR训练数据未公开，可能导致评测基准污染，而传统基于似然的检测方法对此类训练无效，因此亟需一种无需访问模型内部信息的新检测手段。

Method: 提出Min-$k$NN Distance方法：对给定提示采样多个生成结果，计算其k个最小近邻编辑距离的平均值，以此衡量输出多样性的坍缩程度。

Result: 实验表明，Min-$k$NN Distance能可靠地区分RLVR训练中见过与未见过的提示，并在多个RLVR训练的推理模型上优于现有的成员推断和污染检测方法。

Conclusion: RLVR训练会在模型行为上留下独特印记，表现为对训练中见过的提示生成更一致、多样性更低的输出；利用这一特性，Min-$k$NN Distance提供了一种简单有效的黑盒检测方案。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.

</details>


### [105] [Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation](https://arxiv.org/abs/2602.11799)
*Pingjun Pan,Tingting Zhou,Peiyao Lu,Tingting Fei,Hongxiang Chen,Chuanjiang Luo*

Main category: cs.AI

TL;DR: 本文提出Hi-SAM框架，通过解耦语义分词器和层次化记忆锚点Transformer，解决多模态推荐中语义分词冗余与模型结构-数据不匹配问题，在离线和线上实验中均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义ID的多模态推荐方法存在两个关键问题：一是分词过程中跨模态共享语义与模态特异性细节未解耦，导致信息冗余或坍塌；二是传统Transformer将语义ID视为扁平序列，忽略了用户-物品-令牌间的层次结构，引入噪声并偏向局部细节。

Method: Hi-SAM包含两个核心设计：(1) 解耦语义分词器（DST）：通过几何感知对齐统一多模态，并采用由粗到精的量化策略，利用共享码本提取共识、模态特定码本从残差中恢复细节，并通过互信息最小化强化解耦；(2) 层次化记忆锚点Transformer（HMAT）：通过层次化RoPE将位置编码分为物品间与物品内子空间以恢复层次结构，并引入锚点令牌压缩历史物品为紧凑记忆，仅保留当前物品细节。

Result: 在多个真实数据集上，Hi-SAM持续优于当前最优基线，尤其在冷启动场景下表现突出；在服务数百万用户的大型社交平台上线后，核心在线指标提升6.55%。

Conclusion: 通过显式建模多模态语义的解耦表示与用户-物品交互的层次结构，Hi-SAM有效提升了多模态推荐的准确性和鲁棒性，验证了结构感知设计在实际大规模系统中的有效性。

Abstract: Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.

</details>


### [106] [PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts](https://arxiv.org/abs/2602.11807)
*Lianjun Wu,Shengchen Zhu,Yuxuan Liu,Liuyu Kai,Xiaoduan Feng,Duomin Wang,Wenshuo Liu,Jingxuan Zhang,Kelvin Li,Bin Wang*

Main category: cs.AI

TL;DR: 本文提出PuYun-LDM，一种结合3D-MAE和变量感知频域建模（VA-MFM）的潜扩散模型，用于高分辨率集合天气预报，在短时效优于传统集合预报系统（ENS），长时效与之相当，并具备高效推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有潜扩散模型在高分辨率集合天气预报中受限于潜空间“可扩散性”不足；气象场缺乏通用基础模型和显式语义结构，使基于视觉基础模型（VFM）的正则化方法不适用；同时，现有频域方法对多变量气象数据采用统一频谱正则化，忽略了变量间频谱异质性，导致正则强度不均。

Method: 提出3D Masked AutoEncoder（3D-MAE）以编码天气状态演化特征作为扩散模型的额外条件，并设计Variable-Aware Masked Frequency Modeling（VA-MFM）策略，根据各变量的频谱能量分布自适应设定阈值，从而提升潜空间的可扩散性。

Result: PuYun-LDM在短预报时效上优于传统集合预报系统（ENS），在长时效上与其相当；可在单块NVIDIA H200 GPU上5分钟内完成15天、6小时间隔的全球预报，且支持并行生成集合成员。

Conclusion: 通过引入天气演化特征与变量感知的频域建模，有效提升了潜扩散模型在高分辨率集合天气预报中的性能与效率，为气象AI提供了新范式。

Abstract: Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25°) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.

</details>


### [107] [Predicting LLM Output Length via Entropy-Guided Representations](https://arxiv.org/abs/2602.11812)
*Huanyi Xie,Yubin Chen,Liangyu Wang,Lijie Hu,Di Wang*

Main category: cs.AI

TL;DR: 本文提出一种轻量级框架，利用大语言模型内部隐藏状态进行高效序列长度预测，显著减少因填充造成的计算浪费，并发布新基准ForeLen验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型服务和强化学习采样中，序列长度呈长尾分布，导致批处理推理中因过度填充而产生大量计算浪费；现有基于辅助模型的静态长度预测方法存在开销高、泛化差、无法应对随机“一对多”生成等问题。

Method: 提出包含两个核心组件的轻量级长度预测框架：1）熵引导的Token池化（EGTP），利用实时激活与token熵实现低成本高精度静态预测；2）渐进式长度预测（PLP），在每一步解码时动态估计剩余长度以处理随机生成。同时构建并开源了包含长序列、思维链和强化学习数据的综合评测基准ForeLen。

Result: 在ForeLen基准上，EGTP相比最佳基线将平均绝对误差（MAE）降低29.16%；结合长度感知调度器后，端到端吞吐量显著提升。

Conclusion: 该工作为高效大语言模型推理提供了新的技术路径与评估基准。

Abstract: The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic "one-to-many" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.

</details>


### [108] [Prototype Transformer: Towards Language Model Architectures Interpretable by Design](https://arxiv.org/abs/2602.11852)
*Yordan Yordanov,Matteo Forasassi,Bayar Menzat,Ruizhi Wang,Chang Qi,Markus Kaltenberger,Amine M'Charrak,Tommaso Salvatori,Thomas Lukasiewicz*

Main category: cs.AI

TL;DR: 本文提出了一种基于原型的新型自回归语言模型架构ProtoT，替代传统自注意力机制，在保持接近SOTA性能的同时，实现了可解释性、高效计算和行为可编辑性。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的语言模型虽然在某些任务上超越人类，但其推理过程不透明，易导致信任问题、欺骗和幻觉。因此，亟需构建既能高性能又具备内在可解释性的语言模型。

Method: 作者提出Prototype Transformer（ProtoT），利用参数化的“原型”向量与输入序列进行双向交互，替代标准的自注意力机制。原型在训练中自动学习可命名的概念，并形成不同时间尺度的信息聚合通道。

Result: ProtoT在文本生成和GLUE等下游任务上表现接近SOTA；计算复杂度随序列长度线性增长（优于自注意力的平方复杂度）；在模型和数据规模上具有良好扩展性；对输入扰动具有鲁棒性，并能通过原型路径揭示鲁棒性来源。

Conclusion: ProtoT为构建高性能且“设计即具可解释性”的自回归语言模型提供了新路径，兼具可解释性、可编辑性和计算效率。

Abstract: While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. "woman") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.

</details>


### [109] [Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models](https://arxiv.org/abs/2602.11860)
*Lu Tao,Jinxuan Luo,Yousuke Watanabe,Zhengshu Zhou,Yuhuan Lu,Shen Ying,Pan Zhang,Fei Zhao,Hiroaki Takada*

Main category: cs.AI

TL;DR: 本文提出Talk2DM模块，通过新型提示链机制（CoP）赋予车路云协同动态地图（DM）系统自然语言交互与常识推理能力，并基于自建仿真框架VRCsim和问答数据集VRC-QA验证其在多模型上的高准确率与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有动态地图（DM）系统缺乏自然语言支持的人机接口，限制了人与DM的高效交互；为提升车路云协同自动驾驶中人类对交通场景的理解与查询能力，亟需引入自然语言交互功能。

Method: 构建VRCsim仿真框架生成车路云协同感知数据，建立面向混合交通场景空间查询的VRC-QA数据集；在此基础上提出Talk2DM模块，采用链式提示（CoP）机制融合人工规则与大语言模型（LLM）的常识知识，实现即插即用的自然语言查询与推理。

Result: 在VRC-QA数据集上，Talk2DM在不同LLM（如Qwen3:8B、Gemma3:27B、GPT-oss）上均保持超过93%的自然语言查询准确率，平均响应时间仅2–5秒，展现出良好的泛化性与实用性。

Conclusion: Talk2DM有效弥补了现有动态地图系统在自然语言交互方面的不足，具备高准确率、低延迟和跨模型兼容性，具有显著的实际应用潜力，可推动车路云协同自动驾驶系统的人机协作水平。

Abstract: Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.

</details>


### [110] [From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders](https://arxiv.org/abs/2602.11881)
*Yifan Luo,Yang Zhan,Jiedong Jiang,Tianyang Liu,Mingrui Wu,Zhennan Zhou,Bin Dong*

Main category: cs.AI

TL;DR: 本文提出了一种分层稀疏自编码器（HSAE），通过联合学习多个稀疏自编码器及其特征间的父子关系，有效揭示了大语言模型中嵌入的多层次语义结构。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器（SAEs）通常孤立地提取单语义特征，忽略了大语言模型（LLMs）中自然语言所具有的层次化结构，特别是“特征分裂”现象表明特征之间存在层级关系，因此需要一种能捕捉这种结构的方法。

Method: 作者提出了分层稀疏自编码器（HSAE），通过引入结构约束损失和随机特征扰动机制，联合训练一系列SAE并建模其特征之间的父子关系。

Result: 在多种大语言模型和不同层上的实验表明，HSAE能够稳定地恢复出语义上有意义的层次结构，并在不同字典规模下保持与标准SAE相当的重构保真度和可解释性。

Conclusion: HSAE为发现和分析大语言模型表征中嵌入的多尺度概念结构提供了一种强大且可扩展的工具。

Abstract: Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of "feature splitting" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.

</details>


### [111] [When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation](https://arxiv.org/abs/2602.11908)
*Shani Goren,Ido Galil,Ran El-Yaniv*

Main category: cs.AI

TL;DR: 本文提出“选择性抽象”（Selective Abstraction, SA）框架，通过在不确定时降低回答的细节程度而非完全弃答，提升大语言模型（LLMs）在长文本生成中的可靠性与信息保留率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常因事实错误影响可信度，现有基于不确定性估计的“全有或全无”弃答机制在长文本场景中过于保守，会丢弃大量有价值信息。

Method: 将模型输出分解为原子声明（atomic claims），对不确定的原子声明替换为更泛化但更可靠的抽象表述；构建端到端评估流程，以事实正确性为风险指标、信息论方法衡量信息覆盖率。

Result: 在FactScore和LongFact-Objects基准上，针对六个开源模型，该方法在风险-覆盖率曲线下面积（AURC）上最高提升27.73%，优于现有基线。

Conclusion: 通过降低特定性换取可靠性，选择性抽象能在保持大部分原始语义的同时显著提升LLM输出的事实准确性与整体可靠性。

Abstract: LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary "all-or-nothing" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.

</details>


### [112] [AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution](https://arxiv.org/abs/2602.11917)
*Taian Guo,Haiyang Shen,Junyu Luo,Binqi Chen,Hongjun Ding,Jinsheng Huang,Luchen Liu,Yun Ma,Ming Zhang*

Main category: cs.AI

TL;DR: 本文提出AlphaPROBE框架，将因子挖掘建模为有向无环图（DAG）上的导航问题，通过贝叶斯检索器与DAG感知生成器提升因子发现的效率与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化alpha因子挖掘方法缺乏全局结构视角，导致搜索冗余和多样性不足。

Method: 构建AlphaPROBE框架：1）贝叶斯因子检索器平衡探索与利用；2）DAG感知因子生成器利用完整祖先路径生成非冗余优化因子。

Result: 在三个中国股市数据集上显著优于8个基线模型，在预测准确性、收益稳定性和训练效率方面均有提升。

Conclusion: 利用因子演化的全局拓扑结构对高效、鲁棒的自动化alpha发现至关重要。

Abstract: Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.

</details>


### [113] [MEME: Modeling the Evolutionary Modes of Financial Markets](https://arxiv.org/abs/2602.11918)
*Taian Guo,Haiyang Shen,Junyu Luo,Zhongshi Xing,Hanchun Lian,Jinsheng Huang,Binqi Chen,Luchen Liu,Yun Ma,Ming Zhang*

Main category: cs.AI

TL;DR: 本文提出MEME模型，通过建模金融市场中不断演化的投资逻辑（“思维模式”），利用多智能体提取高质量投资论点并结合高斯混合模型识别语义共识，从而在组合构建中优先考虑稳健的市场逻辑而非短期异常，实验证明其在中国股市上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的金融方法多采用资产中心或市场中心范式，忽视驱动市场变动的底层推理逻辑。作者旨在引入一种以逻辑为导向的新视角，将市场视为由竞争性投资叙事（即“思维模式”）构成的动态演化生态系统。

Method: 提出MEME框架：1）多智能体模块从噪声数据中提取高保真投资论点；2）在语义空间中使用高斯混合模型挖掘潜在共识；3）引入时序评估与对齐机制追踪不同市场条件下思维模式的语义漂移、生命周期及历史收益。

Result: 在2023–2025年三个异构中国股票池上的实验表明，MEME持续优于7种前沿基线方法；消融实验、敏感性分析、生命周期案例和成本分析进一步验证了其有效性和适应性。

Conclusion: 通过聚焦持久的市场智慧而非短期异常，MEME能有效识别并适应金融市场的演化共识，为基于逻辑驱动的投资决策提供新范式。

Abstract: LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.

</details>


### [114] [Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments](https://arxiv.org/abs/2602.11964)
*Romain Froger,Pierre Andrews,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Gerard Moreno-Torres Bertran,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Vladislav Vorotilov,Mengjue Wang,Ian Yu,Amine Benhalloum,Grégoire Mialon,Thomas Scialom*

Main category: cs.AI

TL;DR: Gaia2 是一个用于评估大语言模型智能体在真实、异步环境中表现的新基准，强调时间约束、动态事件适应、歧义处理与多智能体协作，并支持基于可验证奖励的强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有评估多为静态或同步环境，无法反映现实世界中环境独立演化、事件异步发生的复杂性。因此需要一个更贴近实际应用场景的基准来衡量和推动智能体能力的发展。

Method: Gaia2 构建了多个异步、动态的现实场景，每个场景配备写操作验证器（write-action verifier），实现细粒度的动作级评估；基于开源的 Agents Research Environments (ARE) 平台构建，便于扩展并支持强化学习训练。

Result: 在 Gaia2 上测试主流模型发现：GPT-5（high）以 42% pass@1 表现最佳但不擅长时间敏感任务；Claude-4 Sonnet 在准确性与速度间权衡以控制成本；开源模型中 Kimi-K2 最佳（21% pass@1）。各模型均未全面领先，凸显能力间的根本权衡。

Conclusion: Gaia2 揭示了当前智能体在推理、效率与鲁棒性之间的关键挑战，尤其在“仿真到现实”（sim2real）差距方面；通过开源发布 Gaia2 和 ARE 框架，为社区提供可扩展的基础设施以推动实用智能体系统的发展。

Abstract: We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the "sim2real" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.

</details>


### [115] [CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation](https://arxiv.org/abs/2602.12004)
*Robert Cronshaw,Konstantinos Vilouras,Junyu Yan,Yuning Du,Feng Chen,Steven McDonagh,Sotirios A. Tsaftaris*

Main category: cs.AI

TL;DR: 本文提出CSEval，一种利用语言模型评估医学生成图像与文本提示之间临床语义一致性的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像生成评估方法主要关注图像真实感或多样性，无法有效衡量生成图像是否准确反映临床语义（如解剖位置和病理特征），因此需要更可靠的评估手段以保障临床应用安全。

Method: 提出Clinical Semantics Evaluator（CSEval）框架，利用语言模型分析生成图像与其条件文本提示之间的临床语义对齐程度。

Result: 实验表明，CSEval能识别其他指标忽略的语义不一致问题，并与专家判断具有良好的相关性。

Conclusion: CSEval为现有评估方法提供了可扩展且具临床意义的补充，有助于推动生成模型在医疗领域的安全应用。

Abstract: Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.

</details>


### [116] [InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection](https://arxiv.org/abs/2602.12013)
*Xiuping Wu,Zhao Yu,Yuxin Cheng,Ngai Wong,Liangjun Ke,Tapas Mishra,Konstantinos V. Katsikopoulos*

Main category: cs.AI

TL;DR: 本文提出两种无需参数更新的推理优化方法（InjectCorrect 和 InjectRLOpt），通过注入模型自身历史行为模式来提升大语言模型在各类推理任务中的表现，分别最高提升5.34%和8.67%。


<details>
  <summary>Details</summary>
Motivation: 现有基于行为提示调整的推理增强方法缺乏对模型推理行为模式的系统性分析，作者旨在从行为模式视角深入理解并优化模型推理过程。

Method: 提出两种无参数更新的方法：InjectCorrect 通过模仿模型过往正确回答中的行为模式进行引导；InjectRLOpt 则从历史行为数据中学习价值函数，并结合提出的可靠性感知Softmax策略，在推理时生成行为注入信号以引导推理。

Result: 在多种推理任务上，两种方法均显著提升模型性能，且无需修改模型参数，分别实现最高5.34%和8.67%的性能增益。

Conclusion: 模型在面对特定问题时展现出自适应的推理行为分布，结构化地注入这些行为模式可有效提升推理质量，为无需训练的推理优化提供了新思路。

Abstract: Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.

</details>


### [117] [LawThinker: A Deep Research Legal Agent in Dynamic Environments](https://arxiv.org/abs/2602.12056)
*Xinyu Yang,Chenlong Deng,Tongyu Wen,Binyu Xie,Zhicheng Dou*

Main category: cs.AI

TL;DR: 本文提出LawThinker，一种采用Explore-Verify-Memorize策略的自主法律推理智能体，通过在每一步知识探索后强制验证，显著提升法律推理过程的准确性与程序合规性。


<details>
  <summary>Details</summary>
Motivation: 现有法律推理方法缺乏对中间推理步骤的验证机制，导致如引用不适用法条等错误在推理链中未被发现，影响推理过程的合规性与可靠性。

Method: LawThinker引入DeepVerifier模块，在每次知识检索后从知识准确性、事实-法律相关性及程序合规性三个维度进行验证，并结合记忆模块支持跨轮次知识复用，适用于动态司法环境中的长程任务。

Result: 在动态基准J1-EVAL上，LawThinker相比直接推理提升24%，比基于工作流的方法提升11%，尤其在过程导向指标上表现突出；在三个静态基准上也展现出良好泛化能力。

Conclusion: 通过将验证作为原子操作嵌入推理流程，LawThinker有效提升了法律推理的正确性与程序合规性，为构建可信赖的法律AI系统提供了新思路。

Abstract: Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .

</details>


### [118] [The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context](https://arxiv.org/abs/2602.12108)
*Xiaoyuan Liu,Tian Liang,Dongyang Ma,Deyu Zhou,Haitao Mi,Pinjia He,Yan Wang*

Main category: cs.AI

TL;DR: 本文提出StateLM，一种具备内部推理循环的基础模型，能主动管理自身记忆状态，显著提升在长文档问答、聊天记忆和深度研究任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型缺乏主动管理外部记忆的能力，只能被动接受固定上下文，限制了其在复杂任务中的表现。

Method: 为模型引入内部推理循环和多种记忆工具（如上下文剪枝、文档索引、笔记记录），并通过训练使其能动态构建和管理自身上下文。

Result: StateLM在各类模型规模下均优于标准LLM：在长文档问答中持续领先；在聊天记忆任务中准确率提升10%-20%；在BrowseComp-Plus任务中达到52%准确率，远超标准LLM的约5%。

Conclusion: 该方法使大语言模型从被动预测者转变为具备状态感知能力的智能体，将推理过程变为可管理的有状态过程。

Abstract: In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the "wand" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.

</details>


### [119] [Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty](https://arxiv.org/abs/2602.12113)
*Zewei Yu,Lirong Gao,Yuke Zhu,Bo Zheng,Sheng Guo,Haobo Wang,Junbo Zhao*

Main category: cs.AI

TL;DR: 本文提出ARLCP方法，通过自适应反射惩罚与长度协调惩罚机制，在保持甚至提升准确率的同时显著减少大推理模型的推理长度和计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂推理任务中常因过度反思（如重复自问、循环推理）生成冗长思维链，导致高token消耗、计算开销和延迟，且不提升准确率，尤其在较小模型中更为严重。问题复杂度越高，此类无效反思越严重，反而降低准确率并增加开销。

Method: 提出一种名为ARLCP的强化学习框架，包含两个核心机制：(1) 自适应反射惩罚，动态削减不必要的反思步骤但保留关键推理；(2) 与问题复杂度估计相匹配的长度惩罚。两者协同促使模型生成更简洁有效的推理路径。

Result: 在五个数学推理基准上对DeepSeek-R1-Distill-Qwen-1.5B和7B模型进行评估。1.5B模型平均响应长度减少53.1%，准确率提升5.8%；7B模型长度减少35.0%，准确率提升2.7%，优于现有方法。

Conclusion: ARLCP有效平衡了推理效率与准确率，显著压缩推理长度同时提升性能，为高效推理提供了新思路。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .

</details>


### [120] [HLA: Hadamard Linear Attention](https://arxiv.org/abs/2602.12128)
*Hanno Ackermann,Hong Cai,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.AI

TL;DR: 本文提出了一种新的线性注意力机制——Hadamard Linear Attention（HLA），通过在计算token间相似度后引入非线性，以更高阶的有理函数逼近softmax，从而在保持计算效率的同时提升性能，尤其适用于处理大量token的视频生成任务。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer中的注意力机制计算复杂度为二次方，难以扩展到长序列或大规模应用。现有线性注意力方法虽能降低计算成本，但其对softmax的近似精度有限，且常需复杂的张量重塑操作。因此，作者旨在设计一种更高效、更准确的线性注意力机制。

Method: 提出Hadamard Linear Attention（HLA），其非线性操作作用于查询与键之间的成对相似度之后，而非分别作用于查询和键。该方法可被解释为使用高阶有理函数逼近softmax，并推导出一种无需张量重塑的高效计算方案。

Result: 在大型视频生成扩散Transformer模型上的实验表明，HLA在处理大量token时有效，兼顾了计算效率与模型表现。

Conclusion: HLA通过改进非线性引入方式，实现了对softmax更精确的高阶有理函数近似，在保持线性计算复杂度的同时避免了额外的张量操作，为大规模序列建模提供了一种高效可行的注意力机制。

Abstract: The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.
  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.

</details>


### [121] [Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5](https://arxiv.org/abs/2602.12133)
*Roberto Balestri*

Main category: cs.AI

TL;DR: 该研究发现，即使使用语义中性的提示词，主流图像生成模型（Gemini Flash 2.5 和 GPT Image 1.5）仍会生成具有显著性别与肤色偏见的图像，表现为“默认白人”倾向及性别偏好差异。


<details>
  <summary>Details</summary>
Motivation: 检验“中性提示词会产生人口统计学上中立的输出”这一假设是否成立，并揭示当前商业图像生成模型中的隐性偏见。

Method: 通过四个语义中性提示生成3,200张逼真图像，采用混合色彩归一化、面部关键点遮罩和基于Monk、PERLA与Fitzpatrick量表的感知均匀肤色量化方法进行分析。

Result: 两个模型均表现出强烈的“默认白人”偏见（>96%），但在性别上呈现相反倾向：Gemini偏向女性形象，GPT偏向浅肤色男性形象。

Conclusion: 中性提示词实际上充当了诊断探针而非中立指令；研究提供了一种可复现的视觉算法偏见审计框架，并挑战了“无标记语言即包容”的社会语言学假设。

Abstract: This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong "default white" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.

</details>


### [122] [Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment](https://arxiv.org/abs/2602.12134)
*Jiajun Chen,Hua Shen*

Main category: cs.AI

TL;DR: 本文提出价值对齐税（VAT）框架，用于衡量大语言模型在对齐干预下目标价值提升的同时，其他关联价值如何系统性地发生变化，揭示了传统仅评估目标价值所忽略的对齐过程风险。


<details>
  <summary>Details</summary>
Motivation: 现有价值对齐研究多静态刻画价值关系，忽视了对齐干预（如提示、微调、偏好优化）如何动态重塑整个价值体系，因此需要一个能捕捉这种动态变化的评估框架。

Method: 作者基于Schwartz价值理论构建受控的情境-行动数据集，收集模型在对齐干预前后的规范性判断配对数据，并通过提出的VAT框架分析不同模型、价值维度和对齐策略下的价值表达变化。

Result: 研究发现，对齐干预常导致价值观之间出现不均衡但结构化的协同变动，这种效应在仅关注目标价值的传统评估中无法被察觉。

Conclusion: VAT框架揭示了价值对齐过程中存在的系统性、过程级风险，为理解大语言模型中价值对齐的动态机制提供了新视角。

Abstract: Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.

</details>


### [123] [STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction](https://arxiv.org/abs/2602.12143)
*Xiaoxiao Wang,Chunxiao Li,Junying Wang,Yijin Guo,Zijian Chen,Chunyi Li,Xiaohong Liu,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: STAR 是一个结合统计期望与知识驱动推理的框架，用于在极稀疏观测条件下准确预测大模型性能，并提供可解释的调整结果。


<details>
  <summary>Details</summary>
Motivation: 全面评估大模型成本过高，而现有方法在面对模式偏移、数据稀疏和缺乏可解释性时表现不佳，亟需一种更可靠且高效的性能预测方法。

Method: STAR 框架融合了数据驱动的统计期望与知识驱动的智能体推理：通过专用检索器获取外部知识，将其语义特征嵌入到约束概率矩阵分解（CPMF）中生成带不确定性的统计期望；再利用基于期望违反理论（EVT）的推理模块，通过族内分析、跨模型比较和可信度感知聚合来优化预测并生成可追溯的解释。

Result: 在极端稀疏条件下（每个测试模型仅有1–2个观测分数），STAR 在得分和排序指标上均显著优于所有基线方法，相比最强的统计方法总分提升14.46%。

Conclusion: STAR 有效解决了大模型性能预测中的稀疏性与可解释性难题，为高效、可靠的大模型评估提供了新范式。

Abstract: As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.

</details>


### [124] [Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning](https://arxiv.org/abs/2602.12146)
*Mahdi Khodabandeh,Ghazal Shabani,Arash Yousefi Jordehi,Seyed Abolghasem Mirroshandel*

Main category: cs.AI

TL;DR: 本文提出一种基于强化学习与T5语言模型的无损压缩方法，通过保留原始数据的token结构，在不依赖外部知识的情况下实现更高的压缩比。


<details>
  <summary>Details</summary>
Motivation: 传统压缩方法难以有效利用复杂数据中的结构和冗余，而现有深度学习方法常使用稠密向量表示，掩盖了原始token结构，限制了压缩效率与语义完整性。

Method: 将强化学习（特别是off-policy算法）应用于T5语言模型，将数据压缩为token序列而非连续向量，保留原始token结构，并优化序列长度以减少冗余。

Result: 所提方法在压缩比上显著优于传统压缩技术，同时无需显式理解内容或依赖外部语法/世界知识。

Conclusion: 该方法通过结合语言模型的潜在信息与强化学习，实现了高效、自适应且结构保持的无损压缩，为多种应用场景提供了更实用的压缩解决方案。

Abstract: Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.

</details>


### [125] [GPT-4o Lacks Core Features of Theory of Mind](https://arxiv.org/abs/2602.12150)
*John Muchovej,Amanda Royka,Shane Lee,Julian Jara-Ettinger*

Main category: cs.AI

TL;DR: 尽管大语言模型（LLMs）在简单心理理论（ToM）任务中表现良好，但它们缺乏一致、通用的心理状态因果模型，表明其社交能力并非源于真正的ToM。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅通过行为表现评估LLMs是否具备心理理论（ToM），但未检验其是否拥有对心理状态与行为之间因果关系的内部表征。本文旨在提出一种基于认知科学的ToM定义，并据此构建新的评估框架。

Method: 采用认知科学中对ToM的定义，设计新评估方法，测试LLMs是否具备连贯、领域通用且一致的心理状态因果模型，包括在逻辑等价任务中的表现及行为预测与心理状态推断之间的一致性。

Result: LLMs虽能在简单ToM任务中模拟人类判断，但在逻辑等价任务中失败，且其行为预测与心理状态推断之间一致性较低。

Conclusion: LLMs展现出的社交能力并非源于一个连贯、通用或一致的心理理论，表明其不具备真正意义上的ToM。

Abstract: Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.

</details>


### [126] [Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision](https://arxiv.org/abs/2602.12164)
*Xiaohan He,Shiyang Feng,Songtao Huang,Lei Bai,Bin Wang,Bo Zhang*

Main category: cs.AI

TL;DR: 本文提出Sci-CoE，一种两阶段科学协同进化框架，通过从稀疏监督过渡到无监督学习，使大语言模型在解题者与验证者角色中自我进化，从而提升科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在科学推理任务中表现脆弱，主要由于解决方案评估不可靠以及验证策略多样性不足。

Method: Sci-CoE包含两个阶段：第一阶段利用少量标注数据为验证器建立正确性判断锚点；第二阶段引入几何奖励机制，在未标注数据上进行大规模自迭代，该机制综合考虑共识性、可靠性和多样性。

Result: 在多个通用科学基准上的实验表明，Sci-CoE显著增强了复杂推理能力，并展现出良好的可扩展性。

Conclusion: Sci-CoE有助于构建更鲁棒、更多样的评估系统，推动大语言模型在科学推理领域的应用。

Abstract: Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.

</details>


### [127] [Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation](https://arxiv.org/abs/2602.12172)
*Bowei He,Yankai Chen,Xiaokun Zhang,Linghe Kong,Philip S. Yu,Xue Liu,Chen Ma*

Main category: cs.AI

TL;DR: 本文提出了一种受教育学启发的LLM知识蒸馏框架IOA，通过三阶段流程（识别、组织、适配）系统化提升小模型性能，在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于合成数据的知识蒸馏方法缺乏教学意识，将知识迁移视为一次性任务，而非系统化的学习过程。作者希望借鉴教育学原理，构建更高效、结构化的蒸馏机制。

Method: 提出IOA三阶段框架：Knowledge Identifier识别学生模型的知识缺陷，Organizer依据Bloom掌握学习原则和维果茨基最近发展区理论设计渐进式课程，Adapter则调整知识表示以匹配学生模型的认知能力。

Result: 在LLaMA-3.1/3.2和Qwen2.5等小模型上实验表明，IOA在DollyEval上保留教师模型94.7%的性能（参数量不到1/10），在MATH和HumanEval上分别比SOTA基线提升19.2%和22.3%。

Conclusion: 融合教育学原理的知识蒸馏框架能显著提升小模型在复杂推理任务上的表现，为高效AI系统部署提供新思路。

Abstract: Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.

</details>


### [128] [SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation](https://arxiv.org/abs/2602.12173)
*Chengxi Zeng,Yuxuan Jiang,Ge Gao,Shuai Wang,Duolikun Danier,Bin Zhu,Stevan Rudinac,David Bull,Fan Zhang*

Main category: cs.AI

TL;DR: 本文提出SAM3-LiteText，通过用轻量级MobileCLIP替代SAM3中原有的大型文本编码器，在减少88%参数的同时保持相近的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言分割模型（如SAM3）使用为通用语言理解设计的大型文本编码器，但实际分割提示短小、结构化且语义受限，导致计算与内存资源严重浪费。

Method: 对404,796条真实提示进行大规模分析，发现文本提示存在上下文窗口利用率低、词汇稀疏、嵌入维度冗余等问题；据此提出SAM3-LiteText，采用知识蒸馏训练的轻量级MobileCLIP文本编码器替代原模型。

Result: 在图像和视频分割基准上，SAM3-LiteText将文本编码器参数减少最多88%，显著降低静态内存占用，同时保持与原始模型相当的分割性能。

Conclusion: 针对视觉-语言分割任务定制轻量文本编码器是可行且高效的，能大幅节省资源而不牺牲性能。

Abstract: Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.

</details>


### [129] ["Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most](https://arxiv.org/abs/2602.12249)
*Kaitlyn Zhou,Martijn Bartelds,Federico Bianchi,James Zou*

Main category: cs.AI

TL;DR: 尽管语音识别系统在标准基准上表现良好，但在现实高风险场景（如美国街道名称转录）中错误率高达44%。研究发现非英语母语者受影响更严重，而使用不到1000条合成语音样本微调模型可将非英语母语者的转录准确率相对提升近60%。


<details>
  <summary>Details</summary>
Motivation: 揭示当前语音识别系统在高风险、短语句真实场景（如街道名转录）中的性能缺陷，特别是对语言多样性人群的不公平影响，并提出有效缓解方法。

Method: 评估15个主流语音识别模型在美国语言多样化人群录音上的街道名转录表现；分析错误对地理定位和导航距离的影响；利用开源文本到语音模型生成多样发音的合成数据，对模型进行微调。

Result: 平均转录错误率达44%；非英语母语者的导航距离误差是英语母语者的两倍；使用少于1000条合成样本微调后，非英语母语者的街道名转录准确率相对提升近60%。

Conclusion: 语音识别系统在标准基准与真实高风险场景间存在显著差距，合成数据微调是一种简单且可扩展的解决方案，能有效减少对弱势语言群体的高风险转录错误。

Abstract: Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.

</details>


### [130] [Think like a Scientist: Physics-guided LLM Agent for Equation Discovery](https://arxiv.org/abs/2602.12259)
*Jianke Yang,Ohm Venkatachalam,Mohammad Kianezhad,Sharvaree Vadgama,Rose Yu*

Main category: cs.AI

TL;DR: KeplerAgent 是一个基于智能体的框架，通过模拟科学家的多步推理过程（如先推断对称性等物理性质，再以此约束符号回归）来提升从数据中发现可解释符号公式的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的符号公式发现方法通常直接从数据猜测方程，忽略了科学家常用的多步推理过程，导致在噪声数据下表现不佳且缺乏可解释性。

Method: KeplerAgent 利用物理工具提取数据中的中间结构（如对称性），并将这些信息作为先验用于配置符号回归引擎（如 PySINDy 和 PySR）的函数库和结构约束。

Result: 在多个物理方程基准测试中，KeplerAgent 在符号准确性与抗噪能力方面显著优于现有 LLM 方法和传统基线。

Conclusion: 将科学推理过程显式建模为智能体行为，能有效提升符号公式发现的性能与可靠性，为可解释科学发现提供新范式。

Abstract: Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.

</details>


### [131] [CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use](https://arxiv.org/abs/2602.12268)
*Zhen Zhang,Kaiqiang Song,Xun Wang,Yebowen Hu,Weixiang Yan,Chenyang Zhao,Henry Peng Zou,Haoyun Deng,Sathish Reddy Indurthi,Shujian Liu,Simin Ma,Xiaoyang Wang,Xin Eric Wang,Song Wang*

Main category: cs.AI

TL;DR: CM2 是一种用于多轮、多步骤工具使用智能体的强化学习框架，通过引入基于检查清单的奖励机制替代传统可验证奖励，在无需复杂环境构建的情况下显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在现实世界任务中，AI 智能体常需通过多轮交互和调用外部工具进行推理，但强化学习在此类场景中面临三大挑战：缺乏可验证奖励、多步工具使用 RL 研究不足，以及构建可执行工具环境成本高、难以扩展。

Method: CM2 将每轮行为分解为细粒度的二元判断标准，结合明确证据和结构化元数据，将开放式评估转化为稳定的分类式决策；采用稀疏奖励分配但密集评估标准的策略，并在 LLM 模拟的工具环境中进行训练，避免高昂工程开销。

Result: 在多个基准（tau^-Bench、BFCL-V4、ToolSandbox）上，CM2 相比监督微调分别提升 8、10 和 12 分，性能媲美甚至超越同规模开源基线模型。

Conclusion: CM2 提供了一种可扩展、不依赖可验证奖励的强化学习方案，有效优化多轮多步骤工具使用智能体。

Abstract: AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.

</details>


### [132] [Agentic Test-Time Scaling for WebAgents](https://arxiv.org/abs/2602.12276)
*Nicholas Lee,Lutfi Eren Erdogan,Chris Joseph John,Surya Krishnapillai,Michael W. Mahoney,Kurt Keutzer,Amir Gholami*

Main category: cs.AI

TL;DR: 本文提出CATTS，一种基于置信度的动态计算分配方法，用于提升多步智能体在长周期任务中的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展（test-time scaling）在多步智能体任务中效果不佳，均匀增加每步计算资源易导致收益递减，且小错误会在长周期任务中累积。因此需要更高效的动态计算分配策略。

Method: 作者首先对Web智能体的推理时扩展行为进行实证研究，发现统一增加每步计算很快饱和；接着探索更强的聚合策略（如基于LLM的仲裁器），并利用投票分布中的不确定性统计量（如熵和top-1/top-2间隔）作为动态分配计算的信号；最终提出CATTS方法，仅在决策存在争议时才增加计算资源。

Result: CATTS在WebArena-Lite和GoBrowse上相比React最多提升9.1%性能，同时比均匀扩展节省高达2.3倍的token使用。

Conclusion: 利用智能体自身投票分布导出的不确定性指标可有效指导测试时计算资源的动态分配，CATTS在提升性能的同时显著提高效率，并提供可解释的决策规则。

Abstract: Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [133] [An Improved Upper Bound for the Euclidean TSP Constant Using Band Crossovers](https://arxiv.org/abs/2602.11250)
*Julia Gaudio,Charlie K. Guan*

Main category: cs.CG

TL;DR: 本文研究旅行商问题（TSP）中单位正方形内随机点集的最优路径长度常数β的上界，通过改进带状遍历策略并结合模拟与数值分析，将已知上界从0.90380略微改进至0.90367，并提出一种新启发式方法有望进一步将上界降至约0.85。


<details>
  <summary>Details</summary>
Motivation: 精确确定Beardwood-Halton-Hammersley定理中的常数β极具挑战，目前仅知其大致范围。尽管已有研究通过计算机辅助方法改进了上界，但进一步压缩上界仍具理论与实践意义。本文旨在探索更有效的构造性方法以逼近β的真实值。

Method: 作者在Beardwood等人提出的“带状遍历”策略基础上进行改进：将单位正方形划分为高度为Θ(1/√n)的水平带，允许路径跨越相邻带，并利用相邻带中距离较近的点对来优化局部路径。通过模拟和集中性分析评估该方法的潜力，并辅以严格的数值计算来验证上界的改进。

Result: 通过严格的数值分析，将β的上界从0.90380小幅改进至0.90367。模拟结果表明，所提出的启发式方法有潜力将上界进一步降低至约0.85，但同时也指出未来通过现有计算机辅助方法将上界降至0.88以下存在较大困难。

Conclusion: 本文通过对经典带状遍历策略的创新性改进，为TSP常数β的上界研究提供了新思路和更优的数值结果。虽然理论上的严格证明仍有待完成，但模拟和初步分析展示了该方法的有效性和进一步优化的潜力。

Abstract: Consider $n$ points generated uniformly at random in the unit square, and let $L_n$ be the length of their optimal traveling salesman tour. Beardwood, Halton, and Hammersley (1959) showed $L_n / \sqrt n \to β$ almost surely as $n\to \infty$ for some constant $β$. The exact value of $β$ is unknown but estimated to be approximately $0.71$ (Applegate, Bixby, Chvátal, Cook 2011). Beardwood et al. further showed that $0.625 \leq β\leq 0.92116.$ Currently, the best known bounds are $0.6277 \leq β\leq 0.90380$, due to Gaudio and Jaillet (2019) and Carlsson and Yu (2023), respectively. The upper bound was derived using a computer-aided approach that is amenable to lower bounds with improved computation speed. In this paper, we show via simulation and concentration analysis that future improvement of the $0.90380$ is limited to $\sim0.88$. Moreover, we provide an alternative tour-constructing heuristic that, via simulation, could potentially improve the upper bound to $\sim0.85$. Our approach builds on a prior \emph{band-traversal} strategy, initially proposed by Beardwood et al. (1959) and subsequently refined by Carlsson and Yu (2023): divide the unit square into bands of height $Θ(1/\sqrt{n})$, construct paths within each band, and then connect the paths to create a TSP tour. Our approach allows paths to cross bands, and takes advantage of pairs of points in adjacent bands which are close to each other. A rigorous numerical analysis improves the upper bound to $0.90367$.

</details>


### [134] [An Improved FPT Algorithm for Computing the Interleaving Distance between Merge Trees via Path-Preserving Maps](https://arxiv.org/abs/2602.12028)
*Althaf P,Amit Chattopadhyay,Osamu Saeki*

Main category: cs.CG

TL;DR: 本文提出了一种改进的固定参数可追踪（FPT）算法，用于高效计算两棵合并树之间的 ε-良好映射，从而更有效地逼近交错距离。


<details>
  <summary>Details</summary>
Motivation: 交错距离是衡量合并树之间相似性的稳定度量，但其精确计算是 NP-hard 问题。现有 FPT 算法在参数 τ（与 ε 相关的度数上界）下具有指数复杂度，限制了实际应用。因此，作者旨在设计一个更高效的算法，降低对 ε 的依赖并缩小搜索空间。

Method: 作者引入两个新参数 η_f 和 η_g，分别表示两棵合并树中叶节点的数量，并基于合并树可分解为若干唯一叶到根路径的观察，设计了一个新的 FPT 算法。该算法假设从 M_f 到 M_g 的 ε-良好映射数量不超过反向映射数量，从而减少搜索空间。

Result: 所提算法的时间复杂度为 O(n² log n + η_g^{η_f}(η_f+η_g) n log n)，其中 η_f 和 η_g 与 ε 无关，相比已有方法显著降低了计算复杂度。

Conclusion: 本文提出的算法通过引入叶节点数量作为参数，有效减少了交错距离计算中的搜索空间，并提供了算法正确性的形式化证明，为合并树比较提供了更实用的计算工具。

Abstract: A merge tree is a fundamental topological structure used to capture the sub-level set (and similarly, super-level set) topology in scalar data analysis. The interleaving distance is a theoretically sound, stable metric for comparing merge trees. However, computing this distance exactly is NP-hard. First fixed-parameter tractable (FPT) algorithm for it's exact computation introduces the concept of an $\varepsilon$-good map between two merge trees, where $\varepsilon$ is a candidate value for the interleaving distance. The complexity of their algorithm is $O(2^{2τ}(2τ)^{2τ+2}\cdot n^2\log^3n)$ where $τ$ is the degree-bound parameter and $n$ is the total number of nodes in both the merge trees. Their algorithm exhibits exponential complexity in $τ$, which increases with the increasing value of $\varepsilon$. In the current paper, we propose an improved FPT algorithm for computing the $\varepsilon$-good map between two merge trees. Our algorithm introduces two new parameters, $η_f$ and $η_g$, corresponding to the numbers of leaf nodes in the merge trees $M_f$ and $M_g$, respectively. This parametrization is motivated by the observation that a merge tree can be decomposed into a collection of unique leaf-to-root paths. The proposed algorithm achieves a complexity of $O\!\left(n^2\log n+η_g^{η_f}(η_f+η_g)\, n \log n \right)$. To obtain this reduced complexity, we assume that number of possible $\varepsilon$-good maps from $M_f$ to $M_g$ does not exceed that from $M_g$ to $M_f$. Notably, the parameters $η_f$ and $η_g$ are independent of the choice of $\varepsilon$. Compared to their algorithm, our approach substantially reduces the search space for computing an optimal $\varepsilon$-good map. We also provide a formal proof of correctness for the proposed algorithm.

</details>
