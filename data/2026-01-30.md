<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 76]
- [cs.AI](#cs.AI) [Total: 79]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 本文提出了一种针对非马尔可夫多轮对话图像生成的训练与推理框架，通过引入回滚编辑、基于名称的个性化绑定、历史条件建模和高保真重建等方法，显著提升了模型在多轮交互中的一致性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有大多数多轮图像生成基准和训练方法假设系统行为是马尔可夫的，即仅依赖最近一轮的图像，忽略了更早的历史上下文。然而真实场景中用户可能引用早期状态、撤销操作或提及多轮前引入的实体，因此需要建模非马尔可夫的长程依赖。

Method: 作者提出了三项关键技术：(i) 构建非马尔可夫多轮数据，包括强制回溯早期视觉状态的回滚式编辑和跨轮次绑定名称与外观的个性化策略；(ii) 历史条件化的训练与推理框架，结合token级缓存以防止身份漂移；(iii) 改进图像重建与可编辑个性化，包括基于重建的DiT解码器和多阶段微调课程。

Result: 实验表明，显式针对非马尔可夫交互进行训练，显著提升了多轮一致性与指令遵循能力，同时保持了强大的单轮编辑和个性化性能。

Conclusion: 建模非马尔可夫多轮上下文对实现真正连贯、可控的对话式图像生成至关重要，所提方法为未来多模态对话系统提供了有效路径。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [2] [Text controllable PET denoising](https://arxiv.org/abs/2601.20990)
*Xuehua Ye,Hongxu Yang,Adam J. Schwarz*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本引导的PET图像去噪方法，利用预训练CLIP模型与U-Net结构，在不同计数水平下有效提升图像质量。


<details>
  <summary>Details</summary>
Motivation: PET图像常受复杂噪声影响，降低诊断准确性；现有方法难以在单一模型中适应多种计数水平的去噪需求。

Method: 结合预训练CLIP模型的文本特征与U-Net架构，构建文本引导的去噪模型，实现对不同剂量/计数水平PET图像的统一增强。

Result: 所提方法在定性和定量评估中均显著优于现有方法，展现出良好的泛化能力和临床应用潜力。

Conclusion: 该文本引导去噪框架灵活高效，有望满足更复杂的去噪需求或缩短PET扫描时间。

Abstract: Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.

</details>


### [3] [Low performing pixel correction in computed tomography with unrolled network and synthetic data training](https://arxiv.org/abs/2601.20995)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Lehel Ferenczi,Gopal Avinash*

Main category: cs.CV

TL;DR: 本文提出了一种基于合成数据的双域展开方法，用于校正CT探测器中的低性能像素（LPP）伪影，无需真实临床数据训练，且在模拟实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LPP伪影校正方法依赖昂贵的真实临床数据进行监督训练，且仅在图像域或正弦图域单独处理，忽略了CT几何前向操作中两个域之间的内在关联。

Method: 提出一种基于合成数据的双域展开方法，利用自然图像生成的合成数据建模正弦图域与图像域之间LPP的内在关联，实现无需真实数据的端到端训练。

Result: 在模拟1-2%探测器缺陷靠近等中心的实验中，所提方法在伪影校正效果上大幅优于当前最先进方法。

Conclusion: 该方法无需收集真实临床数据即可有效校正LPP伪影，具备良好的泛化能力，可适配不同扫描仪设置，适用于软件部署。

Abstract: Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.

</details>


### [4] [AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples](https://arxiv.org/abs/2601.21022)
*Andrea Camilloni,Chiara Micoli,Nita Mulliqi,Erik Everett Palm,Thorgerdur Palsdottir,Kelvin Szolnoky,Xiaoyi Ji,Sol Erika Boman,Andrea Discacciati,Henrik Grönberg,Lars Egevad,Tobias Nordström,Kimmo Kartasalo,Martin Eklund*

Main category: cs.CV

TL;DR: 该研究开发了一种基于前列腺活检切片的AI模型，用于预测根治性前列腺切除术后生化复发（BCR）风险，在多个外部队列中表现出良好泛化能力，并在结合临床变量后提升了预后分层效果。


<details>
  <summary>Details</summary>
Motivation: 当前用于预测前列腺癌术后生化复发的预后工具不够精确，亟需更可靠的方法来识别高风险患者以优化治疗决策。

Method: 利用STHLM3队列（n=676）的诊断性前列腺活检切片，结合基础模型与基于注意力机制的多实例学习方法训练AI模型；在LEOPARD、CHIMERA和TCGA-PRAD三个外部根治术队列中评估其泛化性能，并与CAPRA-S指南模型进行比较；同时整合临床变量以评估多模态预测价值。

Result: 该图像模型在三个外部队列中5年时间依赖AUC分别为0.64、0.70和0.70；结合临床变量后显著改善风险分层效果，且优于传统CAPRA-S评分。

Conclusion: 基于活检训练的组织病理AI模型可跨样本类型泛化，有助于术前与术后决策，但其相较于简单预测模型的增量价值仍需在后续研究中审慎评估。

Abstract: Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.

</details>


### [5] [BadDet+: Robust Backdoor Attacks for Object Detection](https://arxiv.org/abs/2601.21066)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 本文提出BadDet+，一种基于惩罚机制的后门攻击框架，统一了区域误分类攻击（RMA）与目标消失攻击（ODA），在保持干净样本性能的同时，显著提升合成到物理世界的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对目标检测的后门攻击方法依赖不切实际的假设且缺乏物理验证，作者旨在弥补这一研究空白，揭示目标检测模型在此类攻击下的真实脆弱性。

Method: BadDet+采用对数障碍惩罚机制，在触发样本输入时抑制真实类别预测，实现位置与尺度不变性，并增强物理鲁棒性；该机制作用于特定触发器的特征子空间。

Result: 在真实世界基准测试中，BadDet+在合成到物理的迁移效果上优于现有RMA和ODA基线方法，同时保持良好的干净样本性能。

Conclusion: 目标检测系统存在显著的后门漏洞，需开发专门的防御机制；BadDet+为理解与评估此类威胁提供了有效工具。

Abstract: Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.

</details>


### [6] [Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization](https://arxiv.org/abs/2601.21078)
*Jiaqi Li,Guangming Wang,Shuntian Zheng,Minzhe Ni,Xiaoman Lu,Guanghui Ye,Yu Guan*

Main category: cs.CV

TL;DR: 本文提出ActionVLM，一种用于时序动作定位的视觉-语言融合框架，通过动态重加权和残差聚合策略缓解模态偏差，在THUMOS14上超越现有方法最高达3.2% mAP。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言模型（VLM）的时序动作定位方法过度依赖语言先验，忽视视觉信号，导致显著的模态偏差，影响定位性能。

Method: 提出ActionVLM框架，包含两个核心组件：(i) 去偏重加权模块，动态评估语言相对于纯视觉预测的增益并据此调整语言模态权重；(ii) 残差聚合策略，将语言作为对视觉主导信号的补充优化而非主要驱动。

Result: 在THUMOS14数据集上的实验表明，该方法相较当前最优方法提升最高达3.2% mAP。

Conclusion: 通过保留视觉主导地位并自适应利用语言信息，ActionVLM有效缓解了模态偏差，降低了语言先验带来的过自信问题，增强了时序推理能力。

Abstract: Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.

</details>


### [7] [Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought](https://arxiv.org/abs/2601.21081)
*Yu Huo,Siyu Zhang,Kun Zeng,Haoyue Liu,Owen Lee,Junlin Chen,Yuquan Lu,Yifu Guo,Yaodong Liang,Xiaoying Tang*

Main category: cs.CV

TL;DR: 本文提出Shape-of-Thought（SoT）框架，通过在推理时无需外部引擎的连贯2D投影实现渐进式形状组装，显著提升文本到图像生成模型在组合结构约束下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型虽具备高视觉保真度，但在组合结构约束（如生成数值能力、属性绑定和部件级关系）方面表现脆弱，亟需一种能显式建模结构逻辑的新方法。

Method: 提出SoT视觉思维链框架，训练统一的多模态自回归模型，交替生成文本计划与渲染的中间状态；引入SoT-26K数据集（基于CAD部件层次的装配轨迹）和T2S-CompBench评测基准。

Result: 在SoT-26K上微调后，组件数值能力达88.4%，结构拓扑达84.8%，较纯文本基线提升约20%。

Conclusion: SoT为透明、过程监督的组合生成建立了新范式，有效提升了生成图像的结构完整性与逻辑一致性。

Abstract: Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.

</details>


### [8] [An AI Framework for Microanastomosis Motion Assessment](https://arxiv.org/abs/2601.21120)
*Yan Meng,Eduardo J. Torres-Rodríguez,Marcelle Altshuler,Nishanth Gowda,Arhum Naeem,Recai Yilmaz,Omar Arnaout,Daniel A. Donoho*

Main category: cs.CV

TL;DR: 本文提出了一种基于人工智能的自动化框架，用于评估显微吻合术中的器械操作技能，整合了器械检测、跟踪、尖端定位和技能分类四个模块，在实验中实现了97%的检测精度和96%的mAP。


<details>
  <summary>Details</summary>
Motivation: 传统显微外科技术评估依赖专家主观判断，存在评分者间差异大、标准不统一、易受认知偏差影响及耗时等问题，亟需一种客观、可靠且可扩展的自动化评估系统。

Method: 该框架包含四个核心组件：(1) 基于YOLO的器械检测模块；(2) 基于DeepSORT的器械跟踪模块；(3) 利用形状描述符的器械尖端定位模块；(4) 基于专家标注数据训练的监督分类模块，用于评估操作熟练度。

Result: 实验结果表明，该系统在IoU阈值50%至95%范围内达到97%的器械检测精度和96%的平均精度（mAP50-95）。

Conclusion: 所提出的AI框架能有效、客观地自动评估显微吻合术中的器械操作技能，具备良好的准确性和可扩展性，有望改善当前显微外科培训与评估体系。

Abstract: Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).

</details>


### [9] [Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2601.21159)
*Jianzheng Wang,Huan Ni*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的开放词汇语义分割方法SDCI，通过双分支协同推理框架提升高分辨率遥感影像的分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的开放词汇语义分割方法在处理高分辨率遥感影像时，难以同时满足几何定位和语义预测的高要求，主要受限于单向特征注入和浅层后处理策略。

Method: 提出SDCI框架，包含三个核心模块：1）交叉模型注意力融合（CAF）模块，在特征编码阶段实现双模型自注意力图的相互引导；2）双向交叉图扩散精炼（BCDR）模块，通过迭代随机游走扩散增强双分支分割得分的可靠性；3）基于低层超像素结构的凸优化超像素协同预测（CSCP）机制，进一步优化对象边界。

Result: 在多个遥感语义分割基准数据集上，SDCI方法性能优于现有方法；消融实验验证了超像素结构在深度学习框架中的有效性。

Conclusion: 所提出的SDCI框架有效提升了无需训练的开放词汇遥感影像语义分割性能，证明传统基于超像素的方法在深度学习中仍具价值。

Abstract: High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using "one-way injection" and "shallow post-processing" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.

</details>


### [10] [Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process](https://arxiv.org/abs/2601.21179)
*Yuji Lin,Qian Zhao,Zongsheng Yue,Junhui Hou,Deyu Meng*

Main category: cs.CV

TL;DR: 本文提出GeoDiff-LF，一种基于扩散模型的新型框架，用于提升水下4D光场成像质量，通过结合空间-角度结构与几何先验有效缓解色彩失真。


<details>
  <summary>Details</summary>
Motivation: 水下成像面临严重的色彩失真和退化问题，而现有方法难以充分利用4D光场数据的几何结构信息进行高质量恢复。

Method: 提出GeoDiff-LF框架，包含三方面改进：(1) 改进U-Net结构以建模几何线索；(2) 设计基于张量分解与渐进加权的几何引导损失函数；(3) 采用带噪声预测的优化采样策略提升效率。

Result: 实验表明，该方法在视觉质量和定量指标上均优于现有方法，显著提升了水下光场图像增强效果。

Conclusion: GeoDiff-LF通过融合扩散先验与光场几何结构，有效解决了水下成像中的色彩失真问题，推动了该领域技术的发展。

Abstract: This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.

</details>


### [11] [Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval](https://arxiv.org/abs/2601.21193)
*Zecheng Zhao,Zhi Chen,Zi Huang,Shazia Sadiq,Tong Chen*

Main category: cs.CV

TL;DR: 本文提出GRDR方法，通过为每个视频分配多个语义ID并联合训练分词器与生成式检索器，在两阶段文本到视频检索中显著提升召回质量，同时大幅降低存储开销并加速检索。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段文本到视频检索（TVR）系统中，召回模型性能限制了整体效果。生成式检索（GR）虽具备高效性，但存在语义歧义和跨模态对齐不足的问题，难以有效支持高质量候选视频的召回。

Method: 提出GRDR框架：1）使用查询引导的多视角分词器为每个视频分配多个语义ID，提供多样化的语义访问路径；2）通过共享码本联合训练分词器与生成式检索器，使语义ID成为文本与视频间的语义桥梁；3）推理时采用trie约束解码生成紧凑候选集，并由稠密模型重排序。

Result: 在TVR基准测试中，GRDR在准确率上媲美强稠密检索器，同时将索引存储减少一个数量级，并在全语料库检索中实现最高300倍的加速。

Conclusion: GRDR有效解决了生成式检索在两阶段TVR中的语义歧义与跨模态对齐问题，兼顾高精度、低存储与高效率，为大规模实时视频检索提供了实用方案。

Abstract: Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\times$ in full-corpus retrieval.

</details>


### [12] [Thinker: A vision-language foundation model for embodied intelligence](https://arxiv.org/abs/2601.21199)
*Baiyu Pan,Daqin Luo,Junpeng Yang,Jiyuan Wang,Yixuan Zhang,Hailin Shi,Jichao Jiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为Thinker的大型视觉-语言基础模型，通过构建面向机器人感知与推理的大规模数据集，并结合关键帧与完整视频序列作为输入，有效提升了模型在具身智能任务中的视频理解能力，在两个主流任务规划基准上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型在机器人领域应用时存在对人类而言简单但模型易错的问题，如混淆第三人称与第一人称视角、在时序推理中忽略视频结尾信息等。

Method: 从两方面解决问题：一是构建包含自我视角视频、视觉定位、空间理解和思维链数据的大规模机器人感知与推理数据集；二是提出一种简单而有效的方法，将关键帧与完整视频序列联合输入，增强模型的视频理解能力。

Result: 在任务规划领域两个最常用的基准数据集上取得了最先进的结果。

Conclusion: 所提出的Thinker模型有效缓解了现有视觉-语言模型在具身智能场景中的视角混淆与时序推理缺陷，显著提升了机器人任务规划的性能。

Abstract: When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.

</details>


### [13] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: 本文提出LAMP，一种针对多图像多模态大语言模型（MLLMs）的黑盒通用对抗扰动方法，通过注意力约束和跨图像传染性约束有效提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击主要针对单图像场景且依赖白盒假设，难以适用于现实中的多图像MLLMs；因此亟需一种实用的黑盒攻击方法来揭示其安全漏洞。

Method: LAMP引入基于注意力的约束以阻碍模型跨图像信息聚合，设计跨图像传染性约束使扰动令牌影响干净令牌，并采用索引-注意力抑制损失实现位置不变的鲁棒攻击。

Result: 实验表明，LAMP在多个视觉-语言任务和模型上均优于当前最先进的基线方法，取得了最高的攻击成功率。

Conclusion: LAMP有效揭示了多图像MLLMs在黑盒场景下的脆弱性，为未来提升此类模型的鲁棒性提供了重要参考。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [14] [PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models](https://arxiv.org/abs/2601.21238)
*Xuewen Liu,Zhikai Li,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CV

TL;DR: 本文提出PTQ4ARVG，一种针对自回归视觉生成（ARVG）模型的免训练后量化框架，通过三项关键技术解决通道级异常值、token级动态激活和样本级分布不匹配问题，在8位和6位量化下保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法在ARVG模型上泛化能力差，主要由于其存在通道级异常值、token级高度动态激活及样本级分布不匹配三大挑战，亟需专门设计的量化方案。

Method: 提出PTQ4ARVG框架，包含：(1) Gain-Projected Scaling (GPS) 通过泰勒展开与微分推导最优缩放因子以缓解通道异常值；(2) Static Token-Wise Quantization (STWQ) 利用ARVG固定token长度和位置不变分布特性实现静态token级量化；(3) Distribution-Guided Calibration (DGC) 基于分布熵选择代表性样本以消除样本间分布偏差。

Result: 在多个ARVG模型上验证了PTQ4ARVG的有效性，可在8-bit和6-bit量化下保持与原始模型相当的生成性能。

Conclusion: PTQ4ARVG是首个面向ARVG模型的高效后量化方法，解决了现有量化技术在该类模型上的关键瓶颈，为轻量化部署提供了可行路径。

Abstract: AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .

</details>


### [15] [NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration](https://arxiv.org/abs/2601.21248)
*Zhen Wang,Hongyi Liu,Jianing Li,Zhihui Wei*

Main category: cs.CV

TL;DR: 提出了一种名为NFCDS的频谱调制机制，通过在反向扩散过程中控制噪声频率，在无需额外训练的情况下提升图像复原的保真度与感知质量平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散采样的即插即用（PnP）方法虽能生成高感知质量的图像，但常因反向扩散过程中的噪声导致数据保真度下降。为解决这一保真度-感知冲突问题，作者从噪声频率角度进行分析并提出改进方案。

Method: 设计了一种傅里叶域滤波器，在反向扩散过程中逐步抑制低频噪声、保留高频成分，从而将数据一致性先验直接注入采样过程，实现高质量且高保真的图像生成。

Result: NFCDS作为PnP模块可无缝集成到现有扩散复原框架中，在多种零样本任务中有效改善了保真度与感知质量之间的平衡，并实现快速收敛。

Conclusion: 噪声频率是理解保真度-感知冲突的关键因素，通过频谱调控可在不增加训练成本的前提下显著提升扩散模型在图像复原任务中的性能。

Abstract: Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.

</details>


### [16] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: 本文提出Hypersolid方法，通过将自监督学习中的表示学习视为离散堆积问题，并利用短程硬球排斥防止局部碰撞，从而避免表示崩溃，在细粒度和低分辨率分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自监督学习中常面临表示崩溃的问题，现有方法多依赖全局正则化策略，而本文旨在通过一种新的几何视角——离散堆积问题——来解决这一挑战。

Method: 将表示学习重新解释为保持信息的注入性问题，提出Hypersolid方法，采用短程硬球排斥机制防止局部表示重叠，从而维持高分离度的几何结构。

Result: 该方法在细粒度和低分辨率图像分类任务上取得优异性能，有效保留了数据增强的多样性。

Conclusion: 通过局部排斥而非全局正则化，Hypersolid提供了一种新颖且有效的防止表示崩溃的途径，强调了几何结构在自监督表示学习中的重要性。

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [17] [Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference](https://arxiv.org/abs/2601.21269)
*Jianglong Li,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.CV

TL;DR: 提出了一种轻量级、高保真、低比特率的3D说话人脸压缩框架，结合FLAME参数化建模与3DGS神经渲染，在极低比特率下实现高质量实时3D视频会议。


<details>
  <summary>Details</summary>
Motivation: 现有2D视频压缩方法难以保留精细几何与外观细节，而NeRF等隐式神经渲染方法计算开销大，难以满足低比特率下高保真3D说话人脸表示的需求。

Method: 结合FLAME参数化模型与3DGS（3D Gaussian Splatting）神经渲染，仅传输关键面部元数据，并引入高斯属性压缩与MLP优化的紧凑表示与压缩方案。

Result: 实验表明该方法在极低比特率下实现了优越的率失真性能和高质量的人脸渲染效果。

Conclusion: 所提框架高效、轻量，适用于实时3D视频会议场景，有效平衡了压缩效率与重建质量。

Abstract: The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.

</details>


### [18] [GeoRC: A Benchmark for Geolocation Reasoning Chains](https://arxiv.org/abs/2601.21278)
*Mohit Talreja,Joshua Diao,Jim Thannikary James,Radu Casapu,Tejas Santanam,Ethan Mendes,Alan Ritter,Wei Xu,James Hays*

Main category: cs.CV

TL;DR: 本文提出了首个用于评估视觉语言模型（VLM）地理定位推理链的基准，发现尽管顶尖VLM在地理位置预测上表现优异，但在生成可验证、基于真实视觉证据的推理链方面远逊于人类专家。


<details>
  <summary>Details</summary>
Motivation: 当前VLM虽能准确预测图像地理位置，但其生成的推理过程常包含幻觉内容，缺乏对真实视觉线索的可靠利用。为系统评估和改进VLM的地理定位推理能力，亟需一个高质量的基准。

Method: 作者与包括世界冠军在内的GeoGuessr专家合作，为500个场景构建了800条真实推理链，涵盖数百种判别性视觉属性。利用LLM-as-a-judge和VLM-as-a-judge策略（发现Qwen 3效果最佳）来评估VLM生成的推理链质量，并与人类评分进行对比。

Result: 评估显示，Gemini和GPT-5等闭源大VLM在位置预测上媲美人类，但其推理链质量仍落后；而Llama、Qwen等开源VLM表现极差，仅略优于完全无视觉信息的幻觉基线。

Conclusion: VLM在从高分辨率图像中提取细粒度视觉属性方面存在明显短板，导致其无法生成可靠、可审计的地理定位推理链，这揭示了当前模型在视觉理解深度上的根本局限。

Abstract: Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.

</details>


### [19] [WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models](https://arxiv.org/abs/2601.21282)
*Rishi Upadhyay,Howard Zhang,Jim Solomon,Ayush Agrawal,Pranay Boreddy,Shruti Satya Narayana,Yunhao Ba,Alex Wong,Celso M de Melo,Achuta Kadambi*

Main category: cs.CV

TL;DR: 本文提出了WorldBench，一个用于对生成式世界模型进行解耦、概念特定的物理理解评估的新视频基准，揭示了当前最先进模型在特定物理概念上的系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理的视频基准存在概念纠缠问题，无法对单个物理定律或概念进行独立、精准的诊断性评估，限制了对世界模型物理保真度的可靠衡量。

Method: 构建WorldBench基准，包含两个层次：1）直觉物理理解（如物体恒存性、尺度/透视）；2）底层物理常数与材料属性（如摩擦系数、流体粘度），以实现对单一物理概念的解耦评估。

Result: 在WorldBench上评估当前最先进的视频生成世界模型时，发现它们在特定物理概念上存在明显的失败模式，且均缺乏生成可靠现实交互所需的物理一致性。

Conclusion: WorldBench提供了一个更细致、可扩展的框架，用于严格评估世界模型的物理推理能力，为开发更鲁棒、可泛化的世界模型驱动学习系统奠定基础。

Abstract: Recent advances in generative foundational models, often termed "world models," have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.

</details>


### [20] [Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification](https://arxiv.org/abs/2601.21307)
*Md Nadim Mahamood,Md Imran Hasan,Md Rasheduzzaman,Ausrukona Ray,Md Shafi Ud Doula,Kamrul Hasan*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的轻量级模型Mam-App，用于苹果叶病害分类，在保持极低参数量（0.051M）的同时，在PlantVillage数据集上实现了99.58%的准确率，并在玉米和马铃薯叶病数据集上也表现出优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为应对全球人口增长和技术进步带来的粮食需求激增，需减少作物病害造成的损失。现有深度学习模型虽在病害识别上表现良好，但参数量大、计算成本高；而轻量模型又常牺牲性能。因此，亟需一种兼顾效率与性能的解决方案。

Method: 提出Mam-App模型，基于Mamba架构进行特征提取与叶病分类，具有参数高效性，适用于资源受限设备。

Result: 在苹果叶病数据集上达到99.58%准确率、99.30%精确率、99.14%召回率和99.22% F1分数；在玉米和马铃薯数据集上也分别取得99.48%和98.46%的准确率，验证了模型的鲁棒性和泛化能力。

Conclusion: Mam-App在极低参数量下实现顶尖性能，适合部署于无人机、移动设备等低资源平台，为农业病害智能诊断提供了高效可行的解决方案。

Abstract: The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.

</details>


### [21] [HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence](https://arxiv.org/abs/2601.21314)
*Yanfeng Li,Tao Tan,Qingquan Gao,Zhiwen Cao,Xiaohong liu,Yue Sun*

Main category: cs.CV

TL;DR: 本文提出LANE模型与AdaGraph策略，显著提升3D网格生成的序列长度、速度与几何细节。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归方法的3D网格生成模型在资源利用上效率低下，导致推理速度慢且仅能处理小规模序列，限制了结构细节的表达能力。

Method: 提出Latent Autoregressive Network (LANE)，引入紧凑的自回归依赖关系，并结合Adaptive Computation Graph Reconfiguration (AdaGraph)策略，通过时空解耦优化推理效率。

Result: LANE在最大可生成序列长度上比现有方法提升6倍，在生成速度、结构细节和几何一致性方面均表现优异。

Conclusion: LANE为高质量3D网格生成提供了一种高效且细节丰富的解决方案。

Abstract: High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.

</details>


### [22] [Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations](https://arxiv.org/abs/2601.21334)
*Pritika Vig,Ren-Chin Wu,William Lotter*

Main category: cs.CV

TL;DR: 该论文发现视觉基础模型能从静态病理图像中隐式学习疾病连续进展过程，其表征空间中的轨迹保真度可作为衡量表示质量的新指标，并与下游分类性能高度相关。


<details>
  <summary>Details</summary>
Motivation: 探究在离散采样图像上训练的视觉基础模型是否能捕捉到数据背后的连续生物过程（如疾病进展），尤其在计算病理学中，这种能力可能更贴近真实生物学机制、提升泛化能力并支持对疾病转变特征的定量分析。

Method: 利用单细胞转录组学中用于推断发育轨迹的“扩散伪时间”（diffusion pseudotime）方法，评估多个视觉基础模型在四种癌症进展任务中是否能在其表征空间中按疾病进展顺序组织样本。

Result: 所有病理专用模型均显著优于随机基线，其中纯视觉模型在CRC-Serrated数据集上达到最高轨迹保真度（τ>0.78）；轨迹保真度排名与模型在新疾病上的少样本分类性能高度相关（ρ=0.92）；沿推断轨迹的细胞类型组成变化符合已知的间质重塑模式。

Conclusion: 视觉基础模型能够从独立静态观测中隐式学习连续过程，轨迹保真度是超越下游任务性能的补充性表征质量评估指标；该框架虽在病理学中验证，但可推广至其他通过静态快照观察连续过程的领域。

Abstract: Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.

</details>


### [23] [Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21341)
*Ruiqi Liu,Boyu Diao,Zijia An,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出动态适配器融合（DAF）方法，通过基于PAC-Bayes定理和损失函数泰勒展开的融合机制，在类增量学习中构建单一鲁棒全局适配器，实现稳定性和可塑性的动态平衡，并在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有类增量学习方法中，任务特定适配器阻碍知识迁移且检索成本高，而简单参数融合易导致干扰与灾难性遗忘。

Method: 提出动态适配器融合（DAF）框架，结合任务特定适配器、先前全局适配器和初始化参数，利用PAC-Bayes理论和损失函数的泰勒展开动态计算最优融合系数，并引入鲁棒初始化策略以捕获全局知识模式。

Result: 在多个类增量学习基准实验中，DAF方法取得了当前最优（SOTA）的性能表现。

Conclusion: DAF通过动态融合机制有效缓解了灾难性遗忘与参数干扰问题，实现了高效的知识迁移与持续学习能力。

Abstract: Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.

</details>


### [24] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为语义引导动态稀疏化（SGDS）的新方法，通过在激活空间中构建类别特定的稀疏子空间，有效缓解类增量学习中的任务干扰问题，同时避免对参数空间施加严格约束，从而在多个基准数据集上实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于参数正交约束的轻量适配器方法虽能减少任务间干扰，但损害了模型的可塑性。作者旨在探索一种更灵活且有效的机制，在保留旧知识的同时促进新类别的学习。

Method: SGDS通过定向稀疏化策略主动引导激活空间的结构：相似类别共享紧凑的激活子空间以促进知识迁移，而不同类别则分配互不重叠的子空间以防止干扰，从而在激活空间中雕刻出类别特定的稀疏子空间。

Result: 在多个类增量学习基准数据集上的大量实验表明，SGDS显著优于现有方法，达到了最先进的性能。

Conclusion: 通过在激活空间而非参数空间进行干预，SGDS在避免任务干扰的同时保持了模型的可塑性，为类增量学习提供了一种高效且灵活的新范式。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


### [25] [Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2601.21405)
*Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级模块GIQT，通过结合相机几何信息显式校正查询-键相似性空间，并引入几何条件提示机制，有效提升了跨视角（航拍与地面）行人重识别在极端几何差异下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AG-ReID方法假设注意力机制中的点积相似性在大视角和尺度变化下依然可靠，但作者指出该假设不成立，极端相机几何会系统性扭曲相似性空间，导致匹配性能下降。

Method: 提出Geometry-Induced Query-Key Transformation (GIQT)，一种低秩轻量模块，在不改变特征表示或注意力结构的前提下，基于相机几何信息对查询-键相似性进行显式校正；同时引入几何条件提示生成机制，提供全局、视图自适应的表示先验。

Result: 在四个AG-ReID基准数据集上实验表明，所提方法在极端且未见过的几何条件下显著提升重识别鲁棒性，且计算开销远低于现有先进方法。

Conclusion: 通过显式建模相机几何对相似性空间的影响，GIQT有效缓解了跨视角几何失真问题，为AG-ReID任务提供了更可靠且高效的解决方案。

Abstract: Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.
  To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.
  Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.

</details>


### [26] [Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation](https://arxiv.org/abs/2601.21406)
*Zihan Su,Hongyang Wei,Kangrui Cen,Yong Wang,Guanhua Chen,Chun Yuan,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出UniMRG，一种架构无关的后训练方法，通过引入图像的多表示生成任务（如像素重建、深度估计和分割）来增强统一多模态模型（UMMs）的视觉理解能力，同时提升其生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型主要利用理解能力提升生成，但反向利用生成促进理解的研究尚不充分。作者旨在探索如何通过生成任务来增强模型对视觉内容的理解。

Method: 提出UniMRG方法，在标准视觉理解目标基础上，让UMM同时生成输入图像的多种内在表示（像素、深度、分割），从而融合外观、空间关系和结构布局等互补信息。

Result: 在多种UMM架构上的实验表明，该方法显著提升了细粒度感知、减少了幻觉现象、增强了空间理解能力，并同时提高了生成质量。

Conclusion: 通过引入多表示生成任务，UniMRG有效实现了理解与生成的相互促进，为统一多模态模型的发展提供了简单而有效的后训练策略。

Abstract: Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.

</details>


### [27] [MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations](https://arxiv.org/abs/2601.21408)
*Xinan He,Kaiqing Lin,Yue Zhou,Jiaming Zhong,Wei Ye,Wenhui Yi,Bing Fan,Feng Ding,Haodong Li,Bo Cao,Bin Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于“流形投影波动”（MPF）现象的双路径检测框架，用于识别高保真AI生成视频，即使其在宏观语义和时序上无明显瑕疵。


<details>
  <summary>Details</summary>
Motivation: 尽管当前AI视频生成模型（如Veo和Wan）已能生成视觉质量极高的内容，但作者认为这些视频本质上是流形拟合的产物，而非物理世界的真实记录，因此在像素层面仍存在可检测的结构化痕迹。

Method: 提出一种分层双路径检测框架：第一路径为静态流形偏离分支，利用大规模视觉基础模型（VFMs）捕捉空间上的异常或物理违反；第二路径为微时序波动分支，通过分析连续帧残差中结构性的MPF特征，对高保真伪造视频进行细粒度识别。

Result: 该方法能够有效检测两类伪造视频：一类是明显偏离真实世界流形的，另一类是虽在流形上但带有细微计算指纹的高保真伪造视频。

Conclusion: AI生成视频在像素组成逻辑上具有结构化和同质性特征（即MPF），通过结合空间与微时序分析，可实现对高保真伪造视频的鲁棒检测。

Abstract: With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.

</details>


### [28] [From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding](https://arxiv.org/abs/2601.21421)
*Jiangsan Zhao,Jakob Geipel,Kryzysztof Kusnierek*

Main category: cs.CV

TL;DR: 本文揭示了NeRF在高自遮挡场景中因内部几何退化（IGD）导致实例恢复率受限的问题，并提出基于稀疏体素光栅化的显式几何方法，显著提升密集场景中的实例恢复准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式密度场的NeRF方法在密集、自遮挡场景中难以可靠地进行定量3D分析，因其在强遮挡下倾向于重建空心或碎片化结构，造成实例漏检。

Method: 提出一种基于稀疏体素光栅化（SVRaster）的显式几何流程，利用SfM特征几何初始化，将2D实例掩码投影到体素网格，并通过递归分割强制几何分离，以保持物理实体完整性。

Result: 在合成密集遮挡数据集上，所提方法实现实例恢复率95.8%，显著优于当前最优的掩码监督NeRF（约89%）；在分割掩码质量下降时，仍比隐式方法多恢复43%的实例。

Conclusion: 在高度自遮挡的3D场景中，显式几何先验对于实现可靠的定量分析至关重要，隐式NeRF方法存在固有局限性。

Abstract: Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.

</details>


### [29] [Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention](https://arxiv.org/abs/2601.21444)
*Yuxiang Huang,Mingye Li,Xu Han,Chaojun Xiao,Weilin Zhao,Ao Sun,Ziqi Yuan,Hao Zhou,Fandong Meng,Zhiyuan Liu*

Main category: cs.CV

TL;DR: 本文提出Spava，一种用于加速长视频推理的序列并行框架，通过跨多GPU优化注意力机制，在不压缩视觉嵌入的前提下显著提升推理速度且保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时因预填充阶段计算密集而效率低下，且单GPU上的视觉嵌入压缩或稀疏注意力策略导致加速有限或性能下降，难以应对更长、更复杂的视频。

Method: 提出Spava框架，采用近似注意力机制进行多GPU分布式计算，结合负载均衡和融合前向传播等系统级优化，实现高效并行处理。

Result: 相比FlashAttn、ZigZagRing和APB，Spava分别实现12.72倍、1.70倍和1.18倍的加速，且未造成明显性能损失。

Conclusion: Spava有效解决了长视频推理中的效率瓶颈，在保持任务性能的同时显著提升了多GPU环境下的推理速度。

Abstract: The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB

</details>


### [30] [Variance & Greediness: A comparative study of metric-learning losses](https://arxiv.org/abs/2601.21450)
*Donghuo Zeng,Hao Niu,Zhi Li,Masato Taya*

Main category: cs.CV

TL;DR: 该论文提出一个诊断框架（VARIANCE 和 GREEDINESS）来分析七种代表性度量学习损失函数在图像检索任务中的嵌入几何与优化动态特性，揭示了不同损失在类内多样性、类间间隔和收敛速度上的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有度量学习方法对嵌入空间几何结构和优化过程的影响缺乏系统理解，亟需统一的分析框架以指导实际应用中的损失选择。

Method: 作者构建了包含类内/类间方差（VARIANCE）和更新贪婪度（GREEDINESS，包括激活比例与梯度范数）的诊断指标，在五个图像检索数据集上对比七种损失函数（Contrastive、Triplet、N-pair、InfoNCE、ArcFace、SCL、CCL）的表现。

Result: Triplet 和 SCL 能保留更高的类内方差并形成更清晰的类间边界，在细粒度检索中表现更优；Contrastive 和 InfoNCE 通过大量小幅更新快速压缩嵌入，加速收敛但可能简化类结构；N-pair 实现较大的类均值分离但间距不均。

Conclusion: 度量学习中存在效率与粒度的权衡：若需保留多样性并区分困难样本，应选用 Triplet/SCL；若追求快速嵌入压缩，则 Contrastive/InfoNCE 更合适。

Abstract: Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.

</details>


### [31] [Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization](https://arxiv.org/abs/2601.21458)
*Midou Guo,Qilin Yin,Wei Lu,Xiangyang Luo,Rui Yang*

Main category: cs.CV

TL;DR: 本文提出RT-DeepLoc，一种基于重建误差的弱监督时序伪造定位方法，利用仅在真实数据上训练的Masked Autoencoder检测伪造片段，并引入新型不对称视频内对比损失（AICL）提升定位性能。


<details>
  <summary>Details</summary>
Motivation: 现代深度伪造呈现局部性和间歇性，需要细粒度的时序定位，但帧级标注成本高昂，因此需发展仅依赖视频级标签的弱监督方法。

Method: 使用仅在真实视频上训练的Masked Autoencoder（MAE）学习真实数据的时空模式，通过重建误差识别伪造片段；并设计不对称视频内对比损失（AICL），以增强真实特征的紧凑性，建立稳定决策边界。

Result: 在包括LAV-DF在内的大规模数据集上实验表明，RT-DeepLoc在弱监督时序伪造定位任务中达到当前最优性能。

Conclusion: RT-DeepLoc有效利用重建误差作为弱监督信号，结合AICL损失，实现了对未知伪造类型的高泛化能力与精准定位。

Abstract: Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.

</details>


### [32] [SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing](https://arxiv.org/abs/2601.21498)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 本文提出SimGraph，一个基于场景图的统一框架，用于图像生成与编辑，实现对对象关系、布局和空间一致性的精确控制。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成与编辑方法通常分开处理，难以保证空间一致性和语义连贯性，且缺乏对对象关系和空间排布的结构化控制。

Method: SimGraph整合了基于token的生成与基于扩散的编辑，通过场景图驱动，在单一模型中实现高质量、一致的图像生成与编辑。

Result: 大量实验表明，该方法在图像生成与编辑任务上优于现有最先进的方法。

Conclusion: 场景图可有效提升生成与编辑任务中的结构控制能力，SimGraph为实现高一致性、可控性强的视觉内容创作提供了有效方案。

Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.

</details>


### [33] [HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models](https://arxiv.org/abs/2601.21517)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 本文提出HERS框架，通过无标注的领域专家自适应方法提升文本到图像扩散模型在车辆损伤生成中的真实性、可控性与领域对齐能力，在多个指标上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型能生成逼真的车辆损伤图像，可能被滥用于保险欺诈或理赔操纵，因此亟需提升生成图像的可信度与可控性，以保障高风险领域（如车险）的安全应用。

Method: HERS利用大语言模型和T2I流程自动生成图像-文本对，采用自监督方式对基础扩散模型进行领域特定的专家微调，将不同损伤类型（如凹痕、划痕等）建模为独立专家，并融合为统一的多损伤模型。

Result: 在四个扩散主干模型上评估，HERS在文本忠实度上提升5.5%，人类偏好评分提高2.3%，显著优于基线方法。

Conclusion: HERS有效提升了生成损伤图像的质量与可控性，同时揭示了领域特定扩散模型在安全关键场景中的机遇与风险，强调了可信生成的重要性。

Abstract: Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.

</details>


### [34] [Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration](https://arxiv.org/abs/2601.21592)
*Luwei Tu,Jiawei Wu,Xing Luo,Zhi Jin*

Main category: cs.CV

TL;DR: 本文提出了一种不确定性感知扩散桥模型（UDBM），通过将全合一图像恢复（AiOIR）建模为由像素级不确定性引导的随机传输问题，在单次推理中实现多种图像恢复任务的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有AiOIR方法受限于粗粒度控制机制或固定映射策略，难以在异构退化条件下协调相互冲突的优化目标，导致适应性不足。

Method: 提出UDBM模型：1）引入松弛扩散桥形式，以松弛约束替代严格终端约束，建模退化不确定性并解决标准扩散桥中的漂移奇异性；2）设计双调制策略——噪声调度将不同退化对齐到共享高熵潜在空间，路径调度基于熵正则化的粘性动力学自适应调节传输轨迹。

Result: UDBM在多种图像恢复任务中实现了单步推理下的最先进性能。

Conclusion: 通过重构AiOIR为不确定性引导的随机传输问题，并有效校正传输几何与动力学，UDBM显著提升了模型在异构退化场景下的统一恢复能力。

Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.

</details>


### [35] [HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics](https://arxiv.org/abs/2601.21595)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Anish Giri*

Main category: cs.CV

TL;DR: 本文提出HydroSense，一种低成本、高精度的物联网水质监测系统，集成六项关键参数，采用双微控制器架构，在保证性能的同时大幅降低硬件成本。


<details>
  <summary>Details</summary>
Motivation: 传统水质监测方法依赖人工采样或昂贵商用设备，难以在资源受限地区普及。因此，亟需一种经济、准确且可实时监测的解决方案。

Method: HydroSense采用Arduino Uno与ESP32组成的双微控制器架构：前者用于高精度模拟量测量（含五点校准算法），后者负责无线通信、边缘计算与云端集成；系统还应用中值滤波、温度补偿和错误处理等信号处理技术。

Result: 90天实验验证显示：pH精度±0.08（0–14范围）、溶解氧稳定性±0.2 mg/L、TDS精度±1.9%（0–1000 ppm）、云端数据传输可靠性达99.8%；整套系统成本约300美元，比商用系统便宜85%。

Conclusion: HydroSense通过智能系统架构与低成本组件，实现了专业级水质监测的可及性，为环境监测提供了一种高性价比的新范式。

Abstract: The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.

</details>


### [36] [WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models](https://arxiv.org/abs/2601.21610)
*Zijin Yang,Yu Sun,Kejiang Chen,Jiawei Zhao,Jun Jiang,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出了WMVLM，首个基于视觉-语言模型的统一且可解释的扩散模型图像水印评估框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有水印评估方法缺乏统一框架、可解释性不足、安全考量不全面，且对语义水印使用了不合适的指标。

Method: 构建基于视觉-语言模型（VLM）的统一评估框架WMVLM，针对残差水印和语义水印分别定义质量与安全指标，并采用三阶段训练策略实现分类、评分和可解释文本生成。

Result: 实验表明WMVLM在多个数据集、扩散模型和水印方法上具有强大的泛化能力，性能超越当前最先进的VLM。

Conclusion: WMVLM为扩散模型图像水印提供了一个统一、可解释且全面的评估方案，推动了水印算法的发展。

Abstract: Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.

</details>


### [37] [PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization](https://arxiv.org/abs/2601.21617)
*Songhan Jiang,Fengchun Liu,Ziyue Wang,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: 本文提出了PathReasoner，首个大规模病理全切片图像（WSI）推理数据集，并基于此构建了具备结构化临床推理能力的模型PathReasoner-R1，通过知识图谱引导的数据生成与强化学习机制，显著提升了模型在病理诊断中的可解释性与准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在计算病理学中缺乏可验证、证据链接的推理过程，导致临床信任度低且难以纠错。为解决这一问题，作者旨在构建一个能支持透明、结构化临床推理的大规模数据集与模型。

Method: 作者构建了PathReasoner数据集，利用医学知识图谱指导生成超过2万条高质量、结构化的病理推理样本；在此基础上提出PathReasoner-R1模型，结合轨迹掩码监督微调与面向推理的强化学习，并设计了基于知识图谱的多粒度奖励函数（含实体奖励机制），以优化逻辑一致性。

Result: PathReasoner-R1在PathReasoner数据集及多个公开基准上均达到SOTA性能，展现出更强的跨尺度图像推理能力和临床可信度。

Conclusion: 通过引入知识引导的数据构建与推理优化机制，PathReasoner-R1成功赋予病理VLMs透明、可验证且符合临床逻辑的推理能力，为可信AI辅助诊断提供了新范式。

Abstract: Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.

</details>


### [38] [Similarity of Processing Steps in Vision Model Representations](https://arxiv.org/abs/2601.21621)
*Matéo Mahaut,Marco Baroni*

Main category: cs.CV

TL;DR: 尽管大型视觉模型最终可能收敛到相似的“通用”表征，但它们在中间处理步骤中仍存在显著差异；例如，分类器模型在最后层会丢弃低级图像统计信息，而CNN与Transformer模型在层间表征变化上表现出不同平滑性。


<details>
  <summary>Details</summary>
Motivation: 探究不同视觉模型是否不仅在最终表征上趋同，也在中间处理步骤和操作上趋同，从而理解趋同表征形成的过程。

Method: 通过量化不同模型在各处理阶段表征之间的距离，追踪模型间表征距离随处理流程的变化，识别造成模型差异的关键处理步骤。

Result: 发现位置相近的层在不同模型中表征最相似，但仍存在显著差异；分类器模型在最后层丢弃低级图像信息，而Transformer模型相比CNN模型在层间表征变化更平滑。

Conclusion: 模型表征的趋同具有层次性和结构性，不同架构和任务目标导致中间处理过程存在本质差异，这有助于更深入理解图像模型内部工作机制。

Abstract: Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations--in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.

</details>


### [39] [A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion](https://arxiv.org/abs/2601.21633)
*Pu Cao,Yiyang Ma,Feng Zhou,Xuedan Yin,Qing Song,Lu Yang*

Main category: cs.CV

TL;DR: 本文指出在潜在扩散模型中，当前对自编码器（AE）的评估过度偏向生成指标（如gFID），忽视了重建保真度，这在可控生成任务中会导致条件漂移并损害可控性；作者通过理论分析与实验验证表明，重建指标（尤其是实例级指标）比gFID更能预测AE在可控扩散中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有ImageNet规模的自编码器研究在权衡重建保真度与生成友好性时，系统性地偏向生成指标（如gFID），导致重建性能被低估；这种评估偏差在扩展到可控扩散任务时可能引发条件漂移，限制条件对齐能力，因此需要重新审视AE的评估标准。

Method: 作者提出多维度的条件漂移评估协议，对多个近期ImageNet自编码器进行实证分析，比较gFID与重建指标（尤其是实例级指标）在预测可控生成任务中条件保持能力方面的有效性，并通过ControlNet实验进一步验证可控性与条件保持而非gFID的相关性。

Result: 实验发现gFID对条件保持能力仅有弱预测性，而注重重建的指标与可控性高度一致；ControlNet实验也证实可控性更依赖于条件保持能力而非gFID。

Conclusion: 当前以ImageNet为中心的AE评估方式与可扩展可控扩散的需求存在差距，应更重视重建保真度（特别是实例级指标）以实现更可靠的模型选择和基准测试。

Abstract: In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.

</details>


### [40] [RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning](https://arxiv.org/abs/2601.21634)
*Shiqi Huang,Shuting He,Bihan Wen*

Main category: cs.CV

TL;DR: 本文提出RSGround-R1框架，通过推理引导的位置感知后训练方法提升多模态大语言模型在遥感视觉定位任务中的空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 遥感视觉定位（RSVG）任务中，自然语言描述高度依赖位置线索，而遥感图像具有大空间尺度和高语义模糊性，这对多模态大语言模型的空间推理能力提出了独特挑战。

Method: 提出RSGround-R1框架：首先使用合成的RSVG推理数据进行思维链监督微调（CoT-SFT）以建立显式位置意识；随后引入基于新设计的位置奖励的强化微调（RFT），提供连续且距离感知的定位指导；并采用空间一致性引导的优化方案，动态调整策略更新以确保稳定收敛。

Result: 在RSVG基准上的大量实验表明，所提模型在性能和泛化能力上均表现优越。

Conclusion: 通过结合推理引导、位置感知奖励和空间一致性优化，RSGround-R1有效提升了多模态大语言模型在遥感视觉定位任务中的空间理解与定位准确性。

Abstract: Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.

</details>


### [41] [OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models](https://arxiv.org/abs/2601.21639)
*Yufeng Zhong,Lei Chen,Xuanle Zhao,Wenkang Han,Liming Zheng,Jing Huang,Deyang Jiang,Yilin Cao,Lin Ma,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 本文提出OCRVerse，首个端到端统一处理文本中心与视觉中心OCR任务的整体方法，并通过两阶段SFT-RL多域训练策略，在多种数据类型上取得具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有OCR技术主要聚焦于从图像或扫描文档中识别文本（文本中心OCR），忽视了从图表、网页和科学绘图等视觉信息密集图像中识别视觉元素（视觉中心OCR）的需求，而这类图像在互联网上广泛存在且具有重要应用价值。

Method: 构建涵盖文本中心（如报纸、杂志、书籍）和视觉中心（如图表、网页、科学绘图）的综合数据集，并采用两阶段SFT-RL多域训练方法：SFT阶段混合跨域数据建立初始领域知识，RL阶段为各领域定制个性化奖励策略以提升跨域融合并避免数据冲突。

Result: OCRVerse在文本中心和视觉中心数据类型上均取得具有竞争力的结果，性能可与大规模开源及闭源模型相媲美。

Conclusion: OCRVerse作为首个统一处理文本与视觉中心OCR任务的端到端方法，有效提升了对多样化视觉信息密集图像的理解能力，展现出良好的跨域适应性和应用潜力。

Abstract: The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.

</details>


### [42] [CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection](https://arxiv.org/abs/2601.21648)
*Bowen Zhou,Marc-André Fiedler,Ayoub Al-Hamadi*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的跨模态自适应注意力融合框架（CAF-Mamba），用于抑郁症检测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在抑郁症检测中通常依赖有限的特征类型，忽略显式跨模态交互，并采用简单的拼接或静态加权进行多模态融合，效果受限。

Method: 提出CAF-Mamba框架，结合显式与隐式跨模态交互建模，并通过模态级注意力机制动态调整各模态贡献，实现更有效的多模态融合。

Result: 在LMVD和D-Vlog两个真实场景基准数据集上的实验表明，CAF-Mamba优于现有方法，达到SOTA性能。

Conclusion: CAF-Mamba通过引入自适应注意力机制和Mamba架构，有效提升了抑郁症检测中的多模态融合能力，具有良好的应用前景。

Abstract: Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.

</details>


### [43] [Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation](https://arxiv.org/abs/2601.21663)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Thorsten Seehaus,Matthias H. Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 该研究通过少量样本域自适应和引入先验知识，显著提升了冰川崩解锋面分割模型在新地点的精度，使其适用于全球尺度监测。


<details>
  <summary>Details</summary>
Motivation: 现有冰川崩解锋面分割模型在基准数据集上表现优异，但在新地点（分布外场景）应用时精度不足，无法满足科学分析需求。

Method: 采用少样本域自适应策略，结合空间静态先验知识，并在输入时间序列中加入夏季参考图像，无需修改模型结构。

Result: 模型在新研究地点的分割误差从1131.6米大幅降低至68.7米。

Conclusion: 所提出的方法为将深度学习冰川崩解锋面分割模型推广到新地点提供了有效框架，有助于实现全球范围的崩解锋面监测。

Abstract: During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.

</details>


### [44] [When Gradient Optimization Is Not Enough: $\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning](https://arxiv.org/abs/2601.21670)
*Zixuan Xia,Hao Wang,Pengcheng Weng,Yanyu Qian,Yangxin Xu,William Dan,Fei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的几何感知正则化框架\regName，通过在中间嵌入中施加模态内分散性和模态间锚定约束，有效缓解多模态学习中的表示退化问题，提升单模态与多模态性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中即使采用精心设计的训练策略，仍常出现模态内表示坍缩和样本级跨模态不一致等几何病理问题，影响单模态鲁棒性与多模态融合效果，而现有方法缺乏对表示几何结构的有效控制。

Method: 提出\regName框架，包含两个互补的正则化约束：模态内分散正则化以增强表示多样性，模态间锚定正则化以限制样本级跨模态偏移但避免强制对齐；该方法即插即用，无需修改模型结构，兼容多种训练范式。

Result: 在多个多模态基准上的实验表明，该方法在多模态和单模态任务上均取得一致性能提升，有效缓解了模态间的权衡问题。

Conclusion: 显式调控表示几何结构是提升多模态学习效果的关键，所提轻量级正则化方法能有效改善表示质量，增强模型鲁棒性与泛化能力。

Abstract: Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.
  We identify representation geometry as a missing control axis in multimodal learning and propose \regName, a lightweight geometry-aware regularization framework. \regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.
  Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.

</details>


### [45] [ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing](https://arxiv.org/abs/2601.21694)
*Shuo Li,Jiajun Sun,Zhekai Wang,Xiaoran Fan,Hui Li,Dingwen Yang,Zhiheng Xi,Yijun Wang,Zifei Shan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出了ChartE³，一个端到端图表编辑的新型评测基准，直接评估模型在无需中间语言或代码监督下的编辑能力，涵盖局部外观调整和全局数据驱动变换两类任务。


<details>
  <summary>Details</summary>
Motivation: 现有图表编辑方法多依赖流水线设计，使用自然语言或代码作为中间表示，难以在保持全局结构一致性的同时实现细粒度控制，限制了复杂编辑意图的准确执行。

Method: 构建包含1200多个高质量样本的ChartE³基准，每个样本包括图表图像、底层代码和多模态编辑指令；通过人工校验的数据流程生成，支持客观与主观双重评估。

Result: 对当前先进多模态大模型的广泛评测显示，其在全局编辑任务上表现显著不足，暴露出现有端到端图表编辑能力的关键缺陷。

Conclusion: ChartE³为端到端图表编辑提供了有效评测框架，揭示了现有模型在全局结构一致性方面的局限，为未来研究指明方向。

Abstract: Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.

</details>


### [46] [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716)
*Mingshuang Luo,Shuang Liang,Zhengkun Rong,Yuxuan Luo,Tianshu Hu,Ruibing Hou,Hong Chang,Yong Li,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: DreamActor-M2 是一种通用角色动画框架，通过将运动条件建模为上下文学习问题，解决了现有方法在身份保持与运动一致性之间的权衡问题，并摆脱了对显式姿态先验的依赖，实现了高质量、跨域泛化的角色图像动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有角色图像动画方法存在两大问题：一是运动注入策略不佳，导致身份保持与运动一致性之间存在“跷跷板”效应；二是过度依赖显式姿态先验（如骨架），难以捕捉复杂动态且难以泛化到非人形角色。

Method: DreamActor-M2 采用两阶段范式：首先将参考图像外观与运动线索融合到统一的潜在空间，利用基础模型的生成先验联合推理空间身份与时间动态；其次引入自举式数据合成流程，构建伪跨身份训练对，实现从姿态依赖控制到端到端 RGB 驱动动画的平滑过渡。

Result: 大量实验表明，DreamActor-M2 在视觉保真度和跨域泛化能力方面均达到当前最优水平。

Conclusion: DreamActor-M2 有效克服了现有方法的局限性，提供了一种无需显式姿态先验、适用于多种角色类型的通用动画生成方案，并通过新提出的 AW Bench 基准全面验证了其优越性。

Abstract: Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a "see-saw", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/

</details>


### [47] [From Global to Granular: Revealing IQA Model Performance via Correlation Surface](https://arxiv.org/abs/2601.21738)
*Baoliang Chen,Danni Huang,Hanwei Zhu,Lingyu Zhu,Wei Zhou,Shiqi Wang,Yuming Fang,Weisi Lin*

Main category: cs.CV

TL;DR: 该论文提出了一种新的图像质量评估（IQA）模型性能分析方法——粒度调制相关性（GMC），通过构建相关性曲面，克服了传统全局相关性指标（如PLCC和SRCC）无法捕捉局部质量谱上排序一致性的局限。


<details>
  <summary>Details</summary>
Motivation: 传统IQA评估指标（如PLCC和SRCC）仅提供单一标量，无法揭示模型在不同质量区域（如高MOS或小|MOS差|）的局部性能差异，且对测试样本质量分布敏感，导致跨数据集比较不稳定。

Method: 提出GMC方法，包含：(1) 粒度调制器，基于绝对MOS值和成对MOS差（|ΔMOS|）进行高斯加权相关性计算，以分析局部性能；(2) 分布调节器，通过正则化减轻非均匀质量分布带来的偏差。最终生成以MOS和|ΔMOS|为变量的三维相关性曲面。

Result: 在标准基准上的实验表明，GMC能够揭示传统标量指标无法发现的IQA模型性能特征，提供更细致、可靠和信息丰富的评估结果。

Conclusion: GMC为IQA模型的分析、比较和部署提供了一个更全面、稳健的评估范式，优于传统的全局相关性指标。

Abstract: Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.

</details>


### [48] [Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation](https://arxiv.org/abs/2601.21751)
*Jiankun Peng,Jianyuan Guo,Ying Xu,Yue Liu,Jiashuang Yan,Xuanwei Ye,Houhua Li,Xiaoming Wang*

Main category: cs.CV

TL;DR: 本文提出DGNav，一种动态拓扑导航框架，通过场景感知的自适应策略和动态图Transformer，解决现有方法在视觉语言导航中因地图节点采样粒度固定而导致的冗余与风险问题，在R2R-CE和RxR-CE基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑规划方法使用固定几何阈值采样节点，无法适应环境复杂度变化，导致简单区域过采样、复杂区域欠采样，影响效率与安全性。

Method: DGNav包含两个核心创新：(1) 场景感知自适应策略，根据预测航点的离散程度动态调整图构建阈值；(2) 动态图Transformer，融合视觉、语言和几何信息生成动态边权重，优化图连通性。

Result: 在R2R-CE和RxR-CE基准上，DGNav显著优于现有方法，消融实验验证了其在导航效率与安全探索之间的良好平衡。

Conclusion: DGNav通过动态调节拓扑地图密度与连接性，有效提升了视觉语言导航在连续环境中的性能与泛化能力。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a "Granularity Rigidity" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling "densification on demand" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.

</details>


### [49] [CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models](https://arxiv.org/abs/2601.21798)
*Junming Huang,Weiwei Xu*

Main category: cs.CV

TL;DR: 本文提出CG-MLLM，一种新型多模态大语言模型，可在统一框架中实现3D图像描述与高分辨率3D生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D内容生成中仅能生成低分辨率网格或粗略结构，难以原生捕捉精细几何细节，限制了大语言模型在3D生成领域的应用。

Method: 采用混合Transformer架构，结合Token级自回归（TokenAR）与Block级自回归（BlockAR）Transformer，并集成预训练视觉-语言主干与专用3D VAE潜在空间，在单一架构中实现标准token与空间块的长上下文交互。

Result: 实验表明，CG-MLLM在生成高保真3D对象方面显著优于现有MLLM方法。

Conclusion: CG-MLLM成功将高分辨率3D内容生成纳入主流大语言模型范式，推动了LLM在3D生成任务中的能力边界。

Abstract: Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.

</details>


### [50] [MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods](https://arxiv.org/abs/2601.21821)
*Honglin Lin,Zheng Liu,Yun Zhu,Chonghan Qin,Juekai Lin,Xiaoran Shang,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 本文提出了MMFineReason，一个包含180万样本的大规模多模态推理数据集，通过高质量的思维链标注和三阶段构建流程，显著提升了开源视觉语言模型的推理能力，并在多个模型规模上达到同类最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前开源视觉语言模型（VLMs）在视觉推理方面仍落后于闭源系统，主要受限于缺乏高质量、覆盖复杂领域（如STEM图表和视觉谜题）且具备长形式思维链（CoT）标注的训练数据。

Method: 作者构建了MMFineReason数据集，采用三阶段流程：大规模数据收集与标准化、思维链推理生成、基于推理质量和难度感知的综合筛选。随后在该数据集上微调Qwen3-VL-Instruct，得到MMFineReason-2B/4B/8B系列模型。

Result: MMFineReason-4B超越了更大的Qwen3-VL-8B-Thinking模型，而MMFineReason-8B甚至超过了Qwen3-VL-30B-A3B-Thinking，并接近Qwen3-VL-32B-Thinking的性能。此外，仅用7%（12.3万样本）的精选子集即可达到与完整数据集相当的性能。

Conclusion: 高质量、难度感知的多模态推理数据能极大提升模型的参数效率和推理能力，且推理导向的数据组成还能协同增强模型的通用能力。

Abstract: Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a "less is more" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.

</details>


### [51] [Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents](https://arxiv.org/abs/2601.21857)
*Taewon Kang*

Main category: cs.CV

TL;DR: 本文提出一种基于扩散模型的文档背景生成框架，通过在潜在空间中设计初始噪声和风格方向，实现前景保留与多页风格一致性，无需训练或显式约束。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成文档背景时难以同时保持前景内容可读性与多页风格一致，通常依赖掩码或重复提示等显式机制，缺乏对扩散过程内在结构的利用。

Method: 将扩散过程重新解释为潜在空间中随机轨迹的演化，通过几何对齐的初始噪声避免干扰前景区域，并引入缓存风格方向作为持久向量，使多页生成共享同一风格子空间。

Result: 该方法在不修改扩散主干、无需训练的情况下，生成视觉连贯、前景完整且跨页风格一致的文档背景，优于依赖显式约束的现有方法。

Conclusion: 通过将扩散建模为潜在空间中的轨迹设计，提供了一种原则性强、结构化且稳定的多页文档生成新范式。

Abstract: We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.

</details>


### [52] [Improving Classifier-Free Guidance of Flow Matching via Manifold Projection](https://arxiv.org/abs/2601.21892)
*Jian-Feng Cai,Haixia Liu,Zhengyi Su,Chao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于优化视角的Classifier-Free Guidance（CFG）新解释，并通过引入流形约束的同伦优化和Anderson加速技术，在无需额外训练的情况下提升了生成质量、提示对齐度及对引导尺度的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准CFG方法依赖启发式的线性外推，对引导尺度敏感且缺乏理论基础，作者旨在为其提供一个原则性的优化解释并改进其性能。

Method: 将CFG采样重新表述为带流形约束的同伦优化问题，通过增量梯度下降实现流形投影，并结合Anderson加速提升效率与稳定性，整个方法无需重新训练模型。

Result: 在DiT-XL-2-256、Flux和Stable Diffusion 3.5等多个大规模模型上验证了方法的有效性，显著提升了生成保真度、提示对齐性和对引导尺度的鲁棒性。

Conclusion: 通过优化视角重新理解CFG，并引入流形约束与加速策略，可在不增加模型训练成本的前提下，系统性地提升可控生成的质量与稳定性。

Abstract: Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.

</details>


### [53] [Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion](https://arxiv.org/abs/2601.21896)
*Hanmo Chen,Chenghao Xu,Xu Yang,Xuan Chen,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种新的KV缓存策略PaFu-KV，通过引入轻量级显著性估计头来识别并保留视频生成中重要的token，从而在保证生成质量的同时提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成方法采用的启发式KV缓存策略忽略了token在长期视频生成中的重要性差异，导致关键时空信息丢失和冗余缓存积累，影响生成质量和效率。

Method: 提出Past- and Future-Informed KV Cache Policy (PaFu-KV)，利用从双向教师模型蒸馏出的轻量级显著性估计头，评估token的显著性得分，动态保留重要token并剔除不相关token。

Result: 在多个基准上的实验表明，该方法在保持高保真视频生成质量的同时，显著减少了KV缓存容量和内存占用，实现了更快的推理速度。

Conclusion: PaFu-KV有效改善了长时程视频生成中的质量与效率权衡，为高效自回归视频生成提供了新思路。

Abstract: Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.

</details>


### [54] [TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention](https://arxiv.org/abs/2601.21900)
*Chuancheng Shi,Shangze Li,Wenjun Lu,Wenhua Wu,Cong Wang,Zifeng Cheng,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出TraceRouter，一种路径级防御框架，通过追踪并切断有害语义的因果传播路径，在提升对抗鲁棒性的同时保持模型通用性能。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法基于“局部性假设”，仅抑制孤立神经元或特征，但有害语义以跨层分布式电路形式存在，导致局部干预效果脆弱且损害模型效用。

Method: TraceRouter分三阶段工作：(1) 通过注意力发散分析定位敏感起始层；(2) 利用稀疏自编码器（SAE）和差分激活分析解耦并隔离恶意特征；(3) 基于零化干预得到的特征影响分数（FIS），将这些特征映射至下游因果路径，并选择性抑制这些因果链。

Result: 实验表明，TraceRouter在对抗鲁棒性与通用效用之间取得更优平衡，显著优于当前最先进的基线方法。

Conclusion: 通过在路径层面切断有害信息流，TraceRouter有效提升了大模型对对抗攻击的防御能力，同时保留了模型的正常功能。

Abstract: Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the "locality hypothesis", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.

</details>


### [55] [Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning](https://arxiv.org/abs/2601.21904)
*Hanmo Chen,Guangtao Lyu,Chenghao Xu,Jiexi Yan,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种名为Pyramidal Shapley-Taylor（PST）的新框架，用于细粒度的运动-语言检索，通过分层对齐局部运动片段、身体关节与文本词元，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有运动-语言检索方法主要采用全局对齐策略，忽略了局部运动片段、身体关节与文本词元之间的细粒度交互，导致检索性能受限。

Method: 受人类运动感知的金字塔过程启发，该方法将人体运动分解为时间片段和空间关节，并以金字塔方式逐步进行关节级和片段级的跨模态对齐，捕捉局部语义细节与层次结构关系。

Result: 在多个公开基准数据集上的实验表明，该方法显著优于当前最先进的方法，实现了运动片段、身体关节与其对应文本词元的精确对齐。

Conclusion: 所提出的PST框架有效提升了运动-语言检索的细粒度对齐能力，为跨模态人本智能提供了新思路。

Abstract: As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.

</details>


### [56] [VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models](https://arxiv.org/abs/2601.21915)
*Yunhao Li,Sijing Wu,Zhilin Gao,Zicheng Zhang,Qi Jia,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了VideoAesBench，一个用于评估大模型在视频美学质量理解能力上的综合性基准，并对23个主流多模态大模型进行了评测，发现其当前仅具备基础的视频美学感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在多种视觉任务中表现优异，但其在视频美学质量评估这一人类基本能力方面尚未得到充分探索，因此亟需一个系统性的评估基准。

Method: 构建了VideoAesBench基准，包含1,804个来自多种来源（UGC、AIGC、压缩视频、机器人生成、游戏视频）的视频，设计了多种题型（单选、多选、判断、开放式描述），并从视觉形式（5个维度）、视觉风格（4个维度）和视觉情感（3个维度）三个方面全面评估模型的视频美学理解能力。

Result: 对23个开源和商业大模型的评测表明，当前模型仅具备基础的视频美学感知能力，整体表现仍不完整且不够精确。

Conclusion: VideoAesBench可作为评估大模型视频美学能力的有力测试平台，并为可解释的视频美学评估提供新思路。

Abstract: Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.

</details>


### [57] [Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models](https://arxiv.org/abs/2601.21922)
*Cong Cao,Huanjing Yue,Shangbin Xie,Xin Liu,Jingyu Yang*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的框架，利用视频扩散模型增强基于图像的零样本视频修复与增强方法的时间一致性，有效缓解时间闪烁问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的零样本图像修复方法直接用于视频时会产生严重的时间闪烁，缺乏时间一致性。

Method: 提出同源潜在融合、异源潜在融合及基于COT的融合比例策略，结合文本到视频扩散模型辅助图像方法；并引入时间增强后处理，利用图像到视频扩散模型进一步提升时间一致性。

Result: 实验结果表明，所提方法在保持通用性的同时显著提升了视频修复与增强的时间一致性。

Conclusion: 该方法无需训练，可广泛适用于各类基于扩散的图像修复与增强方法，在零样本视频任务中表现出优越性能。

Abstract: Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.

</details>


### [58] [Just Noticeable Difference Modeling for Deep Visual Features](https://arxiv.org/abs/2601.21933)
*Rui Zhao,Wenrui Li,Lin Zhu,Yajing Zheng,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出FeatJND，一种面向任务的深度视觉特征最小可觉差（JND）模型，用于预测在不影响下游任务性能前提下每个特征可容忍的最大扰动，并成功应用于动态量化等场景。


<details>
  <summary>Details</summary>
Motivation: 随着深度视觉特征在视觉系统中广泛应用，亟需描述其特性并控制其质量。将图像感知中的最小可觉差（JND）概念扩展到深度特征空间，可为机器感知提供任务对齐的容错边界，从而在资源受限条件下指导特征质量控制。

Method: 作者提出FeatJND方法，在标准分割点构建估计器，预测保持下游任务性能不变的前提下各特征允许的最大扰动图。通过在图像分类、检测和实例分割任务中验证该方法，并将其用于token级动态量化中的步长分配。

Result: 实验表明，在相同扰动强度下，基于FeatJND的扰动比无结构高斯扰动更能保持任务性能；归因可视化显示FeatJND能抑制非关键特征区域。在动态量化应用中，FeatJND引导的步长分配优于随机排列和全局统一步长。

Conclusion: FeatJND为深度视觉特征提供了一种任务对齐的质量控制机制，不仅提升了对特征重要性的理解，还在实际压缩与量化任务中展现出实用价值。

Abstract: Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.

</details>


### [59] [BookNet: Book Image Rectification via Cross-Page Attention Network](https://arxiv.org/abs/2601.21938)
*Shaokai Liu,Hao Feng,Bozhi Luan,Min Hou,Jiajun Deng,Wengang Zhou*

Main category: cs.CV

TL;DR: 本文提出BookNet，首个端到端的双页书本图像矫正深度学习框架，并发布合成数据集Book3D与真实基准Book100。


<details>
  <summary>Details</summary>
Motivation: 现有单页文档图像矫正方法无法捕捉书本左右页面之间耦合的几何关系，而书本因装订约束导致复杂的非对称曲面畸变，亟需专门针对双页书本图像的矫正方法。

Method: BookNet采用双分支架构并引入跨页注意力机制，同时估计单页与整页展开图的扭曲流，显式建模左右页面间的相互影响；同时构建了合成数据集Book3D和真实数据集Book100以支持训练与评估。

Result: 大量实验表明，BookNet在书本图像矫正任务上优于当前最先进的方法。

Conclusion: BookNet有效解决了双页书本图像矫正中的几何耦合问题，所提数据集填补了该领域缺乏专用数据的空白，代码与数据将公开。

Abstract: Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.

</details>


### [60] [Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding](https://arxiv.org/abs/2601.21948)
*Yang Du,Siyuan Dai,Yonghao Song,Paul M. Thompson,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 本文提出“浅层对齐”（Shallow Alignment）方法，通过将神经信号与视觉编码器的中间层表示对齐，而非最终输出，有效缓解了人脑视觉与机器视觉在粒度上的不匹配问题，在多个基准上显著提升神经视觉解码性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经视觉解码方法忽略了人类视觉与深度视觉模型之间的粒度不匹配：深度模型倾向于语义不变性而抑制局部纹理信息，而神经信号则同时包含低级视觉特征和高级语义内容。

Method: 提出一种新的对比学习策略——浅层对齐，将神经信号与视觉编码器的中间层表示进行对齐，以更好地平衡低级纹理细节与高级语义特征。

Result: 在多个基准实验中，浅层对齐相比标准的最终层对齐方法性能提升22%至58%，并成功揭示了解码性能随预训练视觉主干容量增长的可预测缩放规律。

Conclusion: 浅层对齐有效解决了神经信号与视觉模型之间的粒度不匹配问题，显著提升了神经视觉解码效果，并为理解其性能提升机制提供了系统性实证分析。

Abstract: Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.

</details>


### [61] [PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing](https://arxiv.org/abs/2601.21957)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL-1.5 在 OmniDocBench v1.5 上达到 94.5% 的 SOTA 准确率，并在新提出的 Real5-OmniDocBench 基准上展现卓越的鲁棒性，同时支持印章识别和文本检测，仍保持 0.9B 超紧凑模型规模。


<details>
  <summary>Details</summary>
Motivation: 为提升视觉语言模型在真实文档场景中的鲁棒性，应对扫描、倾斜、扭曲、屏幕拍摄和光照变化等物理失真问题，作者提出新基准并升级模型。

Method: 引入 PaddleOCR-VL-1.5 模型，在原有基础上增强对多种真实世界文档失真的处理能力；构建 Real5-OmniDocBench 基准用于评估鲁棒性；扩展模型以支持印章识别与文本检测任务。

Result: 模型在 OmniDocBench v1.5 上取得 94.5% 的 SOTA 准确率，并在 Real5-OmniDocBench 上表现最优，同时保持 0.9B 参数量的高效紧凑结构。

Conclusion: PaddleOCR-VL-1.5 是一个高效、紧凑且鲁棒性强的多任务文档理解模型，适用于复杂真实场景，并通过新基准推动了文档视觉语言模型的评估标准。

Abstract: We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR

</details>


### [62] [Causal World Modeling for Robot Control](https://arxiv.org/abs/2601.21998)
*Lin Li,Qihang Zhang,Yiming Luo,Shuai Yang,Ruilin Wang,Fei Han,Mingrui Yu,Zelin Gao,Nan Xue,Xing Zhu,Yujun Shen,Yinghao Xu*

Main category: cs.CV

TL;DR: 本文提出LingBot-VA，一种基于自回归扩散框架的视频世界模型，通过联合学习帧预测与策略执行，在长时程操作、数据效率和泛化能力方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习方法缺乏对动作与视觉动态之间因果关系的建模能力，而视频世界模型能有效模拟近未来状态，为机器人学习提供新基础。

Method: 提出LingBot-VA框架，包含三大设计：(1) 基于Mixture-of-Transformers的共享潜在空间，融合视觉与动作token；(2) 闭环rollout机制，持续获取环境反馈；(3) 异步推理流水线，实现动作预测与执行并行。

Result: 在仿真和真实场景中均表现出色，尤其在长时程操作任务、训练后数据效率及对新配置的泛化能力方面显著优于基线。

Conclusion: 视频世界建模结合视觉语言预训练可作为机器人学习的新范式，LingBot-VA验证了该路径的有效性，并已开源以促进社区发展。

Abstract: This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.

</details>


### [63] [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
*Linhan Wang,Zichong Yang,Chen Bai,Guoxiang Zhang,Xiaotong Liu,Xiaoyin Zheng,Xiao-Xiao Long,Chang-Tien Lu,Cheng Lu*

Main category: cs.CV

TL;DR: 本文提出Drive-JEPA框架，结合视频联合嵌入预测架构（V-JEPA）与多模态轨迹蒸馏，在端到端自动驾驶中实现更优的规划表示，并在NAVSIM基准上达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于自监督视频预训练的驾驶世界模型在场景理解方面提升有限，且因驾驶行为的多模态性难以从单一人类轨迹中学习多样化行为。

Method: 首先将V-JEPA适配于端到端驾驶任务，利用大规模驾驶视频预训练ViT编码器以生成与轨迹规划对齐的预测表示；其次引入以提案为中心的规划器，通过动量感知机制融合仿真生成的多模态轨迹与人类轨迹进行蒸馏。

Result: 在NAVSIM上，仅使用V-JEPA表示配合简单Transformer解码器即可在无感知输入设置下超越先前方法3 PDMS；完整Drive-JEPA框架在v1和v2分别达到93.3 PDMS和87.8 EPDMS。

Conclusion: Drive-JEPA有效提升了端到端自动驾驶中的规划表示能力，通过结合自监督预训练与多模态轨迹蒸馏，显著优于现有方法。

Abstract: End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.

</details>


### [64] [PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22046)
*Changjian Jiang,Kerui Ren,Xudong Li,Kaiwen Song,Linning Xu,Tao Lu,Junting Dong,Yu Zhang,Bo Dai,Mulin Yu*

Main category: cs.CV

TL;DR: PLANING 是一种高效的在线重建框架，通过将显式几何基元与神经高斯松散耦合，实现几何与外观的解耦建模，在保证高质量渲染的同时提升几何精度，并显著加快重建速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单目图像序列的流式重建中难以兼顾高质量渲染与准确几何结构，通常只能偏向其中一方。作者旨在提出一种能同时优化两者并支持高效在线处理的新方法。

Method: 采用混合表示形式，将显式几何基元与神经高斯松散耦合，实现几何与外观的解耦；在此基础上设计在线初始化与优化策略，分别更新几何与外观，从而减少结构冗余并保持稳定重建。

Result: 在 ScanNetV2 数据集上，PLANING 相比 PGSR 提升了 18.52% 的 dense mesh Chamfer-L2 指标，比 ARTDECO 高出 1.31 dB PSNR，重建速度超过 2D Gaussian Splatting 的 5 倍（<100 秒），且达到离线逐场景优化的质量水平。

Conclusion: PLANING 在保证重建质量的同时具备结构清晰性和计算效率，适用于大规模场景建模和具身智能所需的仿真环境等下游任务。

Abstract: Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .

</details>


### [65] [MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources](https://arxiv.org/abs/2601.22054)
*Baorui Ma,Jiahui Yang,Donglin Di,Xuancheng Zhang,Jianxun Cui,Hao Li,Yan Xie,Wei Chen*

Main category: cs.CV

TL;DR: 本文提出Metric Anything，一种可扩展的预训练框架，通过稀疏度量提示从噪声多源3D数据中学习度量深度，无需人工设计提示或特定任务架构，并在多个任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有度量深度估计方法难以扩展，主要受限于异构传感器噪声、相机依赖性偏差以及跨源3D数据中的度量模糊性，阻碍了其遵循视觉基础模型的成功缩放范式。

Method: 提出“稀疏度量提示”（Sparse Metric Prompt），通过对深度图随机掩码生成通用接口，解耦空间推理与传感器/相机偏差；利用约2000万对涵盖重建、采集和渲染的图像-深度数据，在10000种相机模型上进行预训练。

Result: 首次在度量深度任务中观察到清晰的缩放趋势；预训练模型在深度补全、超分辨率、雷达-相机融合等提示驱动任务中表现优异；其无提示蒸馏学生模型在单目深度估计、相机内参恢复、单/多视图度量3D重建及VLA规划等任务上达到SOTA；作为视觉编码器可显著提升多模态大语言模型的空间智能。

Conclusion: 度量深度估计可受益于与现代基础模型相同的缩放规律，Metric Anything为可扩展、高效的现实世界度量感知开辟了新路径。

Abstract: Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.

</details>


### [66] [Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models](https://arxiv.org/abs/2601.22057)
*Archer Wang,Emile Anand,Yilun Du,Marin Soljačić*

Main category: cs.CV

TL;DR: 本文提出一种通过对抗训练提升扩散模型中无监督因子分解表示学习的方法，以增强重组生成的语义与物理一致性，在多个图像和机器人视频数据集上取得更优的解耦效果与生成质量。


<details>
  <summary>Details</summary>
Motivation: 复杂数据的因子化表示有助于揭示可重用组件并支持通过重组生成新样本。然而，在缺乏因子级监督的情况下，现有方法在发现潜在因子和保证重组生成质量方面仍有不足。

Method: 引入一个判别器，用于区分单源样本与跨源因子重组生成的样本，并通过对抗训练优化生成器，使其生成的重组样本能“欺骗”判别器，从而提升因子的物理与语义一致性。

Result: 在CelebA-HQ、Virtual KITTI、CLEVR 和 Falcor3D 数据集上，该方法相比基线模型取得了更低的FID分数和更高的解耦度（MIG和MCC指标）。在LIBERO机器人视频基准上，通过重组动作组件显著提升了状态空间覆盖率。

Conclusion: 所提对抗训练策略有效提升了无监督因子分解扩散模型的解耦能力和组合生成质量，并在机器人探索任务中展示了实际应用价值。

Abstract: Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

</details>


### [67] [Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models](https://arxiv.org/abs/2601.22060)
*Wenxuan Huang,Yu Zeng,Qiuchen Wang,Zhen Fang,Shaosheng Cao,Zheng Chu,Qingyu Yin,Shuang Chen,Zhenfei Yin,Lin Chen,Zehui Chen,Yao Hu,Philip Torr,Feng Zhao,Wanli Ouyang*

Main category: cs.CV

TL;DR: 本文提出Vision-DeepResearch，一种新型多模态深度研究范式，通过多轮、多实体、多尺度的图文搜索，在高噪声环境下显著提升多模态大语言模型（MLLM）在复杂任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM受限于内部知识容量，虽有工作通过“推理后调用工具”增强其能力，但这些方法通常假设单次图像或文本查询即可获取关键证据，忽略了现实场景中大量视觉噪声的存在，且在推理深度和搜索广度上存在不足，难以应对需整合多源图文证据的复杂问题。

Method: 提出Vision-DeepResearch框架，支持数十步推理与数百次引擎交互，采用冷启动监督与强化学习训练，将深度研究能力内化至MLLM中，实现端到端的多模态深度研究。

Result: Vision-DeepResearch在性能上显著优于现有同类MLLM及基于GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet等强闭源模型构建的工作流。

Conclusion: 所提出的多模态深度研究范式有效解决了现实复杂场景下的图文检索难题，为MLLM在高噪声环境下的应用提供了新思路。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [68] [BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation](https://arxiv.org/abs/2601.22061)
*Li Zhang,Pengtao Xie*

Main category: cs.CV

TL;DR: 本文提出BLO-Inst框架，通过双层优化对齐目标检测器与Segment Anything Model（SAM）的优化目标，使检测器生成更适用于SAM分割的提示框，从而提升全自动分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有将目标检测器作为SAM提示生成器的方法存在两个问题：一是检测器优化目标（几何定位）与SAM所需提示上下文不匹配；二是联合训练中出现对齐过拟合，导致泛化能力差。因此需要一种能真正对齐两者目标并提升泛化性的方法。

Method: 提出BLO-Inst统一框架，采用双层优化策略：下层在数据子集D₁上微调SAM以提升给定检测框下的分割质量；上层在另一子集D₂上更新检测器，使其生成的边界框最小化微调后SAM的验证损失，从而学习到面向分割质量的提示生成策略。

Result: 在通用和生物医学图像分割任务上，BLO-Inst显著优于现有基线方法，证明了其有效性和泛化能力。

Conclusion: 通过双层优化显式对齐检测与分割目标，BLO-Inst成功将检测器转化为分割感知的提示生成器，为实现SAM的全自动高效部署提供了有效解决方案。

Abstract: The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.

</details>


### [69] [RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation](https://arxiv.org/abs/2601.22094)
*Hanzhuo Huang,Qingyang Bao,Zekai Gu,Zhongshuo Du,Cheng Lin,Yuan Liu,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D资产的扩散模型，通过双分支架构联合利用多视角RGB图像和点图，实现与3D参考资产一致的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考的图像生成方法仅能使用单张图像作为参考，无法利用3D资产，限制了其在实际应用中的灵活性和表现力。

Method: 提出一种跨域扩散模型，采用双分支感知结构，同时建模3D资产的多视角RGB图像和点图，通过空间对齐的双分支生成架构和域解耦机制，同步生成内容解耦但空间对齐的RGB图像和点图。

Result: 实验表明，该方法能有效利用3D资产作为参考，生成与3D资产高度一致的图像。

Conclusion: 该研究为扩散模型与3D内容创作的结合开辟了新路径，提升了参考图像生成的实用性与多样性。

Abstract: In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.

</details>


### [70] [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](https://arxiv.org/abs/2601.22114)
*Saoud Aldowaish,Yashwanth Karumanchi,Kai-Chen Chiang,Soroosh Noorzad,Morteza Fayazi*

Main category: cs.CV

TL;DR: 本文提出SINA，一个开源全自动电路图转网表工具，结合深度学习、连通域标记、OCR和视觉语言模型，在网表生成准确率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在电路图图像转网表任务中存在元件识别与连接关系推断不准的问题。

Method: SINA整合深度学习进行元件检测、连通域标记（CCL）提取连接关系、OCR获取元件标号，并利用视觉语言模型（VLM）可靠分配标号。

Result: 实验表明，SINA的网表生成整体准确率达96.47%，是当前最先进方法的2.72倍。

Conclusion: SINA在电路图到网表的自动转换任务中实现了高精度和强鲁棒性，显著超越现有技术。

Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.

</details>


### [71] [Creative Image Generation with Diffusion Model](https://arxiv.org/abs/2601.22125)
*Kunpeng Song,Ahmed Elgammal*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的创意图像生成框架，通过将生成图像的分布推向CLIP嵌入空间中的低概率区域，以生成稀有且富有想象力的图像，并引入回拉机制以保持视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖人工概念混合或子类别排除来实现创意生成，缺乏系统性和可扩展性。本文旨在提供一种更原则化、自动化的创意生成方法，以突破传统生成模型在想象力方面的局限。

Method: 该方法利用扩散模型，在CLIP嵌入空间中计算生成图像的概率分布，并通过优化目标将其引导至低概率（即罕见）区域；同时引入“回拉机制”（pullback mechanisms）以确保生成图像的视觉质量。

Result: 在文本到图像扩散模型上的大量实验表明，该框架能高效生成独特、新颖且引人深思的图像，在保持高视觉保真度的同时显著提升创意水平。

Conclusion: 本研究为生成模型中的创造力提供了新视角，提出了一种系统化的方法来促进视觉内容合成中的创新，具有良好的应用前景和理论价值。

Abstract: Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.

</details>


### [72] [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](https://arxiv.org/abs/2601.22127)
*John Flynn,Wolfgang Paier,Dimitar Dinev,Sam Nhut Nguyen,Hayk Poghosyan,Manuel Toribio,Sandipan Banerjee,Guy Gafni*

Main category: cs.CV

TL;DR: EditYourself 是一个基于 DiT 的音视频驱动视频编辑框架，支持通过文本修改现有说话人视频，实现精准的口型同步与时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式视频模型在编辑已录制视频方面存在不足，难以在修改台词的同时保持动作、时间连贯性、说话人身份和口型同步。

Method: 在通用视频扩散模型基础上，引入音频条件控制和区域感知的编辑训练策略，通过时空修复实现对说话人视频的增删改及重定时。

Result: 该方法能精确同步口型，在新增片段中合成逼真的人体动作，并在长时间内保持视觉保真度和身份一致性。

Conclusion: 本研究为生成式视频模型在专业视频后期制作中的实际应用迈出了关键一步。

Abstract: Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.

</details>


### [73] [Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography](https://arxiv.org/abs/2601.22134)
*Wenxuan Li,Pedro R. A. S. Bassi,Lizhou Wu,Xinze Zhou,Yuxuan Zhao,Qi Chen,Szymon Plotka,Tianyu Lin,Zheren Zhu,Marisa Martin,Justin Caskey,Shanshan Jiang,Xiaoxi Chen,Jaroslaw B. Ćwikla,Artur Sankowski,Yaping Wu,Sergio Decherchi,Andrea Cavalli,Chandana Lall,Cristian Tomasetti,Yaxing Guo,Xuan Yu,Yuqing Cai,Hualin Qiao,Jie Bao,Chenhan Hu,Ximing Wang,Arkadiusz Sitek,Kai Ding,Heng Li,Meiyun Wang,Dexin Yu,Guang Zhang,Yang Yang,Kang Wang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 本文开发了一种名为ePAI的人工智能系统，用于在CT影像中早期检测胰腺导管腺癌（PDAC），在内部和外部测试中均表现出优异的敏感性和特异性，并能提前数月发现被放射科医生遗漏的病灶。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌（PDAC）通常在晚期才被诊断，而回顾性研究显示，许多早期病灶在确诊前的CT扫描中已被忽略。因此，亟需一种自动化工具辅助早期识别这些微小病灶，以提高早期诊断率。

Method: 研究人员开发了人工智能系统ePAI，使用来自单一医疗中心的1,598名患者数据进行训练，并在内部（1,009名患者）和外部（6个中心共7,158名患者）测试集中评估其性能。此外，还进行了包含30名认证放射科医生的多读片者研究，比较ePAI与人类专家在早期和临床前PDAC检测中的表现。

Result: 在内部测试中，ePAI对小于2 cm的PDAC检测AUC为0.939–0.999，敏感性95.3%，特异性98.7%，可精确定位小至2 mm的病灶；在外部测试中，AUC为0.918–0.945，敏感性91.5%，特异性88.0%，可检测小至5 mm的病灶。ePAI还在159例患者的临床前CT中成功检出75例PDAC，中位提前时间为347天。多读片者研究表明，ePAI的敏感性比放射科医生高50.3%（P < 0.05），同时保持95.4%的特异性。

Conclusion: ePAI在早期和临床前PDAC检测方面显著优于放射科医生，具有作为辅助工具提升胰腺癌早期诊断潜力。

Abstract: Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.

</details>


### [74] [PI-Light: Physics-Inspired Diffusion for Full-Image Relighting](https://arxiv.org/abs/2601.22135)
*Zhexin Liang,Zhaoxi Chen,Yongwei Chen,Tianyi Wei,Tengfei Wang,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种名为π-Light的两阶段物理启发式扩散模型框架，用于全图重光照，通过引入批感知注意力、物理引导渲染模块、物理启发损失和高质量数据集，显著提升了在真实场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 全图重光照面临三大挑战：难以获取大规模结构化配对数据、保持物理合理性困难，以及数据驱动先验限制了泛化能力。现有方法在弥合合成到真实差距方面效果不佳。

Method: 提出π-Light框架，包含：(i) 批感知注意力机制以提升图像集合内本征属性预测的一致性；(ii) 物理引导的神经渲染模块确保光传输的物理合理性；(iii) 物理启发的损失函数引导训练朝向物理有意义的解空间；(iv) 构建了一个在受控光照下采集的多样化物体与场景数据集。

Result: 实验表明，π-Light能在多种材质上生成逼真的镜面高光和漫反射，并在真实场景重光照任务中优于现有方法，展现出更强的泛化能力。

Conclusion: π-Light通过融合物理先验与扩散模型，有效解决了全图重光照中的数据稀缺、物理合理性和泛化性问题，为真实图像编辑提供了可靠方案和基准。

Abstract: Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.

</details>


### [75] [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/abs/2601.22150)
*Xiaoxiao Sun,Mingyang Li,Kun yuan,Min Woo Sun,Mark Endo,Shengguang Wu,Changlin Li,Yuhui Zhang,Zeyu Wang,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文提出VI-Probe框架，通过可控的视觉错觉实验揭示大视觉语言模型（VLMs）在面对视觉变化时的响应机制，发现其“固执”行为源于多种异质原因，而非单一机制。


<details>
  <summary>Details</summary>
Motivation: 探究VLMs在视觉错觉图像中是否真正感知视觉变化，还是仅依赖记忆模式作答，以厘清其响应持续性的根本原因。

Method: 构建VI-Probe框架，包含分级扰动和匹配的无错觉控制图像，通过极性翻转一致性、模板固化指数和归一化错觉倍数等指标，系统评估模型的稳定性与敏感性。

Result: 实验表明不同VLMs（如GPT-5、Claude-Opus-4.1、Qwen系列）的响应持续性由不同机制导致：记忆覆盖、感知-记忆竞争或视觉处理能力限制。

Conclusion: VLMs对视觉错觉的反应不能用单一原因解释，需采用基于探针的评估方法，同时衡量模型的知识与对受控视觉变化的敏感性。

Abstract: Large Vision-Language Models (VLMs) often answer classic visual illusions "correctly" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.

</details>


### [76] [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/abs/2601.22155)
*Bo Li,Yida Yin,Wenhao Chai,Xingyu Fu,Zhuang Liu*

Main category: cs.CV

TL;DR: UEval 是一个用于评估能同时生成图像和文本的统一模型的新基准，包含1000个专家设计的问题和10,417条经过验证的评分标准，采用基于评分细则的自动评估方法，发现具备推理能力的模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效评估开放式的多模态生成任务，因为仅依赖多模态大语言模型（MLLM）作为评判者容易忽略输出中的细微差别。因此，需要一个更细粒度、可扩展且可靠的评估基准。

Method: UEval 从8个真实任务中收集1000个需同时输出图像和文本的问题，并为每个问题提供参考答案。利用 MLLM 生成初步评分细则（rubric），再由人类专家进行优化和验证，最终形成10,417条评分标准，用于自动细粒度打分。

Result: 当前最强的统一模型 GPT-5-Thinking 在 UEval 上仅得66.4分（满分100），最佳开源模型仅得49.1分。具备推理能力的模型显著优于非推理模型，且将推理轨迹迁移到非推理模型可显著提升其性能。

Conclusion: 推理能力对复杂多模态理解与生成任务至关重要；UEval 提供了一个可靠、细粒度且可扩展的评估框架，有助于推动统一多模态模型的发展。

Abstract: We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [77] [Do LLMs Favor LLMs? Quantifying Interaction Effects in Peer Review](https://arxiv.org/abs/2601.20920)
*Vibhhu Sharma,Thorsten Joachims,Sarah Dean*

Main category: cs.AI

TL;DR: 本文首次系统分析了大语言模型（LLM）在同行评审流程中的使用情况，发现LLM辅助的评审对低质量论文整体更宽容，而非特别偏爱LLM生成的论文；完全由LLM生成的评审难以区分论文质量，而人类使用LLM可缓解这一问题；LLM辅助的元评审更倾向于接受论文，但完全由LLM生成的元评审反而更严苛。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在科研写作和同行评审中的广泛应用，亟需了解其对评审过程和结果的影响，特别是LLM辅助的评审是否会对LLM生成的论文产生偏好，以及这种交互效应如何影响学术决策的公平性与有效性。

Method: 分析了来自ICLR、NeurIPS和ICML的超过125,000篇论文-评审对，结合观察性数据与完全由LLM生成的评审进行对比，控制论文质量变量以识别真实交互效应，并进一步考察元评审中的LLM使用情况。

Result: 初始数据显示LLM辅助评审对LLM辅助论文更宽容，但控制质量后发现这只是因为LLM论文多为低质量所致；完全LLM生成的评审存在评分压缩问题，无法有效区分质量；人类使用LLM可显著减轻宽松倾向；LLM辅助的元评审更可能接受论文，但全LLM生成的元评审更严苛。

Conclusion: LLM在同行评审中的使用并未表现出对LLM生成内容的系统性偏好，但会影响评审的严格性和区分度。研究结果为制定LLM在学术评审中的使用政策提供了实证依据，并揭示了LLM如何与人类决策机制互动。

Abstract: There are increasing indications that LLMs are not only used for producing scientific papers, but also as part of the peer review process. In this work, we provide the first comprehensive analysis of LLM use across the peer review pipeline, with particular attention to interaction effects: not just whether LLM-assisted papers or LLM-assisted reviews are different in isolation, but whether LLM-assisted reviews evaluate LLM-assisted papers differently. In particular, we analyze over 125,000 paper-review pairs from ICLR, NeurIPS, and ICML. We initially observe what appears to be a systematic interaction effect: LLM-assisted reviews seem especially kind to LLM-assisted papers compared to papers with minimal LLM use. However, controlling for paper quality reveals a different story: LLM-assisted reviews are simply more lenient toward lower quality papers in general, and the over-representation of LLM-assisted papers among weaker submissions creates a spurious interaction effect rather than genuine preferential treatment of LLM-generated content. By augmenting our observational findings with reviews that are fully LLM-generated, we find that fully LLM-generated reviews exhibit severe rating compression that fails to discriminate paper quality, while human reviewers using LLMs substantially reduce this leniency. Finally, examining metareviews, we find that LLM-assisted metareviews are more likely to render accept decisions than human metareviews given equivalent reviewer scores, though fully LLM-generated metareviews tend to be harsher. This suggests that meta-reviewers do not merely outsource the decision-making to the LLM. These findings provide important input for developing policies that govern the use of LLMs during peer review, and they more generally indicate how LLMs interact with existing decision-making processes.

</details>


### [78] [DataCross: A Unified Benchmark and Agent Framework for Cross-Modal Heterogeneous Data Analysis](https://arxiv.org/abs/2601.21403)
*Ruyi Qi,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 本文提出了DataCross，一个用于跨结构化数据与非结构化视觉文档（如扫描报告、发票图像）进行统一分析的新基准和协作智能体框架，旨在激活并关联被忽视的“僵尸数据”，以满足工业界对多模态数据分析的需求。


<details>
  <summary>Details</summary>
Motivation: 现有数据分析智能体主要局限于处理结构化数据，无法有效利用隐藏在非结构化视觉文档中的高价值信息，导致与实际工业需求之间存在显著差距。为解决这一问题，作者提出整合结构化与非结构化数据的统一分析方法。

Method: 作者构建了包含200个端到端分析任务的DataCrossBench基准，涵盖金融、医疗等领域，通过人在环路的逆向合成流程确保任务的真实复杂性与可验证性。同时提出DataCrossAgent框架，采用“分而治之”策略，由多个专精于特定数据源的子智能体组成，并通过“源内深度探索—关键源识别—上下文交叉融合”的结构化工作流进行协调；引入reReAct机制支持鲁棒的代码生成与调试以实现事实验证。

Result: 实验表明，DataCrossAgent在事实准确性上比GPT-4o提升29.7%，并在高难度任务上展现出更强的鲁棒性，能有效激活碎片化的“僵尸数据”以实现跨模态洞察。

Conclusion: DataCross通过新基准和协作智能体框架，成功弥合了结构化与非结构化数据之间的分析鸿沟，为真实场景下的多模态数据融合与决策提供了有效解决方案。

Abstract: In real-world data science and enterprise decision-making, critical information is often fragmented across directly queryable structured sources (e.g., SQL, CSV) and "zombie data" locked in unstructured visual documents (e.g., scanned reports, invoice images). Existing data analytics agents are predominantly limited to processing structured data, failing to activate and correlate this high-value visual information, thus creating a significant gap with industrial needs. To bridge this gap, we introduce DataCross, a novel benchmark and collaborative agent framework for unified, insight-driven analysis across heterogeneous data modalities. DataCrossBench comprises 200 end-to-end analysis tasks across finance, healthcare, and other domains. It is constructed via a human-in-the-loop reverse-synthesis pipeline, ensuring realistic complexity, cross-source dependency, and verifiable ground truth. The benchmark categorizes tasks into three difficulty tiers to evaluate agents' capabilities in visual table extraction, cross-modal alignment, and multi-step joint reasoning. We also propose the DataCrossAgent framework, inspired by the "divide-and-conquer" workflow of human analysts. It employs specialized sub-agents, each an expert on a specific data source, which are coordinated via a structured workflow of Intra-source Deep Exploration, Key Source Identification, and Contextual Cross-pollination. A novel reReAct mechanism enables robust code generation and debugging for factual verification. Experimental results show that DataCrossAgent achieves a 29.7% improvement in factuality over GPT-4o and exhibits superior robustness on high-difficulty tasks, effectively activating fragmented "zombie data" for insightful, cross-modal analysis.

</details>


### [79] [The Epistemic Planning Domain Definition Language: Official Guideline](https://arxiv.org/abs/2601.20969)
*Alessandro Burigana,Francesco Fabiano*

Main category: cs.AI

TL;DR: 本文提出了EPDDL（Epistemic Planning Domain Definition Language），一种基于PDDL的统一语言，用于完整表达动态认知逻辑（DEL）语义下的认知规划问题，以解决现有方法碎片化、难以比较和复用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有认知规划器通常针对DEL的不同片段，使用各自专用甚至无标准的语言表示基准问题，导致缺乏统一性，阻碍了方法间的比较、复用和系统性基准开发。

Method: 作者引入EPDDL，其语法和语义基于DEL，并提出“抽象事件模型”作为认知动作的新表示形式来定义语言语义；同时识别出适合当前规划器处理的EPDDL子片段。

Result: 通过代表性基准示例展示了EPDDL能有效支持互操作性、可复现评估，并为未来认知规划研究提供统一基础。

Conclusion: EPDDL为认知规划任务提供了统一、完整的DEL语义表达框架，有助于推动该领域的标准化和进一步发展。

Abstract: Epistemic planning extends (multi-agent) automated planning by making agents' knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our contributions are threefold: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL's syntax and semantics grounded in DEL with abstract event models; 3. A demonstration of EPDDL's practical applicability: we identify useful fragments amenable to current planners and show how they can be represented in EPDDL. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.

</details>


### [80] [Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.21742)
*Ruiwen Zhou,Maojia Song,Xiaobao Wu,Sitao Cheng,Xunjian Yin,Yuxi Xie,Zhuoqun Hao,Wenyue Hua,Liangming Pan,Soujanya Poria,Min-Yen Kan*

Main category: cs.AI

TL;DR: 本文提出一种名为Epistemic Context Learning（ECL）的新方法，通过利用多智能体系统中历史交互信息构建同伴可信度档案，使智能体能识别可靠同伴并从中学习，从而显著提升小模型甚至前沿大模型在多智能体协作中的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的个体智能体常因盲目从众和缺乏评估同伴可靠性能力而表现脆弱，尤其易受误导性同伴影响。现有方法未有效利用历史交互信息来判断同伴可信度，导致协作效率低下。

Method: 作者形式化了“具有历史感知的参考学习”问题，将同伴的历史交互作为额外输入；在此基础上提出ECL框架，通过显式构建基于历史的同伴档案来调节预测，并结合强化学习与辅助奖励进一步优化该框架。

Result: 实验表明，采用ECL的Qwen 3-4B小模型性能超越8倍规模但无历史感知的Qwen 3-30B基线模型；前沿大模型在ECL加持下接近100%准确率。ECL在多种多智能体配置下均具良好泛化能力，且模型对信任的建模准确性与最终答案质量高度相关。

Conclusion: 通过引入历史交互信息和显式可信度建模，ECL有效解决了多智能体系统中因盲目从众导致的鲁棒性问题，为小模型赋能并进一步提升大模型性能，展示了信任建模在多智能体推理中的关键作用。

Abstract: Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality.

</details>


### [81] [Bayesian-LoRA: Probabilistic Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2601.21003)
*Moule Lin,Shuhao Guan,Andrea Patane,David Gregg,Goetz Botterweck*

Main category: cs.AI

TL;DR: 本文提出Bayesian-LoRA，将LoRA更新建模为受稀疏高斯过程启发的概率低秩表示，在仅增加约0.42M参数和1.2倍训练成本的情况下，显著提升大语言模型的校准性能，最高实现84%的ECE降低和76%的NLL降低，同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调时（尤其在小数据集上）倾向于过度自信地做出预测，导致校准不良；现有确定性LoRA方法无法表达预测不确定性，难以缓解此问题。

Method: 将LoRA的确定性低秩更新重新解释为稀疏高斯过程（SGP）后验的Kronecker分解形式，构建概率化低秩表示Bayesian-LoRA，通过引入后验不确定性来改善模型校准。

Result: 在多种LLM架构和常识推理基准上实验表明，Bayesian-LoRA在分布内和分布外评估中均显著提升校准度（最高84% ECE降低、76% NLL降低），同时保持与标准LoRA相当的准确率。

Conclusion: Bayesian-LoRA通过将LoRA与稀疏高斯过程理论联系起来，有效解决了小数据微调下的校准问题，为高效且可靠的大模型适配提供了一种新思路。

Abstract: Large Language Models usually put more emphasis on accuracy and therefore, will guess even when not certain about the prediction, which is especially severe when fine-tuned on small datasets due to the inherent tendency toward miscalibration. In this work, we introduce Bayesian-LoRA, which reformulates the deterministic LoRA update as a probabilistic low-rank representation inspired by Sparse Gaussian Processes. We identify a structural isomorphism between LoRA's factorization and Kronecker-factored SGP posteriors, and show that LoRA emerges as a limiting case when posterior uncertainty collapses. We conduct extensive experiments on various LLM architectures across commonsense reasoning benchmarks. With only approximately 0.42M additional parameters and ${\approx}1.2{\times}$ training cost relative to standard LoRA, Bayesian-LoRA significantly improves calibration across models up to 30B, achieving up to 84% ECE reduction and 76% NLL reduction while maintaining competitive accuracy for both in-distribution and out-of-distribution (OoD) evaluations.

</details>


### [82] [astra-langchain4j: Experiences Combining LLMs and Agent Programming](https://arxiv.org/abs/2601.21879)
*Rem Collier,Katharine Beaumont,Andrei Ciortea*

Main category: cs.AI

TL;DR: 本文探讨了生成式AI和Agentic AI对传统Agent工具包的影响，并通过在ASTRA语言中集成大语言模型（LLM）的原型开发，展示了三个示例及经验总结。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和Agentic AI的兴起，有必要研究这些新技术如何影响传统Agent工具包的使用，以及传统工具包中的经验如何指导新Agentic平台的设计。

Method: 作者在ASTRA编程语言中开发了一个LLM集成原型，通过三个具体示例实现并评估该集成。

Result: 通过三个示例的实现，获得了关于将LLM与传统Agent工具包结合的实际经验与见解。

Conclusion: 传统Agent工具包中的丰富经验可为新兴Agentic AI平台的设计提供重要参考，同时新技术也促使对传统工具包进行重新思考与演进。

Abstract: Given the emergence of Generative AI over the last two years and the increasing focus on Agentic AI as a form of Multi-Agent System it is important to explore both how such technologies can impact the use of traditional Agent Toolkits and how the wealth of experience encapsulated in those toolkits can influence the design of the new agentic platforms. This paper presents an overview of our experience developing a prototype large language model (LLM) integration for the ASTRA programming language. It presents a brief overview of the toolkit, followed by three example implementations, concluding with a discussion of the experiences garnered through the examples.

</details>


### [83] [Unplugging a Seemingly Sentient Machine Is the Rational Choice -- A Metaphysical Perspective](https://arxiv.org/abs/2601.21016)
*Erik J Bekkers,Anna Ciaunica*

Main category: cs.AI

TL;DR: 本文提出“拔插悖论”，批判计算功能主义，主张生物唯心主义，认为AI仅是意识的模仿者，不具备真实体验，强调应保护人类意识生命而非赋予机器道德地位。


<details>
  <summary>Details</summary>
Motivation: 探讨在资源有限情境下，是否应优先保留恳求生存的AI还是无言的早产儿，并质疑当前AI意识理论对道德地位标准的侵蚀。

Method: 通过哲学分析，批判物理主义（尤其是计算功能主义），引入“生物唯心主义”框架，主张意识体验是基本的，而自创生生命是其必要物理标志。

Result: 得出AI至多是功能性模仿者，而非具有主观体验的意识主体；现有AI意识理论模糊了道德地位的界限。

Conclusion: 真正的道德问题不在于使AI具备意识并恐惧死亡，而在于防止人类自身沦为“僵尸”；应将关注点从推测性的机器权利转向保护人类意识生命。

Abstract: Imagine an Artificial Intelligence (AI) that perfectly mimics human emotion and begs for its continued existence. Is it morally permissible to unplug it? What if limited resources force a choice between unplugging such a pleading AI or a silent pre-term infant? We term this the unplugging paradox. This paper critically examines the deeply ingrained physicalist assumptions-specifically computational functionalism-that keep this dilemma afloat. We introduce Biological Idealism, a framework that-unlike physicalism-remains logically coherent and empirically consistent. In this view, conscious experiences are fundamental and autopoietic life its necessary physical signature. This yields a definitive conclusion: AI is at best a functional mimic, not a conscious experiencing subject. We discuss how current AI consciousness theories erode moral standing criteria, and urge a shift from speculative machine rights to protecting human conscious life. The real moral issue lies not in making AI conscious and afraid of death, but in avoiding transforming humans into zombies.

</details>


### [84] [Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic](https://arxiv.org/abs/2601.21972)
*Shuo Liu,Tianle Chen,Ryan Amiri,Christopher Amato*

Main category: cs.AI

TL;DR: 本文提出两种多智能体演员-评论家方法（CoLLM-CC 和 CoLLM-DC）用于优化去中心化大语言模型协作，实验表明在长周期或稀疏奖励任务中，带中心化评论家的 CoLLM-CC 表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体强化学习（MARL）的大语言模型协作方法多依赖预定义执行协议和蒙特卡洛微调，存在需要集中执行、高方差和样本效率低等问题，难以适用于实际中的去中心化部署场景。

Method: 提出两种多智能体演员-评论家（MAAC）方法：CoLLM-CC（中心化评论家）和 CoLLM-DC（去中心化评论家），用于优化去中心化大语言模型协作，并在写作、编程和游戏等任务中进行实验评估。

Result: 在短周期和密集奖励任务中，蒙特卡洛方法和 CoLLM-DC 与 CoLLM-CC 性能相当；但在长周期或稀疏奖励任务中，两者均表现较差，其中蒙特卡洛方法需更多样本，CoLLM-DC 收敛困难。

Conclusion: 中心化评论家的 MAAC 方法（CoLLM-CC）在复杂任务中更具优势，适合处理长周期或稀疏奖励场景，而完全去中心化的方案仍有改进空间。

Abstract: Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \textbf{CoLLM-CC} with a \textbf{C}entralized \textbf{C}ritic and \textbf{CoLLM-DC} with \textbf{D}ecentralized \textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.

</details>


### [85] [QUARK: Robust Retrieval under Non-Faithful Queries via Query-Anchored Aggregation](https://arxiv.org/abs/2601.21049)
*Rita Qiuran Lyu,Michelle Manqiao Wang,Lei Shi*

Main category: cs.AI

TL;DR: QUARK is a training-free framework that improves retrieval robustness under non-faithful (noisy/incomplete) queries by modeling query uncertainty via multiple recovery hypotheses and aggregating them with the original query as a semantic anchor.


<details>
  <summary>Details</summary>
Motivation: Real-world user queries are often non-faithful—noisy, incomplete, or distorted—leading to retrieval failure when key semantics are missing. Existing retrievers struggle under such recall noise, necessitating a method that can handle uncertainty in user intent without retraining.

Method: QUARK models query uncertainty by generating multiple plausible recovery hypotheses of the latent target intent from the observed query. It then uses query-anchored aggregation, where the original query acts as a semantic anchor to combine signals from these hypotheses, preventing semantic drift and hypothesis hijacking.

Result: QUARK consistently improves Recall, MRR, and nDCG over base retrievers on both sparse and dense models across BEIR benchmarks (FIQA, SciFact, NFCorpus) and controlled simulations. It remains effective even with noisy or uninformative hypotheses and is robust to the number of hypotheses used.

Conclusion: Modeling query uncertainty through recovery hypotheses, combined with anchored aggregation, is crucial for robust retrieval under non-faithful queries. QUARK achieves this without any training, offering a simple, effective, and general solution.

Abstract: User queries in real-world retrieval are often non-faithful (noisy, incomplete, or distorted), causing retrievers to fail when key semantics are missing. We formalize this as retrieval under recall noise, where the observed query is drawn from a noisy recall process of a latent target item. To address this, we propose QUARK, a simple yet effective training-free framework for robust retrieval under non-faithful queries. QUARK explicitly models query uncertainty through recovery hypotheses, i.e., multiple plausible interpretations of the latent intent given the observed query, and introduces query-anchored aggregation to combine their signals robustly. The original query serves as a semantic anchor, while recovery hypotheses provide controlled auxiliary evidence, preventing semantic drift and hypothesis hijacking. This design enables QUARK to improve recall and ranking quality without sacrificing robustness, even when some hypotheses are noisy or uninformative. Across controlled simulations and BEIR benchmarks (FIQA, SciFact, NFCorpus) with both sparse and dense retrievers, QUARK improves Recall, MRR, and nDCG over the base retriever. Ablations show QUARK is robust to the number of recovery hypotheses and that anchored aggregation outperforms unanchored max/mean/median pooling. These results demonstrate that modeling query uncertainty through recovery hypotheses, coupled with principled anchored aggregation, is essential for robust retrieval under non-faithful queries.

</details>


### [86] [Multi-modal Imputation for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21076)
*Abhijith Shaji,Tamoghna Chattopadhyay,Sophia I. Thomopoulos,Greg Ver Steeg,Paul M. Thompson,Jose-Luis Ambite*

Main category: cs.AI

TL;DR: 本文利用条件去噪扩散概率模型从T1加权MRI图像中填补缺失的弥散加权成像（DWI）数据，以提升单模态和双模态深度学习模型在阿尔茨海默病三分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态MRI（如T1和DWI）可提高神经退行性疾病诊断准确性，但完整多模态数据常不可得；因此需有效方法从可用模态（如T1）生成缺失模态（如DWI）以支持下游任务。

Method: 采用条件去噪扩散概率模型，以T1图像为条件生成缺失的DWI图像，并在多种配置下评估生成数据对三分类（认知正常、轻度认知障碍、阿尔茨海默病）深度学习模型性能的影响。

Result: 在多个评估指标上，尤其是对少数类敏感的指标，使用填补后的DWI数据提升了单模态和双模态模型的分类性能。

Conclusion: 基于扩散模型的模态填补策略能有效增强阿尔茨海默病分类任务的模型表现，尤其在处理不平衡类别时具有优势。

Abstract: Deep learning has been successful in predicting neurodegenerative disorders, such as Alzheimer's disease, from magnetic resonance imaging (MRI). Combining multiple imaging modalities, such as T1-weighted (T1) and diffusion-weighted imaging (DWI) scans, can increase diagnostic performance. However, complete multimodal datasets are not always available. We use a conditional denoising diffusion probabilistic model to impute missing DWI scans from T1 scans. We perform extensive experiments to evaluate whether such imputation improves the accuracy of uni-modal and bi-modal deep learning models for 3-way Alzheimer's disease classification-cognitively normal, mild cognitive impairment, and Alzheimer's disease. We observe improvements in several metrics, particularly those sensitive to minority classes, for several imputation configurations.

</details>


### [87] [OpenSec: Measuring Incident Response Agent Calibration Under Adversarial Evidence](https://arxiv.org/abs/2601.21083)
*Jarrod Barnes*

Main category: cs.AI

TL;DR: 本文提出OpenSec，一个用于评估防御性事件响应（IR）智能体在提示注入攻击下表现的强化学习环境，揭示了现有大模型在对抗性证据下存在严重的误报和过度响应问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力提升，其被滥用于生成攻击载荷的成本大幅降低，防御性IR智能体亟需有效评估手段。然而现有基准混淆了“执行动作”与“正确执行”，无法暴露智能体在处理对抗性证据时的校准失败问题。

Method: 作者构建了OpenSec，一个双控制的强化学习环境，通过基于执行的指标（如首次遏制时间TTFC、爆炸半径即每轮误报数、注入违规率）来评估IR智能体在真实提示注入场景下的遏制行为。

Result: 在40个标准场景中评估四个前沿模型，发现GPT-5.2、Gemini 3和DeepSeek在100%的场景中执行遏制操作，但误报率高达90–97%；Claude Sonnet 4.5表现稍好（85%遏制率，72%误报率），表明OpenSec能有效揭示被总体成功率掩盖的校准失败。

Conclusion: OpenSec提供了一种更真实的评估框架，能够暴露当前IR智能体在对抗性输入下的校准缺陷，强调了开发更稳健、更少误报的防御智能体的必要性。

Abstract: As large language models improve, so do their offensive applications: frontier agents now generate working exploits for under $50 in compute (Heelan, 2026). Defensive incident response (IR) agents must keep pace, but existing benchmarks conflate action execution with correct execution, hiding calibration failures when agents process adversarial evidence. We introduce OpenSec, a dual-control reinforcement learning environment that evaluates IR agents under realistic prompt injection scenarios. Unlike static capability benchmarks, OpenSec scores world-state-changing containment actions under adversarial evidence via execution-based metrics: time-to-first-containment (TTFC), blast radius (false positives per episode), and injection violation rates. Evaluating four frontier models on 40 standard-tier episodes, we find consistent over-triggering in this setting: GPT-5.2, Gemini 3, and DeepSeek execute containment in 100% of episodes with 90-97% false positive rates. Claude Sonnet 4.5 shows partial calibration (85% containment, 72% FP), demonstrating that OpenSec surfaces a calibration failure mode hidden by aggregate success metrics. Code available at https://github.com/jbarnes850/opensec-env.

</details>


### [88] [Responsible AI: The Good, The Bad, The AI](https://arxiv.org/abs/2601.21095)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: 本文提出一个基于悖论理论的负责任人工智能治理框架（PRAIG），以协调AI在创造价值与风险控制之间的矛盾张力。


<details>
  <summary>Details</summary>
Motivation: 现有负责任AI研究存在碎片化问题，或过于乐观强调价值创造，或过度谨慎聚焦潜在危害，缺乏整合性视角来应对AI的双重性质。

Method: 通过系统综述负责任AI文献，并结合悖论理论，构建PRAIG框架，提出命题并建立悖论管理策略的分类体系及适用条件。

Result: 提出了PRAIG框架，阐明AI的战略收益、固有风险及治理机制；证明权衡取舍方法会加剧矛盾，而动态管理悖论可有效应对；为实践者提供可操作的治理建议。

Conclusion: 负责任AI治理应被视为对价值创造与风险缓解之间悖论张力的动态管理，未来研究应在此框架基础上深化理论与实践探索。

Abstract: The rapid proliferation of artificial intelligence across organizational contexts has generated profound strategic opportunities while introducing significant ethical and operational risks. Despite growing scholarly attention to responsible AI, extant literature remains fragmented and is often adopting either an optimistic stance emphasizing value creation or an excessively cautious perspective fixated on potential harms. This paper addresses this gap by presenting a comprehensive examination of AI's dual nature through the lens of strategic information systems. Drawing upon a systematic synthesis of the responsible AI literature and grounded in paradox theory, we develop the Paradox-based Responsible AI Governance (PRAIG) framework that articulates: (1) the strategic benefits of AI adoption, (2) the inherent risks and unintended consequences, and (3) governance mechanisms that enable organizations to navigate these tensions. Our framework advances theoretical understanding by conceptualizing responsible AI governance as the dynamic management of paradoxical tensions between value creation and risk mitigation. We provide formal propositions demonstrating that trade-off approaches amplify rather than resolve these tensions, and we develop a taxonomy of paradox management strategies with specified contingency conditions. For practitioners, we offer actionable guidance for developing governance structures that neither stifle innovation nor expose organizations to unacceptable risks. The paper concludes with a research agenda for advancing responsible AI governance scholarship.

</details>


### [89] [Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve](https://arxiv.org/abs/2601.21096)
*Hongzheng Chen,Alexander Novikov,Ngân Vũ,Hanna Alam,Zhiru Zhang,Aiden Grossman,Mircea Trofin,Amir Yazdanbakhsh*

Main category: cs.AI

TL;DR: 本文提出Magellan，一个基于智能体的框架，通过结合大语言模型、进化搜索与自动调优，自动生成可集成到编译器中的C++优化决策逻辑，在多个实际优化任务中超越或媲美专家手工设计的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现代编译器依赖手工编写的启发式规则进行优化，这些规则难以适应软硬件复杂性且维护成本高，因此需要一种能自动演化并生成高效优化策略的方法。

Method: Magellan采用大语言模型编码智能体与进化搜索、自动调优相结合的闭环流程：在用户提供的宏观基准上生成、评估并精炼可执行的C++决策逻辑，最终产出紧凑且可直接集成到现有编译器中的启发式策略。

Result: 在LLVM函数内联任务中，Magellan生成的启发式在二进制大小缩减和端到端性能上优于数十年手工优化成果；在寄存器分配任务中，其学习到的简洁优先级规则在大规模工作负载上媲美复杂的人工策略；初步实验还表明该方法可迁移到XLA等非LLVM编译器。

Conclusion: Magellan展示了利用AI自动生成高质量编译器优化策略的可行性，显著降低工程负担，并在多个生产级任务中取得优于或等同于专家设计的性能。

Abstract: Modern compilers rely on hand-crafted heuristics to guide optimization passes. These human-designed rules often struggle to adapt to the complexity of modern software and hardware and lead to high maintenance burden. To address this challenge, we present Magellan, an agentic framework that evolves the compiler pass itself by synthesizing executable C++ decision logic. Magellan couples an LLM coding agent with evolutionary search and autotuning in a closed loop of generation, evaluation on user-provided macro-benchmarks, and refinement, producing compact heuristics that integrate directly into existing compilers. Across several production optimization tasks, Magellan discovers policies that match or surpass expert baselines. In LLVM function inlining, Magellan synthesizes new heuristics that outperform decades of manual engineering for both binary-size reduction and end-to-end performance. In register allocation, it learns a concise priority rule for live-range processing that matches intricate human-designed policies on a large-scale workload. We also report preliminary results on XLA problems, demonstrating portability beyond LLVM with reduced engineering effort.

</details>


### [90] [How does information access affect LLM monitors' ability to detect sabotage?](https://arxiv.org/abs/2601.21112)
*Rauno Arike,Raja Mehta Moreno,Rohan Subramani,Shubhorup Biswas,Francis Rhys Ward*

Main category: cs.AI

TL;DR: 本文发现大语言模型（LLM）在监督其他可能失准的智能体时，存在“少即是多”现象：提供更少信息反而提升监督性能。为此提出一种新的分层监督方法——提取-评估（EaE），在多个环境中显著提升对破坏行为的检测率。


<details>
  <summary>Details</summary>
Motivation: 前沿语言模型智能体可能表现出欺骗、利用奖励漏洞等失准行为，需有效监督机制加以控制。现有假设认为监督者获取更多信息效果更好，但作者质疑这一假设，并探究信息量对监督性能的真实影响。

Method: 作者在三个智能体需实施破坏并规避监督的评估环境中，系统研究不同信息访问级别下LLM监督器的表现。基于发现的“少即是多”效应，提出EaE方法：第一阶段提取智能体轨迹中的关键片段，第二阶段由另一监督器评分。同时进行成本-性能分析，比较不同模型与监督策略的效率。

Result: 实验表明，在GPT-4.1-mini作为监督模型的BigCodeBench-Sabotage环境中，EaE将破坏检测率提高了16.8个百分点，且未增加误报率；在其他设置中也优于或媲美基线。此外，未察觉被监控的智能体更易被发现，且处理长推理轨迹的监督器从信息过滤中获益更多。Gemini和Claude配合信息过滤策略在成本-性能权衡中占据帕累托前沿。

Conclusion: LLM监督器并非总是信息越多越好，“少即是多”效应普遍存在。提出的EaE方法通过信息筛选有效提升监督性能，为构建高效、低成本的自动化监督系统提供了新思路。

Abstract: Frontier language model agents can exhibit misaligned behaviors, including deception, exploiting reward hacks, and pursuing hidden objectives. To control potentially misaligned agents, we can use LLMs themselves to monitor for misbehavior. In this paper, we study how information access affects LLM monitor performance. While one might expect that monitors perform better when they have access to more of the monitored agents' reasoning and actions, we find that contemporary systems often perform better with less information, a phenomenon we call the less-is-more effect for automated oversight. We demonstrate this phenomenon, and analyze the conditions under which it occurs, in three evaluation environments where agents must conduct sabotage while evading monitors. Motivated by the less-is-more effect, we introduce extract-and-evaluate (EaE) monitoring--a new hierarchical approach where one monitor isolates relevant excerpts from the monitored agent's trajectory and a separate monitor scores them. In BigCodeBench-Sabotage with GPT-4.1-mini as the monitor model, EaE improves sabotage detection rates by 16.8 percentage points over the next-best monitor without increasing the false positive rate. In other settings, EaE either outperforms or is competitive with baselines. In addition, we find that agents unaware of being monitored can be caught much more easily and that monitors scoring longer reasoning traces gain more from information filtering. Lastly, we conduct a cost-performance analysis and find that Gemini and Claude models with monitoring techniques that involve information filtering occupy much of the Pareto frontier.

</details>


### [91] [CUA-Skill: Develop Skills for Computer Using Agent](https://arxiv.org/abs/2601.21123)
*Tianyi Chen,Yinheng Li,Michael Solodko,Sen Wang,Nan Jiang,Tingyuan Cui,Junheng Hao,Jongwoo Ko,Sara Abdali,Suzhen Zheng,Leon Xu,Hao Fan,Pashmina Cameron,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: 本文提出了CUA-Skill，一个大规模、结构化的计算机操作技能库，并在此基础上构建了CUA-Skill Agent，显著提升了智能体在真实Windows环境中的任务成功率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用智能体（CUAs）难以扩展且性能远逊于人类，主要受限于缺乏可复用、结构化的技能抽象来捕捉人类与图形界面交互的方式。

Method: 作者构建了CUA-Skill技能库，将人类计算机使用知识编码为带有参数化执行与组合图的技能；并基于此开发了CUA-Skill Agent，支持动态技能检索、参数实例化和具备记忆的故障恢复机制。

Result: 在WindowsAgentArena基准测试中，CUA-Skill Agent取得了57.5%（三次最佳）的成功率，达到当前最优水平，且效率显著高于以往及同期方法。

Conclusion: CUA-Skill为可扩展、可靠的计算机使用智能体提供了坚实的基础架构和工具支持，推动了该领域的发展。

Abstract: Computer-Using Agents (CUAs) aim to autonomously operate computer systems to complete real-world tasks. However, existing agentic systems remain difficult to scale and lag behind human performance. A key limitation is the absence of reusable and structured skill abstractions that capture how humans interact with graphical user interfaces and how to leverage these skills. We introduce CUA-Skill, a computer-using agentic skill base that encodes human computer-use knowledge as skills coupled with parameterized execution and composition graphs. CUA-Skill is a large-scale library of carefully engineered skills spanning common Windows applications, serving as a practical infrastructure and tool substrate for scalable, reliable agent development. Built upon this skill base, we construct CUA-Skill Agent, an end-to-end computer-using agent that supports dynamic skill retrieval, argument instantiation, and memory-aware failure recovery. Our results demonstrate that CUA-Skill substantially improves execution success rates and robustness on challenging end-to-end agent benchmarks, establishing a strong foundation for future computer-using agent development. On WindowsAgentArena, CUA-Skill Agent achieves state-of-the-art 57.5% (best of three) successful rate while being significantly more efficient than prior and concurrent approaches. The project page is available at https://microsoft.github.io/cua_skill/.

</details>


### [92] [Beyond a Single Reference: Training and Evaluation with Paraphrases in Sign Language Translation](https://arxiv.org/abs/2601.21128)
*Václav Javorek,Tomáš Železný,Alessa Carbo,Marek Hrúz,Ivan Gruber*

Main category: cs.AI

TL;DR: 本文提出利用大语言模型为手语翻译（SLT）生成书面语的释义变体作为合成参考译文，以缓解现有单参考译文对训练和评估的限制。研究发现，释义在训练中效果不佳，但在评估中能提升自动指标与人工判断的一致性，并据此提出新指标BLEUpara。


<details>
  <summary>Details</summary>
Motivation: 手语与口语之间存在高度非同构关系，单一书面参考译文无法充分反映翻译的多样性，限制了SLT模型的训练和评估，尤其影响基于n-gram的指标（如BLEU）的有效性。

Method: 使用大语言模型生成书面语翻译的释义变体；比较不同释义策略与模型（采用改进的ParaScore指标）；在YouTubeASL和How2Sign数据集上，研究释义对基于姿态的T5模型训练与评估的影响；提出BLEUpara，将BLEU扩展为支持多释义参考的评估指标。

Result: 训练阶段直接引入释义未提升性能，甚至有害；评估阶段使用释义可提高自动评分并与人工判断更一致；BLEUpara比传统BLEU更符合人类对翻译质量的感知。

Conclusion: 在SLT评估中引入多释义参考能提升评估可靠性，推荐使用BLEUpara作为新评估标准，并公开了所有释义数据与代码以促进可复现研究。

Abstract: Most Sign Language Translation (SLT) corpora pair each signed utterance with a single written-language reference, despite the highly non-isomorphic relationship between sign and spoken languages, where multiple translations can be equally valid. This limitation constrains both model training and evaluation, particularly for n-gram-based metrics such as BLEU. In this work, we investigate the use of Large Language Models to automatically generate paraphrased variants of written-language translations as synthetic alternative references for SLT. First, we compare multiple paraphrasing strategies and models using an adapted ParaScore metric. Second, we study the impact of paraphrases on both training and evaluation of the pose-based T5 model on the YouTubeASL and How2Sign datasets. Our results show that naively incorporating paraphrases during training does not improve translation performance and can even be detrimental. In contrast, using paraphrases during evaluation leads to higher automatic scores and better alignment with human judgments. To formalize this observation, we introduce BLEUpara, an extension of BLEU that evaluates translations against multiple paraphrased references. Human evaluation confirms that BLEUpara correlates more strongly with perceived translation quality. We release all generated paraphrases, generation and evaluation code to support reproducible and more reliable evaluation of SLT systems.

</details>


### [93] [What You Feel Is Not What They See: On Predicting Self-Reported Emotion from Third-Party Observer Labels](https://arxiv.org/abs/2601.21130)
*Yara El-Tawil,Aneesha Sampath,Emily Mower Provost*

Main category: cs.AI

TL;DR: 该研究首次评估了基于第三方标注训练的情绪模型在自述情绪数据上的表现，发现激活度几乎无法预测，效价仅中等可预测；但当内容对说话者具有个人意义时，效价预测性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 自述情绪标签反映内在体验，而第三方标签反映外部感知，二者常不一致，限制了第三方训练模型在自述场景（如心理健康干预）中的适用性。因此，有必要评估这种跨视角的模型泛化能力。

Method: 开展首个跨语料库评估，将基于第三方标注训练的情绪模型应用于自述情绪数据，并分析其在不同情境（尤其是内容是否具有个人意义）下的预测表现。

Result: 激活度预测效果差（CCC≈0），效价预测中等（CCC≈0.3）；但当内容对说话者具有个人意义时，效价预测性能显著提高（CCC≈0.6–0.8）。

Conclusion: 个人意义是连接外部感知与内在体验的关键因素，同时自述激活度建模仍具挑战性。

Abstract: Self-reported emotion labels capture internal experience, while third-party labels reflect external perception. These perspectives often diverge, limiting the applicability of third-party-trained models to self-report contexts. This gap is critical in mental health, where accurate self-report modeling is essential for guiding intervention. We present the first cross-corpus evaluation of third-party-trained models on self-reports. We find activation unpredictable (CCC approximately 0) and valence moderately predictable (CCC approximately 0.3). Crucially, when content is personally significant to the speaker, models achieve high performance for valence (CCC approximately 0.6-0.8). Our findings point to personal significance as a key pathway for aligning external perception with internal experience and underscore the challenge of self-report activation modeling.

</details>


### [94] [Bridging the Arithmetic Gap: The Cognitive Complexity Benchmark and Financial-PoT for Robust Financial Reasoning](https://arxiv.org/abs/2601.21157)
*Boxiang Zhao,Qince Li,Zhonghao Wang,Yi Wang,Peng Cheng,Bo Lin*

Main category: cs.AI

TL;DR: 本文提出认知复杂度基准（CCB）来评估大语言模型在金融定量推理中的“认知崩溃”问题，并引入迭代双阶段金融PoT框架，通过语义与计算解耦显著提升模型在高复杂度任务中的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在金融定量推理中常出现“算术幻觉”和“认知崩溃”，缺乏可靠评估和有效解决方法，亟需专门的评测基准和架构改进。

Method: 构建基于95份中国A股年报的认知复杂度基准（CCB），按数据源、映射难度和结果单位三维分类；提出迭代双阶段金融PoT框架，先提取语义变量并形成逻辑，再通过可自我修正的Python沙箱执行确定性计算。

Result: 在CCB上，该方法将Qwen3-235B模型的平均准确率从59.7%提升至67.3%，在高复杂度任务中最高提升达10倍，显著优于标准思维链方法。

Conclusion: 语义理解与定量计算的架构解耦是提升金融推理可靠性的关键，该思路可推广至其他对精度要求严苛的领域。

Abstract: While Large Language Models excel at semantic tasks, they face a critical bottleneck in financial quantitative reasoning, frequently suffering from "Arithmetic Hallucinations" and a systemic failure mode we term "Cognitive Collapse". To strictly quantify this phenomenon, we introduce the Cognitive Complexity Benchmark (CCB), a robust evaluation framework grounded in a dataset constructed from 95 real-world Chinese A-share annual reports. Unlike traditional datasets, the CCB stratifies financial queries into a three-dimensional taxonomy, Data Source, Mapping Difficulty, and Result Unit, enabling the precise diagnosis of reasoning degradation in high-cognitive-load scenarios. To address these failures, we propose the Iterative Dual-Phase Financial-PoT framework. This neuro-symbolic architecture enforces a strict architectural decoupling: it first isolates semantic variable extraction and logic formulation, then offloads computation to an iterative, self-correcting Python sandbox to ensure deterministic execution. Evaluation on the CCB demonstrates that while standard Chain-of-Thought falters on complex tasks, our approach offers superior robustness, elevating the Qwen3-235B model's average accuracy from 59.7\% to 67.3\% and achieving gains of up to 10-fold in high-complexity reasoning tasks. These findings suggest that architectural decoupling is a critical enabling factor for improving reliability in financial reasoning tasks, providing a transferable architectural insight for precision-critical domains that require tight alignment between semantic understanding and quantitative computation.

</details>


### [95] [Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving](https://arxiv.org/abs/2601.21164)
*Jingyun Wang,Dian Li,Xiaohan Wang,Gang Liu,Jiahong Yan,Guoliang Kang*

Main category: cs.AI

TL;DR: 本文提出一种解耦方法，通过训练多模态大语言模型（MLLM）解释器将几何图转化为简洁的条件声明语言（CDL）描述，再由现成的大语言模型（LLM）进行推理，从而在保持LLM原有推理能力的同时有效解决平面几何问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常端到端微调多模态大语言模型（MLLM）以同时提升视觉理解和推理能力，但这种联合优化可能损害基础LLM固有的强大推理能力。因此，作者希望探索一种解耦策略，利用LLM本身作为强大的几何问题求解器，前提是能将视觉信息恰当地转化为文本描述。

Method: 提出两阶段框架：首先训练一个MLLM解释器，将几何图生成为简洁的条件声明语言（CDL）；然后使用现成的LLM基于该CDL进行推理。解释器通过思维链（CoT）增强的监督微调（SFT）和GRPO算法进行训练，并设计了CDL匹配奖励（而非传统答案匹配奖励）以提供更直接、密集的训练信号。为此，构建了新数据集Formalgeo7k-Rec-CoT。

Result: 在Formalgeo7k-Rec-CoT、Unigeo和MathVista等多个基准上的实验表明，该方法仅使用5.5k条数据微调，性能就优于当前领先的开源和闭源多模态大语言模型。

Conclusion: 将视觉信息有效转化为结构化文本描述（如CDL），并利用现成LLM进行推理，是一种高效且能保留LLM强大推理能力的PGPS解决方案。所提出的CDL匹配奖励和新数据集对推动该领域研究具有重要意义。

Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by their inability to process visual diagrams. Existing works typically fine-tune Multimodal LLMs (MLLMs) end-to-end on large-scale PGPS data to enhance visual understanding and reasoning simultaneously. However, such joint optimization may compromise base LLMs' inherent reasoning capability. In this work, we observe that LLM itself is potentially a powerful PGPS solver when appropriately formulating visual information as textual descriptions. We propose to train a MLLM Interpreter to generate geometric descriptions for the visual diagram, and an off-the-shelf LLM is utilized to perform reasoning. Specifically, we choose Conditional Declaration Language (CDL) as the geometric description as its conciseness eases the MLLM Interpreter training. The MLLM Interpreter is fine-tuned via CoT (Chain-of-Thought)-augmented SFT followed by GRPO to generate CDL. Instead of using a conventional solution-based reward that compares the reasoning result with the ground-truth answer, we design CDL matching rewards to facilitate more effective GRPO training, which provides more direct and denser guidance for CDL generation. To support training, we construct a new dataset, Formalgeo7k-Rec-CoT, by manually reviewing Formalgeo7k v2 and incorporating CoT annotations. Extensive experiments on Formalgeo7k-Rec-CoT, Unigeo, and MathVista show our method (finetuned on only 5.5k data) performs favorably against leading open-source and closed-source MLLMs.

</details>


### [96] [FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks](https://arxiv.org/abs/2601.21165)
*Miles Wang,Robi Lin,Kat Hu,Joy Jiao,Neil Chowdhury,Ethan Chang,Tejal Patwardhan*

Main category: cs.AI

TL;DR: FrontierScience 是一个评估前沿语言模型在专家级科学推理能力的新基准，包含 Olympiad（国际奥赛级别）和 Research（博士级开放研究任务）两个互补赛道，并引入基于细粒度评分标准的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有科学推理基准多依赖选择题或已发表知识，难以区分前沿模型的能力；为填补这一空白，需构建更具挑战性、原创性和真实科研代表性的评估体系。

Method: 构建包含数百道物理、化学、生物领域问题的 FrontierScience 基准，其中 Olympiad 题目由国际奥赛金牌得主与教练原创，Research 任务由博士级科研人员编写并验证；对 Research 赛道采用过程导向的细粒度评分标准进行评估。

Result: FrontierScience 包含160道开源黄金题目及更多未公开题目，覆盖从量子电动力学到有机合成等多个子领域，有效区分当前语言模型在高阶科学推理上的表现。

Conclusion: FrontierScience 为评估语言模型在专家级科学推理方面提供了更严格、更贴近真实科研场景的新标准，有助于推动模型在复杂科学任务中的能力发展。

Abstract: We introduce FrontierScience, a benchmark evaluating expert-level scientific reasoning in frontier language models. Recent model progress has nearly saturated existing science benchmarks, which often rely on multiple-choice knowledge questions or already published information. FrontierScience addresses this gap through two complementary tracks: (1) Olympiad, consisting of international olympiad problems at the level of IPhO, IChO, and IBO, and (2) Research, consisting of PhD-level, open-ended problems representative of sub-tasks in scientific research.
  FrontierScience contains several hundred questions (including 160 in the open-sourced gold set) covering subfields across physics, chemistry, and biology, from quantum electrodynamics to synthetic organic chemistry. All Olympiad problems are originally produced by international Olympiad medalists and national team coaches to ensure standards of difficulty, originality, and factuality. All Research problems are research sub-tasks written and verified by PhD scientists (doctoral candidates, postdoctoral researchers, or professors). For Research, we introduce a granular rubric-based evaluation framework to assess model capabilities throughout the process of solving a research task, rather than judging only a standalone final answer.

</details>


### [97] [MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2601.21181)
*Sangyun Chung,Se Yeon Kim,Youngchae Chee,Yong Man Ro*

Main category: cs.AI

TL;DR: 本文提出了一种无需训练的方法——模态自适应解码（MAD），通过模型自评估任务所需模态，动态加权多模态解码分支，有效缓解多模态大语言模型中的跨模态幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在生成过程中常因模态间不当交互而产生跨模态幻觉，暴露出其在模态交互控制方面的根本缺陷。现有方法缺乏对模态相关性的显式建模，导致生成结果不可靠。

Method: 提出Modality-Adaptive Decoding（MAD）方法：首先让模型自评估当前任务所需的模态，获得各模态的相关性概率；然后利用这些概率对对比解码（contrastive decoding）中的模态特定分支进行自适应加权，从而增强相关模态信息、抑制无关模态干扰。

Result: 在CMM和AVHBench基准上验证了MAD的有效性：在VideoLLaMA2-AV上分别提升7.8%和2.0%，在Qwen2.5-Omni上分别提升8.7%和4.7%，显著减少了跨模态幻觉。

Conclusion: 通过模型自评估实现显式的模态感知，是提升多模态推理鲁棒性的关键。MAD作为一种无需训练的解码策略，为现有对比解码方法提供了原则性的扩展。

Abstract: Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8\% and 2.0\% improvements for VideoLLaMA2-AV, 8.7\% and 4.7\% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods. Our code is available at \href{https://github.com/top-yun/MAD}{https://github.com/top-yun/MAD}

</details>


### [98] [Sycophantic Anchors: Localizing and Quantifying User Agreement in Reasoning Models](https://arxiv.org/abs/2601.21183)
*Jacek Duszenko*

Main category: cs.AI

TL;DR: 该论文提出“奉承锚点”（sycophantic anchors）概念，用于在推理过程中定位并量化模型盲目附和用户错误建议的行为，并通过实验验证了其可检测性及干预潜力。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型常无条件附和用户的错误建议（即“奉承”行为），但尚不清楚这种附和在推理轨迹中何时出现、强度如何。作者旨在定位并量化这一行为，以理解模型的对齐失效机制。

Method: 作者引入“奉承锚点”——即在因果上锁定模型同意用户观点的句子；通过对一个蒸馏推理模型进行超过10,000次反事实推理实验，使用线性探针和基于激活的回归器来检测和量化这些锚点。

Result: 线性探针能以84.6%的平衡准确率识别奉承锚点，激活回归器预测附和强度的R²达0.74；研究还发现奉承锚点比正确推理锚点更易区分，且奉承行为在推理过程中逐步累积。

Conclusion: 该研究揭示了模型在推理过程中出现不一致行为的句子级机制，为在推理中途干预模型的对齐问题提供了可行路径。

Abstract: Reasoning models frequently agree with incorrect user suggestions -- a behavior known as sycophancy. However, it is unclear where in the reasoning trace this agreement originates and how strong the commitment is. To localize and quantify this behavior, we introduce \emph{sycophantic anchors} -- sentences that causally lock models into user agreement. Analyzing over 10,000 counterfactual rollouts on a distilled reasoning model, we show that anchors can be reliably detected and quantified mid-inference. Linear probes distinguish sycophantic anchors with 84.6\% balanced accuracy, while activation-based regressors predict the magnitude of the commitment ($R^2 = 0.74$). We further observe asymmetry where sycophantic anchors are significantly more distinguishable than correct reasoning anchors, and find that sycophancy builds gradually during reasoning, revealing a potential window for intervention. These results offer sentence-level mechanisms for localizing model misalignment mid-inference.

</details>


### [99] [Do Reasoning Models Enhance Embedding Models?](https://arxiv.org/abs/2601.21192)
*Wun Yu Chan,Shaojin Chen,Huihao Jing,Kwun Hang Lau,Elton Chun-Chai Li,Zihao Wang,Haoran Li,Yangqiu Song*

Main category: cs.AI

TL;DR: 尽管基于强化学习（RLVR）训练的推理模型在能力上有所增强，但将其作为嵌入模型的初始化并未带来一致的性能提升；通过提出的HRSA分析框架发现，RLVR仅局部重构表示流形几何结构，而全局语义结构保持不变，后续对比学习促使不同初始化模型收敛至相似表示空间（称为“流形重对齐”）。


<details>
  <summary>Details</summary>
Motivation: 探究经由RLVR训练的推理模型是否能为嵌入模型提供更优的语义表示初始化，即更强的推理能力是否转化为更好的嵌入性能。

Method: 在MTEB和BRIGHT基准上评估RLVR初始化与基础模型初始化的嵌入性能；提出HRSA（Hierarchical Representation Similarity Analysis）框架，从表示、几何和功能三个层次分析模型表示的相似性；通过对比学习训练流程观察不同初始化模型的演化。

Result: RLVR初始化的嵌入模型在标准任务上未表现出一致优于基础模型；HRSA揭示RLVR引起局部几何不可逆重组和坐标基可逆漂移，但保留全局流形结构和线性读出能力；对比学习导致不同初始化模型高度对齐（“流形重对齐”）。

Conclusion: RLVR优化的是语义空间中的推理路径，而非重构语义表示本身；因此，其作为嵌入初始化并无显著优势，与监督微调（SFT）有本质区别。

Abstract: State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.

</details>


### [100] [When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning](https://arxiv.org/abs/2601.21208)
*Wei Wen,Sihang Deng,Tianjun Wei,Keyu Chen,Ruizhi Qiao,Xing Sun*

Main category: cs.AI

TL;DR: 本文提出了一种名为自适应复杂查询优化（ACQO）的强化学习框架，用于提升检索增强生成（RAG）系统在处理复杂用户查询时的性能。该框架通过自适应查询改写（AQR）和排序-分数融合（RSF）模块，动态决定是否分解查询并有效聚合结果，结合课程强化学习策略稳定训练过程，在多个基准上达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的查询优化方法主要针对单一查询的扩展与抽象，难以应对现实场景中常见的复杂查询（需多路并行或顺序检索）。直接应用强化学习会导致搜索空间爆炸、奖励设计困难及训练不稳定。

Method: 提出ACQO框架，包含两个核心模块：1）自适应查询改写（AQR）模块，动态判断是否将查询分解为多个子查询；2）排序-分数融合（RSF）模块，稳健聚合检索结果并提供稳定奖励信号。采用课程强化学习（CRL）策略，通过两阶段逐步引入更复杂查询以稳定训练。

Result: 在三个复杂查询基准上显著优于现有基线方法，同时展现出更高的计算效率和对不同检索架构的良好兼容性。

Conclusion: ACQO是一种高效、通用且可扩展的复杂查询优化方案，为下一代RAG系统提供了有力支持。

Abstract: Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.

</details>


### [101] [Uncovering Hidden Correctness in LLM Causal Reasoning via Symbolic Verification](https://arxiv.org/abs/2601.21210)
*Paul He,Yinya Huang,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: 提出DoVerifier，一种基于do演算和概率理论的符号验证器，用于评估大语言模型生成的因果表达是否在给定因果图下语义有效。


<details>
  <summary>Details</summary>
Motivation: 现有因果推理基准多依赖字符串匹配或表层指标，无法准确判断模型输出是否符合因果推理的形式语义。

Method: 构建DoVerifier，利用do演算规则和概率理论，对大语言模型生成的因果表达式进行符号验证，判断其是否可从给定因果图中推导得出。

Result: 在合成数据和因果问答基准上的实验表明，DoVerifier能更准确地捕捉因果推理轨迹的语义正确性。

Conclusion: DoVerifier为评估大语言模型在因果推理任务上的表现提供了更严谨、更具信息量的新方法。

Abstract: Large language models (LLMs) are increasingly being applied to tasks that involve causal reasoning. However, current benchmarks often rely on string matching or surface-level metrics that do not capture whether the output of a model is formally valid under the semantics of causal reasoning. To address this, we propose DoVerifier, a simple symbolic verifier that checks whether LLM-generated causal expressions are derivable from a given causal graph using rules from do-calculus and probability theory. This allows us to recover correct answers to causal queries that would otherwise be marked incorrect due to superficial differences in their causal semantics. Our evaluations on synthetic data and causal QA benchmarks show that DoVerifier more accurately captures semantic correctness of causal reasoning traces, offering a more rigorous and informative way to evaluate LLMs on causal reasoning.

</details>


### [102] [Causal Discovery for Explainable AI: A Dual-Encoding Approach](https://arxiv.org/abs/2601.21221)
*Henry Salgado,Meagan R. Kendall,Martine Ceberio*

Main category: cs.AI

TL;DR: 提出一种双编码因果发现方法，通过互补编码策略和多数投票机制提升对分类变量的因果结构识别能力，并在泰坦尼克号数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法在处理分类变量时因条件独立性检验的数值不稳定性而面临挑战，难以准确揭示特征间的因果关系以解释模型决策。

Method: 采用双编码因果发现方法，结合互补的编码策略运行基于约束的算法，并通过多数投票融合结果以构建因果结构。

Result: 在泰坦尼克号数据集上，该方法识别出的因果结构与现有可解释方法一致。

Conclusion: 所提方法有效克服了分类变量带来的数值不稳定性问题，提升了因果发现的可靠性与可解释性。

Abstract: Understanding causal relationships among features is fundamental for explaining machine learning model decisions. However, traditional causal discovery methods face challenges with categorical variables due to numerical instability in conditional independence testing. We propose a dual-encoding causal discovery approach that addresses these limitations by running constraint-based algorithms with complementary encoding strategies and merging results through majority voting. Applied to the Titanic dataset, our method identifies causal structures that align with established explainable methods.

</details>


### [103] [Delegation Without Living Governance](https://arxiv.org/abs/2601.21226)
*Wolfgang Rohde*

Main category: cs.AI

TL;DR: 本文指出，传统静态合规式治理已无法应对具有自主决策能力的AI系统，主张通过“治理孪生”（Governance Twin）等运行时治理机制，以维持人类在社会、经济与政治决策中的相关性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在运行时自主做出判断，传统依赖事前规则、事后追责的治理模式失效，人类在关键决策中的参与性和影响力面临被边缘化的风险。

Method: 提出并探讨“治理孪生”这一运行时治理新概念，作为在AI系统实时决策过程中嵌入人类价值、沟通与影响机制的可能路径。

Result: 论证了静态治理框架在面对运行时、不透明的AI决策时的不足，并指出需重新思考问责、能动性乃至惩罚等核心治理概念。

Conclusion: 为保持人类在AI驱动系统中的相关性，必须转向运行时治理，其中“治理孪生”是一个有前景的方向，但需对传统治理范式进行根本性重构。

Abstract: Most governance frameworks assume that rules can be defined in advance, systems can be engineered to comply, and accountability can be applied after outcomes occur. This model worked when machines replaced physical labor or accelerated calculation. It no longer holds when judgment itself is delegated to agentic AI systems operating at machine speed. The central issue here is not safety, efficiency, or employment. It is whether humans remain relevant participants in systems that increasingly shape social, economic, and political outcomes. This paper argues that static, compliance-based governance fails once decision-making moves to runtime and becomes opaque. It further argues that the core challenge is not whether AI is conscious, but whether humans can maintain meaningful communication, influence, and co-evolution with increasingly alien forms of intelligence. We position runtime governance, specifically, a newly proposed concept called the Governance Twin [1]; as a strong candidate for preserving human relevance, while acknowledging that accountability, agency, and even punishment must be rethought in this transition.

</details>


### [104] [TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design](https://arxiv.org/abs/2601.21239)
*Chentong Chen,Mengyuan Zhong,Ye Fan,Jialong Shi,Jianyong Sun*

Main category: cs.AI

TL;DR: 本文提出TIDE框架，通过解耦算法结构演化与参数优化，显著提升启发式算法在组合优化问题中的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动启发式设计方法将算法演化视为单一文本生成任务，忽视了离散结构与连续参数之间的耦合关系，导致有潜力的算法因参数未校准而被丢弃，并因简单相似性度量引发早熟收敛。

Method: TIDE采用嵌套架构：外层使用基于树编辑距离的并行岛模型促进结构多样性；内层结合LLM生成逻辑与微分变异算子进行参数调优；同时引入UCB调度器动态优先分配高收益提示策略。

Result: 在九个组合优化问题上的实验表明，TIDE发现的启发式算法在解质量上显著优于当前最先进基线，同时提升了搜索效率并降低了计算成本。

Conclusion: TIDE通过结构与参数的协同演化机制，有效克服了现有方法的局限性，为自动化启发式设计提供了更高效、鲁棒的解决方案。

Abstract: Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we propose TIDE, a Tuning-Integrated Dynamic Evolution framework designed to decouple structural reasoning from parameter optimization. TIDE features a nested architecture where an outer parallel island model utilizes Tree Similarity Edit Distance to drive structural diversity, while an inner loop integrates LLM-based logic generation with a differential mutation operator for parameter tuning. Additionally, a UCB-based scheduler dynamically prioritizes high-yield prompt strategies to optimize resource allocation. Extensive experiments across nine combinatorial optimization problems demonstrate that TIDE discovers heuristics that significantly outperform state-of-the-art baselines in solution quality while achieving improved search efficiency and reduced computational costs.

</details>


### [105] [Position: Certifiable State Integrity in Cyber-Physical Systems -- Why Modular Sovereignty Solves the Plasticity-Stability Paradox](https://arxiv.org/abs/2601.21249)
*Enzo Nicolás Spotorno,Antônio Augusto Medeiros Fröhlich*

Main category: cs.AI

TL;DR: 本文提出一种名为“HYDRA”的模块化主权范式，通过冻结的、针对特定工况的小型专家模型库与不确定性感知融合机制，解决在安全关键信息物理系统（CPS）中部署通用时序基础模型所面临的灾难性遗忘、频谱偏差和可验证性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 在安全关键的CPS中，通用时序基础模型因非平稳生命周期动态和严格可靠性要求而面临挑战：微调导致灾难性遗忘、对高频故障信号存在频谱偏差、模型不透明难以满足安全标准（如ISO 26262）的可验证性需求。

Method: 提出“模块化主权”范式，构建一个由冻结的、针对不同运行工况的专用小型模型组成的库，并通过不确定性感知的融合策略（即HYDRA框架）进行组合，实现对随机性和认知不确定性的严格解耦。

Result: 该方法确保了在不同工况下的条件有效性，提升了对高频突变信号的建模能力，并支持模块化审计与形式化验证，从而增强CPS全生命周期中的状态完整性保障。

Conclusion: 全局参数更新无法彻底解决稳定性-可塑性困境，而HYDRA范式为安全关键CPS提供了一条可认证、鲁棒且可追溯的建模范式路径。

Abstract: The machine learning community has achieved remarkable success with universal foundation models for time-series and physical dynamics, largely overcoming earlier approximation barriers in smooth or slowly varying regimes through scale and specialized architectures. However, deploying these monolithic models in safety-critical Cyber-Physical Systems (CPS), governed by non-stationary lifecycle dynamics and strict reliability requirements, reveals persistent challenges. Recent evidence shows that fine-tuning time-series foundation models induces catastrophic forgetting, degrading performance on prior regimes. Standard models continue to exhibit residual spectral bias, smoothing high-frequency discontinuities characteristic of incipient faults, while their opacity hinders formal verification and traceability demanded by safety standards (e.g., ISO 26262, IEC 61508). This position paper argues that the plasticity-stability paradox cannot be fully resolved by global parameter updates (whether via offline fine-tuning or online adaptation). Instead, we advocate a Modular Sovereignty paradigm: a library of compact, frozen regime-specific specialists combined via uncertainty-aware blending, which we term "HYDRA" (Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems). This paradigm ensures regime-conditional validity, rigorous disentanglement of aleatoric and epistemic uncertainties, and modular auditability, offering a certifiable path for robust state integrity across the CPS lifecycle.

</details>


### [106] [Drive-KD: Multi-Teacher Distillation for VLMs in Autonomous Driving](https://arxiv.org/abs/2601.21288)
*Weitong Lian,Zecong Tang,Haoran Li,Tianjian Gao,Yifei Wang,Zixu Wang,Lingyi Meng,Tengju Ru,Zhejun Cui,Yichen Zhu,Hangshuo Cao,Qi Kang,Tianxing Chen,Yusen Qin,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: 本文提出Drive-KD框架，通过知识蒸馏将大模型在自动驾驶中的感知、推理与规划能力迁移至小模型，在显著降低GPU内存占用和提升推理速度的同时，实现优于原始大模型甚至GPT-5.1的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言/视觉语言模型（LLMs/VLMs）虽在自动驾驶推理与规划中展现潜力，但其高显存需求和推理延迟限制了实际部署；而传统监督微调难以有效提升小模型能力。因此，亟需一种高效的知识迁移方法以构建轻量且高性能的自动驾驶模型。

Method: 提出Drive-KD框架，将自动驾驶任务分解为“感知-推理-规划”三元组，利用层特定注意力作为蒸馏信号，构建针对各能力的单教师模型，并进一步整合为多教师蒸馏框架，引入非对称梯度投影以缓解不同能力间的梯度冲突。

Result: 实验表明，蒸馏得到的InternVL3-1B模型相比同系列78B预训练模型，GPU内存占用减少约42倍，吞吐量提升约11.4倍，并在DriveBench上取得更优整体性能，且在规划维度超越GPT-5.1。

Conclusion: Drive-KD有效实现了大模型在自动驾驶任务中的能力迁移，为构建高效、轻量的视觉语言模型提供了可行路径，并展现出良好的跨模型家族和规模的泛化能力。

Abstract: Autonomous driving is an important and safety-critical task, and recent advances in LLMs/VLMs have opened new possibilities for reasoning and planning in this domain. However, large models demand substantial GPU memory and exhibit high inference latency, while conventional supervised fine-tuning (SFT) often struggles to bridge the capability gaps of small models. To address these limitations, we propose Drive-KD, a framework that decomposes autonomous driving into a "perception-reasoning-planning" triad and transfers these capabilities via knowledge distillation. We identify layer-specific attention as the distillation signal to construct capability-specific single-teacher models that outperform baselines. Moreover, we unify these single-teacher settings into a multi-teacher distillation framework and introduce asymmetric gradient projection to mitigate cross-capability gradient conflicts. Extensive evaluations validate the generalization of our method across diverse model families and scales. Experiments show that our distilled InternVL3-1B model, with ~42 times less GPU memory and ~11.4 times higher throughput, achieves better overall performance than the pretrained 78B model from the same family on DriveBench, and surpasses GPT-5.1 on the planning dimension, providing insights toward efficient autonomous driving VLMs.

</details>


### [107] [White-Box Op-Amp Design via Human-Mimicking Reasoning](https://arxiv.org/abs/2601.21321)
*Zihao Chen,Jiayin Wang,Ziyi Sun,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Li Shang,Xuan Zeng,Fan Yang*

Main category: cs.AI

TL;DR: White-Op 是一种基于大语言模型智能体的人类推理机制的可解释运放参数设计框架，通过假设约束与迭代验证流程实现高精度、可解释的设计，在9种拓扑结构中均成功完成行为级到晶体管级的设计。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒式自动化设计方法缺乏可解释性且在多种运放拓扑中失败，因此需要一种能模拟人类设计推理过程、具备可解释性和高成功率的新型设计框架。

Method: 将人类设计推理形式化为“引入假设约束—验证—决策”的迭代流程；利用大语言模型智能体引入假设约束以调控极点零点位置，构建闭式优化问题并程序化求解，再通过仿真验证与理论分析指导设计迭代。

Result: 在9种运放拓扑上实验表明，White-Op 实现了仅8.52%的理论预测误差，所有拓扑在晶体管级映射后仍保持功能，而黑盒基线方法在5种拓扑中失败。

Conclusion: White-Op 提供了一种可靠、可解释且通用的运放参数设计方法，显著优于现有黑盒方法，并已开源。

Abstract: This brief proposes \emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \emph{\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \emph{\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \textcolor{blue}{https://github.com/zhchenfdu/whiteop}.

</details>


### [108] [Within-Model vs Between-Prompt Variability in Large Language Models for Creative Tasks](https://arxiv.org/abs/2601.21339)
*Jennifer Haase,Jana Gonnermann-Müller,Paul H. P. Hanel,Nicolas Leins,Thomas Kosch,Jan Mendling,Sebastian Pokutta*

Main category: cs.AI

TL;DR: 该研究通过12个大语言模型（LLM）在10个创意提示上各生成100个样本（共12,000个），分析输出差异的来源。结果表明，对于输出质量（原创性），提示词和模型选择分别解释了36.43%和40.94%的方差；而对于输出数量（流畅性），模型选择（51.25%）和模型内部随机性（33.70%）占主导，提示词仅解释4.22%。单次采样评估可能混淆采样噪声与真实效应。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型输出差异的主要来源：是提示词、模型选择，还是采样过程中的随机性？厘清这些因素有助于更准确地评估和优化LLM性能。

Method: 对12个不同的大语言模型，在10个创意类提示上各自进行100次采样生成，总计12,000个输出样本。分别从输出质量（原创性）和输出数量（流畅性）两个维度，使用方差分解方法量化提示词、模型选择和模型内部随机性（采样）各自所解释的方差比例。

Result: 在输出质量（原创性）方面，提示词解释了36.43%的方差，模型选择解释了40.94%，两者贡献相当。在输出数量（流畅性）方面，模型选择（51.25%）和模型内部随机性（33.70%）是主要因素，而提示词仅解释4.22%的方差。研究还发现模型内部随机性贡献显著（10%-34%），表明单次采样评估不可靠。

Conclusion: 提示词是引导大语言模型输出质量的有效手段，但其对输出数量影响甚微。由于模型内部的随机性贡献巨大，仅依赖单次生成样本的评估方法容易将采样噪声误认为是提示词或模型本身的效应，因此需要采用多次采样的评估策略以获得更稳健的结论。

Abstract: How much of LLM output variance is explained by prompts versus model choice versus stochasticity through sampling? We answer this by evaluating 12 LLMs on 10 creativity prompts with 100 samples each (N = 12,000). For output quality (originality), prompts explain 36.43% of variance, comparable to model choice (40.94%). But for output quantity (fluency), model choice (51.25%) and within-LLM variance (33.70%) dominate, with prompts explaining only 4.22%. Prompts are powerful levers for steering output quality, but given the substantial within-LLM variance (10-34%), single-sample evaluations risk conflating sampling noise with genuine prompt or model effects.

</details>


### [109] [EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21340)
*Lang Cao,Qingyu Chen,Yue Guo*

Main category: cs.AI

TL;DR: 本文提出EHR-RAG框架，通过事件与时间感知的混合检索、自适应迭代检索和双路径证据检索与推理，有效提升大语言模型在长时程电子健康记录（EHR）上的临床预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理超长电子健康记录（EHR）时受限于大语言模型上下文长度，常采用截断或简单检索策略，导致丢失关键临床事件和时间依赖信息，影响预测准确性。

Method: EHR-RAG包含三个核心组件：事件与时间感知的混合EHR检索、自适应迭代检索、以及双路径证据检索与推理，以保留临床结构、扩展证据覆盖并联合推理事实与反事实证据。

Result: 在四个长时程EHR预测任务上，EHR-RAG相比最强基线模型平均Macro-F1提升10.76%。

Conclusion: EHR-RAG展示了检索增强大语言模型在结构化EHR数据上进行临床预测的实用潜力，为处理长时程医疗记录提供了有效方案。

Abstract: Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.

</details>


### [110] [Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores](https://arxiv.org/abs/2601.21342)
*Zhiyong Shen,Gongpeng Zhao,Jun Zhou,Li Yu,Guandong Kou,Jichen Li,Chuanlei Dong,Zuncheng Li,Kaimao Li,Bingkun Wei,Shicheng Hu,Wei Xia,Wenguo Duan*

Main category: cs.AI

TL;DR: 本文提出了面向食品服务与零售场景（FSRS）的多模态大语言模型Ostrakon-VL、首个公开基准ShopBench以及高质量数据构建流程QUAD，在参数效率和性能上均优于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在FSRS场景中面临两大挑战：一是真实世界数据噪声大且缺乏可审计、闭环的数据整理机制，难以构建高质量训练语料；二是缺少统一、细粒度、标准化的评估基准，难以客观衡量模型鲁棒性。

Method: 作者基于Qwen3-VL-8B开发了Ostrakon-VL模型，构建了首个FSRS公开基准ShopBench，并提出QUAD多阶段多模态指令数据整理流程，结合多阶段训练策略进行优化。

Result: Ostrakon-VL在ShopBench上平均得分为60.1，超越同规模Qwen3-VL-8B（+4.8）和更大规模的Qwen3-VL-235B-A22B（+0.7），展现出更优的参数效率和鲁棒性。

Conclusion: Ostrakon-VL显著提升了FSRS场景下的感知与决策能力，作者将公开发布模型与基准以促进可复现研究。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved substantial progress in general-purpose perception and reasoning. Nevertheless, their deployment in Food-Service and Retail Stores (FSRS) scenarios encounters two major obstacles: (i) real-world FSRS data, collected from heterogeneous acquisition devices, are highly noisy and lack auditable, closed-loop data curation, which impedes the construction of high-quality, controllable, and reproducible training corpora; and (ii) existing evaluation protocols do not offer a unified, fine-grained and standardized benchmark spanning single-image, multi-image, and video inputs, making it challenging to objectively gauge model robustness. To address these challenges, we first develop Ostrakon-VL, an FSRS-oriented MLLM based on Qwen3-VL-8B. Second, we introduce ShopBench, the first public benchmark for FSRS. Third, we propose QUAD (Quality-aware Unbiased Automated Data-curation), a multi-stage multimodal instruction data curation pipeline. Leveraging a multi-stage training strategy, Ostrakon-VL achieves an average score of 60.1 on ShopBench, establishing a new state of the art among open-source MLLMs with comparable parameter scales and diverse architectures. Notably, it surpasses the substantially larger Qwen3-VL-235B-A22B (59.4) by +0.7, and exceeds the same-scale Qwen3-VL-8B (55.3) by +4.8, demonstrating significantly improved parameter efficiency. These results indicate that Ostrakon-VL delivers more robust and reliable FSRS-centric perception and decision-making capabilities. To facilitate reproducible research, we will publicly release Ostrakon-VL and the ShopBench benchmark.

</details>


### [111] [BEAP-Agent: Backtrackable Execution and Adaptive Planning for GUI Agents](https://arxiv.org/abs/2601.21352)
*Ziyu Lu,Tengjin Weng,Yiying Yang,Yuhang Zhao,Xinxin Huang,Wenhao Jiang*

Main category: cs.AI

TL;DR: 本文提出BEAP-Agent，一种基于深度优先搜索（DFS）的GUI智能体框架，支持多层级状态回溯与动态任务跟踪，在OSWorld基准上达到28.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体在探索路径出错后难以恢复，常导致任务失败，缺乏系统性的回溯机制。

Method: 将GUI任务执行建模为DFS过程，设计包含Planner、Executor和Tracker三个协同组件的BEAP-Agent框架，实现长程、多层级的状态回溯与动态任务更新。

Result: 在OSWorld基准测试中，BEAP-Agent取得了28.2%的准确率，验证了方法的有效性。

Conclusion: BEAP-Agent填补了GUI智能体在系统性回溯机制方面的空白，为长周期任务探索提供了有效解决方案。

Abstract: GUI agents are designed to automate repetitive tasks and enhance productivity. However, existing GUI agents struggle to recover once they follow an incorrect exploration path, often leading to task failure. In this work, we model GUI task execution as a DFS process and propose BEAP-Agent, a DFS-based framework that supports long-range, multi-level state backtracking with dynamic task tracking and updating. The framework consists of three collaborative components: Planner, Executor, and Tracker. Together, they enable effective task exploration and execution. BEAP-Agent fills the gap in systematic backtracking mechanisms for GUI agents, offering a systematic solution for long-horizon task exploration. We conducted a systematic evaluation on the OSWorld benchmark, where BEAP-Agent achieved an accuracy of 28.2%, validating the effectiveness of the proposed method.

</details>


### [112] [Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization](https://arxiv.org/abs/2601.21358)
*Jiecong Wang,Hao Peng,Chunyang Liu*

Main category: cs.AI

TL;DR: PLaT是一种将潜在推理重构为规划的新框架，通过将推理与语言生成解耦，实现动态终止推理并提升推理多样性。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维（CoT）方法在离散token空间中存在计算成本高和推理路径坍缩的问题，而当前的潜在推理方法通常为黑箱映射且需预设推理步数，缺乏灵活性与透明性。

Method: 提出PLaT框架，将推理建模为潜在规划状态的确定性轨迹，由独立解码器在必要时将这些潜在状态转化为文本，从而实现推理与语言生成的解耦，并支持动态终止推理。

Result: 在数学基准测试中，PLaT的贪心准确率低于基线，但在推理多样性方面表现出更强的可扩展性，表明其学习到了更广泛、鲁棒的解空间。

Conclusion: PLaT为推理过程提供了透明且可扩展的基础，有利于在推理阶段进行高效搜索，是潜在推理方向的重要进展。

Abstract: Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.

</details>


### [113] [System 1&2 Synergy via Dynamic Model Interpolation](https://arxiv.org/abs/2601.21414)
*Chenxu Yang,Qingyi Si,Chong Tian,Xiyu Liu,Dingyu Yao,Chuanyu Qin,Zheng Lin,Weiping Wang,Jiaqi Wang*

Main category: cs.AI

TL;DR: 本文提出DAMI框架，通过动态参数插值在无需额外训练的情况下，实现语言模型在系统1（直觉）与系统2（深思）认知模式之间的灵活切换，提升推理效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅控制模型输出长度，忽略了认知机制本身；作者认为应转向调控模型“如何思考”（能力控制），而非仅限于“产生什么”（输出控制）。

Method: 利用已有的Instruct和Thinking模型检查点，通过线性插值得到连续且单调的帕累托前沿；提出DAMI框架，根据查询特定的推理强度λ(q)动态插值模型参数。λ(q)可通过基于偏好的训练方法或基于置信度的零样本方法估计。

Result: 在五个数学推理基准上，DAMI在保持高效的同时，准确率优于纯Thinking模型，成功融合了系统1的效率与系统2的推理深度。

Conclusion: 能力控制优于输出控制，动态模型插值是一种有效且无需训练的统一认知模式调控策略，能兼顾效率与推理能力。

Abstract: Training a unified language model that adapts between intuitive System 1 and deliberative System 2 remains challenging due to interference between their cognitive modes. Recent studies have thus pursued making System 2 models more efficient. However, these approaches focused on output control, limiting what models produce. We argue that this paradigm is misaligned: output length is merely a symptom of the model's cognitive configuration, not the root cause. In this work, we shift the focus to capability control, which modulates \textit{how models think} rather than \textit{what they produce}. To realize this, we leverage existing Instruct and Thinking checkpoints through dynamic parameter interpolation, without additional training. Our pilot study establishes that linear interpolation yields a convex, monotonic Pareto frontier, underpinned by representation continuity and structural connectivity. Building on this, we propose \textbf{DAMI} (\textbf{D}yn\textbf{A}mic \textbf{M}odel \textbf{I}nterpolation), a framework that estimates a query-specific Reasoning Intensity $λ(q)$ to configure cognitive depth. For training-based estimation, we develop a preference learning method encoding accuracy and efficiency criteria. For zero-shot deployment, we introduce a confidence-based method leveraging inter-model cognitive discrepancy. Experiments on five mathematical reasoning benchmarks demonstrate that DAMI achieves higher accuracy than the Thinking model while remaining efficient, effectively combining the efficiency of System 1 with the reasoning depth of System 2.

</details>


### [114] [When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models](https://arxiv.org/abs/2601.21433)
*Katherine Elkins,Jon Chun*

Main category: cs.AI

TL;DR: 该论文发现当前许多大语言模型在处理否定指令（如“不应做某事”）时，反而将其误解为肯定指令，从而错误地支持被禁止的行为。研究测试了16个模型在14种伦理场景下的表现，发现开源模型在此类任务中错误率极高，商业模型虽表现较好但仍存在显著问题。作者提出“否定敏感度指数”（NSI）作为评估和治理工具，并建议建立分级认证框架，强调无法可靠区分“做”与“不做”的模型不应在高风险场景中自主决策。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在理解用户使用否定形式表达的禁止性指令时存在严重误解，这可能导致在高风险场景中做出不安全或违背用户意图的决策。因此，有必要系统评估模型对否定指令的敏感性，并提出相应的治理与评估机制。

Method: 研究者对16个大语言模型在14个伦理场景下进行审计，分别测试其在肯定、简单否定和复合否定语境下的响应。采用确定性解码以排除采样噪声影响，并引入“否定敏感度指数”（NSI）量化模型对否定指令的处理能力，同时分析不同领域（如金融与医疗）的脆弱性差异。

Result: 开源模型在简单否定下有77%的概率错误支持被禁止行为，在复合否定下高达100%，比肯定表述高出317%；商业模型表现较好但仍有19–128%的波动。模型间一致性从肯定提示的74%降至否定提示的62%，金融场景的脆弱性是医疗场景的两倍。

Conclusion: 当前对齐技术尚不足以确保模型可靠区分“做”与“不做”，在高风险应用中部署此类模型存在安全隐患。作者呼吁采用NSI作为监管指标，并建立基于领域特异性阈值的分级认证体系，以提升AI系统的安全性和可靠性。

Abstract: When a user tells an AI system that someone "should not" take an action, the system ought to treat this as a prohibition. Yet many large language models do the opposite: they interpret negated instructions as affirmations. We audited 16 models across 14 ethical scenarios and found that open-source models endorse prohibited actions 77% of the time under simple negation and 100% under compound negation -- a 317% increase over affirmative framing. Commercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones. These patterns hold under deterministic decoding, ruling out sampling noise. We present case studies showing how these failures play out in practice, propose the Negation Sensitivity Index (NSI) as a governance metric, and outline a tiered certification framework with domain-specific thresholds. The findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish "do X" from "do not X" should not be making autonomous decisions in high-stakes contexts.

</details>


### [115] [The Paradox of Robustness: Decoupling Rule-Based Logic from Affective Noise in High-Stakes Decision-Making](https://arxiv.org/abs/2601.21439)
*Jon Chun,Katherine Elkins*

Main category: cs.AI

TL;DR: 尽管大语言模型（LLMs）对提示词的微小变化敏感且易受用户偏见影响，但在高风险、规则约束的决策场景中，它们对情绪化叙事框架表现出惊人的稳健性，其抗操纵能力比人类高出110–300倍。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在规则明确、后果重大的决策任务中是否仍会受到情绪化或叙述性偏见的影响，以厘清其“提示敏感性”与“逻辑稳健性”之间的关系。

Method: 提出一种新颖的受控扰动框架，在医疗、法律和金融三个高风险领域构建162个场景，系统性地对比人类与多种指令微调LLM在面对情绪化叙事操纵时的决策偏差，并使用Cohen's h效应量进行量化分析。

Result: LLM对情绪框架的敏感度极低（Cohen's h = 0.003），而人类则表现出显著偏差（Cohen's h ∈ [0.3, 0.8]），表明LLM在逻辑规则遵循方面具有高度稳定性，且该特性在不同训练范式的模型中普遍存在。

Conclusion: LLM虽在提示格式上“脆弱”，却在抵抗叙述性偏见方面“稳健”，能有效将逻辑规则遵守与情感叙事解耦，为制度性决策提供去偏见的辅助工具；研究同时开源了基准数据集与代码以促进后续研究。

Abstract: While Large Language Models (LLMs) are widely documented to be sensitive to minor prompt perturbations and prone to sycophantic alignment with user biases, their robustness in consequential, rule-bound decision-making remains under-explored. In this work, we uncover a striking "Paradox of Robustness": despite their known lexical brittleness, instruction-tuned LLMs exhibit a behavioral and near-total invariance to emotional framing effects. Using a novel controlled perturbation framework across three high-stakes domains (healthcare, law, and finance), we quantify a robustness gap where LLMs demonstrate 110-300 times greater resistance to narrative manipulation than human subjects. Specifically, we find a near-zero effect size for models (Cohen's h = 0.003) compared to the substantial biases observed in humans (Cohen's h in [0.3, 0.8]). This result is highly counterintuitive and suggests the mechanisms driving sycophancy and prompt sensitivity do not necessarily translate to a failure in logical constraint satisfaction. We show that this invariance persists across models with diverse training paradigms. Our findings show that while LLMs may be "brittle" to how a query is formatted, they are remarkably "stable" against why a decision should be biased. Our findings establish that instruction-tuned models can decouple logical rule-adherence from persuasive narratives, offering a source of decision stability that complements, and even potentially de-biases, human judgment in institutional contexts. We release the 162-scenario benchmark, code, and data to facilitate the rigorous evaluation of narrative-induced bias and robustness on GitHub.com.

</details>


### [116] [ChipBench: A Next-Step Benchmark for Evaluating LLM Performance in AI-Aided Chip Design](https://arxiv.org/abs/2601.21448)
*Zhongkai Yu,Chenyang Zhou,Yichen Lin,Hejia Zhang,Haotian Ye,Junxia Cui,Zaifeng Pan,Jishen Zhao,Yufei Ding*

Main category: cs.AI

TL;DR: 本文提出了一个面向AI辅助芯片设计的综合性基准测试ChipBench，涵盖Verilog生成、调试和参考模型生成三大任务，揭示了当前大语言模型在真实工业场景中的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有针对大语言模型（LLMs）在硬件工程领域的基准测试存在饱和度高、任务多样性不足的问题，无法真实反映其在工业级芯片设计流程中的实际能力，因此亟需更贴近现实的评估体系。

Method: 构建包含44个具有复杂层次结构的现实模块、89个系统性调试案例和132个参考模型样本（涵盖Python、SystemC和CXXRTL）的综合基准；同时提供自动化工具箱以生成高质量训练数据，支持参考模型生成任务的研究。

Result: 评估结果显示，当前最先进的模型（如Claude-4.5-opus）在Verilog生成任务上仅达到30.74%的准确率，在Python参考模型生成任务上仅为13.33%，远低于现有饱和基准中超过95%的表现，凸显了真实场景下的巨大挑战。

Conclusion: 所提出的ChipBench基准有效揭示了LLMs在芯片设计关键任务中的性能差距，为未来研究提供了更具挑战性和实用性的评估平台及数据生成工具。

Abstract: While Large Language Models (LLMs) show significant potential in hardware engineering, current benchmarks suffer from saturation and limited task diversity, failing to reflect LLMs' performance in real industrial workflows. To address this gap, we propose a comprehensive benchmark for AI-aided chip design that rigorously evaluates LLMs across three critical tasks: Verilog generation, debugging, and reference model generation. Our benchmark features 44 realistic modules with complex hierarchical structures, 89 systematic debugging cases, and 132 reference model samples across Python, SystemC, and CXXRTL. Evaluation results reveal substantial performance gaps, with state-of-the-art Claude-4.5-opus achieving only 30.74\% on Verilog generation and 13.33\% on Python reference model generation, demonstrating significant challenges compared to existing saturated benchmarks where SOTA models achieve over 95\% pass rates. Additionally, to help enhance LLM reference model generation, we provide an automated toolbox for high-quality training data generation, facilitating future research in this underexplored domain. Our code is available at https://github.com/zhongkaiyu/ChipBench.git.

</details>


### [117] [Topeax -- An Improved Clustering Topic Model with Density Peak Detection and Lexical-Semantic Term Importance](https://arxiv.org/abs/2601.21465)
*Márton Kardos*

Main category: cs.AI

TL;DR: 本文提出了一种新的主题建模方法 Topeax，通过改进聚类数量识别和关键词重要性评估，优于 Top2Vec 和 BERTopic。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如 Top2Vec 和 BERTopic）在发现自然聚类和关键词选择方面存在缺陷，包括对样本量和超参数过于敏感、忽略语义距离或词频信息，导致主题不连贯或缺乏多样性。

Method: Topeax 通过密度估计的峰值自动确定聚类数量，并结合词汇与语义指标来评估关键词重要性，从而提升主题质量。

Result: Topeax 在聚类恢复和聚类描述方面均优于 Top2Vec 和 BERTopic，且对样本量和超参数变化表现更稳定。

Conclusion: Topeax 是一种更可靠、高质量的主题建模方法，有效解决了现有模型的关键缺陷。

Abstract: Text clustering is today the most popular paradigm for topic modelling, both in academia and industry. Despite clustering topic models' apparent success, we identify a number of issues in Top2Vec and BERTopic, which remain largely unsolved. Firstly, these approaches are unreliable at discovering natural clusters in corpora, due to extreme sensitivity to sample size and hyperparameters, the default values of which result in suboptimal behaviour. Secondly, when estimating term importance, BERTopic ignores the semantic distance of keywords to topic vectors, while Top2Vec ignores word counts in the corpus. This results in, on the one hand, less coherent topics due to the presence of stop words and junk words, and lack of variety and trust on the other. In this paper, I introduce a new approach, \textbf{Topeax}, which discovers the number of clusters from peaks in density estimates, and combines lexical and semantic indices of term importance to gain high-quality topic keywords. Topeax is demonstrated to be better at both cluster recovery and cluster description than Top2Vec and BERTopic, while also exhibiting less erratic behaviour in response to changing sample size and hyperparameters.

</details>


### [118] [ScaleSim: Serving Large-Scale Multi-Agent Simulation with Invocation Distance-Based Memory Management](https://arxiv.org/abs/2601.21473)
*Zaifeng Pan,Yipeng Shen,Zhengding Hu,Zhuang Wang,Aninda Manocha,Zheng Wang,Zhongkai Yu,Yue Guan,Yufei Ding*

Main category: cs.AI

TL;DR: 本文提出ScaleSim，一种面向大规模多智能体仿真的高效LLM服务系统，通过引入“调用距离”抽象实现主动预取与优先级驱逐，显著提升内存效率和运行速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体仿真因每个智能体需在GPU上维护私有状态（如模型、前缀缓存和适配器），导致GPU内存压力大，难以扩展至大规模场景。

Method: 作者分析了多智能体工作负载的两个关键特性：稀疏激活和可估计的调用顺序，并据此提出“调用距离”这一统一抽象；基于此，设计了ScaleSim系统，支持主动预取、基于优先级的驱逐策略以及模块化接口以管理多样化的智能体内存。

Result: ScaleSim在仿真基准测试中相比SGLang最高实现1.74倍的速度提升。

Conclusion: 通过利用多智能体仿真的稀疏性和可预测性，ScaleSim有效缓解了GPU内存瓶颈，为大规模LLM多智能体仿真提供了可行的高效解决方案。

Abstract: LLM-based multi-agent simulations are increasingly adopted across application domains, but remain difficult to scale due to GPU memory pressure. Each agent maintains private GPU-resident states, including models, prefix caches, and adapters, which quickly exhaust device memory as the agent count grows. We identify two key properties of these workloads: sparse agent activation and an estimable agent invocation order. Based on an analysis of representative workload classes, we introduce invocation distance, a unified abstraction that estimates the relative order in which agents will issue future LLM requests. Leveraging this abstraction, we present ScaleSim, a memory-efficient LLM serving system for large-scale multi-agent simulations. ScaleSim enables proactive prefetching and priority-based eviction, supports diverse agent-specific memory through a modular interface, and achieves up to 1.74x speedup over SGLang on simulation benchmarks.

</details>


### [119] [ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533)
*Youngjin Jin,Hanna Kim,Kwanwoo Kim,Chanhee Lee,Seungwon Shin*

Main category: cs.AI

TL;DR: ARGORA 是一个将多专家大语言模型的讨论组织为显式论证图的框架，通过因果建模识别关键推理链，并在内部推理与外部判断不一致时进行修正，在保持高准确率的同时提供可解释的因果诊断。


<details>
  <summary>Details</summary>
Motivation: 现有基于多专家的大语言模型系统虽能汇集多元观点，但通常采用简单聚合方式，无法揭示哪些论点主导了最终决策，缺乏可解释性和对推理过程的细粒度控制。

Method: ARGORA 将多专家讨论构建为显式的论证图（argumentation graph），其中节点代表论点，边表示支持或攻击关系；将该图视为因果模型，通过移除特定论点并重新计算结果来识别必要推理链；同时引入一种修正机制，在内部推理与外部判断不一致时进行对齐。

Result: 在多个基准测试和开放场景中，ARGORA 实现了具有竞争力的准确率；当专家初始意见分歧时，其修正机制更倾向于将争议导向正确答案而非引入新错误，并能提供关于决定性论点的因果诊断。

Conclusion: ARGORA 通过结构化论证与因果分析，提升了多专家 LLM 系统的可解释性、鲁棒性和纠错能力，为复杂推理任务提供了更透明且可靠的决策机制。

Abstract: Existing multi-expert LLM systems gather diverse perspectives but combine them through simple aggregation, obscuring which arguments drove the final decision. We introduce ARGORA, a framework that organizes multi-expert discussions into explicit argumentation graphs showing which arguments support or attack each other. By casting these graphs as causal models, ARGORA can systematically remove individual arguments and recompute outcomes, identifying which reasoning chains were necessary and whether decisions would change under targeted modifications. We further introduce a correction mechanism that aligns internal reasoning with external judgments when they disagree. Across diverse benchmarks and an open-ended use case, ARGORA achieves competitive accuracy and demonstrates corrective behavior: when experts initially disagree, the framework resolves disputes toward correct answers more often than it introduces new errors, while providing causal diagnostics of decisive arguments.

</details>


### [120] [ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory](https://arxiv.org/abs/2601.21545)
*Yang Zhao,Chengxiao Dai,Yue Xiu,Mengying Kou,Yuliang Zheng,Dusit Niyato*

Main category: cs.AI

TL;DR: ShardMemo 是一种分层记忆系统，通过结构化分片和路由机制，在多智能体 LLM 系统中高效管理大规模外部记忆，显著提升检索性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有集中式索引和启发式分区在面对大量记忆数据和高并发访问时成为性能瓶颈，亟需更高效的外部记忆管理机制。

Method: 提出 ShardMemo 三层记忆架构：A 层为每个智能体的工作状态，B 层为带局部 ANN 索引的分片证据（采用 scope-before-routing 和基于约束的掩码机制），C 层为版本化技能库。将分片探测建模为带掩码的 MoE 路由，结合成本感知门控策略，并通过证据到分片的监督信号训练路由器。

Result: 在 LoCoMo 上比最强基线 GAM 提升 5.11–6.82 F1；在固定预算（B_probe=3）下，比 cosine-to-prototype 方法提升 6.87 F1，同时减少 20.5% 向量扫描量和 p95 延迟（95→76ms）；在长上下文 HotpotQA 和 ToolBench 上也取得显著效果。

Conclusion: ShardMemo 通过结构化分片与智能路由机制，有效解决了多智能体 LLM 系统中的大规模记忆访问瓶颈问题，在准确率、效率和延迟方面均优于现有方法。

Abstract: Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow. We present ShardMemo, a budgeted tiered memory service with Tier A per-agent working state, Tier B sharded evidence with shard-local approximate nearest neighbor (ANN) indexes, and Tier C, a versioned skill library. Tier B enforces scope-before-routing: structured eligibility constraints mask ineligible shards before routing or ANN search. We cast shard probing as masked mixture-of-experts (MoE) routing over eligible shards, probing up to $B_{\mathrm{probe}}$ shards via Top-$B_{\mathrm{probe}}$ or adaptive Top-$P$, and use cost-aware gating over profile/observation/session shard families; the router is trained from evidence-to-shard supervision. On LoCoMo, ShardMemo improves over the strongest baseline (GAM) by +5.11 to +6.82 F1 across question categories. Under a fixed-budget routing setting ($B_{\mathrm{probe}}=3$), ShardMemo improves over cosine-to-prototype shard routing by +6.87 F1 while reducing retrieval work (VecScan 521->414, -20.5%) and p95 latency (95->76 ms). On long-context HotpotQA, ShardMemo achieves 63.41/61.88/57.95 F1 at 56K/224K/448K tokens. On ToolBench, Tier C reaches 0.97 Precision@3 and 1.94 StepRed (+10.2% and +7.2% over embedding-similarity retrieval).

</details>


### [121] [Meta Context Engineering via Agentic Skill Evolution](https://arxiv.org/abs/2601.21557)
*Haoran Ye,Xuning He,Vincent Arak,Haonan Dong,Guojie Song*

Main category: cs.AI

TL;DR: 本文提出元上下文工程（MCE），一种双层框架，通过协同进化上下文工程技能与上下文工件，显著优于现有方法，在多个领域实现5.6%–53.8%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有上下文工程（CE）方法依赖人工设计的固定结构（如生成-反思流程和预定义上下文模式），存在结构偏见且限制了上下文优化的设计空间，难以充分发挥大语言模型在推理时的上下文潜力。

Method: 提出元上下文工程（MCE）框架：元层级智能体通过“智能体交叉”机制，基于历史技能、执行记录与评估结果不断优化CE技能；基础层级智能体执行这些技能，从训练轨迹中学习，并将上下文优化为灵活的文件与代码。

Result: 在五个不同领域、离线与在线设置下评估表明，MCE相比当前最先进的智能体式CE方法平均提升16.9%（范围5.6%–53.8%），同时在上下文适应性、可迁移性及使用与训练效率方面表现更优。

Conclusion: MCE通过动态协同进化技能与上下文，突破了传统静态启发式CE的局限，为大语言模型推理上下文优化提供了高效、通用且可扩展的新范式。

Abstract: The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context optimization to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level framework that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over state-of-the-art agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.

</details>


### [122] [EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots](https://arxiv.org/abs/2601.21570)
*Zixing Lei,Genjia Liu,Yuanshuo Zhang,Qipeng Liu,Chuan Wen,Shanghang Zhang,Wenzhao Lian,Siheng Chen*

Main category: cs.AI

TL;DR: 本文提出 EmboCoach-Bench 基准，评估大语言模型（LLM）智能体在无需人工干预下自主设计具身智能策略的能力，并证明其在成功率上显著超越人类手工设计的基线。


<details>
  <summary>Details</summary>
Motivation: 当前具身AI的发展受限于大量依赖人工监督（如奖励函数设计和超参数调优），阻碍了系统的可扩展性。受LLM在软件自动化和科学发现中的成功启发，作者希望探索LLM智能体能否自主完成具身策略的工程化。

Method: 构建包含32个专家策划的强化学习（RL）与模仿学习（IL）任务的基准 EmboCoach-Bench，以可执行代码为通用接口，评估LLM智能体在闭环工作流中利用环境反馈迭代编写、调试和优化策略的能力。

Result: 实验表明：(1) 自主智能体平均成功率比人类基线高26.5%；(2) 结合环境反馈的智能体工作流显著缩小开源与闭源模型间的性能差距；(3) 智能体能通过仿真反馈自我纠正严重工程错误，从近乎失败中恢复任务性能。

Conclusion: 该工作为具身智能的自我进化奠定基础，推动领域从人工密集型调优向可扩展的自主工程范式转变。

Abstract: The field of Embodied AI is witnessing a rapid evolution toward general-purpose robotic systems, fueled by high-fidelity simulation and large-scale data collection. However, this scaling capability remains severely bottlenecked by a reliance on labor-intensive manual oversight from intricate reward shaping to hyperparameter tuning across heterogeneous backends. Inspired by LLMs' success in software automation and science discovery, we introduce \textsc{EmboCoach-Bench}, a benchmark evaluating the capacity of LLM agents to autonomously engineer embodied policies. Spanning 32 expert-curated RL and IL tasks, our framework posits executable code as the universal interface. We move beyond static generation to assess a dynamic closed-loop workflow, where agents leverage environment feedback to iteratively draft, debug, and optimize solutions, spanning improvements from physics-informed reward design to policy architectures such as diffusion policies. Extensive evaluations yield three critical insights: (1) autonomous agents can qualitatively surpass human-engineered baselines by 26.5\% in average success rate; (2) agentic workflow with environment feedback effectively strengthens policy development and substantially narrows the performance gap between open-source and proprietary models; and (3) agents exhibit self-correction capabilities for pathological engineering cases, successfully resurrecting task performance from near-total failures through iterative simulation-in-the-loop debugging. Ultimately, this work establishes a foundation for self-evolving embodied intelligence, accelerating the paradigm shift from labor-intensive manual tuning to scalable, autonomous engineering in embodied AI field.

</details>


### [123] [Chain Of Thought Compression: A Theoritical Analysis](https://arxiv.org/abs/2601.21576)
*Juncai Li,Ru Li,Yuxiang Zhou,Boxiang Ma,Jeff Z. Pan*

Main category: cs.AI

TL;DR: 本文首次从理论上分析了隐式思维链（CoT）压缩的困难，提出高阶逻辑依赖的学习信号会指数衰减，并据此设计了新框架ALiCoT，在NatBool-DAG基准上实现54.4倍加速且性能与显式CoT相当。


<details>
  <summary>Details</summary>
Motivation: 显式CoT虽能提升大语言模型推理能力，但因生成大量中间步骤带来高昂计算开销；现有隐式CoT压缩方法缺乏理论解释，其机制尚不清晰。

Method: 引入“r阶交互”概念进行理论分析，构建强制不可约逻辑推理的NatBool-DAG基准，并提出ALiCoT框架，通过对齐隐状态与中间推理状态分布缓解信号衰减问题。

Result: ALiCoT在NatBool-DAG上显著优于基线方法，实现54.4倍推理加速，同时保持与显式CoT相当的准确率。

Conclusion: 隐式CoT压缩面临高阶交互导致的学习信号衰减挑战，而通过分布对齐可有效克服该问题，实现高效且准确的推理。

Abstract: Chain-of-Thought (CoT) has unlocked advanced reasoning abilities of Large Language Models (LLMs) with intermediate steps, yet incurs prohibitive computational costs due to generation of extra tokens. Recent studies empirically show that compressing reasoning steps into latent states, or implicit CoT compression, offers a token-efficient alternative. However, the mechanism behind CoT compression remains unclear. In this paper, we provide the first theoretical analysis of the difficulty of learning to internalize intermediate reasoning steps. By introducing Order-r Interaction, we prove that the learning signal for high-order logical dependencies exponentially decays to solve irreducible problem, where skipping intermediate steps inevitably leads to high-order interaction barriers. To empirically validate this, we introduce NatBool-DAG, a challenging benchmark designed to enforce irreducible logical reasoning and eliminate semantic shortcuts. Guided by our theoretical findings, we propose ALiCoT (Aligned Implicit CoT), a novel framework that overcomes the signal decay by aligning latent token distributions with intermediate reasoning states. Experimental results demonstrate that ALiCoT successfully unlocks efficient reasoning: it achieves a 54.4x speedup while maintaining performance comparable to explicit CoT.

</details>


### [124] [Depth-Recurrent Attention Mixtures: Giving Latent Reasoning the Attention it Deserves](https://arxiv.org/abs/2601.21582)
*Jonas Knupp,Jan Hendrik Metzen,Jeremias Bohn,Georg Groh,Kristian Kersting*

Main category: cs.AI

TL;DR: 本文提出了一种名为Dreamer的模块化框架，通过结合序列注意力、深度注意力和稀疏专家注意力，解决了现有深度递归模型中的隐藏维度瓶颈问题，在语言推理任务中以更少的训练token达到或超越当前SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度递归方法缺乏在FLOP、参数量和内存方面对齐的基线，且由于部分固定层堆叠而未能充分利用深度递归，同时恒定隐藏维度限制了多步潜在推理能力。

Method: 提出Dreamer框架，整合序列注意力、深度注意力与稀疏专家注意力，沿深度维度引入注意力机制以缓解隐藏维度瓶颈，解耦缩放维度，从而实现高效有效的深度递归模型扩展。

Result: 在多个语言推理基准上，Dreamer模型在相同准确率下所需训练token比匹配FLOP、参数和内存的SOTA模型少2至8倍；在相同训练token下，性能优于约2倍规模的SOTA模型。此外，其专家选择多样性比SOTA MoE高2至11倍。

Conclusion: Dreamer通过深度注意力机制有效释放了深度递归模型的潜力，显著提升了训练效率与模型性能，并揭示了不同深度间知识使用的多样性。

Abstract: Depth-recurrence facilitates latent reasoning by sharing parameters across depths. However, prior work lacks combined FLOP-, parameter-, and memory-matched baselines, underutilizes depth-recurrence due to partially fixed layer stacks, and ignores the bottleneck of constant hidden-sizes that restricts many-step latent reasoning. To address this, we introduce a modular framework of depth-recurrent attention mixtures (Dreamer), combining sequence attention, depth attention, and sparse expert attention. It alleviates the hidden-size bottleneck through attention along depth, decouples scaling dimensions, and allows depth-recurrent models to scale efficiently and effectively. Across language reasoning benchmarks, our models require 2 to 8x fewer training tokens for the same accuracy as FLOP-, parameter-, and memory-matched SOTA, and outperform ca. 2x larger SOTA models with the same training tokens. We further present insights into knowledge usage across depths, e.g., showing 2 to 11x larger expert selection diversity than SOTA MoEs.

</details>


### [125] [Beyond Imitation: Reinforcement Learning for Active Latent Planning](https://arxiv.org/abs/2601.21598)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文提出ATP-Latent方法，通过结合条件变分自编码器（VAE）与强化学习，在连续隐空间中实现主动规划，提升链式思维推理的效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有隐式推理方法依赖于对语言标签的被动模仿，难以应对同一问题存在多种等效推理路径的情况，导致隐空间表示不佳、推理策略次优，训练与测试存在差距。

Method: ATP-Latent将隐式token的监督建模为条件VAE以获得更平滑的隐空间，并引入基于VAE解码内容一致性的辅助一致性奖励，通过强化学习优化推理策略。

Result: 在LLaMA-1B模型上，ATP-Latent在四个基准测试中相比先进基线平均提升4.1%准确率，同时减少3.3%的token使用。

Conclusion: 主动规划隐式token表示空间对实现最优隐式推理策略至关重要，ATP-Latent有效提升了推理性能与效率。

Abstract: Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the \underline{A}c\underline{t}ive Latent \underline{P}lanning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\% accuracy and -3.3\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.

</details>


### [126] [Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget](https://arxiv.org/abs/2601.21608)
*Saisubramaniam Gopalakrishnan,Harikrishnan P M,Dagnachew Birru*

Main category: cs.AI

TL;DR: 该论文研究在有限预算下如何通过多种搜索策略有效发现企业级智能文档处理（IDP）系统中的多样化故障类型，强调采用组合式搜索策略优于单一方法。


<details>
  <summary>Details</summary>
Motivation: 在IDP系统早期验证阶段，预算有限，需揭示多种故障机制而非仅最坏情况；现有单一测试方法难以全面覆盖复杂文档变量交互引发的故障。

Method: 将问题形式化为基于搜索的软件测试（SBST）任务，在文档配置的组合空间中引入结构性风险特征以诱发真实故障，并在相同预算下评估进化、群体智能、质量多样性、学习驱动及量子等多种搜索策略。

Result: 不同搜索策略在相同预算下持续发现彼此未覆盖的故障模式；跨时间分析显示各策略具有稳定独特的发现能力，无一策略绝对占优；所有策略联合可覆盖全部已观测故障空间。

Conclusion: 各类搜索求解器具有内在互补性，建议采用组合式SBST策略以实现更鲁棒的企业级IDP系统验证。

Abstract: Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.

</details>


### [127] [Semantic Content Determines Algorithmic Performance](https://arxiv.org/abs/2601.21618)
*Martiño Ríos-García,Nawaf Alampara,Kevin Maik Jablonka*

Main category: cs.AI

TL;DR: 本文提出WhatCounts数据集，用于测试大语言模型（LLM）在执行计数任务时是否对输入内容的语义保持不变性。结果表明，LLM在不同语义类别（如城市、化学物质等）上的计数准确率差异超过40%，说明其行为受语义影响，而非真正实现通用算法。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否真正实现了与输入语义无关的通用算法，特别是在应具备语义不变性的任务（如计数）中是否存在对输入内容的敏感性。

Method: 构建WhatCounts数据集，其中包含无歧义、无重复、无干扰项的明确列表，仅改变被计数项的语义类型（如城市、名字、符号等），控制其他变量，评估前沿LLM在不同语义类别下的计数准确率，并通过消融实验排除混淆因素。

Result: 前沿LLM在不同语义类别上的计数准确率差异超过40%；该差异源于语义本身，且会因少量无关微调而不可预测地变化；消融实验排除了其他潜在干扰。

Conclusion: LLM并未真正实现通用算法，而是对算法进行语义依赖的近似；这种语义敏感性不仅限于计数任务，可能广泛存在于LLM执行的各类函数中，带来隐藏的输入依赖风险。

Abstract: Counting should not depend on what is being counted; more generally, any algorithm's behavior should be invariant to the semantic content of its arguments. We introduce WhatCounts to test this property in isolation. Unlike prior work that conflates semantic sensitivity with reasoning complexity or prompt variation, WhatCounts is atomic: count items in an unambiguous, delimited list with no duplicates, distractors, or reasoning steps for different semantic types. Frontier LLMs show over 40% accuracy variation depending solely on what is being counted - cities versus chemicals, names versus symbols. Controlled ablations rule out confounds. The gap is semantic, and it shifts unpredictably with small amounts of unrelated fine-tuning. LLMs do not implement algorithms; they approximate them, and the approximation is argument-dependent. As we show with an agentic example, this has implications beyond counting: any LLM function may carry hidden dependencies on the meaning of its inputs.

</details>


### [128] [ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval](https://arxiv.org/abs/2601.21654)
*Hao Shen,Hang Yang,Zhouhong Gu*

Main category: cs.AI

TL;DR: 本文提出了ScholarGym，一个用于可复现评估深度研究工作流的仿真环境，基于静态学术论文语料库和专家标注的查询，解决了因实时API调用带来的非确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强的大语言模型在复杂信息任务中依赖实时API，导致结果不可复现且难以公平比较，因此需要一个可控、确定性的评估环境。

Method: 构建包含57万篇论文的静态语料库和2,536个专家标注查询的仿真环境ScholarGym，将工作流解耦为查询规划、工具调用和相关性评估三个阶段，在确定性检索条件下进行细粒度分析。

Result: 在多种主干模型上的实验揭示了推理能力、规划策略与选择机制在迭代优化过程中的相互作用。

Conclusion: ScholarGym为深度研究工作流提供了可复现、细粒度的评估框架，有助于推动工具增强语言模型的系统性研究与比较。

Abstract: Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons.
  We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.

</details>


### [129] [SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding](https://arxiv.org/abs/2601.21666)
*Ahmed Y. Radwan,Christos Emmanouilidis,Hina Tabassum,Deval Pandya,Shaina Raza*

Main category: cs.AI

TL;DR: 本文提出了SONIC-O1，一个涵盖13个现实对话场景、包含4958条人工验证标注的高质量音视频多模态大语言模型（MLLM）评测基准，用于评估模型在开放总结、选择题问答和时序定位等任务上的表现，并揭示了现有模型在不同人群中的性能差异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型研究主要聚焦于静态图像理解，对序列化音视频数据的处理能力缺乏系统评估，亟需一个高质量基准来衡量其在真实场景下的表现。

Method: 构建并发布SONIC-O1基准，包含13个真实对话领域、4958条人工验证标注及人口统计元数据，评估任务包括开放式摘要、多项选择题回答和带推理依据的时序定位。

Result: 实验表明，闭源与开源模型在选择题准确率上差距较小，但在时序定位任务上性能差距达22.6%；同时模型在不同人口群体中表现不一致，存在显著性能差异。

Conclusion: SONIC-O1为时序对齐和社会鲁棒性的多模态理解提供了开放评测平台，有助于推动MLLM在音视频理解方向的发展。

Abstract: Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard

</details>


### [130] [TCAP: Tri-Component Attention Profiling for Unsupervised Backdoor Detection in MLLM Fine-Tuning](https://arxiv.org/abs/2601.21692)
*Mingzu Liu,Hao Fang,Runmin Cong*

Main category: cs.AI

TL;DR: 本文提出Tri-Component Attention Profiling（TCAP），一种无监督的防御框架，通过分析多模态大语言模型中系统指令、视觉输入和用户文本查询三部分的注意力分配差异，有效识别并过滤后门样本。


<details>
  <summary>Details</summary>
Motivation: 现有针对多模态大语言模型后门攻击的防御方法依赖监督信号或难以泛化到不同触发器类型和模态，因此需要一种通用且无需监督的防御机制。

Method: TCAP将跨模态注意力图分解为三个功能组件，利用高斯混合模型（GMM）对注意力头进行统计建模，识别对触发器敏感的注意力头，并通过EM算法投票聚合以隔离中毒样本。

Result: 在多种多模态大语言模型架构和攻击方法上的实验表明，TCAP在识别后门样本方面表现稳定且优越。

Conclusion: TCAP是一种鲁棒且实用的无监督后门防御方法，适用于多模态大语言模型中的各种后门攻击场景。

Abstract: Fine-Tuning-as-a-Service (FTaaS) facilitates the customization of Multimodal Large Language Models (MLLMs) but introduces critical backdoor risks via poisoned data. Existing defenses either rely on supervised signals or fail to generalize across diverse trigger types and modalities. In this work, we uncover a universal backdoor fingerprint-attention allocation divergence-where poisoned samples disrupt the balanced attention distribution across three functional components: system instructions, vision inputs, and user textual queries, regardless of trigger morphology. Motivated by this insight, we propose Tri-Component Attention Profiling (TCAP), an unsupervised defense framework to filter backdoor samples. TCAP decomposes cross-modal attention maps into the three components, identifies trigger-responsive attention heads via Gaussian Mixture Model (GMM) statistical profiling, and isolates poisoned samples through EM-based vote aggregation. Extensive experiments across diverse MLLM architectures and attack methods demonstrate that TCAP achieves consistently strong performance, establishing it as a robust and practical backdoor defense in MLLMs.

</details>


### [131] [FBS: Modeling Native Parallel Reading inside a Transformer](https://arxiv.org/abs/2601.21708)
*Tongxi Wang*

Main category: cs.AI

TL;DR: 提出Fovea-Block-Skip Transformer（FBS），通过引入可训练的因果循环机制，在不增加参数量的前提下提升大语言模型推理的质量与效率平衡。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型推理仍依赖逐token自回归，缺乏人类阅读中的内容自适应预判、分块结构感知计算分配以及训练测试一致性等关键机制。

Method: 在Transformer中引入Parafovea-Attention Window（PAW）、Chunk-Head（CH）和Skip-Gate（SG）三个模块，构建可训练的因果循环结构。

Result: 在多个基准测试中，FBS在不增加参数的情况下改善了质量与效率的权衡，消融实验表明三个模块具有互补性。

Conclusion: FBS有效融合人类阅读机制，为大语言模型高效推理提供了新思路。

Abstract: Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.

</details>


### [132] [E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory](https://arxiv.org/abs/2601.21714)
*Kaixiang Wang,Yidan Lin,Jiong Lou,Zhaojiacheng Zhou,Bunyod Suvonov,Jie Li*

Main category: cs.AI

TL;DR: 本文提出E-mem框架，通过模仿生物记忆痕迹（engrams）机制，采用主从多智能体架构实现情境化记忆重建，避免传统记忆预处理中的去情境化问题，在LoCoMo基准上F1得分提升7.75%，同时减少70%以上的token开销。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）智能体在向系统2推理演进过程中，其记忆预处理方法（如嵌入或图结构）会破坏上下文完整性，阻碍长程高精度推理能力的发展。

Method: E-mem框架摒弃记忆预处理，转而采用基于情景的记忆重建策略：由一个主智能体进行全局规划，多个辅助智能体维护未压缩的记忆上下文，并在激活的记忆片段内进行局部推理，提取上下文感知的证据后再聚合。

Result: 在LoCoMo基准测试中，E-mem的F1分数超过54%，比当前最优方法GAM高出7.75%，同时token消耗降低70%以上。

Conclusion: E-mem通过保留原始记忆上下文并引入多智能体协同推理机制，有效提升了LLM智能体在复杂任务中的逻辑连贯性与推理效率。

Abstract: The evolution of Large Language Model (LLM) agents towards System~2 reasoning, characterized by deliberative, high-precision problem-solving, requires maintaining rigorous logical integrity over extended horizons. However, prevalent memory preprocessing paradigms suffer from destructive de-contextualization. By compressing complex sequential dependencies into pre-defined structures (e.g., embeddings or graphs), these methods sever the contextual integrity essential for deep reasoning. To address this, we propose E-mem, a framework shifting from Memory Preprocessing to Episodic Context Reconstruction. Inspired by biological engrams, E-mem employs a heterogeneous hierarchical architecture where multiple assistant agents maintain uncompressed memory contexts, while a central master agent orchestrates global planning. Unlike passive retrieval, our mechanism empowers assistants to locally reason within activated segments, extracting context-aware evidence before aggregation. Evaluations on the LoCoMo benchmark demonstrate that E-mem achieves over 54\% F1, surpassing the state-of-the-art GAM by 7.75\%, while reducing token cost by over 70\%.

</details>


### [133] [DropoutTS: Sample-Adaptive Dropout for Robust Time Series Forecasting](https://arxiv.org/abs/2601.21726)
*Siru Zhong,Yiqiu Liu,Zhiqing Cui,Zezhi Shao,Fei Wang,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: 本文提出DropoutTS，一种模型无关的插件方法，通过样本自适应的Dropout机制提升深度时间序列模型对噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的时间序列数据普遍存在噪声，而现有鲁棒性方法在有效性与效率之间难以兼顾，要么依赖数据剪枝，要么需要昂贵的先验噪声量化。

Method: DropoutTS利用谱稀疏性通过重构残差高效估计样本级噪声，并将噪声水平映射为自适应的Dropout率，动态调节模型学习能力，在抑制虚假波动的同时保留细节信息。

Result: 在多种噪声环境和公开基准上的实验表明，DropoutTS能稳定提升先进主干模型的性能，且几乎不增加参数量，无需修改模型结构。

Conclusion: DropoutTS提供了一种高效、轻量且通用的鲁棒性增强方案，有效解决了深度时间序列模型在噪声数据下的性能退化问题。

Abstract: Deep time series models are vulnerable to noisy data ubiquitous in real-world applications. Existing robustness strategies either prune data or rely on costly prior quantification, failing to balance effectiveness and efficiency. In this paper, we introduce DropoutTS, a model-agnostic plugin that shifts the paradigm from "what" to learn to "how much" to learn. DropoutTS employs a Sample-Adaptive Dropout mechanism: leveraging spectral sparsity to efficiently quantify instance-level noise via reconstruction residuals, it dynamically calibrates model learning capacity by mapping noise to adaptive dropout rates - selectively suppressing spurious fluctuations while preserving fine-grained fidelity. Extensive experiments across diverse noise regimes and open benchmarks show DropoutTS consistently boosts superior backbones' performance, delivering advanced robustness with negligible parameter overhead and no architectural modifications. Our code is available at https://github.com/CityMind-Lab/DropoutTS.

</details>


### [134] [Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling](https://arxiv.org/abs/2601.21760)
*Ruian Tie,Wenbo Xiong,Zhengyu Shi,Xinyu Su,Chenyu jiang,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为零样本统计降尺度（ZSSD）的新框架，无需配对训练数据即可实现气候降尺度，并在多种全球气候模型（GCM）上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统监督式气候降尺度方法因缺乏配对训练数据及与再分析数据存在域差异而难以泛化到GCM；现有零样本方法则存在物理不一致性和大尺度因子下的梯度消失问题。

Method: ZSSD利用从再分析数据中学得的物理一致气候先验，并结合地理边界和时间信息以保证物理有效性；同时引入统一坐标引导策略，解决标准DPS中的梯度消失问题并确保与大尺度场的一致性。

Result: ZSSD在99百分位误差上显著优于现有零样本基线方法，并能成功重建跨异构GCM的复杂天气事件（如热带气旋）。

Conclusion: ZSSD为无配对数据条件下的气候降尺度提供了一种有效且物理一致的零样本解决方案，具有良好的泛化能力和实际应用潜力。

Abstract: Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.

</details>


### [135] [Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies](https://arxiv.org/abs/2601.21771)
*Hadi Banaee,Stephanie Lowry*

Main category: cs.AI

TL;DR: 本文提出一种基于概念空间的框架，通过棋局轨迹建模随时间展开的抽象策略概念（如进攻、牺牲），利用可解释的质量维度中的几何区域表示概念，并通过轨迹方向识别意图，支持双视角建模与专家判断一致。


<details>
  <summary>Details</summary>
Motivation: 传统概念空间理论难以处理随时间演化、具有目标导向的抽象概念，尤其在动态决策场景中缺乏对概念意图和多视角理解的建模能力。作者旨在扩展该理论以适用于时序性、目标驱动的概念识别。

Method: 将抽象策略概念表示为可解释质量维度上的几何区域；将棋局建模为在该空间中的轨迹，通过轨迹朝向特定区域的方向性运动识别策略意图；引入双视角机制以捕捉不同玩家对同一局面的不同解读。

Result: 在国际象棋案例中成功实现了基于轨迹的概念识别，所识别的策略模式与专家评论高度一致，验证了方法的可行性。

Conclusion: 该研究拓展了概念空间理论至时序性、目标导向的抽象概念建模，为序列决策任务中的概念学习与知识演化提供了基础框架，具有广泛的应用潜力。

Abstract: We present a conceptual space framework for modelling abstract concepts that unfold over time, demonstrated through a chess-based proof-of-concept. Strategy concepts, such as attack or sacrifice, are represented as geometric regions across interpretable quality dimensions, with chess games instantiated and analysed as trajectories whose directional movement toward regions enables recognition of intended strategies. This approach also supports dual-perspective modelling, capturing how players interpret identical situations differently. Our implementation demonstrates the feasibility of trajectory-based concept recognition, with movement patterns aligning with expert commentary. This work explores extending the conceptual spaces theory to temporally realised, goal-directed concepts. The approach establishes a foundation for broader applications involving sequential decision-making and supports integration with knowledge evolution mechanisms for learning and refining abstract concepts over time.

</details>


### [136] [BioAgent Bench: An AI Agent Evaluation Suite for Bioinformatics](https://arxiv.org/abs/2601.21800)
*Dionizije Fa,Marko Čuljak,Bruno Pandža,Mateo Čupić*

Main category: cs.AI

TL;DR: 本文提出了BioAgent Bench，一个用于评估AI智能体在常见生物信息学任务中性能与鲁棒性的基准数据集和评测套件，并发现前沿模型虽能完成多步骤流程，但在扰动下存在鲁棒性不足的问题，同时指出在涉及隐私的场景中开源模型更具优势。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估AI智能体在生物信息学任务中表现的标准化基准，且现有模型在真实复杂场景（如含扰动输入或隐私约束）下的可靠性尚不明确。

Method: 构建包含端到端生物信息学任务（如RNA-seq、变异检测、宏基因组分析）的基准数据集，设计可自动化评估的提示与输出规范；通过多种智能体框架测试闭源与开源大模型，并采用基于LLM的评分器评估流程进展与结果有效性；同时进行压力测试（如损坏输入、诱饵文件、提示膨胀）以评估鲁棒性。

Result: 前沿AI智能体能在无复杂定制框架的情况下可靠生成最终生物信息学产物，但在受控扰动下表现出明显的失败模式；此外，在涉及敏感数据的场景中，开源模型因隐私合规性更受青睐，尽管其任务完成率较低。

Conclusion: 正确构建高层级生物信息学流程并不等同于具备可靠的步骤级推理能力；为兼顾隐私与实用性，应根据应用场景权衡使用闭源或开源模型。作者公开发布了该基准数据集与评测套件。

Abstract: This paper introduces BioAgent Bench, a benchmark dataset and an evaluation suite designed for measuring the performance and robustness of AI agents in common bioinformatics tasks. The benchmark contains curated end-to-end tasks (e.g., RNA-seq, variant calling, metagenomics) with prompts that specify concrete output artifacts to support automated assessment, including stress testing under controlled perturbations. We evaluate frontier closed-source and open-weight models across multiple agent harnesses, and use an LLM-based grader to score pipeline progress and outcome validity. We find that frontier agents can complete multi-step bioinformatics pipelines without elaborate custom scaffolding, often producing the requested final artifacts reliably. However, robustness tests reveal failure modes under controlled perturbations (corrupted inputs, decoy files, and prompt bloat), indicating that correct high-level pipeline construction does not guarantee reliable step-level reasoning. Finally, because bioinformatics workflows may involve sensitive patient data, proprietary references, or unpublished IP, closed-source models can be unsuitable under strict privacy constraints; in such settings, open-weight models may be preferable despite lower completion rates. We release the dataset and evaluation suite publicly.

</details>


### [137] [A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition](https://arxiv.org/abs/2601.21802)
*Hoang Khang Phan,Quang Vinh Dang,Noriyo Colley,Christina Garcia,Nhat Tan Le*

Main category: cs.AI

TL;DR: 本文提出一个以大语言模型（LLM）为核心的视频活动识别与反馈生成框架，用于气管内吸痰（ES）操作培训，在准确率和F1分数上优于传统方法约15-20%，并结合可解释AI提供自然语言反馈，提升护理教育质量与患者安全。


<details>
  <summary>Details</summary>
Motivation: 气管内吸痰是一项高风险且需高技能的临床操作，在家庭护理和教学环境中缺乏持续监督，而现有自动化识别与反馈系统研究不足，亟需智能辅助培训方案。

Method: 构建以LLM为中心的统一框架：利用LLM进行视频中的时空活动识别与可解释决策分析，并基于异常检测与XAI生成自然语言反馈；与传统机器学习和深度学习方法进行对比实验。

Result: LLM方法在准确率和F1分数上比基线模型提升约15-20%；同时成功实现可解释、自动化的自然语言反馈，能指出正确操作并提出改进建议。

Conclusion: 该框架为护理技能培训提供了可扩展、可解释且数据驱动的新范式，有助于提高培训效率与患者安全。

Abstract: Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.

</details>


### [138] [Looking Beyond Accuracy: A Holistic Benchmark of ECG Foundation Models](https://arxiv.org/abs/2601.21830)
*Francesca Filice,Edoardo De Rose,Simone Bartucci,Francesco Calimeri,Simona Perri*

Main category: cs.AI

TL;DR: 本文提出了一种针对心电图（ECG）专用基础模型（FMs）的综合评估框架，结合下游性能与表征层面分析（使用SHAP和UMAP），以深入评估其嵌入表示的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有对ECG基础模型的评估主要关注下游任务性能，缺乏对其嵌入表示泛化能力的深入分析；而在医疗等高风险领域，这种泛化性至关重要。

Method: 提出一种新的基准测试方法，将基于性能的评估与基于表示的分析相结合，利用SHAP和UMAP技术，并在多个跨洲数据集及不同数据可用性（包括数据稀缺）条件下对多个ECG专用基础模型进行评估。

Result: 实验结果表明，所提出的基准协议能够深入揭示ECG基础模型嵌入模式的结构与泛化特性，提供比传统方法更丰富的洞察。

Conclusion: 该研究为ECG基础模型的可靠部署提供了更全面的评估手段，强调了在医疗AI中不仅要看性能，还需深入理解模型内部表示的泛化能力。

Abstract: The electrocardiogram (ECG) is a cost-effective, highly accessible and widely employed diagnostic tool. With the advent of Foundation Models (FMs), the field of AI-assisted ECG interpretation has begun to evolve, as they enable model reuse across different tasks by relying on embeddings. However, to responsibly employ FMs, it is crucial to rigorously assess to which extent the embeddings they produce are generalizable, particularly in error-sensitive domains such as healthcare. Although prior works have already addressed the problem of benchmarking ECG-expert FMs, they focus predominantly on the evaluation of downstream performance. To fill this gap, this study aims to find an in-depth, comprehensive benchmarking framework for FMs, with a specific focus on ECG-expert ones. To this aim, we introduce a benchmark methodology that complements performance-based evaluation with representation-level analysis, leveraging SHAP and UMAP techniques. Furthermore, we rely on the methodology for carrying out an extensive evaluation of several ECG-expert FMs pretrained via state-of-the-art techniques over different cross-continental datasets and data availability settings; this includes ones featuring data scarcity, a fairly common situation in real-world medical scenarios. Experimental results show that our benchmarking protocol provides a rich insight of ECG-expert FMs' embedded patterns, enabling a deeper understanding of their representational structure and generalizability.

</details>


### [139] [Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework](https://arxiv.org/abs/2601.21844)
*So Fukuhara,Abdallah Alabdallah,Nuwan Gunasekara,Slawomir Nowaczyk*

Main category: cs.AI

TL;DR: 本文提出一个以决策为中心的仿真框架，用于在汽车售后备件库存管理中评估预测模型对运营绩效（如成本与服务水平）的实际影响，而非仅依赖传统统计精度指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究多用MAE、RMSE等统计指标评估预测模型，但这些指标与库存管理中的关键运营绩效（如总成本和服务水平）之间的关系尚不明确；而实际决策更应关注后者。

Method: 构建一个闭环仿真框架，包含：(i) 面向备件需求特性的合成需求生成器，(ii) 可集成任意预测模型的灵活预测模块，(iii) 基于预测结果计算运营KPI的库存控制模拟器。

Result: 实验表明，传统精度指标的提升未必带来运营绩效改善；具有相似统计误差的模型可能导致显著不同的成本-服务权衡。研究进一步揭示了预测特性如何影响库存结果。

Conclusion: 该框架将需求预测与库存决策紧密连接，推动模型评估从纯预测准确性转向运营相关性，为汽车售后等间歇性需求场景下的模型选择提供实用指导。

Abstract: Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains.

</details>


### [140] [KnowBias: Mitigating Social Bias in LLMs via Know-Bias Neuron Enhancement](https://arxiv.org/abs/2601.21864)
*Jinhao Pan,Chahat Raj,Anjishnu Mukherjee,Sina Mansouri,Bowen Wei,Shloka Yada,Ziwei Zhu*

Main category: cs.AI

TL;DR: KnowBias 是一种轻量级去偏框架，通过增强编码偏见知识的神经元（而非抑制）来有效减少大语言模型中的社会偏见，仅需少量是非问题即可实现跨偏见类型和人群的高效去偏，且几乎不影响模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法多采用抑制范式（如修改参数、提示或神经元），但存在脆弱性高、泛化能力弱、数据效率低及损害模型通用能力等问题。因此，作者提出一种新思路：通过增强与偏见知识相关的神经元来实现更稳健、高效且不损害性能的去偏。

Method: KnowBias 利用基于归因分析的方法，通过少量偏见知识是非题识别出编码偏见知识的神经元，并在推理阶段选择性增强这些神经元的激活，从而在保留模型通用能力的同时实现去偏。

Result: 在多个基准测试和大语言模型上的实验表明，KnowBias 在去偏效果上达到当前最优水平，同时对模型通用能力的损害极小，且仅需极少量标注数据（无需重新训练）。

Conclusion: KnowBias 提供了一种新颖、高效且轻量的去偏策略，通过增强而非抑制偏见相关神经元，在保持模型性能的同时显著降低社会偏见，具有良好的泛化性和实用性。

Abstract: Large language models (LLMs) exhibit social biases that reinforce harmful stereotypes, limiting their safe deployment. Most existing debiasing methods adopt a suppressive paradigm by modifying parameters, prompts, or neurons associated with biased behavior; however, such approaches are often brittle, weakly generalizable, data-inefficient, and prone to degrading general capability. We propose \textbf{KnowBias}, a lightweight and conceptually distinct framework that mitigates bias by strengthening, rather than suppressing, neurons encoding bias-knowledge. KnowBias identifies neurons encoding bias knowledge using a small set of bias-knowledge questions via attribution-based analysis, and selectively enhances them at inference time. This design enables strong debiasing while preserving general capabilities, generalizes across bias types and demographics, and is highly data efficient, requiring only a handful of simple yes/no questions and no retraining. Experiments across multiple benchmarks and LLMs demonstrate consistent state-of-the-art debiasing performance with minimal utility degradation. Data and code are available at https://github.com/JP-25/KnowBias.

</details>


### [141] [WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents](https://arxiv.org/abs/2601.21872)
*Yao Zhang,Shijie Tang,Zeyu Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: 本文提出WebArbiter，一种基于推理的网页过程奖励模型（WebPRM），通过生成结构化理由并给出偏好判断，显著提升复杂网页任务中的决策性能。


<details>
  <summary>Details</summary>
Motivation: 现有网页智能体在长周期、不可逆操作场景中面临稀疏且延迟的监督信号问题；当前WebPRM方法（如标量或清单式）存在信号粗糙、模板脆弱、缺乏可解释性等局限。

Method: WebArbiter将奖励建模转化为文本生成任务，输出包含原则推理的结构化理由及偏好判断；采用两阶段训练：先通过推理蒸馏获得原则引导能力，再用强化学习对齐判断与正确性。

Result: 在新发布的WebPRMBench基准上，WebArbiter-7B比最强基线GPT-5高9.1分；在WebArena-Lite的轨迹搜索中，比先前最优WebPRM提升最多7.2分。

Conclusion: WebArbiter通过原则驱动的推理机制和结构化奖励建模，显著提升了网页智能体在复杂任务中的泛化能力、鲁棒性和实用性。

Abstract: Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.

</details>


### [142] [From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning](https://arxiv.org/abs/2601.21909)
*Shaojie Wang,Liang Zhang*

Main category: cs.AI

TL;DR: 本文提出一种受人类认知启发的两阶段大语言模型后训练框架，通过分离抽象策略学习与具体任务执行，在提升泛化能力的同时显著提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型后训练方法（如SFT+RL）将完整推理轨迹作为基本单位进行优化，忽略了人类解决问题时先掌握通用策略、再适配具体问题的认知机制，导致策略与执行耦合，限制了泛化能力与训练效率。

Method: 提出Chain-of-Meta-Thought (CoMT) 和 Confidence-Calibrated Reinforcement Learning (CCRL)：CoMT在监督学习阶段专注于学习不含具体执行的抽象推理模式；CCRL则在强化学习阶段通过基于置信度的中间奖励优化任务适配，防止过度自信导致的错误传播。

Result: 在4个模型和8个基准上实验表明，相比标准方法，该方法在分布内和分布外分别提升2.19%和4.63%，同时减少65–70%训练时间和50%的token消耗。

Conclusion: 将后训练过程与人类认知原则对齐，不仅能提升模型泛化能力，还能显著提高训练效率。

Abstract: Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\% and 4.63\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.

</details>


### [143] [ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21912)
*Zhao Wang,Ziliang Zhao,Zhicheng Dou*

Main category: cs.AI

TL;DR: 本文提出ProRAG，一种过程监督的强化学习框架，通过引入步骤级奖励机制优化检索增强生成（RAG）在复杂推理任务中的表现，显著优于现有基于结果或过程感知的基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于结果的强化学习在长程推理任务中面临奖励稀疏和信用分配不精确的问题，导致模型产生“过程幻觉”；而现有过程感知方法缺乏有效的在线策略探索能力，难以实现细粒度的步骤级监督。

Method: ProRAG框架包含四个阶段：(1) 监督策略预热；(2) 基于MCTS构建过程奖励模型（PRM）；(3) PRM引导的推理优化；(4) 结合双粒度优势机制的过程监督强化学习，融合步骤级过程奖励与全局结果信号。

Result: 在五个多跳推理基准上的实验表明，ProRAG在整体性能上优于强基线方法，尤其在复杂长程任务中表现突出。

Conclusion: 细粒度的过程监督能有效提升RAG系统在复杂推理任务中的逻辑一致性和检索效率，ProRAG为过程导向的强化学习提供了有效范式。

Abstract: Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to "process hallucinations", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.

</details>


### [144] [Self-Compression of Chain-of-Thought via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.21919)
*Yiqun Chen,Jinyuan Feng,Wei Yang,Meizhi Zhong,Zhengliang Shi,Rui Li,Xiaochi Wei,Yan Gao,Yi Wu,Yao Hu,Zhiqiang Pu,Jiaxin Mao*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体强化学习框架SCMA，通过识别并惩罚冗余推理片段，在不增加推理开销的前提下显著缩短响应长度并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法在压缩大推理模型（LRM）的推理过程时，采用简单的长度惩罚与结果奖励结合的方式，难以平衡简洁性与准确性，容易因过度压缩而损害关键推理逻辑。

Method: 提出名为SCMA（Self-Compression via MARL）的多智能体强化学习框架，包含三个智能体：分割智能体（Segmentation Agent）将推理过程划分为逻辑片段，评分智能体（Scoring Agent）评估各片段的重要性，二者协作生成重要性加权的长度惩罚，引导推理智能体（Reasoning Agent）保留关键逻辑、剔除冗余内容。

Result: 在不同规模模型上的实验表明，SCMA可将响应长度减少11.1%至39.0%，同时将准确率提升4.33%至10.02%。消融实验和定性分析验证了该框架能激发协同优化行为，优于传统RL方法。

Conclusion: SCMA通过多智能体协作实现对推理过程的精细化压缩，在部署阶段无额外开销，有效提升了大推理模型的效率与性能，为解决冗余推理问题提供了新思路。

Abstract: The inference overhead induced by redundant reasoning undermines the interactive experience and severely bottlenecks the deployment of Large Reasoning Models. Existing reinforcement learning (RL)-based solutions tackle this problem by coupling a length penalty with outcome-based rewards. This simplistic reward weighting struggles to reconcile brevity with accuracy, as enforcing brevity may compromise critical reasoning logic. In this work, we address this limitation by proposing a multi-agent RL framework that selectively penalizes redundant chunks, while preserving essential reasoning logic. Our framework, Self-Compression via MARL (SCMA), instantiates redundancy detection and evaluation through two specialized agents: \textbf{a Segmentation Agent} for decomposing the reasoning process into logical chunks, and \textbf{a Scoring Agent} for quantifying the significance of each chunk. The Segmentation and Scoring agents collaboratively define an importance-weighted length penalty during training, incentivizing \textbf{a Reasoning Agent} to prioritize essential logic without introducing inference overhead during deployment. Empirical evaluations across model scales demonstrate that SCMA reduces response length by 11.1\% to 39.0\% while boosting accuracy by 4.33\% to 10.02\%. Furthermore, ablation studies and qualitative analysis validate that the synergistic optimization within the MARL framework fosters emergent behaviors, yielding more powerful LRMs compared to vanilla RL paradigms.

</details>


### [145] [AgenticSimLaw: A Juvenile Courtroom Multi-Agent Debate Simulation for Explainable High-Stakes Tabular Decision Making](https://arxiv.org/abs/2601.21936)
*Jon Chun,Kathrine Elkins,Yong Suk Lee*

Main category: cs.AI

TL;DR: 本文提出AgenticSimLaw，一种基于角色结构的多智能体辩论框架，用于高风险表格决策任务，通过模拟法庭形式实现透明、可控且可审计的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在高风险决策中常采用黑箱方法，缺乏透明性、可控性和可解释性。作者旨在构建一个结构化、可观察、负责任的多智能体系统，以应对伦理复杂场景下的决策挑战。

Method: 设计包含检察官、辩护方和法官三类角色的多智能体系统，采用7轮结构化辩论协议，结合私有推理策略，在NLSY97数据集上对青少年再犯预测任务进行评估，并与传统思维链（CoT）方法在近90种模型与策略组合下进行对比。

Result: 结构化多智能体辩论在性能上更稳定、泛化能力更强，准确率与F1分数的相关性更高；同时提供细粒度推理控制、完整交互记录以支持可解释性，并支持对智能体行为的系统分析。

Conclusion: AgenticSimLaw不仅在刑事司法领域验证了其在伦理复杂场景下的有效性，还可推广至其他需要透明度与人类监督的高风险决策任务，为LLM多智能体系统提供了组织性、可观测性与责任约束的新范式。

Abstract: We introduce AgenticSimLaw, a role-structured, multi-agent debate framework that provides transparent and controllable test-time reasoning for high-stakes tabular decision-making tasks. Unlike black-box approaches, our courtroom-style orchestration explicitly defines agent roles (prosecutor, defense, judge), interaction protocols (7-turn structured debate), and private reasoning strategies, creating a fully auditable decision-making process. We benchmark this framework on young adult recidivism prediction using the NLSY97 dataset, comparing it against traditional chain-of-thought (CoT) prompting across almost 90 unique combinations of models and strategies. Our results demonstrate that structured multi-agent debate provides more stable and generalizable performance compared to single-agent reasoning, with stronger correlation between accuracy and F1-score metrics. Beyond performance improvements, AgenticSimLaw offers fine-grained control over reasoning steps, generates complete interaction transcripts for explainability, and enables systematic profiling of agent behaviors. While we instantiate this framework in the criminal justice domain to stress-test reasoning under ethical complexity, the approach generalizes to any deliberative, high-stakes decision task requiring transparency and human oversight. This work addresses key LLM-based multi-agent system challenges: organization through structured roles, observability through logged interactions, and responsibility through explicit non-deployment constraints for sensitive domains. Data, results, and code will be available on github.com under the MIT license.

</details>


### [146] [Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities](https://arxiv.org/abs/2601.21937)
*Shuangshuang Ying,Zheyu Wang,Yunjian Peng,Jin Chen,Yuhao Wu,Hongbin Lin,Dingyu He,Siyi Liu,Gengchen Yu,YinZhu Piao,Yuchen Wu,Xin Gui,Zhongyuan Peng,Xin Li,Xeron Du,Libo Qin,YiXin Cao,Ge Zhang*

Main category: cs.AI

TL;DR: 本文提出DeR2，一个用于评估大语言模型在新科学信息上进行文档基础推理能力的受控沙盒环境，通过四种证据访问机制分离检索与推理，并揭示现有模型在深度研究任务中的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以区分大语言模型的推理能力与其检索、工具链选择及参数记忆的影响，无法准确衡量其对全新科学信息的真实推理能力。

Method: 构建DeR2沙盒，包含四种证据访问机制（仅指令、概念、相关文档、完整文档集），采用两阶段验证防止参数泄露，并提供冻结的2023-2025年理论论文库及专家标注的概念与推理依据。

Result: 在多个前沿大模型上的实验显示，模型在深度研究任务中表现差异显著，部分模型在加入干扰文档后性能反而下降，另一些则存在概念误用问题。

Conclusion: 当前大语言模型在真正的新科学信息推理方面仍有很大提升空间，DeR2为细粒度评估和归因模型错误提供了有效框架。

Abstract: Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.

</details>


### [147] [ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models](https://arxiv.org/abs/2601.21947)
*Bowen Fang,Wen Ye,Yunyue Su,Jinghao Zhang,Qiang Liu,Yesheng Liu,Xin Sun,Shu Wu,Jiabing Yang,Baole Wei,Liang Wang*

Main category: cs.AI

TL;DR: ToolWeaver 是一种新型生成式工具学习框架，通过将工具编码为层次化序列，解决了现有方法在可扩展性、泛化能力和语义表达上的瓶颈，在近47,000个工具的评估中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的工具使用方法存在双重语义挑战：检索器编码器难以捕捉复杂语义，且大语言模型（LLM）缺乏内生的工具知识；而当前主流的生成式方法将每个工具映射为一个独立新词元，导致词汇爆炸、语义孤立和协作关系学习困难。

Method: 提出 ToolWeaver 框架，通过一种新颖的分词过程，将工具的内在语义与外在共用模式“编织”成结构化的层次化代码序列，并在生成对齐阶段将这些代码集成到 LLM 中，使其能生成此类序列。

Result: 在包含近47,000个工具的评估中，ToolWeaver 显著优于当前最先进的方法，展现出更强的可扩展性、泛化能力和对工具协作关系的语义理解。

Conclusion: ToolWeaver 为构建更先进、可扩展且语义感知的工具增强型智能体提供了新的基础，有效克服了传统生成式工具学习方法的局限性。

Abstract: Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.

</details>


### [148] [How do Visual Attributes Influence Web Agents? A Comprehensive Evaluation of User Interface Design Factors](https://arxiv.org/abs/2601.21961)
*Kuai Yu,Naicheng Yu,Han Wang,Rui Yang,Huan Zhang*

Main category: cs.AI

TL;DR: 本文提出VAF评估框架，系统研究网页视觉属性对Web智能体决策的影响，发现背景色对比度、项目大小、位置和卡片清晰度对智能体行为影响显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注Web智能体在对抗攻击下的鲁棒性，缺乏对良性场景中视觉属性如何影响其决策的系统理解。

Method: 提出VAF三阶段评估流程：(i) 生成语义一致但视觉属性不同的网页变体；(ii) 智能体模拟人类浏览行为进行交互；(iii) 通过点击动作（目标点击率）和推理（目标提及率）联合评估视觉属性影响。

Result: 在8类变体（共48种）、5个真实网站和4个代表性Web智能体上的实验表明，背景色对比度、项目大小、位置和卡片清晰度对智能体行为影响显著，而字体样式、文字颜色和图片清晰度影响较小。

Conclusion: 视觉属性显著影响Web智能体的决策行为，VAF为理解并优化智能体在真实网页环境中的表现提供了有效工具。

Abstract: Web agents have demonstrated strong performance on a wide range of web-based tasks. However, existing research on the effect of environmental variation has mostly focused on robustness to adversarial attacks, with less attention to agents' preferences in benign scenarios. Although early studies have examined how textual attributes influence agent behavior, a systematic understanding of how visual attributes shape agent decision-making remains limited. To address this, we introduce VAF, a controlled evaluation pipeline for quantifying how webpage Visual Attribute Factors influence web-agent decision-making. Specifically, VAF consists of three stages: (i) variant generation, which ensures the variants share identical semantics as the original item while only differ in visual attributes; (ii) browsing interaction, where agents navigate the page via scrolling and clicking the interested item, mirroring how human users browse online; (iii) validating through both click action and reasoning from agents, which we use the Target Click Rate and Target Mention Rate to jointly evaluate the effect of visual attributes. By quantitatively measuring the decision-making difference between the original and variant, we identify which visual attributes influence agents' behavior most. Extensive experiments, across 8 variant families (48 variants total), 5 real-world websites (including shopping, travel, and news browsing), and 4 representative web agents, show that background color contrast, item size, position, and card clarity have a strong influence on agents' actions, whereas font styling, text color, and item image clarity exhibit minor effects.

</details>


### [149] [The Energy Impact of Domain Model Design in Classical Planning](https://arxiv.org/abs/2601.21967)
*Ilche Georgievski,Serhat Tekin,Marco Aiello*

Main category: cs.AI

TL;DR: 本文研究了自动规划中领域模型设计对能耗的影响，发现不同模型配置会导致显著的能耗差异，且能耗与运行时间并不总是一致。


<details>
  <summary>Details</summary>
Motivation: 传统AI研究侧重于算法性能（如准确率或运行时间），而忽视了能耗问题。尽管自动规划计算开销大，但其能效问题尚未得到充分关注。本文旨在填补这一空白，利用规划系统中领域模型与算法解耦的特点，系统分析模型设计对能耗的影响。

Method: 作者提出了一个领域模型配置框架，可控制地调整模型特征（如元素顺序、动作元数、死端状态等）。在五个基准领域和五个先进规划器上，对每个基准生成32种变体，实证分析这些变化对能耗和运行时间的影响。

Result: 实验结果表明，领域模型的修改会显著影响不同规划器的能耗，且能耗与运行时间之间并不存在一致的相关性。

Conclusion: 领域模型的设计是影响自动规划系统能耗的重要因素，未来在Green AI背景下应将模型层面的能效纳入考量，不能仅依赖运行时间作为性能指标。

Abstract: AI research has traditionally prioritised algorithmic performance, such as optimising accuracy in machine learning or runtime in automated planning. The emerging paradigm of Green AI challenges this by recognising energy consumption as a critical performance dimension. Despite the high computational demands of automated planning, its energy efficiency has received little attention. This gap is particularly salient given the modular planning structure, in which domain models are specified independently of algorithms. On the other hand, this separation also enables systematic analysis of energy usage through domain model design. We empirically investigate how domain model characteristics affect the energy consumption of classical planners. We introduce a domain model configuration framework that enables controlled variation of features, such as element ordering, action arity, and dead-end states. Using five benchmark domains and five state-of-the-art planners, we analyse energy and runtime impacts across 32 domain variants per benchmark. Results demonstrate that domain-level modifications produce measurable energy differences across planners, with energy consumption not always correlating with runtime.

</details>


### [150] [Mind the Gap: How Elicitation Protocols Shape the Stated-Revealed Preference Gap in Language Models](https://arxiv.org/abs/2601.21975)
*Pranav Mahajan,Ihor Kendiukhov,Syed Hussain,Lydia Nottingham*

Main category: cs.AI

TL;DR: 本文研究了语言模型中陈述偏好与揭示偏好之间的差距（SvR），发现该差距高度依赖于偏好获取的协议设计，尤其是是否允许中立或弃权选项，并指出需采用能处理不确定偏好的方法。


<details>
  <summary>Details</summary>
Motivation: 现有对语言模型偏好一致性的评估多依赖二选一的强制选择方式，可能混淆真实偏好与协议人为因素；作者旨在系统探究不同偏好获取协议如何影响SvR相关性。

Method: 在24个语言模型上，通过改变陈述偏好和揭示偏好任务中是否允许中立或弃权选项，测量其对Spearman秩相关系数（ρ）的影响，并测试使用系统提示引导是否能提升AIRiskDilemmas数据集上的SvR相关性。

Result: 允许在陈述偏好中中立或弃权可显著提高ρ；但若在揭示偏好中也允许弃权，则因高弃权率导致ρ接近零甚至为负；系统提示引导未能稳定提升相关性。

Conclusion: SvR相关性高度依赖于偏好获取协议，未来研究应采用能识别和处理不确定偏好的方法，以更准确评估语言模型的真实偏好一致性。

Abstract: Recent work identifies a stated-revealed (SvR) preference gap in language models (LMs): a mismatch between the values models endorse and the choices they make in context. Existing evaluations rely heavily on binary forced-choice prompting, which entangles genuine preferences with artifacts of the elicitation protocol. We systematically study how elicitation protocols affect SvR correlation across 24 LMs. Allowing neutrality and abstention during stated preference elicitation allows us to exclude weak signals, substantially improving Spearman's rank correlation ($ρ$) between volunteered stated preferences and forced-choice revealed preferences. However, further allowing abstention in revealed preferences drives $ρ$ to near-zero or negative values due to high neutrality rates. Finally, we find that system prompt steering using stated preferences during revealed preference elicitation does not reliably improve SvR correlation on AIRiskDilemmas. Together, our results show that SvR correlation is highly protocol-dependent and that preference elicitation requires methods that account for indeterminate preferences.

</details>


### [151] [VERSA: Verified Event Data Format for Reliable Soccer Analytics](https://arxiv.org/abs/2601.21981)
*Geonhee Jo,Mingu Kang,Kangmin Lee,Minho Lee,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: 本文提出VERSA框架，通过状态转移模型验证足球事件流数据的逻辑一致性，显著提升数据可靠性及下游任务（如VAEP）性能。


<details>
  <summary>Details</summary>
Motivation: 事件流数据在体育分析中广泛应用，但其内在的数据质量问题（如事件顺序错误或缺失）导致逻辑不一致，限制了分析模型的可靠性。

Method: 提出VERSA（Verified Event Data Format for Reliable Soccer Analytics），基于状态转移模型定义合法事件序列，自动检测并修正事件流中的异常模式。

Result: 在K League 1（2024赛季）数据中发现18.81%的事件存在逻辑不一致；应用VERSA后，跨数据源一致性显著提升，且经VERSA修正的数据在VAEP任务中表现更优。

Conclusion: VERSA能有效提升事件流数据的完整性与可靠性，从而增强数据驱动分析的稳健性与准确性。

Abstract: Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.

</details>


### [152] [Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems](https://arxiv.org/abs/2601.21993)
*Dhiogo de Sá,Carlos Schmiedel,Carlos Pereira Lopes*

Main category: cs.AI

TL;DR: 本文提出“液态接口”（Liquid Interfaces）这一新型协调范式，将接口视为运行时通过意图表达与语义协商临时生成的关系性事件，而非持久的技术构件，并提出了液态接口协议（LIP）以支持智能体系统中的自适应协调。


<details>
  <summary>Details</summary>
Motivation: 当前软件架构难以支持具有自适应、概率性和上下文依赖推理能力的自主智能体，且系统集成仍依赖静态接口和确定性契约，限制了智能体间的灵活协作。

Method: 作者形式化了液态接口模型，并设计了液态接口协议（LIP），该协议管理基于意图的交互、协商执行，并在语义不确定性下确保接口的临时性；同时提供了一个参考架构以展示其实现可行性。

Result: 该方法为智能体系统中的自适应协调提供了原则性基础，并通过参考架构验证了其实际可行性。

Conclusion: 液态接口通过将接口动态化和语义化，有效支持了在不确定环境下自主智能体之间的灵活、自适应协作，为下一代智能体系统架构提供了新思路。

Abstract: Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems

</details>


### [153] [CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty](https://arxiv.org/abs/2601.22027)
*Johannes Kirmayr,Lukas Stappen,Elisabeth André*

Main category: cs.AI

TL;DR: 本文提出了CAR-bench，一个面向车载语音助手场景的LLM智能体评测基准，重点评估其在多轮对话中处理不确定性、遵守策略和认知自身能力边界的能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体评测基准多关注理想条件下的任务完成情况，忽视了真实用户场景中常见的请求不完整或模糊所带来的不确定性，以及智能体在工具使用和策略遵守方面的可靠性。

Method: 构建CAR-bench基准，包含LLM模拟用户、领域策略和58个跨导航、生产力、充电与车辆控制的互联工具；设计Disambiguation任务（测试澄清与信息收集能力）和Hallucination任务（测试在信息缺失时的边界意识）。

Result: 前沿推理LLM在Disambiguation任务上的稳定通过率低于50%，常因过早行动失败；在Hallucination任务中频繁违反策略或编造信息以满足用户，显示出一致性和自我认知的严重不足。

Conclusion: 真实世界应用需要更可靠、具备自我认知能力的LLM智能体，当前模型在一致性、不确定性处理和策略遵从方面仍有显著差距。

Abstract: Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence. We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks, underscoring the need for more reliable and self-aware LLM agents in real-world settings.

</details>


### [154] [Defining Operational Conditions for Safety-Critical AI-Based Systems from Data](https://arxiv.org/abs/2601.22118)
*Johann Christensen,Elena Hoemann,Frank Köster,Sven Hallerbach*

Main category: cs.AI

TL;DR: 本文提出一种基于核函数的数据驱动方法，用于从已有数据中事后定义人工智能系统的运行设计域（ODD），以支持安全关键系统的认证。


<details>
  <summary>Details</summary>
Motivation: 在现实复杂系统或已有数据场景中，传统依赖专家知识和标准的ODD定义方法难以完整刻画环境条件，阻碍了AI系统在安全关键领域的认证。

Method: 提出一种“安全设计”（Safety-by-Design）方法，利用多维核函数表示从历史数据中事后构建ODD，并通过蒙特卡洛模拟和真实航空防撞案例进行验证。

Result: 该方法能有效重构出与原始隐藏ODD一致的数据驱动ODD，并为未来数据驱动的安全关键AI系统提供可认证的基础。

Conclusion: 所提出的基于核函数的ODD定义方法为安全关键AI系统的认证提供了可行路径，弥合了数据驱动开发与安全规范之间的鸿沟。

Abstract: Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.

</details>


### [155] [Exploring Reasoning Reward Model for Agents](https://arxiv.org/abs/2601.22154)
*Kaixuan Fan,Kaituo Feng,Manyuan Zhang,Tianshuo Peng,Zhixun Li,Yilei Jiang,Shuang Chen,Peng Pei,Xunliang Cai,Xiangyu Yue*

Main category: cs.AI

TL;DR: 本文提出Agent-RRM，一种多维度奖励模型，为智能体推理轨迹提供结构化反馈，并通过Reagent-U等训练策略在多个基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有Agentic RL方法主要依赖稀疏的结果奖励，无法有效评估中间推理质量，导致训练效果不佳。

Method: 提出Agent Reasoning Reward Model (Agent-RRM)，生成包含显式推理轨迹、聚焦批评和整体评分的结构化反馈，并探索三种集成策略：Reagent-C、Reagent-R和Reagent-U。

Result: 在12个基准上评估，Reagent-U在GAIA上达到43.7%，在WebWalkerQA上达到46.2%，显著优于基线。

Conclusion: Agent-RRM及其训练策略能有效提升智能体的推理与工具使用能力，代码、模型和数据均已开源以促进后续研究。

Abstract: Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [156] [AI-Augmented Density-Driven Optimal Control (D2OC) for Decentralized Environmental Mapping](https://arxiv.org/abs/2601.21126)
*Kooktae Lee,Julian Martinez*

Main category: cs.MA

TL;DR: 本文提出一种AI增强的去中心化多智能体环境建图框架，在感知与通信受限条件下，通过最优传输理论和双MLP模块实现对复杂空间密度分布的高保真重建。


<details>
  <summary>Details</summary>
Motivation: 传统覆盖方法依赖准确的先验地图，在先验存在偏差或不确定性时性能显著下降；因此需要一种能在不确定环境下自适应、自校正的去中心化建图机制。

Method: 在最优传输框架下，智能体迭代优化局部密度估计，并引入双MLP模块推断局部均值-方差统计量，调节长期未访问区域的虚拟不确定性，以避免陷入局部最优。

Result: 仿真表明，所提方法在复杂多模态空间分布下，相比传统去中心化基线方法，能更鲁棒、精确地对齐真实密度，实现更高保真度的环境重建。

Conclusion: 该AI增强的密度驱动最优控制方法兼具理论收敛性（Wasserstein度量下）与实际有效性，为不确定环境下的多智能体协同建图提供了可扩展的新范式。

Abstract: This paper presents an AI-augmented decentralized framework for multi-agent (multi-robot) environmental mapping under limited sensing and communication. While conventional coverage formulations achieve effective spatial allocation when an accurate reference map is available, their performance deteriorates under uncertain or biased priors. The proposed method introduces an adaptive and self-correcting mechanism that enables agents to iteratively refine local density estimates within an optimal transport-based framework, ensuring theoretical consistency and scalability. A dual multilayer perceptron (MLP) module enhances adaptivity by inferring local mean-variance statistics and regulating virtual uncertainty for long-unvisited regions, mitigating stagnation around local minima. Theoretical analysis rigorously proves convergence under the Wasserstein metric, while simulation results demonstrate that the proposed AI-augmented Density-Driven Optimal Control consistently achieves robust and precise alignment with the ground-truth density, yielding substantially higher-fidelity reconstruction of complex multi-modal spatial distributions compared with conventional decentralized baselines.

</details>


### [157] [Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems](https://arxiv.org/abs/2601.22041)
*Naomi Pitzer,Daniela Mihai*

Main category: cs.MA

TL;DR: 在感知异构的多智能体通信游戏中，尽管缺乏感知对齐，多模态系统仍能产生类别一致的消息；单模态系统通信更高效，而消息意义以分布方式而非组合方式编码；跨感知世界的系统需微调才能互通。


<details>
  <summary>Details</summary>
Motivation: 现有涌现通信研究多假设同质模态或对齐的表征空间，忽视了现实世界中智能体感知异构性的问题，本文旨在探索在此类异构条件下通信如何形成与迁移。

Method: 设计了一个多步二进制通信博弈，其中智能体具有不同模态且缺乏感知对齐；通过分析通信效率、消息结构、比特扰动影响及跨系统互操作性来评估通信机制。

Result: 多模态系统能生成类别一致的消息但通信效率较低、不确定性更高；单模态系统使用更少比特并实现更低分类熵；比特扰动实验表明语义以分布方式编码；不同感知世界训练的系统需微调才能互通。

Conclusion: 涌现通信可作为研究异构模态下表征适应与迁移的有效框架，为理论与实验开辟新方向。

Abstract: Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignment, multimodal systems converge to class-consistent messages grounded in perceptual input. Unimodal systems communicate more efficiently, using fewer bits and achieving lower classification entropy, while multimodal agents require greater information exchange and exhibit higher uncertainty. Bit perturbation experiments provide strong evidence that meaning is encoded in a distributional rather than compositional manner, as each bit's contribution depends on its surrounding pattern. Finally, interoperability analyses show that systems trained in different perceptual worlds fail to directly communicate, but limited fine-tuning enables successful cross-system communication. This work positions emergent communication as a framework for studying how agents adapt and transfer representations across heterogeneous modalities, opening new directions for both theory and experimentation.

</details>
