<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 44]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.CG](#cs.CG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 50]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Three-dimensional Damage Visualization of Civil Structures via Gaussian Splatting-enabled Digital Twins](https://arxiv.org/abs/2602.16713)
*Shuo Wang,Shuo Wang,Xin Nie,Yasutaka Narazaki,Thomas Matiki,Billie F. Spencer*

Main category: cs.CV

TL;DR: 本文提出一种基于高斯泼溅（Gaussian Splatting, GS）的数字孪生方法，用于实现土木基础设施中损伤的高效、精确三维可视化。


<details>
  <summary>Details</summary>
Motivation: 传统二维图像损伤识别难以满足现代基础设施巡检对三维损伤可视化的需求；现有三维重建方法如NeRF在效率和细节表现上存在局限，而GS在渲染质量和效率方面更具优势。

Method: 该方法利用GS进行三维重建，将二维损伤分割结果映射到三维空间以减少分割误差；采用多尺度重建策略平衡效率与细节；并支持随时间演化的损伤更新数字孪生模型。

Result: 在开源合成地震后检测数据集上的实验表明，该方法能有效实现全面、精确的三维损伤可视化。

Conclusion: 基于GS的数字孪生方法为土木基础设施损伤的三维可视化提供了一种高效且具前景的技术路径。

Abstract: Recent advancements in civil infrastructure inspections underscore the need for precise three-dimensional (3D) damage visualization on digital twins, transcending traditional 2D image-based damage identifications. Compared to conventional photogrammetric 3D reconstruction techniques, modern approaches such as Neural Radiance Field (NeRF) and Gaussian Splatting (GS) excel in scene representation, rendering quality, and handling featureless regions. Among them, GS stands out for its efficiency, leveraging discrete anisotropic 3D Gaussians to represent radiance fields, unlike NeRF's continuous implicit model. This study introduces a GS-enabled digital twin method tailored for effective 3D damage visualization. The method's key contributions include: 1) utilizing GS-based 3D reconstruction to visualize 2D damage segmentation results while reducing segmentation errors; 2) developing a multi-scale reconstruction strategy to balance efficiency and damage detail; 3) enabling digital twin updates as damage evolves over time. Demonstrated on an open-source synthetic dataset for post-earthquake inspections, the proposed approach offers a promising solution for comprehensive 3D damage visualization in civil infrastructure digital twins.

</details>


### [2] [Analytic Score Optimization for Multi Dimension Video Quality Assessment](https://arxiv.org/abs/2602.16856)
*Boda Lin,Yongjie Zhu,Wenyu Qin,Meng Wang,Pengfei Wan*

Main category: cs.CV

TL;DR: 本文提出了一个大规模多维视频质量评估数据集UltraVQA，并引入分析性评分优化（ASO）方法，通过理论驱动的后训练目标提升多维视频质量预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统视频质量评估依赖单一平均意见分数，难以全面反映用户生成内容的多维质量特性。因此，亟需构建包含细粒度、可解释标注的多维数据集，并开发能有效利用此类丰富标注的新评估方法。

Method: 构建包含五维质量标注（运动质量、运动幅度、美学质量、内容质量和清晰度）的UltraVQA数据集，每段视频由至少3名评分者打分并附带GPT生成的解释性理由；提出Analytic Score Optimization (ASO)方法，将质量评估重构为带正则化的决策过程，获得闭式解以捕捉人类评分的序数特性。

Result: 所提ASO方法在实验中优于多数基线模型（包括闭源API和开源模型），并在质量预测任务中显著降低平均绝对误差（MAE）。

Conclusion: 多维、可解释的标注结合基于强化对齐的优化策略，对推动视频质量评估的发展具有重要意义。

Abstract: Video Quality Assessment (VQA) is evolving beyond single-number mean opinion score toward richer, multi-faceted evaluations of video content. In this paper, we present a large-scale multi-dimensional VQA dataset UltraVQA that encompasses diverse User-Generated Content~(UGC) annotated across five key quality dimensions: Motion Quality, Motion Amplitude, Aesthetic Quality, Content Quality, and Clarity Quality. Each video in our dataset is scored by over 3 human raters on these dimensions, with fine-grained sub-attribute labels, and accompanied by an explanatory rationale generated by GPT based on the collective human judgments. To better leverage these rich annotations and improve discrete quality score assessment, we introduce Analytic Score Optimization (ASO), a theoretically grounded post-training objective derived for multi-dimensional VQA. By reframing quality assessment as a regularized decision-making process, we obtain a closed-form solution that naturally captures the ordinal nature of human ratings, ensuring alignment with human ranking preferences. In experiments, our method outperforms most baselines including closed-source APIs and open-source models, while also reducing mean absolute error (MAE) in quality prediction. Our work highlights the importance of multi-dimensional, interpretable annotations and reinforcement-based alignment in advancing video quality assessment.

</details>


### [3] [DODO: Discrete OCR Diffusion Models](https://arxiv.org/abs/2602.16872)
*Sean Man,Roy Ganz,Roi Ronen,Shahar Tsiper,Shai Mazor,Niv Nayman*

Main category: cs.CV

TL;DR: 本文提出DODO，一种基于块离散扩散机制的视觉语言模型，用于光学字符识别（OCR），在保持接近最先进准确率的同时，实现比自回归方法快3倍的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在OCR任务中主要依赖自回归解码，导致长文档处理时计算开销大、速度慢；而虽然OCR任务具有高度确定性，理论上适合并行解码，但现有掩码扩散模型因结构不稳定难以满足OCR对精确匹配的严格要求。

Method: 提出DODO模型，首次将块离散扩散机制引入OCR任务，通过将生成过程分解为多个块，缓解全局扩散中的同步错误，从而实现高效并行解码。

Result: DODO在多个OCR基准上达到接近最先进水平的准确率，同时推理速度相比自回归基线提升最高达3倍。

Conclusion: 块离散扩散机制能有效兼顾OCR任务的准确性与效率，为高确定性视觉-文本转换任务提供了一种新的高效建模范式。

Abstract: Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual understanding. While modern Vision-Language Models (VLM) have achieved high accuracy in this domain, they predominantly rely on autoregressive decoding, which becomes computationally expensive and slow for long documents as it requires a sequential forward pass for every generated token. We identify a key opportunity to overcome this bottleneck: unlike open-ended generation, OCR is a highly deterministic task where the visual input strictly dictates a unique output sequence, theoretically enabling efficient, parallel decoding via diffusion models. However, we show that existing masked diffusion models fail to harness this potential; those introduce structural instabilities that are benign in flexible tasks, like captioning, but catastrophic for the rigid, exact-match requirements of OCR. To bridge this gap, we introduce DODO, the first VLM to utilize block discrete diffusion and unlock its speedup potential for OCR. By decomposing generation into blocks, DODO mitigates the synchronization errors of global diffusion. Empirically, our method achieves near state-of-the-art accuracy while enabling up to 3x faster inference compared to autoregressive baselines.

</details>


### [4] [StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation](https://arxiv.org/abs/2602.16915)
*Zeyu Ren,Xiang Li,Yiran Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出StereoAdapter-2，通过引入基于选择性状态空间模型的ConvSS2D算子替代传统ConvGRU，实现单步高效长距离视差传播，并构建大规模合成水下双目数据集UW-StereoDepth-80K，在零样本设置下显著提升水下深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 水下立体深度估计受波长相关光衰减、散射和折射引起的严重域偏移影响；现有基于GRU的方法因局部卷积核和顺序门控机制需多次迭代才能传播长距离视差，在大视差和无纹理区域表现受限。

Method: 提出ConvSS2D算子，采用四向扫描策略契合对极几何并捕捉垂直结构一致性，以线性计算复杂度在单次更新中实现高效长程传播；构建包含多样基线、衰减与散射参数的合成水下双目数据集UW-StereoDepth-80K；结合动态LoRA适配机制。

Result: 在TartanAir-UW和SQUID水下基准上分别实现17%和7.2%的零样本性能提升，并在BlueROV2平台上验证了方法的现实鲁棒性。

Conclusion: StereoAdapter-2通过新型状态空间算子和高质量合成数据有效解决了水下深度估计中的长距离依赖与域偏移问题，显著优于现有方法。

Abstract: Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2.

</details>


### [5] [SemCovNet: Towards Fair and Semantic Coverage-Aware Learning for Underrepresented Visual Concepts](https://arxiv.org/abs/2602.16917)
*Sakib Ahammed,Xia Cui,Xinqi Fan,Wenqi Lu,Moi Hoon Yap*

Main category: cs.CV

TL;DR: 本文提出SemCovNet模型，通过引入语义描述图、描述注意力调制模块和描述-视觉对齐损失，有效缓解视觉模型中的语义覆盖不平衡（SCI）问题，提升模型的公平性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中存在语义覆盖不平衡（SCI）问题，即语义层面的长尾分布导致模型难以学习稀有但有意义的语义概念，影响模型的推理能力与公平性，而这一偏差此前未被充分关注。

Method: 提出SemCovNet模型，包含语义描述图（SDM）、描述注意力调制模块（DAM）和描述-视觉对齐损失（DVA），并通过覆盖率差异指数（CDI）量化语义公平性。

Result: 在多个数据集上的实验表明，SemCovNet显著降低CDI，提升模型在稀有语义上的表现，实现更公平、可靠的视觉理解。

Conclusion: SCI是一种可度量且可校正的偏差，本文为推动语义公平性和可解释的视觉学习提供了新基础。

Abstract: Modern vision models increasingly rely on rich semantic representations that extend beyond class labels to include descriptive concepts and contextual attributes. However, existing datasets exhibit Semantic Coverage Imbalance (SCI), a previously overlooked bias arising from the long-tailed semantic representations. Unlike class imbalance, SCI occurs at the semantic level, affecting how models learn and reason about rare yet meaningful semantics. To mitigate SCI, we propose Semantic Coverage-Aware Network (SemCovNet), a novel model that explicitly learns to correct semantic coverage disparities. SemCovNet integrates a Semantic Descriptor Map (SDM) for learning semantic representations, a Descriptor Attention Modulation (DAM) module that dynamically weights visual and concept features, and a Descriptor-Visual Alignment (DVA) loss that aligns visual features with descriptor semantics. We quantify semantic fairness using a Coverage Disparity Index (CDI), which measures the alignment between coverage and error. Extensive experiments across multiple datasets demonstrate that SemCovNet enhances model reliability and substantially reduces CDI, achieving fairer and more equitable performance. This work establishes SCI as a measurable and correctable bias, providing a foundation for advancing semantic fairness and interpretable vision learning.

</details>


### [6] [Xray-Visual Models: Scaling Vision models on Industry Scale Data](https://arxiv.org/abs/2602.16918)
*Shlok Mishra,Tsung-Yu Lin,Linda Wang,Hongli Xu,Yimin Liu,Michael Hsu,Chaitanya Ahuja,Hao Yuan,Jianpeng Cheng,Hong-You Chen,Haoyuan Xu,Chao Li,Abhijeet Awasthi,Jihye Moon,Don Husa,Michael Ge,Sumedha Singla,Arkabandhu Chowdhury,Phong Dingh,Satya Narayan Shukla,Yonghuan Yang,David Jacobs,Qi Guo,Jun Xiao,Xiangjun Fan,Aashu Singh*

Main category: cs.CV

TL;DR: Xray-Visual 是一种在大规模社交媒体数据上训练的统一视觉模型架构，在图像和视频理解任务中达到最先进性能，兼具高准确率与计算效率。


<details>
  <summary>Details</summary>
Motivation: 为应对大规模图像与视频理解任务，需构建一个能有效利用海量社交媒体数据、兼顾多模态（图像、视频、文本）且具备强泛化能力的统一视觉模型。

Method: 模型基于 Vision Transformer，并引入高效 token 重组（EViT）；采用三阶段训练流程：自监督 MAE、半监督 hashtag 分类和 CLIP 式对比学习；训练数据包括 150 亿图像-文本对和 100 亿视频-hashtag 对，并通过数据平衡与去噪策略提升语义多样性；此外，探索将大语言模型作为文本编码器（LLM2CLIP）以增强检索性能。

Result: Xray-Visual 在 ImageNet、Kinetics、HMDB51 和 MSCOCO 等多个基准上取得 SOTA 结果，展现出对域偏移和对抗扰动的强鲁棒性，且 LLM2CLIP 显著提升跨模态检索效果。

Conclusion: Xray-Visual 为可扩展的多模态视觉模型设立了新基准，在保持高精度的同时实现优异的计算效率，适用于真实世界的大规模应用场景。

Abstract: We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines self-supervised MAE, semi-supervised hashtag classification, and CLIP-style contrastive learning to jointly optimize image and video modalities. Our architecture builds on a Vision Transformer backbone enhanced with efficient token reorganization (EViT) for improved computational efficiency. Extensive experiments demonstrate that Xray-Visual achieves state-of-the-art performance across diverse benchmarks, including ImageNet for image classification, Kinetics and HMDB51 for video understanding, and MSCOCO for cross-modal retrieval. The model exhibits strong robustness to domain shift and adversarial perturbations. We further demonstrate that integrating large language models as text encoders (LLM2CLIP) significantly enhances retrieval performance and generalization capabilities, particularly in real-world environments. Xray-Visual establishes new benchmarks for scalable, multimodal vision models, while maintaining superior accuracy and computational efficiency.

</details>


### [7] [HS-3D-NeRF: 3D Surface and Hyperspectral Reconstruction From Stationary Hyperspectral Images Using Multi-Channel NeRFs](https://arxiv.org/abs/2602.16950)
*Kibon Ku,Talukder Z. Jubery,Adarsh Krishnamurthy,Baskar Ganapathysubramanian*

Main category: cs.CV

TL;DR: 本文提出HSI-SC-NeRF，一种基于固定相机的多通道神经辐射场框架，用于高通量的高光谱三维重建，适用于农产品采后检测。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱成像与3D重建方法在农业自动化表型系统中难以规模化集成，传统硬件复杂且NeRF方法通常依赖移动相机，限制了室内农业环境中的通量与可重复性。

Method: 采用固定相机配合旋转物体，在特制聚四氟乙烯成像腔内获取多视角高光谱数据；利用ArUco标记估计物体姿态并通过模拟姿态变换将其转换至相机坐标系；提出多通道NeRF模型，结合复合光谱损失函数和两阶段训练策略（先几何初始化，再辐射度优化）进行联合重建。

Result: 在三种农产品样本上的实验表明，该方法在可见光与近红外波段均实现了高空间重建精度和良好的光谱保真度。

Conclusion: HSI-SC-NeRF适合集成到自动化农业工作流中，为高通量农产品质量与表型分析提供了有效解决方案。

Abstract: Advances in hyperspectral imaging (HSI) and 3D reconstruction have enabled accurate, high-throughput characterization of agricultural produce quality and plant phenotypes, both essential for advancing agricultural sustainability and breeding programs. HSI captures detailed biochemical features of produce, while 3D geometric data substantially improves morphological analysis. However, integrating these two modalities at scale remains challenging, as conventional approaches involve complex hardware setups incompatible with automated phenotyping systems. Recent advances in neural radiance fields (NeRF) offer computationally efficient 3D reconstruction but typically require moving-camera setups, limiting throughput and reproducibility in standard indoor agricultural environments. To address these challenges, we introduce HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for high-throughput hyperspectral 3D reconstruction targeting postharvest inspection of agricultural produce. Multi-view hyperspectral data is captured using a stationary camera while the object rotates within a custom-built Teflon imaging chamber providing diffuse, uniform illumination. Object poses are estimated via ArUco calibration markers and transformed to the camera frame of reference through simulated pose transformations, enabling standard NeRF training on stationary-camera data. A multi-channel NeRF formulation optimizes reconstruction across all hyperspectral bands jointly using a composite spectral loss, supported by a two-stage training protocol that decouples geometric initialization from radiometric refinement. Experiments on three agricultural produce samples demonstrate high spatial reconstruction accuracy and strong spectral fidelity across the visible and near-infrared spectrum, confirming the suitability of HSI-SC-NeRF for integration into automated agricultural workflows.

</details>


### [8] [DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.16968)
*Dahye Kim,Deepti Ghadiyaram,Raghudeep Gadde*

Main category: cs.CV

TL;DR: 本文提出动态分词策略，在扩散Transformer（DiT）推理过程中根据内容复杂度和去噪时间步动态调整图像/视频块大小，从而显著提升推理速度而不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前DiT模型在图像和视频生成中计算开销大，主要源于固定大小的分块策略，无法根据去噪阶段的内容复杂度自适应调整。

Method: 提出动态分词方法：在早期去噪步骤使用较大块以建模全局结构，后期使用较小块以细化局部细节，并在推理时动态分配不同时间步的块大小。

Result: 在FLUX-1.Dev和Wan 2.1上分别实现最高3.52倍和3.2倍的加速，同时保持生成质量和提示一致性。

Conclusion: 动态分词是一种高效且有效的测试时策略，可在不牺牲感知质量的前提下显著降低DiT的计算成本。

Abstract: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\times$ and $3.2\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.

</details>


### [9] [Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling](https://arxiv.org/abs/2602.16979)
*Divyam Madaan,Sumit Chopra,Kyunghyun Cho*

Main category: cs.CV

TL;DR: 本文提出PRIMO模型，通过潜在变量建模缺失模态，实现不完整多模态数据下的有效训练与推理，并能量化缺失模态对预测的影响。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM方法通常假设训练和推理阶段所有模态均可用，但实际中多模态数据常因缺失、异步采集或仅部分样本具备而呈现不完整性，亟需能处理此类情况的方法。

Method: PRIMO是一种有监督的潜在变量填补模型，将缺失模态建模为与观测模态及预测任务相关的潜在变量；训练时利用所有完整或部分模态样本，推理时从学习到的缺失模态分布中采样，获得边缘预测分布并分析缺失模态对单个样本预测的影响。

Result: 在XOR合成数据集、Audio-Vision MNIST和MIMIC-III（用于死亡率和ICD-9预测）上的实验表明：当某一模态完全缺失时，PRIMO性能与单模态基线相当；当所有模态可用时，性能与多模态基线相当。此外，PRIMO可通过基于方差的指标量化每个样本中缺失模态的预测影响，并可视化不同填补结果对应的合理标签集合。

Conclusion: PRIMO有效解决了多模态数据不完整问题，不仅保持了预测性能，还能在实例层面量化和解释缺失模态对预测的影响，提升了多模态模型在现实场景中的实用性与可解释性。

Abstract: Despite the recent success of Multimodal Large Language Models (MLLMs), existing approaches predominantly assume the availability of multiple modalities during training and inference. In practice, multimodal data is often incomplete because modalities may be missing, collected asynchronously, or available only for a subset of examples. In this work, we propose PRIMO, a supervised latent-variable imputation model that quantifies the predictive impact of any missing modality within the multimodal learning setting. PRIMO enables the use of all available training examples, whether modalities are complete or partial. Specifically, it models the missing modality through a latent variable that captures its relationship with the observed modality in the context of prediction. During inference, we draw many samples from the learned distribution over the missing modality to both obtain the marginal predictive distribution (for the purpose of prediction) and analyze the impact of the missing modalities on the prediction for each instance. We evaluate PRIMO on a synthetic XOR dataset, Audio-Vision MNIST, and MIMIC-III for mortality and ICD-9 prediction. Across all datasets, PRIMO obtains performance comparable to unimodal baselines when a modality is fully missing and to multimodal baselines when all modalities are available. PRIMO quantifies the predictive impact of a modality at the instance level using a variance-based metric computed from predictions across latent completions. We visually demonstrate how varying completions of the missing modality result in a set of plausible labels.

</details>


### [10] [Patch-Based Spatial Authorship Attribution in Human-Robot Collaborative Paintings](https://arxiv.org/abs/2602.17030)
*Eric Chen,Patricia Alves-Oliveira*

Main category: cs.CV

TL;DR: 本文提出一种基于图像块的框架，用于在人机协作绘画中进行空间作者归属，通过15幅抽象画作的案例研究，在图像块级别达到88.8%的准确率，并利用条件香农熵量化风格重叠，验证了模型对混合作者身份的识别能力。


<details>
  <summary>Details</summary>
Motivation: 随着具身智能体在创意生产中的参与日益增多，明确记录人类与机器人在协作艺术作品中的作者身份变得至关重要，尤其在艺术、收藏和法律语境下。

Method: 采用基于图像块的作者归属方法，利用普通平板扫描仪获取数据，并通过留一画作交叉验证；使用条件香农熵衡量风格重叠程度，以评估混合创作区域的不确定性。

Result: 该方法在图像块级别达到88.8%的准确率（画作级别为86.7%），优于基于纹理和预训练特征的基线方法（68.0%-84.7%）；混合区域的不确定性显著高于纯人类或纯机器人作品（p=0.003）。

Conclusion: 该框架虽针对特定人机组合训练，但为数据稀缺的人机协作创作场景提供了高效、可扩展的作者归属方法论基础，未来有望推广至更广泛的人机绘画协作系统。

Abstract: As agentic AI becomes increasingly involved in creative production, documenting authorship has become critical for artists, collectors, and legal contexts. We present a patch-based framework for spatial authorship attribution within human-robot collaborative painting practice, demonstrated through a forensic case study of one human artist and one robotic system across 15 abstract paintings. Using commodity flatbed scanners and leave-one-painting-out cross-validation, the approach achieves 88.8% patch-level accuracy (86.7% painting-level via majority vote), outperforming texture-based and pretrained-feature baselines (68.0%-84.7%). For collaborative artworks, where ground truth is inherently ambiguous, we use conditional Shannon entropy to quantify stylistic overlap; manually annotated hybrid regions exhibit 64% higher uncertainty than pure paintings (p=0.003), suggesting the model detects mixed authorship rather than classification failure. The trained model is specific to this human-robot pair but provides a methodological grounding for sample-efficient attribution in data-scarce human-AI creative workflows that, in the future, has the potential to extend authorship attribution to any human-robot collaborative painting.

</details>


### [11] [PartRAG: Retrieval-Augmented Part-Level 3D Generation and Editing](https://arxiv.org/abs/2602.17033)
*Peize Li,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出PartRAG，一种结合外部部件数据库与扩散Transformer的检索增强框架，用于实现具有部件级结构的单图3D生成，并支持高效局部编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理部件几何多样性、多视角一致性以及支持精确局部编辑方面存在不足，难以覆盖长尾分布的部件形状并保持编辑后的整体一致性。

Method: PartRAG引入层次对比检索模块，将图像块与3D部件潜在表示在部件和物体两个粒度上对齐，并从包含1,236个带注释资产的数据库中检索多样且物理合理的部件；同时设计了一个掩码部件级编辑器，在共享规范空间中支持部件替换、属性微调和组合更新，无需重新生成整个对象。

Result: 在Objaverse、ShapeNet和ABO数据集上表现优异：Objaverse上的Chamfer Distance从0.1726降至0.1528，F-Score从0.7472提升至0.844；推理时间为38秒，交互式编辑耗时5–8秒。定性结果显示出更清晰的部件边界、更好的细结构保真度及对可动部件对象的鲁棒性。

Conclusion: PartRAG通过检索增强机制有效提升了单图3D生成的部件级结构质量和编辑灵活性，在多个指标和视觉效果上均优于现有方法。

Abstract: Single-image 3D generation with part-level structure remains challenging: learned priors struggle to cover the long tail of part geometries and maintain multi-view consistency, and existing systems provide limited support for precise, localized edits. We present PartRAG, a retrieval-augmented framework that integrates an external part database with a diffusion transformer to couple generation with an editable representation. To overcome the first challenge, we introduce a Hierarchical Contrastive Retrieval module that aligns dense image patches with 3D part latents at both part and object granularity, retrieving from a curated bank of 1,236 part-annotated assets to inject diverse, physically plausible exemplars into denoising. To overcome the second challenge, we add a masked, part-level editor that operates in a shared canonical space, enabling swaps, attribute refinements, and compositional updates without regenerating the whole object while preserving non-target parts and multi-view consistency. PartRAG achieves competitive results on Objaverse, ShapeNet, and ABO-reducing Chamfer Distance from 0.1726 to 0.1528 and raising F-Score from 0.7472 to 0.844 on Objaverse-with inference of 38s and interactive edits in 5-8s. Qualitatively, PartRAG produces sharper part boundaries, better thin-structure fidelity, and robust behavior on articulated objects. Code: https://github.com/AIGeeksGroup/PartRAG. Website: https://aigeeksgroup.github.io/PartRAG.

</details>


### [12] [Amber-Image: Efficient Compression of Large-Scale Diffusion Transformers](https://arxiv.org/abs/2602.17047)
*Chaojie Yang,Tian Li,Yue Zhang,Jun Gao*

Main category: cs.CV

TL;DR: 本文提出了一种高效的压缩框架，将基于MMDiT的Qwen-Image模型压缩为轻量级的Amber-Image系列模型（10B和6B），在显著减少参数量（70%）和训练成本（<2000 GPU小时）的同时，保持了高质量图像生成和文本渲染能力。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformer（DiT）架构虽然推动了文本到图像生成的发展，但其计算成本高昂且部署困难。为了解决这些问题，作者旨在开发一种无需从头训练的高效压缩方法，以降低模型规模和资源消耗。

Method: 首先采用时间步敏感的深度剪枝策略得到Amber-Image-10B，并通过局部权重平均重初始化保留层，再结合逐层蒸馏和全参数微调进行优化。接着，通过引入混合流架构（将深层双流转换为单流并从图像分支初始化），进一步压缩得到Amber-Image-6B，并使用渐进式蒸馏和轻量微调进行精炼。

Result: Amber-Image系列模型在DPG-Bench和LongText-Bench等基准上表现出高保真图像合成和优越的文本渲染能力，性能媲美更大规模模型，同时参数减少70%，整个压缩与训练流程耗时少于2000 GPU小时。

Conclusion: 所提出的压缩框架有效解决了DiT模型的高计算成本和部署难题，在大幅降低模型规模和训练资源需求的同时，保持了优异的生成质量，为高效T2I模型开发提供了可行路径。

Abstract: Diffusion Transformer (DiT) architectures have significantly advanced Text-to-Image (T2I) generation but suffer from prohibitive computational costs and deployment barriers. To address these challenges, we propose an efficient compression framework that transforms the 60-layer dual-stream MMDiT-based Qwen-Image into lightweight models without training from scratch. Leveraging this framework, we introduce Amber-Image, a series of streamlined T2I models. We first derive Amber-Image-10B using a timestep-sensitive depth pruning strategy, where retained layers are reinitialized via local weight averaging and optimized through layer-wise distillation and full-parameter fine-tuning. Building on this, we develop Amber-Image-6B by introducing a hybrid-stream architecture that converts deep-layer dual streams into a single stream initialized from the image branch, further refined via progressive distillation and lightweight fine-tuning. Our approach reduces parameters by 70% and eliminates the need for large-scale data engineering. Notably, the entire compression and training pipeline-from the 10B to the 6B variant-requires fewer than 2,000 GPU hours, demonstrating exceptional cost-efficiency compared to training from scratch. Extensive evaluations on benchmarks like DPG-Bench and LongText-Bench show that Amber-Image achieves high-fidelity synthesis and superior text rendering, matching much larger models.

</details>


### [13] [StructCore: Structure-Aware Image-Level Scoring for Training-Free Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.17048)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: 提出StructCore方法，通过结构感知的图像级评分替代最大池化，在无需训练的情况下显著提升无监督异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 最大池化在基于记忆库的无监督异常检测中仅依赖单一极值响应，忽略了异常证据在图像中的分布与结构信息，导致正常与异常图像得分重叠。

Method: StructCore从异常分数图中提取低维结构描述符phi(S)，捕捉其分布与空间特征，并利用来自正常训练样本的对角马氏距离校准进行图像级评分，不改变像素级定位。

Result: 在MVTec AD和VisA数据集上分别达到99.6%和98.4%的图像级AUROC，显著优于传统最大池化方法。

Conclusion: StructCore通过挖掘最大池化忽略的结构特征，实现了更鲁棒且高效的图像级异常检测，且无需额外训练。

Abstract: Max pooling is the de facto standard for converting anomaly score maps into image-level decisions in memory-bank-based unsupervised anomaly detection (UAD). However, because it relies on a single extreme response, it discards most information about how anomaly evidence is distributed and structured across the image, often causing normal and anomalous scores to overlap.
  We propose StructCore, a training-free, structure-aware image-level scoring method that goes beyond max pooling. Given an anomaly score map, StructCore computes a low-dimensional structural descriptor phi(S) that captures distributional and spatial characteristics, and refines image-level scoring via a diagonal Mahalanobis calibration estimated from train-good samples, without modifying pixel-level localization.
  StructCore achieves image-level AUROC scores of 99.6% on MVTec AD and 98.4% on VisA, demonstrating robust image-level anomaly detection by exploiting structural signatures missed by max pooling.

</details>


### [14] [Cholec80-port: A Geometrically Consistent Trocar Port Segmentation Dataset for Robust Surgical Scene Understanding](https://arxiv.org/abs/2602.17060)
*Shunsuke Kikuchi,Atsushi Kouno,Hiroki Matsuzaki*

Main category: cs.CV

TL;DR: 本文提出了一个高质量的腹腔镜Trocar穿刺孔分割数据集Cholec80-port，并制定了统一的标注标准，强调在标注时排除中心开口区域，以提升几何一致性，从而显著增强下游视觉任务（如图像拼接、3D重建和SLAM）的跨数据集鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Trocar穿刺孔因其固定位置、高光纹理表面以及对视野的持续遮挡，严重影响基于几何的视觉任务性能；然而现有公开数据集中缺乏明确且几何一致的穿刺孔标注，尤其常错误地将可见解剖结构的中心开口区域也进行掩码处理。

Method: 作者基于Cholec80数据集构建了Cholec80-port分割数据集，并制定了一套标准操作流程（SOP），规定仅标注穿刺孔套管部分而排除中心开口；同时，依据该SOP清洗并统一了多个现有公开数据集的标注。

Result: 实验表明，采用几何一致的标注方式能显著提升模型在不同数据集间的泛化能力，其效果优于单纯增加数据量。

Conclusion: 几何一致的Trocar穿刺孔标注对于提升手术视觉系统中几何相关任务的稳定性与鲁棒性至关重要，所提出的Cholec80-port及SOP为未来研究提供了可靠基准。

Abstract: Trocar ports are camera-fixed, pseudo-static structures that can persistently occlude laparoscopic views and attract disproportionate feature points due to specular, textured surfaces. This makes ports particularly detrimental to geometry-based downstream pipelines such as image stitching, 3D reconstruction, and visual SLAM, where dynamic or non-anatomical outliers degrade alignment and tracking stability. Despite this practical importance, explicit port labels are rare in public surgical datasets, and existing annotations often violate geometric consistency by masking the central lumen (opening), even when anatomical regions are visible through it. We present Cholec80-port, a high-fidelity trocar port segmentation dataset derived from Cholec80, together with a rigorous standard operating procedure (SOP) that defines a port-sleeve mask excluding the central opening. We additionally cleanse and unify existing public datasets under the same SOP. Experiments demonstrate that geometrically consistent annotations substantially improve cross-dataset robustness beyond what dataset size alone provides.

</details>


### [15] [Cross Pseudo Labeling For Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2602.17077)
*Lee Dayeon,Kim Dongheyong,Park Chaewon,Woo Sungmin,Lee Sangyoun*

Main category: cs.CV

TL;DR: 本文提出CPL-VAD，一种双分支弱监督视频异常检测框架，通过交叉伪标签机制在片段级异常定位与异常类别识别之间实现互补，取得当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 弱监督视频异常检测仅使用视频级标签，难以同时实现精确的异常定位和准确的异常类别识别。现有方法往往在时序精度或语义判别能力上存在不足。

Method: CPL-VAD包含两个分支：二元异常检测分支用于片段级异常定位，类别分类分支利用视觉-语言对齐识别异常事件类别。两个分支通过交换伪标签相互增强。

Result: 在XD-Violence和UCF-Crime数据集上的实验表明，CPL-VAD在异常检测和异常类别分类两项任务上均达到最先进的性能。

Conclusion: 通过交叉伪标签机制融合时序定位与语义分类的优势，CPL-VAD有效提升了弱监督视频异常检测的整体性能。

Abstract: Weakly supervised video anomaly detection aims to detect anomalies and identify abnormal categories with only video-level labels. We propose CPL-VAD, a dual-branch framework with cross pseudo labeling. The binary anomaly detection branch focuses on snippet-level anomaly localization, while the category classification branch leverages vision-language alignment to recognize abnormal event categories. By exchanging pseudo labels, the two branches transfer complementary strengths, combining temporal precision with semantic discrimination. Experiments on XD-Violence and UCF-Crime demonstrate that CPL-VAD achieves state-of-the-art performance in both anomaly detection and abnormal category classification.

</details>


### [16] [ComptonUNet: A Deep Learning Model for GRB Localization with Compton Cameras under Noisy and Low-Statistic Conditions](https://arxiv.org/abs/2602.17085)
*Shogo Sato,Kazuo Tanaka,Shojun Ogasawara,Kazuki Yamamoto,Kazuhiko Murasaki,Ryuichi Tanida,Jun Kataoka*

Main category: cs.CV

TL;DR: 提出ComptonUNet，一种结合原始数据处理与图像重建的混合深度学习框架，用于在低光子统计和强背景噪声条件下更准确地定位微弱伽马暴（GRB）。


<details>
  <summary>Details</summary>
Motivation: 微弱伽马暴（尤其来自遥远宇宙的）对研究早期恒星形成具有重要意义，但其探测与定位因光子统计量低和背景噪声强而极具挑战；现有机器学习方法难以兼顾统计稳健性与噪声抑制。

Method: 设计ComptonUNet，融合直接重建模型的统计效率与基于图像架构的去噪能力，在模拟低地球轨道任务背景中嵌入GRB事件进行训练与评估。

Result: ComptonUNet在多种低统计量、高背景场景下显著优于现有方法，实现了更高的定位精度。

Conclusion: ComptonUNet为微弱伽马暴的稳健定位提供了一种有效解决方案，有望提升高能天体物理观测能力。

Abstract: Gamma-ray bursts (GRBs) are among the most energetic transient phenomena in the universe and serve as powerful probes for high-energy astrophysical processes. In particular, faint GRBs originating from a distant universe may provide unique insights into the early stages of star formation. However, detecting and localizing such weak sources remains challenging owing to low photon statistics and substantial background noise. Although recent machine learning models address individual aspects of these challenges, they often struggle to balance the trade-off between statistical robustness and noise suppression. Consequently, we propose ComptonUNet, a hybrid deep learning framework that jointly processes raw data and reconstructs images for robust GRB localization. ComptonUNet was designed to operate effectively under conditions of limited photon statistics and strong background contamination by combining the statistical efficiency of direct reconstruction models with the denoising capabilities of image-based architectures. We perform realistic simulations of GRB-like events embedded in background environments representative of low-Earth orbit missions to evaluate the performance of ComptonUNet. Our results demonstrate that ComptonUNet significantly outperforms existing approaches, achieving improved localization accuracy across a wide range of low-statistic and high-background scenarios.

</details>


### [17] [3D Scene Rendering with Multimodal Gaussian Splatting](https://arxiv.org/abs/2602.17124)
*Chi-Shiang Gau,Konstantinos D. Polyzos,Athanasios Bacharis,Saketh Madhuvarasu,Tara Javidi*

Main category: cs.CV

TL;DR: 本文提出一种融合射频（RF）感知与3D高斯泼溅（GS）的多模态框架，利用RF信号在恶劣环境下的鲁棒性，提升GS在稀疏或不可靠视觉条件下的重建质量与效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的3D高斯泼溅方法依赖大量相机视角进行初始化和训练，在低光照、恶劣天气或部分遮挡等视觉线索不可靠的场景中表现不佳；而射频信号对这些干扰具有较强鲁棒性，因此作者希望融合RF感知以增强GS的适用性和稳定性。

Method: 提出一种多模态框架，将汽车雷达等RF传感数据与GS渲染结合，从稀疏的RF深度测量中高效预测深度，生成高质量3D点云用于初始化高斯函数，并适配多种GS架构。

Result: 实验表明，引入RF感知可显著提升GS在结构准确性方面的表现，实现高保真度的3D场景渲染，尤其在视觉信息受限的条件下优势明显。

Conclusion: 融合RF与GS的多模态方法为3D场景重建提供了一种更高效、鲁棒的替代方案，拓展了GS在复杂真实环境中的应用潜力。

Abstract: 3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitoring, robotics, and autonomous driving. Recent advances in 3D Gaussian Splatting (GS) and its variants have achieved impressive rendering fidelity while maintaining high computational and memory efficiency. However, conventional vision-based GS pipelines typically rely on a sufficient number of camera views to initialize the Gaussian primitives and train their parameters, typically incurring additional processing cost during initialization while falling short in conditions where visual cues are unreliable, such as adverse weather, low illumination, or partial occlusions. To cope with these challenges, and motivated by the robustness of radio-frequency (RF) signals to weather, lighting, and occlusions, we introduce a multimodal framework that integrates RF sensing, such as automotive radar, with GS-based rendering as a more efficient and robust alternative to vision-only GS rendering. The proposed approach enables efficient depth prediction from only sparse RF-based depth measurements, yielding a high-quality 3D point cloud for initializing Gaussian functions across diverse GS architectures. Numerical tests demonstrate the merits of judiciously incorporating RF sensing into GS pipelines, achieving high-fidelity 3D scene rendering driven by RF-informed structural accuracy.

</details>


### [18] [B$^3$-Seg: Camera-Free, Training-Free 3DGS Segmentation via Analytic EIG and Beta-Bernoulli Bayesian Updates](https://arxiv.org/abs/2602.17134)
*Hiromichi Kamata,Samuel Arthur Munro,Fuminori Homma*

Main category: cs.CV

TL;DR: 提出了一种名为B³-Seg的快速、无需训练且不依赖预设视角的3D高斯泼溅（3DGS）交互式分割方法，通过贝叶斯序贯更新与信息增益引导视图选择，在几秒内实现高质量开放词汇分割。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS分割方法依赖预设视角、真实标签或昂贵重训练，难以满足影视与游戏制作中对低延迟交互编辑的需求。

Method: 将分割问题建模为序贯Beta-Bernoulli贝叶斯更新，并通过解析形式的期望信息增益（EIG）主动选择下一观察视角；利用EIG的自适应单调性与子模性，采用贪心策略逼近最优视角采样策略。

Result: 在多个数据集上，B³-Seg在无需训练和相机视角先验条件下，几秒内完成端到端分割，性能媲美高成本监督方法。

Conclusion: B³-Seg实现了实用、高效且具有理论保障的交互式3DGS分割，显著提升了信息利用效率与实时性。

Abstract: Interactive 3D Gaussian Splatting (3DGS) segmentation is essential for real-time editing of pre-reconstructed assets in film and game production. However, existing methods rely on predefined camera viewpoints, ground-truth labels, or costly retraining, making them impractical for low-latency use. We propose B$^3$-Seg (Beta-Bernoulli Bayesian Segmentation for 3DGS), a fast and theoretically grounded method for open-vocabulary 3DGS segmentation under camera-free and training-free conditions. Our approach reformulates segmentation as sequential Beta-Bernoulli Bayesian updates and actively selects the next view via analytic Expected Information Gain (EIG). This Bayesian formulation guarantees the adaptive monotonicity and submodularity of EIG, which produces a greedy $(1{-}1/e)$ approximation to the optimal view sampling policy. Experiments on multiple datasets show that B$^3$-Seg achieves competitive results to high-cost supervised methods while operating end-to-end segmentation within a few seconds. The results demonstrate that B$^3$-Seg enables practical, interactive 3DGS segmentation with provable information efficiency.

</details>


### [19] [BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning](https://arxiv.org/abs/2602.17168)
*Siyuan Liang,Yongcheng Jing,Yingjie Wang,Jiaxing Huang,Ee-chien Chang,Dacheng Tao*

Main category: cs.CV

TL;DR: BadCLIP++ 是一种针对多模态对比学习模型的后门攻击框架，在仅0.3%投毒率下实现99.99%攻击成功率，兼具高隐蔽性与抗微调持久性。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击方法在多模态对比学习中因跨模态不一致和低投毒率下的梯度稀释问题，难以同时满足隐蔽性和持久性，亟需统一建模与解决。

Method: 提出语义融合QR微触发器与目标对齐子集选择以增强隐蔽性；通过半径收缩、质心对齐、曲率控制和弹性权重固化提升持久性；并给出首个理论分析证明干净微调与后门目标梯度在信任区域内同向。

Result: 在数字攻击中仅0.3%投毒率达99.99% ASR，优于基线11.4点；在19种防御下ASR仍超99.90%，干净准确率下降不足0.8%；物理攻击成功率达65.03%，且对水印移除防御具鲁棒性。

Conclusion: BadCLIP++ 有效解决了多模态后门攻击中的隐蔽性与持久性难题，理论与实验均验证其优越性，为多模态安全研究提供新范式。

Abstract: Research on backdoor attacks against multimodal contrastive learning models faces two key challenges: stealthiness and persistence. Existing methods often fail under strong detection or continuous fine-tuning, largely due to (1) cross-modal inconsistency that exposes trigger patterns and (2) gradient dilution at low poisoning rates that accelerates backdoor forgetting. These coupled causes remain insufficiently modeled and addressed. We propose BadCLIP++, a unified framework that tackles both challenges. For stealthiness, we introduce a semantic-fusion QR micro-trigger that embeds imperceptible patterns near task-relevant regions, preserving clean-data statistics while producing compact trigger distributions. We further apply target-aligned subset selection to strengthen signals at low injection rates. For persistence, we stabilize trigger embeddings via radius shrinkage and centroid alignment, and stabilize model parameters through curvature control and elastic weight consolidation, maintaining solutions within a low-curvature wide basin resistant to fine-tuning. We also provide the first theoretical analysis showing that, within a trust region, gradients from clean fine-tuning and backdoor objectives are co-directional, yielding a non-increasing upper bound on attack success degradation. Experiments demonstrate that with only 0.3% poisoning, BadCLIP++ achieves 99.99% attack success rate (ASR) in digital settings, surpassing baselines by 11.4 points. Across nineteen defenses, ASR remains above 99.90% with less than 0.8% drop in clean accuracy. The method further attains 65.03% success in physical attacks and shows robustness against watermark removal defenses.

</details>


### [20] [NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting](https://arxiv.org/abs/2602.17182)
*Jiwei Shan,Zeyu Cai,Yirui Li,Yongbo Chen,Lijun Han,Yun-hui Liu,Hesheng Wang,Shing Shin Cheng*

Main category: cs.CV

TL;DR: 本文提出NRGS-SLAM，一种基于3D Gaussian Splatting的单目非刚性SLAM系统，用于解决内窥镜场景中因软组织形变导致的相机运动与形变耦合问题，显著提升了位姿估计精度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 内窥镜场景中的软组织持续形变违反了传统V-SLAM的刚性假设，导致相机自运动与内在形变之间存在强耦合模糊性；现有方法缺乏有效的解耦机制且依赖稀疏或低保真度的场景表示，造成跟踪漂移和重建质量受限。

Method: 提出NRGS-SLAM系统：1）引入形变感知的3D高斯地图，为每个高斯图元赋予可学习的形变概率，并通过贝叶斯自监督策略优化；2）设计可变形跟踪模块，优先利用低形变区域进行由粗到精的位姿估计，并逐帧更新形变；3）构建可变形建图模块以平衡表达能力与计算效率；4）采用融合外部几何先验的统一鲁棒几何损失函数缓解单目非刚性SLAM的病态性。

Result: 在多个公开内窥镜数据集上的实验表明，NRGS-SLAM相比现有最先进方法，相机位姿估计误差（RMSE）最多降低50%，并能生成更高质量的照片级真实感重建结果；消融实验验证了各关键设计的有效性。

Conclusion: NRGS-SLAM通过形变感知的3D高斯表示与贝叶斯自监督机制，有效解耦了内窥镜场景中的运动与形变，显著提升了单目非刚性SLAM的精度与重建质量，为内窥镜导航提供了可靠的技术支持。

Abstract: Visual simultaneous localization and mapping (V-SLAM) is a fundamental capability for autonomous perception and navigation. However, endoscopic scenes violate the rigidity assumption due to persistent soft-tissue deformations, creating a strong coupling ambiguity between camera ego-motion and intrinsic deformation. Although recent monocular non-rigid SLAM methods have made notable progress, they often lack effective decoupling mechanisms and rely on sparse or low-fidelity scene representations, which leads to tracking drift and limited reconstruction quality. To address these limitations, we propose NRGS-SLAM, a monocular non-rigid SLAM system for endoscopy based on 3D Gaussian Splatting. To resolve the coupling ambiguity, we introduce a deformation-aware 3D Gaussian map that augments each Gaussian primitive with a learnable deformation probability, optimized via a Bayesian self-supervision strategy without requiring external non-rigidity labels. Building on this representation, we design a deformable tracking module that performs robust coarse-to-fine pose estimation by prioritizing low-deformation regions, followed by efficient per-frame deformation updates. A carefully designed deformable mapping module progressively expands and refines the map, balancing representational capacity and computational efficiency. In addition, a unified robust geometric loss incorporates external geometric priors to mitigate the inherent ill-posedness of monocular non-rigid SLAM. Extensive experiments on multiple public endoscopic datasets demonstrate that NRGS-SLAM achieves more accurate camera pose estimation (up to 50\% reduction in RMSE) and higher-quality photo-realistic reconstructions than state-of-the-art methods. Comprehensive ablation studies further validate the effectiveness of our key design choices. Source code will be publicly available upon paper acceptance.

</details>


### [21] [Selective Training for Large Vision Language Models via Visual Information Gain](https://arxiv.org/abs/2602.17186)
*Seulbi Lee,Sangheum Hwang*

Main category: cs.CV

TL;DR: 本文提出视觉信息增益（VIG）指标，用于量化视觉输入对语言模型预测的贡献，并基于此设计选择性训练策略，提升模型视觉接地能力并缓解语言偏见。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLMs）常因语言偏见而忽略视觉证据，且缺乏对训练样本或词元层面视觉信息贡献的量化方法。

Method: 引入基于困惑度的VIG指标，衡量视觉输入带来的预测不确定性降低程度，并据此构建VIG引导的选择性训练方案，优先训练高VIG样本和词元。

Result: 该方法在显著减少监督数据的同时，有效提升了模型的视觉接地能力，缓解了语言偏见，性能优于现有方法。

Conclusion: VIG提供了一种细粒度评估和利用视觉信息的新途径，通过聚焦视觉信息丰富的样本和词元，可高效提升LVLM的可靠性与性能。

Abstract: Large Vision Language Models (LVLMs) have achieved remarkable progress, yet they often suffer from language bias, producing answers without relying on visual evidence. While prior work attempts to mitigate this issue through decoding strategies, architectural modifications, or curated instruction data, they typically lack a quantitative measure of how much individual training samples or tokens actually benefit from the image. In this work, we introduce Visual Information Gain (VIG), a perplexity-based metric that measures the reduction in prediction uncertainty provided by visual input. VIG enables fine-grained analysis at both sample and token levels, effectively highlighting visually grounded elements such as colors, spatial relations, and attributes. Leveraging this, we propose a VIG-guided selective training scheme that prioritizes high-VIG samples and tokens. This approach improves visual grounding and mitigates language bias, achieving superior performance with significantly reduced supervision by focusing exclusively on visually informative samples and tokens.

</details>


### [22] [EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models](https://arxiv.org/abs/2602.17196)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Chengmei Yang,Yihang Liu,Longzhen Yang,Yuyin Zhou,Ying Wen,Lianghua He*

Main category: cs.CV

TL;DR: 本文提出EntropyPrune，一种基于矩阵熵的视觉token剪枝方法，通过识别“熵崩溃层”（ECL）实现高效、可解释且跨模型通用的多模态大语言模型推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有视觉token剪枝方法依赖经验选择的静态层，缺乏可解释性与跨模型泛化能力；作者旨在提供一种基于信息理论的自适应剪枝准则。

Method: 引入矩阵熵视角，识别视觉表征信息量骤降的“熵崩溃层”（ECL），据此构建EntropyPrune框架，利用对偶Gram矩阵的谱等价性高效计算token信息价值并剪枝冗余token，无需依赖注意力图。

Result: 在多个多模态基准上，EntropyPrune在准确率和效率上均优于现有方法；在LLaVA-1.5-7B上减少68.2% FLOPs的同时保留96.0%原始性能，并成功泛化至高分辨率与视频模型。

Conclusion: EntropyPrune提供了一种原理清晰、高效且可扩展的多模态大语言模型加速方案，具有强鲁棒性和广泛适用性。

Abstract: Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual tokens per image. Although token pruning has proven effective for accelerating inference, determining when and where to prune remains largely heuristic. Existing approaches typically rely on static, empirically selected layers, which limit interpretability and transferability across models. In this work, we introduce a matrix-entropy perspective and identify an "Entropy Collapse Layer" (ECL), where the information content of visual representations exhibits a sharp and consistent drop, which provides a principled criterion for selecting the pruning stage. Building on this observation, we propose EntropyPrune, a novel matrix-entropy-guided token pruning framework that quantifies the information value of individual visual tokens and prunes redundant ones without relying on attention maps. Moreover, to enable efficient computation, we exploit the spectral equivalence of dual Gram matrices, reducing the complexity of entropy computation and yielding up to a 64x theoretical speedup. Extensive experiments on diverse multimodal benchmarks demonstrate that EntropyPrune consistently outperforms state-of-the-art pruning methods in both accuracy and efficiency. On LLaVA-1.5-7B, our method achieves a 68.2% reduction in FLOPs while preserving 96.0% of the original performance. Furthermore, EntropyPrune generalizes effectively to high-resolution and video-based models, highlighting the strong robustness and scalability in practical MLLM acceleration. The code will be publicly available at https://github.com/YahongWang1/EntropyPrune.

</details>


### [23] [HiMAP: History-aware Map-occupancy Prediction with Fallback](https://arxiv.org/abs/2602.17231)
*Yiming Xu,Yi Yang,Hao Cheng,Monika Sester*

Main category: cs.CV

TL;DR: HiMAP 是一种无需多目标跟踪（MOT）的轨迹预测框架，通过历史占用图和历史查询模块，在不依赖对象身份信息的情况下实现鲁棒的运动预测，在 MOT 失败时仍保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有运动预测方法严重依赖多目标跟踪（MOT）提供的身份关联，但在遮挡、身份切换或漏检等 MOT 失败情况下，预测性能显著下降，带来安全隐患。因此，亟需一种不依赖跟踪身份的可靠预测方法。

Method: HiMAP 将历史检测结果转换为时空不变的历史占用图，并引入历史查询模块，根据当前智能体状态从无标签的占用图中迭代检索其专属历史信息；随后将检索到的历史信息压缩为时间地图嵌入，并与最终查询和地图上下文一起输入 DETR 风格解码器，生成多模态未来轨迹。

Result: 在 Argoverse 2 数据集上，HiMAP 在不使用身份信息的情况下性能媲美基于跟踪的方法；在无跟踪设置下，相较微调后的 QCNet 基线，FDE 提升 11%、ADE 提升 12%、MR 降低 4%。

Conclusion: HiMAP 成功摆脱了对对象身份的依赖，支持流式推理，并在跟踪失效时提供稳定、同步的全智能体预测，具有重要的安全关键型自动驾驶应用价值。

Abstract: Accurate motion forecasting is critical for autonomous driving, yet most predictors rely on multi-object tracking (MOT) with identity association, assuming that objects are correctly and continuously tracked. When tracking fails due to, e.g., occlusion, identity switches, or missed detections, prediction quality degrades and safety risks increase. We present \textbf{HiMAP}, a tracking-free, trajectory prediction framework that remains reliable under MOT failures. HiMAP converts past detections into spatiotemporally invariant historical occupancy maps and introduces a historical query module that conditions on the current agent state to iteratively retrieve agent-specific history from unlabeled occupancy representations. The retrieved history is summarized by a temporal map embedding and, together with the final query and map context, drives a DETR-style decoder to produce multi-modal future trajectories. This design lifts identity reliance, supports streaming inference via reusable encodings, and serves as a robust fallback when tracking is unavailable. On Argoverse~2, HiMAP achieves performance comparable to tracking-based methods while operating without IDs, and it substantially outperforms strong baselines in the no-tracking setting, yielding relative gains of 11\% in FDE, 12\% in ADE, and a 4\% reduction in MR over a fine-tuned QCNet. Beyond aggregate metrics, HiMAP delivers stable forecasts for all agents simultaneously without waiting for tracking to recover, highlighting its practical value for safety-critical autonomy. The code is available under: https://github.com/XuYiMing83/HiMAP.

</details>


### [24] [A Multi-modal Detection System for Infrastructure-based Freight Signal Priority](https://arxiv.org/abs/2602.17252)
*Ziyan Zhang,Chuheng Wei,Xuanpeng Zhao,Siyan Li,Will Snyder,Mike Stas,Peng Hao,Kanok Boriboonsomsin,Guoyuan Wu*

Main category: cs.CV

TL;DR: 本文设计并部署了一种基于基础设施的多模态货运车辆检测系统，融合LiDAR与摄像头传感器，通过混合感知架构和无线通信实现高时空分辨率的实时监测，支持货运信号优先（FSP）应用。


<details>
  <summary>Details</summary>
Motivation: 为支持基础设施驱动的货运信号优先（FSP），需对驶近信号交叉口的货运车辆进行可靠检测与运动估计，准确获取其类型、位置和速度信息。

Method: 采用由路口子系统和路段中点子系统组成的混合传感架构，结合LiDAR与摄像头，通过无线通信同步传输数据；感知流程融合基于聚类与深度学习的检测方法，并使用卡尔曼滤波进行跟踪；LiDAR数据注册至大地坐标系以实现车道级定位。

Result: 实地评估表明，该系统能以高时空分辨率可靠监测货运车辆运动，具备稳定实时性能。

Conclusion: 该系统的设计与部署为开发支持FSP的基础设施感知系统提供了实践参考。

Abstract: Freight vehicles approaching signalized intersections require reliable detection and motion estimation to support infrastructure-based Freight Signal Priority (FSP). Accurate and timely perception of vehicle type, position, and speed is essential for enabling effective priority control strategies. This paper presents the design, deployment, and evaluation of an infrastructure-based multi-modal freight vehicle detection system integrating LiDAR and camera sensors. A hybrid sensing architecture is adopted, consisting of an intersection-mounted subsystem and a midblock subsystem, connected via wireless communication for synchronized data transmission. The perception pipeline incorporates both clustering-based and deep learning-based detection methods with Kalman filter tracking to achieve stable real-time performance. LiDAR measurements are registered into geodetic reference frames to support lane-level localization and consistent vehicle tracking. Field evaluations demonstrate that the system can reliably monitor freight vehicle movements at high spatio-temporal resolution. The design and deployment provide practical insights for developing infrastructure-based sensing systems to support FSP applications.

</details>


### [25] [EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection](https://arxiv.org/abs/2602.17260)
*Hung Mai,Loi Dinh,Duc Hai Nguyen,Dat Do,Luong Doan,Khanh Nguyen Quoc,Huan Vu,Phong Ho,Naeem Ul Islam,Tuan Do*

Main category: cs.CV

TL;DR: 本文提出EA-Swin模型和EA-Video数据集，用于高效检测现代AI生成视频，在多个主流生成器上达到0.97–0.99的准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪造检测方法在面对Sora2、Veo3等先进基础视频生成器时表现不足，因其依赖浅层嵌入轨迹、图像适配或计算开销大的多模态大语言模型（MLLMs），难以有效捕捉复杂时空特征。

Method: 提出EA-Swin，一种嵌入无关的Swin Transformer，通过因子化窗口注意力机制直接在预训练视频嵌入上建模时空依赖关系，兼容通用ViT风格的patch编码器；同时构建包含13万视频的EA-Video基准数据集，涵盖多种商用与开源生成器，并设置未见生成器划分以评估泛化能力。

Result: EA-Swin在主流生成器上取得0.97–0.99的检测准确率，比当前最优方法（通常0.8–0.9）提升5–20%，且在未见分布上保持强泛化能力。

Conclusion: EA-Swin提供了一种可扩展、鲁棒的现代AI生成视频检测方案，结合新构建的EA-Video数据集，为该领域设立了新的基准。

Abstract: Recent advances in foundation video generators such as Sora2, Veo3, and other commercial systems have produced highly realistic synthetic videos, exposing the limitations of existing detection methods that rely on shallow embedding trajectories, image-based adaptation, or computationally heavy MLLMs. We propose EA-Swin, an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via a factorized windowed attention design, making it compatible with generic ViT-style patch-based encoders. Alongside the model, we construct the EA-Video dataset, a benchmark dataset comprising 130K videos that integrates newly collected samples with curated existing datasets, covering diverse commercial and open-source generators and including unseen-generator splits for rigorous cross-distribution evaluation. Extensive experiments show that EA-Swin achieves 0.97-0.99 accuracy across major generators, outperforming prior SoTA methods (typically 0.8-0.9) by a margin of 5-20%, while maintaining strong generalization to unseen distributions, establishing a scalable and robust solution for modern AI-generated video detection.

</details>


### [26] [Attachment Anchors: A Novel Framework for Laparoscopic Grasping Point Prediction in Colorectal Surgery](https://arxiv.org/abs/2602.17310)
*Dennis N. Schneider,Lars Wagner,Daniel Rueckert,Dirk Wilhelm*

Main category: cs.CV

TL;DR: 本文提出“附着锚点”作为结直肠手术中组织抓取点预测的中间表示，通过编码组织与解剖附着点之间的局部几何与力学关系，显著提升了机器学习模型在分布内和分布外场景下的抓取点预测性能。


<details>
  <summary>Details</summary>
Motivation: 结直肠手术复杂且耗时，当前研究对其关注不足，但其重复性组织操作为自主化、机器学习驱动的手术支持提供了理想的学习环境。准确预测抓取点是实现自主组织操作的关键挑战。

Method: 提出“附着锚点”这一结构化表示方法，将手术场景归一化到一致的局部参考系中，并从腹腔镜图像中预测该表示，将其整合进基于机器学习的抓取框架。

Result: 在包含90例结直肠手术的数据集上，使用附着锚点的方法在抓取点预测上优于仅依赖图像的基线方法，尤其在未见过的手术类型和外科医生的操作场景（分布外）中提升显著。

Conclusion: 附着锚点是一种有效的中间表示，有助于提升基于学习的结直肠手术组织操作系统的泛化能力和鲁棒性。

Abstract: Accurate grasping point prediction is a key challenge for autonomous tissue manipulation in minimally invasive surgery, particularly in complex and variable procedures such as colorectal interventions. Due to their complexity and prolonged duration, colorectal procedures have been underrepresented in current research. At the same time, they pose a particularly interesting learning environment due to repetitive tissue manipulation, making them a promising entry point for autonomous, machine learning-driven support. Therefore, in this work, we introduce attachment anchors, a structured representation that encodes the local geometric and mechanical relationships between tissue and its anatomical attachments in colorectal surgery. This representation reduces uncertainty in grasping point prediction by normalizing surgical scenes into a consistent local reference frame. We demonstrate that attachment anchors can be predicted from laparoscopic images and incorporated into a grasping framework based on machine learning. Experiments on a dataset of 90 colorectal surgeries demonstrate that attachment anchors improve grasping point prediction compared to image-only baselines. There are particularly strong gains in out-of-distribution settings, including unseen procedures and operating surgeons. These results suggest that attachment anchors are an effective intermediate representation for learning-based tissue manipulation in colorectal surgery.

</details>


### [27] [Polaffini: A feature-based approach for robust affine and polyaffine image registration](https://arxiv.org/abs/2602.17337)
*Antoine Legouhy,Cosimo Campo,Ross Callaghan,Hojjat Azadbakht,Hui Zhang*

Main category: cs.CV

TL;DR: 本文提出Polaffini，一种基于解剖结构的快速、鲁棒且准确的医学图像配准框架，利用深度学习分割模型提取解剖区域质心作为对应特征点，实现从仿射到多仿射的可调平滑变换，在结构对齐和后续非线性配准初始化方面优于传统强度配准方法。


<details>
  <summary>Details</summary>
Motivation: 传统医学图像配准主要依赖基于强度的方法，而基于解剖特征的方法虽理论上更优，却因特征提取困难而较少使用；随着深度学习预训练分割模型的发展，可靠精细的解剖结构分割成为可能，为构建新的解剖结构引导配准算法提供了契机。

Method: Polaffini利用预训练分割模型获得解剖区域，提取其质心作为具有一一对应关系的特征点，通过闭式解实现高效全局与局部仿射匹配，并组合成从仿射到具有可调平滑性的多仿射变换；该变换嵌入在log-Euclidean框架中以保证微分同胚性质。

Result: 实验表明，Polaffini在结构对齐方面优于主流强度配准方法，并能为后续非线性配准提供更优的初始变换。

Conclusion: Polaffini是一种快速、鲁棒且准确的解剖结构引导配准方法，适用于独立配准或作为非线性配准的预对齐步骤，非常适合集成到医学图像处理流程中。

Abstract: In this work we present Polaffini, a robust and versatile framework for anatomically grounded registration. Medical image registration is dominated by intensity-based registration methods that rely on surrogate measures of alignment quality. In contrast, feature-based approaches that operate by identifying explicit anatomical correspondences, while more desirable in theory, have largely fallen out of favor due to the challenges of reliably extracting features. However, such challenges are now significantly overcome thanks to recent advances in deep learning, which provide pre-trained segmentation models capable of instantly delivering reliable, fine-grained anatomical delineations. We aim to demonstrate that these advances can be leveraged to create new anatomically-grounded image registration algorithms. To this end, we propose Polaffini, which obtains, from these segmented regions, anatomically grounded feature points with 1-to-1 correspondence in a particularly simple way: extracting their centroids. These enable efficient global and local affine matching via closed-form solutions. Those are used to produce an overall transformation ranging from affine to polyaffine with tunable smoothness. Polyaffine transformations can have many more degrees of freedom than affine ones allowing for finer alignment, and their embedding in the log-Euclidean framework ensures diffeomorphic properties. Polaffini has applications both for standalone registration and as pre-alignment for subsequent non-linear registration, and we evaluate it against popular intensity-based registration techniques. Results demonstrate that Polaffini outperforms competing methods in terms of structural alignment and provides improved initialisation for downstream non-linear registration. Polaffini is fast, robust, and accurate, making it particularly well-suited for integration into medical image processing pipelines.

</details>


### [28] [Tree crop mapping of South America reveals links to deforestation and conservation](https://arxiv.org/abs/2602.17372)
*Yuchang Jiang,Anton Raichuk,Xiaoye Tong,Vivien Sainte Fare Garnot,Daniel Ortiz-Gonzalo,Dan Morris,Konrad Schindler,Jan Dirk Wegner,Maxim Neumann*

Main category: cs.CV

TL;DR: 本研究利用多模态时空深度学习模型，基于Sentinel-1和Sentinel-2卫星时序影像，生成了南美洲首张10米分辨率的木本作物地图，揭示现有法规地图常将小农混农林业误判为“森林”，可能导致错误的毁林警报，并为零毁林政策提供更公平有效的数据基础。


<details>
  <summary>Details</summary>
Motivation: 支持如欧盟无毁林产品法规（EUDR）等零毁林政策，需高分辨率数据以准确区分农业系统与森林，但目前缺乏此类数据，尤其难以识别小农混农林业，易导致政策执行偏差。

Method: 采用多模态、时空深度学习模型，结合Sentinel-1（雷达）和Sentinel-2（光学）卫星影像时间序列，生成10米分辨率的南美洲木本作物分布图。

Result: 绘制出约1100万公顷的木本作物区域，其中23%与2000–2020年间的森林覆盖损失相关；发现现有EUDR支持地图常将已建立的农业（尤其是小农混农林业）误分类为“森林”。

Conclusion: 该高分辨率木本作物地图可减少误判风险，为制定更有效、包容和公平的森林保护与零毁林政策提供关键基线数据。

Abstract: Monitoring tree crop expansion is vital for zero-deforestation policies like the European Union's Regulation on Deforestation-free Products (EUDR). However, these efforts are hindered by a lack of highresolution data distinguishing diverse agricultural systems from forests. Here, we present the first 10m-resolution tree crop map for South America, generated using a multi-modal, spatio-temporal deep learning model trained on Sentinel-1 and Sentinel-2 satellite imagery time series. The map identifies approximately 11 million hectares of tree crops, 23% of which is linked to 2000-2020 forest cover loss. Critically, our analysis reveals that existing regulatory maps supporting the EUDR often classify established agriculture, particularly smallholder agroforestry, as "forest". This discrepancy risks false deforestation alerts and unfair penalties for small-scale farmers. Our work mitigates this risk by providing a high-resolution baseline, supporting conservation policies that are effective, inclusive, and equitable.

</details>


### [29] [DRetHTR: Linear-Time Decoder-Only Retentive Network for Handwritten Text Recognition](https://arxiv.org/abs/2602.17387)
*Changhun Kim,Martin Mayr,Thomas Gorges,Fei Wu,Mathias Seuret,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: DRetHTR 是一种基于 RetNet 的解码器-only 手写文本识别模型，相比同等规模的 Transformer，在保持准确率的同时实现 1.6–1.9 倍更快推理速度和 38–42% 更低内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有基于 Transformer 的 HTR 系统因 KV 缓存随输出增长而造成解码慢、内存消耗大，亟需更高效的架构。

Method: 采用无 softmax 的 retention 机制替代注意力，引入多尺度序列先验，并设计逐层 gamma 缩放策略以恢复局部到全局的归纳偏置，从而避免 KV 缓存增长，实现时间和内存线性复杂度的解码。

Result: 在 IAM-A（2.26%）、RIMES（1.81%）和 Bentham（3.46%）上取得当前最优字符错误率，在 READ-2016 上也具竞争力（4.21%）。

Conclusion: DRetHTR 在维持 Transformer 级别准确率的同时显著提升了解码速度与内存效率，验证了 RetNet 架构在 HTR 任务中的优越性。

Abstract: State-of-the-art handwritten text recognition (HTR) systems commonly use Transformers, whose growing key-value (KV) cache makes decoding slow and memory-intensive. We introduce DRetHTR, a decoder-only model built on Retentive Networks (RetNet). Compared to an equally sized decoder-only Transformer baseline, DRetHTR delivers 1.6-1.9x faster inference with 38-42% less memory usage, without loss of accuracy. By replacing softmax attention with softmax-free retention and injecting multi-scale sequential priors, DRetHTR avoids a growing KV cache: decoding is linear in output length in both time and memory. To recover the local-to-global inductive bias of attention, we propose layer-wise gamma scaling, which progressively enlarges the effective retention horizon in deeper layers. This encourages early layers to model short-range dependencies and later layers to capture broader context, mitigating the flexibility gap introduced by removing softmax. Consequently, DRetHTR achieves best reported test character error rates of 2.26% (IAM-A, en), 1.81% (RIMES, fr), and 3.46% (Bentham, en), and is competitive on READ-2016 (de) with 4.21%. This demonstrates that decoder-only RetNet enables Transformer-level HTR accuracy with substantially improved decoding speed and memory efficiency.

</details>


### [30] [SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery](https://arxiv.org/abs/2602.17395)
*Lorenzo Caselli,Marco Mistretta,Simone Magistri,Andrew D. Bagdanov*

Main category: cs.CV

TL;DR: SpectralGCD 是一种高效且有效的多模态方法，用于广义类别发现（GCD），通过利用 CLIP 的跨模态图像-概念相似性作为统一表示，在多个基准上以较低计算成本实现优于或媲美当前最优方法的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有 GCD 方法在仅使用图像特征训练时容易对已知类别过拟合，而现有结合文本信息的多模态方法则存在模态独立处理和计算开销高的问题。

Method: 提出 SpectralGCD，将每张图像表示为大型任务无关语义概念字典上的混合分布，并引入 Spectral Filtering 机制，利用教师模型计算的跨模态协方差矩阵自动筛选相关概念；同时采用前后向知识蒸馏确保学生模型的跨模态表示既语义充分又对齐良好。

Result: 在六个基准数据集上，SpectralGCD 在显著降低计算成本的同时，取得了与当前最优方法相当或更优的准确率。

Conclusion: 通过统一的跨模态表示、语义锚定和高效的蒸馏机制，SpectralGCD 有效提升了 GCD 的性能与效率，为多模态广义类别发现提供了新思路。

Abstract: Generalized Category Discovery (GCD) aims to identify novel categories in unlabeled data while leveraging a small labeled subset of known classes. Training a parametric classifier solely on image features often leads to overfitting to old classes, and recent multimodal approaches improve performance by incorporating textual information. However, they treat modalities independently and incur high computational cost. We propose SpectralGCD, an efficient and effective multimodal approach to GCD that uses CLIP cross-modal image-concept similarities as a unified cross-modal representation. Each image is expressed as a mixture over semantic concepts from a large task-agnostic dictionary, which anchors learning to explicit semantics and reduces reliance on spurious visual cues. To maintain the semantic quality of representations learned by an efficient student, we introduce Spectral Filtering which exploits a cross-modal covariance matrix over the softmaxed similarities measured by a strong teacher model to automatically retain only relevant concepts from the dictionary. Forward and reverse knowledge distillation from the same teacher ensures that the cross-modal representations of the student remain both semantically sufficient and well-aligned. Across six benchmarks, SpectralGCD delivers accuracy comparable to or significantly superior to state-of-the-art methods at a fraction of the computational cost. The code is publicly available at: https://github.com/miccunifi/SpectralGCD.

</details>


### [31] [A High-Level Survey of Optical Remote Sensing](https://arxiv.org/abs/2602.17397)
*Panagiotis Koletsis,Vasilis Efthymiou,Maria Vakalopoulou,Nikos Komodakis,Anastasios Doulamis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 本文综述了基于RGB相机的光学遥感领域的能力、数据集和关键方法，旨在为新进入该领域的研究人员提供全面的指导。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉的发展和无人机的普及，使用RGB相机进行遥感的研究日益增多，但缺乏对这一领域整体视角的综述。

Method: 对现有光学遥感文献进行系统性回顾，涵盖多种任务、方法和数据集，提炼出高层次见解。

Result: 整理并呈现了该领域的核心能力、常用数据集及研究趋势，突出了RGB遥感的独特优势与挑战。

Conclusion: 本综述填补了现有文献中缺乏整体视角的空白，为研究人员提供了入门指南和研究方向聚焦的参考。

Abstract: In recent years, significant advances in computer vision have also propelled progress in remote sensing. Concurrently, the use of drones has expanded, with many organizations incorporating them into their operations. Most drones are equipped by default with RGB cameras, which are both robust and among the easiest sensors to use and interpret. The body of literature on optical remote sensing is vast, encompassing diverse tasks, capabilities, and methodologies. Each task or methodology could warrant a dedicated survey. This work provides a comprehensive overview of the capabilities of the field, while also presenting key information, such as datasets and insights. It aims to serve as a guide for researchers entering the field, offering high-level insights and helping them focus on areas most relevant to their interests. To the best of our knowledge, no existing survey addresses this holistic perspective.

</details>


### [32] [EAGLE: Expert-Augmented Attention Guidance for Tuning-Free Industrial Anomaly Detection in Multimodal Large Language Models](https://arxiv.org/abs/2602.17419)
*Xiaomeng Peng,Xilang Huang,Seon Han Choi*

Main category: cs.CV

TL;DR: 本文提出了一种无需微调的框架EAGLE，通过引入专家模型的输出来引导多模态大语言模型（MLLM）在工业异常检测中同时实现高准确率和可解释性，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前许多深度学习方法在工业异常检测中仅提供二元判断，缺乏语义解释；而现有的多模态大语言模型（MLLM）方法通常需要昂贵的微调，且在检测精度上并未显著优于轻量级专用检测器。

Method: 提出EAGLE框架，一种无需微调的方法，将专家模型的输出作为注意力引导信号，注入到MLLM中，以增强其对异常区域的关注，并生成可解释的异常描述。同时分析了MLLM中间层对异常区域的注意力分布变化。

Result: 在MVTec-AD和VisA数据集上的实验表明，EAGLE在不更新任何参数的情况下，提升了多种MLLM的异常检测性能，效果可与基于微调的方法相媲美。

Conclusion: EAGLE是一种有效且高效的调优-free框架，能够提升MLLM在工业异常检测中的准确性和可解释性，同时揭示了注意力集中于异常区域与检测成功之间的关联。

Abstract: Industrial anomaly detection is important for smart manufacturing, but many deep learning approaches produce only binary decisions and provide limited semantic explanations. Multimodal large language models (MLLMs) can potentially generate fine-grained, language-based analyses, yet existing methods often require costly fine-tuning and do not consistently improve anomaly detection accuracy compared to lightweight specialist detectors. We propose expert-augmented attention guidance for industrial anomaly detection in MLLMs (EAGLE), a tuning-free framework that integrates outputs from expert model to guide MLLMs toward both accurate detection and interpretable anomaly descriptions. We further study how EAGLE affects MLLMs internals by examining the attention distribution of MLLMs to the anomalous image regions in the intermediate layers. We observe that successful anomaly detection is associated with increased attention concentration on anomalous regions, and EAGLE tends to encourage this alignment. Experiments on MVTec-AD and VisA show that EAGLE improves anomaly detection performance across multiple MLLMs without any parameter updates, achieving results comparable to fine-tuning based methods. Code is available at \href{https://github.com/shengtun/Eagle}{https://github.com/shengtun/Eagle}

</details>


### [33] [4D Monocular Surgical Reconstruction under Arbitrary Camera Motions](https://arxiv.org/abs/2602.17473)
*Jiwei Shan,Zeyu Cai,Cheng-Tai Hsieh,Yirui Li,Hao Liu,Lijun Han,Hesheng Wang,Shing Shin Cheng*

Main category: cs.CV

TL;DR: 本文提出Local-EndoGS，一种用于单目内窥镜视频的高质量4D重建框架，能处理任意相机运动和可变形场景，在多个公开数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示或3D高斯泼溅的方法在处理具有大范围相机运动的单目内窥镜序列时受限，因其依赖固定视角、立体深度先验或精确的运动结构初始化，难以适用于真实临床环境。

Method: Local-EndoGS采用渐进式窗口化全局表示，为每个观测窗口分配局部可变形场景模型；通过融合多视角几何、跨窗口信息和单目深度先验的由粗到精策略实现鲁棒初始化；并引入长程2D像素轨迹约束与物理运动先验以提升形变合理性。

Result: 在三个公开可变形内窥镜数据集上的实验表明，Local-EndoGS在外观质量和几何精度方面均优于当前最先进方法，消融研究验证了关键设计的有效性。

Conclusion: Local-EndoGS有效解决了单目内窥镜视频中大相机运动下的4D重建难题，具备良好的临床应用潜力。

Abstract: Reconstructing deformable surgical scenes from endoscopic videos is challenging and clinically important. Recent state-of-the-art methods based on implicit neural representations or 3D Gaussian splatting have made notable progress. However, most are designed for deformable scenes with fixed endoscope viewpoints and rely on stereo depth priors or accurate structure-from-motion for initialization and optimization, limiting their ability to handle monocular sequences with large camera motion in real clinical settings. To address this, we propose Local-EndoGS, a high-quality 4D reconstruction framework for monocular endoscopic sequences with arbitrary camera motion. Local-EndoGS introduces a progressive, window-based global representation that allocates local deformable scene models to each observed window, enabling scalability to long sequences with substantial motion. To overcome unreliable initialization without stereo depth or accurate structure-from-motion, we design a coarse-to-fine strategy integrating multi-view geometry, cross-window information, and monocular depth priors, providing a robust foundation for optimization. We further incorporate long-range 2D pixel trajectory constraints and physical motion priors to improve deformation plausibility. Experiments on three public endoscopic datasets with deformable scenes and varying camera motions show that Local-EndoGS consistently outperforms state-of-the-art methods in appearance quality and geometry. Ablation studies validate the effectiveness of our key designs. Code will be released upon acceptance at: https://github.com/IRMVLab/Local-EndoGS.

</details>


### [34] [QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery](https://arxiv.org/abs/2602.17478)
*Xuan-Bac Nguyen,Hoang-Quan Nguyen,Sankalp Pandey,Tim Faltermeier,Nicholas Borys,Hugh Churchill,Khoa Luu*

Main category: cs.CV

TL;DR: 本文提出了一种物理感知的多模态框架，用于从光学显微图像中表征二维量子材料，包括合成数据生成器Synthia、首个量子材料指令数据集QMat-Instruct、物理感知指令微调方法QuPAINT，以及综合评测基准QF-Bench。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型在二维量子材料表征任务中表现不佳，因其缺乏物理先验知识，难以泛化到新材料或不同成像条件下；同时，真实标注数据稀缺且跨实验室差异大。

Method: 1）开发基于物理的合成数据生成器Synthia，模拟薄膜干涉下的量子材料光学响应；2）构建多模态、物理引导的指令数据集QMat-Instruct；3）提出QuPAINT架构，通过物理感知注意力机制融合视觉特征与光学先验；4）建立涵盖多种材料、衬底和成像条件的评测基准QF-Bench。

Result: 所提方法显著提升了模型对量子材料层数和形貌的理解能力，在跨材料和跨设备设置下展现出更强的泛化性和鲁棒性，并通过QF-Bench实现了标准化评估。

Conclusion: 将物理先验融入多模态大模型可有效解决量子材料光学图像分析中的数据稀缺与泛化难题，为材料科学与人工智能的交叉研究提供了新范式。

Abstract: Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since they lack physical priors and cannot generalize to new materials or hardware conditions. This work presents a new physics-aware multimodal framework that addresses these limitations from both the data and model perspectives. We first present Synthia, a physics-based synthetic data generator that simulates realistic optical responses of quantum material flakes under thin-film interference. Synthia produces diverse and high-quality samples, helping reduce the dependence on expert manual annotation. We introduce QMat-Instruct, the first large-scale instruction dataset for quantum materials, comprising multimodal, physics-informed question-answer pairs designed to teach Multimodal Large Language Models (MLLMs) to understand the appearance and thickness of flakes. Then, we propose Physics-Aware Instruction Tuning (QuPAINT), a multimodal architecture that incorporates a Physics-Informed Attention module to fuse visual embeddings with optical priors, enabling more robust and discriminative flake representations. Finally, we establish QF-Bench, a comprehensive benchmark spanning multiple materials, substrates, and imaging settings, offering standardized protocols for fair and reproducible evaluation.

</details>


### [35] [Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection](https://arxiv.org/abs/2602.17484)
*Yichen Lu,Siwei Nie,Minlong Lu,Xudong Yang,Xiaobo Zhang,Peng Zhang*

Main category: cs.CV

TL;DR: 本文提出PixTrace和CopyNCE，通过像素级几何追踪提升图像复制检测的细粒度对应学习，在DISC21数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于自监督学习的图像复制检测方法在复杂编辑场景下因缺乏细粒度对应关系建模而表现不佳。

Method: 提出PixTrace模块追踪像素坐标变化，并设计CopyNCE损失函数，利用几何映射的重叠比引导patch级别的对比学习。

Result: 在DISC21数据集上取得88.7% uAP / 83.9% RP90（matcher）和72.6% uAP / 68.4% RP90（descriptor）的性能，优于现有方法。

Conclusion: 所提方法有效结合像素级可追踪性与patch级相似性学习，提升了图像复制检测的准确性和可解释性。

Abstract: Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insufficient fine-grained correspondence learning. We address this limitation by exploiting the inherent geometric traceability in edited content through two key innovations. First, we propose PixTrace - a pixel coordinate tracking module that maintains explicit spatial mappings across editing transformations. Second, we introduce CopyNCE, a geometrically-guided contrastive loss that regularizes patch affinity using overlap ratios derived from PixTrace's verified mappings. Our method bridges pixel-level traceability with patch-level similarity learning, suppressing supervision noise in SSL training. Extensive experiments demonstrate not only state-of-the-art performance (88.7% uAP / 83.9% RP90 for matcher, 72.6% uAP / 68.4% RP90 for descriptor on DISC21 dataset) but also better interpretability over existing methods.

</details>


### [36] [FoundationPose-Initialized 3D-2D Liver Registration for Surgical Augmented Reality](https://arxiv.org/abs/2602.17517)
*Hanyuan Zhang,Lucas He,Runlong He,Abdolrahim Kadkhodamohammadi,Danail Stoyanov,Brian R. Davidson,Evangelos B. Mazomenos,Matthew J. Clarkson*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Augmented reality can improve tumor localization in laparoscopic liver surgery. Existing registration pipelines typically depend on organ contours; deformable (non-rigid) alignment is often handled with finite-element (FE) models coupled to dimensionality-reduction or machine-learning components. We integrate laparoscopic depth maps with a foundation pose estimator for camera-liver pose estimation and replace FE-based deformation with non-rigid iterative closest point (NICP) to lower engineering/modeling complexity and expertise requirements. On real patient data, the depth-augmented foundation pose approach achieved 9.91 mm mean registration error in 3 cases. Combined rigid-NICP registration outperformed rigid-only registration, demonstrating NICP as an efficient substitute for finite-element deformable models. This pipeline achieves clinically relevant accuracy while offering a lightweight, engineering-friendly alternative to FE-based deformation.

</details>


### [37] [LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs](https://arxiv.org/abs/2602.17535)
*Behzad Bozorgtabar,Dwarikanath Mahapatra,Sudipta Roy,Muzammal Naseer,Imran Razzak,Zongyuan Ge*

Main category: cs.CV

TL;DR: 本文提出LATA方法，在不更新模型、无需标签的前提下，通过在图像-图像k近邻图上平滑零样本概率，提升医学视觉语言模型在分布偏移下的不确定性校准效果，显著减小预测集大小和类间覆盖率差距，同时保持有限样本覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在分布偏移下可靠性依赖于具有理论保证的不确定性校准。现有分割保形预测（SCP）方法虽具有限样本覆盖保证，但预测集过大、类间覆盖率不平衡，且直接利用校准标签会破坏可交换性，导致理论保证失效。

Method: 提出LATA（Laplacian-Assisted Transductive Adaptation）方法：1）在联合校准与测试样本池上构建k-NN图，通过少量CCCP均值场更新对零样本概率进行平滑；2）引入失败感知的保形分数，结合ViLU框架提供实例难度与标签合理性信息；3）整个过程为确定性变换，不破坏SCP的可交换性假设。

Result: 在3个医学VLM和9个下游任务上，LATA一致降低预测集大小和类条件覆盖率差距（CCV），同时匹配或更紧地达到目标覆盖率，优于现有转导基线方法，接近使用标签的方法性能，但计算开销显著更低。

Conclusion: LATA是一种黑盒、轻量、无需训练和标签的后处理方法，能有效提升医学VLM在分布偏移下的预测效率与类间平衡性，同时严格保持保形预测的理论保证。

Abstract: Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \texttt{\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \texttt{\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \textbf{three} medical VLMs and \textbf{nine} downstream tasks, \texttt{\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \texttt{\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.

</details>


### [38] [GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking](https://arxiv.org/abs/2602.17555)
*Zixu Cheng,Da Li,Jian Hu,Ziquan Liu,Wei Li,Shaogang Gong*

Main category: cs.CV

TL;DR: 本文提出GraphThinker，通过构建事件级场景图并结合强化微调与视觉注意力奖励机制，显式建模视频中事件的因果关系，从而减少多模态大语言模型在视频推理中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于密集字幕或视频摘要的多模态大语言模型缺乏对视频事件间因果关系的显式建模，导致在视频推理过程中容易产生幻觉。

Method: 提出GraphThinker方法：首先利用多模态大语言模型构建事件级视频场景图（EVSG），显式表示事件内部及事件间的因果关系，并将其作为中间推理过程；同时在强化微调中引入视觉注意力奖励以增强视觉定位能力。

Result: 在RexTime和VidHalluc两个数据集上的实验表明，GraphThinker在捕捉对象与事件关系、精确定位事件方面表现更优，显著减少了视频推理中的幻觉现象。

Conclusion: 通过结构化建模事件因果关系并强化视觉接地，GraphThinker有效提升了视频推理的准确性和可靠性，为减少多模态模型幻觉提供了新思路。

Abstract: Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or video summaries for video reasoning, such modeling still lacks causal understanding. Without explicit causal structure modeling within and across video events, these models suffer from hallucinations during the video reasoning. In this work, we propose GraphThinker, a reinforcement finetuning-based method that constructs structural event-level scene graphs and enhances visual grounding to jointly reduce hallucinations in video reasoning. Specifically, we first employ an MLLM to construct an event-based video scene graph (EVSG) that explicitly models both intra- and inter-event relations, and incorporate these formed scene graphs into the MLLM as an intermediate thinking process. We also introduce a visual attention reward during reinforcement finetuning, which strengthens video grounding and further mitigates hallucinations. We evaluate GraphThinker on two datasets, RexTime and VidHalluc, where it shows superior ability to capture object and event relations with more precise event localization, reducing hallucinations in video reasoning compared to prior methods.

</details>


### [39] [Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment](https://arxiv.org/abs/2602.17599)
*Ivan Rinaldi,Matteo Mendula,Nicola Fanelli,Florence Levé,Matteo Testi,Giovanna Castellano,Gennaro Vessio*

Main category: cs.CV

TL;DR: 本文提出ArtToMus框架和ArtSound数据集，首次实现直接从艺术作品生成音乐，无需依赖图像到文本的中间转换。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像生成音乐的方法主要使用自然照片训练，且依赖图像到文本的语义简化，难以捕捉艺术作品丰富的语义、风格与文化内涵，限制了视觉到音频的直接学习。

Method: 构建包含105,884对艺术作品-音乐样本的ArtSound数据集，并提出ArtToMus框架，将视觉嵌入直接映射到潜在扩散模型的条件空间，实现无语言中介的视觉引导音乐生成。

Result: ArtToMus能生成音乐连贯、风格一致且反映原画作视觉特征的音频；尽管跨模态对齐得分低于文本条件模型，但感知质量和跨模态关联性具有竞争力。

Conclusion: 本研究确立了直接视觉到音乐生成作为一项新颖且具挑战性的研究方向，并为多媒体艺术、文化遗产和AI辅助创作提供了新资源与方法。

Abstract: Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural photographs, limiting their ability to capture the richer semantic, stylistic, and cultural content of artworks; and (ii) most rely on an image-to-text conversion stage, using language as a semantic shortcut that simplifies conditioning but prevents direct visual-to-audio learning. Motivated by these gaps, we introduce ArtSound, a large-scale multimodal dataset of 105,884 artwork-music pairs enriched with dual-modality captions, obtained by extending ArtGraph and the Free Music Archive. We further propose ArtToMus, the first framework explicitly designed for direct artwork-to-music generation, which maps digitized artworks to music without image-to-text translation or language-based semantic supervision. The framework projects visual embeddings into the conditioning space of a latent diffusion model, enabling music synthesis guided solely by visual information. Experimental results show that ArtToMus generates musically coherent and stylistically consistent outputs that reflect salient visual cues of the source artworks. While absolute alignment scores remain lower than those of text-conditioned systems-as expected given the substantially increased difficulty of removing linguistic supervision-ArtToMus achieves competitive perceptual quality and meaningful cross-modal correspondence. This work establishes direct visual-to-music generation as a distinct and challenging research direction, and provides resources that support applications in multimedia art, cultural heritage, and AI-assisted creative practice. Code and dataset will be publicly released upon acceptance.

</details>


### [40] [Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery](https://arxiv.org/abs/2602.17605)
*Jowaria Khan,Anindya Sarkar,Yevgeniy Vorobeychik,Elizabeth Bondi-Kelly*

Main category: cs.CV

TL;DR: 本文提出一个结合主动学习、在线元学习和概念引导推理的统一地理空间发现框架，通过引入“概念相关性”来指导采样与元学习过程，在数据稀疏且环境动态变化的条件下高效发现目标。


<details>
  <summary>Details</summary>
Motivation: 在环境监测、灾难响应和公共卫生等现实场景中，数据采集成本高、环境动态变化，且真实标签稀疏且存在偏差，导致现有基于学习的方法（如强化学习）难以有效应用。因此，需要一种能在有限资源下高效探索未观测区域并发现隐藏目标的新方法。

Method: 提出一个统一框架，包含两个基于“概念相关性”的创新：一是概念加权的不确定性采样策略，利用领域概念（如土地覆盖、污染源距离）调节采样不确定性；二是相关性感知的元批次构建策略，在在线元学习中促进语义多样性，提升模型在动态环境中的泛化能力。

Result: 在真实世界的PFAS（致癌污染物）污染数据集上进行实验，结果表明该方法在数据有限且环境变化的情况下，能可靠地发现目标。

Conclusion: 所提出的框架通过融合领域知识与学习机制，有效应对了稀疏标注和动态环境带来的挑战，为地理空间目标发现提供了一种高效且实用的解决方案。

Abstract: In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constraints. Yet, sparse and biased geospatial ground truth limits the applicability of existing learning-based methods, such as reinforcement learning. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning. Our approach introduces two key innovations built on a shared notion of *concept relevance*, which captures how domain-specific factors influence target presence: a *concept-weighted uncertainty sampling strategy*, where uncertainty is modulated by learned relevance based on readily-available domain-specific concepts (e.g., land cover, source proximity); and a *relevance-aware meta-batch formation strategy* that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include testing on a real-world dataset of cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination, showcasing our method's reliability at uncovering targets with limited data and a varying environment.

</details>


### [41] [CORAL: Correspondence Alignment for Improved Virtual Try-On](https://arxiv.org/abs/2602.17636)
*Jiyoung Kim,Youngjin Shin,Siyoon Jin,Dahyun Chung,Jisu Nam,Tongmin Kim,Jongjae Park,Hyeonwoo Kang,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出CORAL，一种基于DiT的虚拟试穿框架，通过显式对齐查询-键匹配与外部对应关系，提升服装细节保留和整体形状迁移效果。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法在无配对设置下难以保留精细服装细节，且未明确建模人-服装对齐，也缺乏对DiT中对应关系形成机制的解释。

Method: 分析DiT中全3D注意力机制，发现人-服装对应依赖于精确的查询-键匹配；据此提出CORAL框架，包含对应蒸馏损失和注意力熵最小化损失，并引入基于视觉语言模型的评估协议。

Result: CORAL在全局形状迁移和局部细节保留方面均优于基线方法，消融实验验证了各组件的有效性。

Conclusion: 显式对齐人-服装查询-键匹配与外部对应关系能有效提升DiT在虚拟试穿任务中的性能，所提评估协议更贴合人类偏好。

Abstract: Existing methods for Virtual Try-On (VTON) often struggle to preserve fine garment details, especially in unpaired settings where accurate person-garment correspondence is required. These methods do not explicitly enforce person-garment alignment and fail to explain how correspondence emerges within Diffusion Transformers (DiTs). In this paper, we first analyze full 3D attention in DiT-based architecture and reveal that the person-garment correspondence critically depends on precise person-garment query-key matching within the full 3D attention. Building on this insight, we then introduce CORrespondence ALignment (CORAL), a DiT-based framework that explicitly aligns query-key matching with robust external correspondences. CORAL integrates two complementary components: a correspondence distillation loss that aligns reliable matches with person-garment attention, and an entropy minimization loss that sharpens the attention distribution. We further propose a VLM-based evaluation protocol to better reflect human preference. CORAL consistently improves over the baseline, enhancing both global shape transfer and local detail preservation. Extensive ablations validate our design choices.

</details>


### [42] [IntRec: Intent-based Retrieval with Contrastive Refinement](https://arxiv.org/abs/2602.17639)
*Pourya Shamsolmoali,Masoumeh Zareapoor,Eric Granger,Yue Lu*

Main category: cs.CV

TL;DR: 本文提出IntRec，一种交互式目标检索框架，通过用户反馈动态优化检索结果，在LVIS和LVIS-Ambiguous数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇检测器采用一次性预测方式，无法根据用户反馈细化结果，尤其在查询模糊或多目标相似的复杂场景中表现不佳。

Method: 引入意图状态（Intent State, IS）机制，维护正向锚点（确认线索）和负向约束（拒绝假设）两组记忆，并通过对比对齐函数对候选目标进行排序，最大化与正向线索的相似性并惩罚被拒假设。

Result: 在LVIS上达到35.4 AP，优于OVMR、CoDet和CAKE；在LVIS-Ambiguous上，仅一次反馈即提升+7.9 AP，每次交互增加延迟不足30毫秒。

Conclusion: IntRec通过轻量级交互机制显著提升复杂场景下的目标检索精度，无需额外监督，具备高效性和实用性。

Abstract: Retrieving user-specified objects from complex scenes remains a challenging task, especially when queries are ambiguous or involve multiple similar objects. Existing open-vocabulary detectors operate in a one-shot manner, lacking the ability to refine predictions based on user feedback. To address this, we propose IntRec, an interactive object retrieval framework that refines predictions based on user feedback. At its core is an Intent State (IS) that maintains dual memory sets for positive anchors (confirmed cues) and negative constraints (rejected hypotheses). A contrastive alignment function ranks candidate objects by maximizing similarity to positive cues while penalizing rejected ones, enabling fine-grained disambiguation in cluttered scenes. Our interactive framework provides substantial improvements in retrieval accuracy without additional supervision. On LVIS, IntRec achieves 35.4 AP, outperforming OVMR, CoDet, and CAKE by +2.3, +3.7, and +0.5, respectively. On the challenging LVIS-Ambiguous benchmark, it improves performance by +7.9 AP over its one-shot baseline after a single corrective feedback, with less than 30 ms of added latency per interaction.

</details>


### [43] [When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs](https://arxiv.org/abs/2602.17659)
*Yu Fang,Yuchun Feng,Dong Jing,Jiaqi Liu,Yue Yang,Zhenyu Wei,Daniel Szafir,Mingyu Ding*

Main category: cs.CV

TL;DR: 本文提出了一种名为Counterfactual Action Guidance（CAG）的新方法，用于提升视觉-语言-动作模型（VLAs）在遵循语言指令方面的鲁棒性，通过引入一个无语言条件的视觉-动作模块进行反事实对比，有效缓解了因数据集偏差导致的视觉捷径问题，并在新构建的LIBERO-CF基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型（VLAs）在缺乏强场景监督的语言指令下容易产生反事实失败（counterfactual failures），即依赖训练数据中的视觉捷径而忽略语言意图。为系统研究此问题，作者构建了首个针对VLAs的反事实基准LIBERO-CF，并提出无需额外训练或架构修改的推理阶段解决方案。

Method: 提出Counterfactual Action Guidance（CAG）方法，采用双分支推理结构：一个标准VLA策略分支和一个无语言条件的视觉-动作（VA）分支，在动作选择时进行反事实对比，从而显式地正则化语言条件，减少对视觉捷径的依赖。

Result: 在LIBERO-CF基准上，CAG在不修改模型或增加训练数据的情况下，将语言遵循准确率（π₀.₅）提升9.7%，任务成功率提升3.6%；若结合VA模型，进一步提升至15.5%和8.5%。真实机器人实验中，CAG平均减少9.4%的反事实失败，任务成功率提升17.2%。

Conclusion: CAG是一种即插即用、训练无关的有效方法，显著提升了现有VLA模型在语言指令遵循方面的鲁棒性和泛化能力，尤其在未充分观察的任务上表现突出，为解决VLA中的反事实失败问题提供了实用方案。

Abstract: Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they act based on vision shortcuts induced by dataset biases, repeatedly executing well-learned behaviors and selecting objects frequently seen during training regardless of language intent. To systematically study it, we introduce LIBERO-CF, the first counterfactual benchmark for VLAs that evaluates language following capability by assigning alternative instructions under visually plausible LIBERO layouts. Our evaluation reveals that counterfactual failures are prevalent yet underexplored across state-of-the-art VLAs. We propose Counterfactual Action Guidance (CAG), a simple yet effective dual-branch inference scheme that explicitly regularizes language conditioning in VLAs. CAG combines a standard VLA policy with a language-unconditioned Vision-Action (VA) module, enabling counterfactual comparison during action selection. This design reduces reliance on visual shortcuts, improves robustness on under-observed tasks, and requires neither additional demonstrations nor modifications to existing architectures or pretrained models. Extensive experiments demonstrate its plug-and-play integration across diverse VLAs and consistent improvements. For example, on LIBERO-CF, CAG improves $π_{0.5}$ by 9.7% in language following accuracy and 3.6% in task success on under-observed tasks using a training-free strategy, with further gains of 15.5% and 8.5%, respectively, when paired with a VA model. In real-world evaluations, CAG reduces counterfactual failures of 9.4% and improves task success by 17.2% on average.

</details>


### [44] [OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents](https://arxiv.org/abs/2602.17665)
*Akashah Shabbir,Muhammad Umer Sheikh,Muhammad Akhtar Munir,Hiyam Debary,Mustansar Fiaz,Muhammad Zaigham Zaheer,Paolo Fraccaro,Fahad Shahbaz Khan,Muhammad Haris Khan,Xiao Xiang Zhu,Salman Khan*

Main category: cs.CV

TL;DR: OpenEarthAgent 是一个面向遥感领域的多模态推理框架，通过工具增强和结构化推理轨迹训练，提升模型在地理空间分析中的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有通用多模态推理模型难以有效处理遥感图像中涉及的空间尺度、地理结构和多光谱指数等复杂因素，缺乏在遥感领域进行连贯多步逻辑推理的能力。

Method: 提出 OpenEarthAgent 框架，利用包含卫星图像、自然语言查询和详细推理轨迹的数据集，通过监督微调训练工具增强的地理空间智能体；训练数据涵盖城市、环境、灾害和基础设施等多个领域，并整合 GIS 操作与 NDVI、NBR、NDBI 等指数分析。

Result: 在包含 14,538 个训练样本和 1,169 个评估样本的数据集上，模型展现出稳定的多步推理能力、空间理解能力和可解释性，在多个任务上优于强基线模型，并与当前开源及闭源模型性能相当。

Conclusion: OpenEarthAgent 为遥感领域的多模态智能体提供了有效解决方案，其基于显式推理轨迹的训练方法显著提升了模型在复杂地理空间任务中的结构化推理与工具使用能力。

Abstract: Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geographic structures, and multispectral indices while maintaining coherent multi-step logic. To bridge this gap, OpenEarthAgent introduces a unified framework for developing tool-augmented geospatial agents trained on satellite imagery, natural-language queries, and detailed reasoning traces. The training pipeline relies on supervised fine-tuning over structured reasoning trajectories, aligning the model with verified multistep tool interactions across diverse analytical contexts. The accompanying corpus comprises 14,538 training and 1,169 evaluation instances, with more than 100K reasoning steps in the training split and over 7K reasoning steps in the evaluation split. It spans urban, environmental, disaster, and infrastructure domains, and incorporates GIS-based operations alongside index analyses such as NDVI, NBR, and NDBI. Grounded in explicit reasoning traces, the learned agent demonstrates structured reasoning, stable spatial understanding, and interpretable behaviour through tool-driven geospatial interactions across diverse conditions. We report consistent improvements over a strong baseline and competitive performance relative to recent open and closed-source models.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [45] [Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance](https://arxiv.org/abs/2602.16738)
*Rebin Saleh,Khanh Pham Dinh,Balázs Villányi,Truong-Son Hy*

Main category: cs.MA

TL;DR: 本文提出SEMAS，一种自演化的分层多智能体系统，用于工业物联网预测性维护，在边缘、雾和云三层部署专用智能体，兼顾实时性、可解释性与资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有静态模型无法适应动态工况，而基于大语言模型的单体系统计算开销过大，难以在边缘设备部署；因此需要一种既能实时检测异常又具备可解释性和低资源消耗的解决方案。

Method: SEMAS采用三层架构：边缘层进行轻量特征提取，雾层执行多样化的集成检测与动态共识投票，云层通过PPO算法持续优化策略，并结合LLM生成可解释响应及联邦知识聚合实现策略自演化。

Result: 在锅炉模拟器和风力涡轮机两个工业数据集上，SEMAS展现出优越的异常检测性能、在动态环境下的稳定性、持续的准确率以及显著降低的延迟，消融实验验证了各组件的有效性。

Conclusion: 资源感知的自演化多智能体协同机制是实现满足低延迟与高可解释性要求的工业物联网预测性维护系统的关键。

Abstract: Industrial IoT predictive maintenance requires systems capable of real-time anomaly detection without sacrificing interpretability or demanding excessive computational resources. Traditional approaches rely on static, offline-trained models that cannot adapt to evolving operational conditions, while LLM-based monolithic systems demand prohibitive memory and latency, rendering them impractical for on-site edge deployment. We introduce SEMAS, a self-evolving hierarchical multi-agent system that distributes specialized agents across Edge, Fog, and Cloud computational tiers. Edge agents perform lightweight feature extraction and pre-filtering; Fog agents execute diversified ensemble detection with dynamic consensus voting; and Cloud agents continuously optimize system policies via Proximal Policy Optimization (PPO) while maintaining asynchronous, non-blocking inference. The framework incorporates LLM-based response generation for explainability and federated knowledge aggregation for adaptive policy distribution. This architecture enables resource-aware specialization without sacrificing real-time performance or model interpretability. Empirical evaluation on two industrial benchmarks (Boiler Emulator and Wind Turbine) demonstrates that SEMAS achieves superior anomaly detection performance with exceptional stability under adaptation, sustains prediction accuracy across evolving operational contexts, and delivers substantial latency improvements enabling genuine real-time deployment. Ablation studies confirm that PPO-driven policy evolution, consensus voting, and federated aggregation each contribute materially to system effectiveness. These findings indicate that resource-aware, self-evolving 1multi-agent coordination is essential for production-ready industrial IoT predictive maintenance under strict latency and explainability constraints.

</details>


### [46] [AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence](https://arxiv.org/abs/2602.16873)
*Geunbin Yu*

Main category: cs.MA

TL;DR: 当大语言模型性能趋同时，任务自适应的多智能体编排拓扑结构比单模型选择更能提升系统性能；提出的AdaptOrch框架通过动态选择并行、串行、分层或混合拓扑，在多个任务上实现12–23%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着不同提供商的大语言模型在基准测试中表现趋同，仅靠挑选单一最优模型对任务性能提升有限，因此需转向优化多模型协同的编排结构以获得更大收益。

Method: 提出AdaptOrch框架，包含：(1) 性能收敛缩放定律，界定编排优于模型选择的条件；(2) 拓扑路由算法，将任务依赖图映射至最优编排模式（时间复杂度O(|V|+|E|)）；(3) 自适应合成协议，确保并行输出的一致性与终止性。

Result: 在SWE-bench（编码）、GPQA（推理）和检索增强生成任务上验证，AdaptOrch相比静态单拓扑基线提升12–23%，即使使用相同底层模型。

Conclusion: 编排设计应被视为独立于模型规模扩展的一等优化目标，其结构选择对系统级性能起主导作用。

Abstract: As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dynamically selects among four canonical topologies (parallel, sequential, hierarchical, and hybrid) based on task dependency graphs and empirically derived domain characteristics. Our framework introduces three key contributions: (1) a Performance Convergence Scaling Law, formalizing conditions under which orchestration selection outweighs model selection; (2) a Topology Routing Algorithm that maps task decomposition DAGs to optimal orchestration patterns in O(|V| + |E|) time; and (3) an Adaptive Synthesis Protocol with provable termination guarantees and heuristic consistency scoring for parallel agent outputs. We validate AdaptOrch across coding (SWE-bench), reasoning (GPQA), and retrieval-augmented generation tasks, demonstrating that topology-aware orchestration achieves 12-23% improvement over static single-topology baselines, even when using identical underlying models. Our results establish orchestration design as a first-class optimization target independent of model scaling.

</details>


### [47] [AgentConductor: Topology Evolution for Multi-Agent Competition-Level Code Generation](https://arxiv.org/abs/2602.17100)
*Siyu Wang,Ruotian Lu,Zhihao Yang,Yuchao Wang,Yanzhou Zhang,Lei Xu,Qimin Xu,Guojun Yin,Cailian Chen,Xinping Guan*

Main category: cs.MA

TL;DR: 本文提出AgentConductor，一种基于强化学习优化的多智能体系统，通过LLM驱动的协调器动态生成任务自适应的交互拓扑，在代码生成任务中显著提升准确率并降低通信密度与token成本。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的多智能体系统在代码生成等复杂任务中缺乏对任务难度的感知，无法动态调整交互拓扑密度，也未利用执行反馈迭代优化拓扑结构，导致通信冗余和性能瓶颈。

Method: AgentConductor引入一个基于LLM的协调器智能体，为每个查询推断任务难度与智能体角色，并构建任务自适应、密度感知的分层有向无环图（DAG）拓扑。其核心创新包括：1）设计新的拓扑密度函数，刻画多智能体交互的通信感知数学特性；2）采用难度区间划分策略，实现更精细的拓扑密度上界控制，避免过度剪枝。

Result: 在三个竞赛级和两个基础代码数据集上，AgentConductor在pass@1准确率上最高提升14.6%，通信密度降低13%，token成本减少68%，均优于最强基线。

Conclusion: AgentConductor通过端到端反馈驱动的动态拓扑生成机制，有效解决了多智能体系统中拓扑静态化与任务不匹配的问题，为复杂任务中的高效协作提供了新范式。

Abstract: Large language model(LLM)-driven multi-agent systems(MAS) coordinate specialized agents through predefined interaction topologies and have shown promise for complex tasks such as competition-level code generation. Recent studies demonstrate that carefully designed multi-agent workflows and communication graphs can significantly improve code generation performance by leveraging collaborative reasoning. However, existing methods neither adapt topology density to task difficulty nor iteratively refine the topology within an instance using execution feedback, which leads to redundant communication and performance bottlenecks. To address these issues, we propose AgentConductor: a reinforcement learning-optimized MAS with an LLM-based orchestrator agent as its core, which enables end-to-end feedback-driven dynamic generation of interaction topologies. For each query, AgentConductor infers agent roles and task difficulty, then constructs a task-adapted, density-aware layered directed acyclic graph (DAG) topology, underpinned by two key innovations. First, we design a novel topological density function that captures communication-aware mathematical characterizations of multi-agent interactions. Second, we adopt difficulty interval partitioning to avoid excessive pruning for precise topological density upper bound measurement per difficulty level and finer-grained control. Empirically, across three competition-level and two foundational code datasets, AgentConductor achieves state-of-the-art accuracy, outperforming the strongest baseline by up to 14.6% in pass@1 accuracy, 13% in density reduction, and 68% in token cost reduction.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [48] [On the complexity of covering points by disjoint segments and by guillotine cuts](https://arxiv.org/abs/2602.17294)
*Delia Garijo,Alberto Márquez,Rodrigo I. Silveira*

Main category: cs.CG

TL;DR: 本文证明了两个与用不相交线段覆盖平面上点相关的几何覆盖问题是NP完全的。


<details>
  <summary>Details</summary>
Motivation: 研究平面上点集能否被有限数量的不相交线段或“guillotine cuts”完全覆盖，这类问题在计算几何和组合优化中具有理论和应用价值。

Method: 通过归约方法，将已知的NP完全问题转化为所研究的两个几何覆盖问题，从而证明其NP完全性。

Result: 证明了以下两个问题是NP完全的：(1) 给定平面上n个点和整数k，是否能用k条互不相交的线段覆盖所有点；(2) 类似地，是否能用k次guillotine切割覆盖所有点。

Conclusion: 这两个几何覆盖问题属于NP完全类，表明它们在计算上是困难的，除非P=NP，否则不存在多项式时间算法。

Abstract: We show that two geometric cover problems in the plane, related to covering points with disjoint line segments, are NP-complete. Given $n$ points in the plane and a value $k$, the first problem asks if all points can be covered by $k$ disjoint line segments; the second problem treats the analogous question for $k$ guillotine cuts.

</details>


### [49] [Computational Hardness of Private Coreset](https://arxiv.org/abs/2602.17488)
*Badih Ghazi,Cristóbal Guzmán,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi*

Main category: cs.CG

TL;DR: 本文研究了差分隐私（DP）下计算k-means问题的coreset的计算复杂性，并证明了该问题的首个计算下界。


<details>
  <summary>Details</summary>
Motivation: 在保护数据隐私的前提下，高效地构建适用于k-means聚类的coreset具有重要应用价值。然而，现有工作缺乏对这一任务计算复杂性的理论理解，尤其是是否存在高效的差分隐私算法。

Method: 作者基于密码学假设（单向函数存在），通过归约方法证明：在ℓ∞度量下，对于任意常数α>0和k=3，不存在多项式时间的(ε,1/n^{ω(1)})-DP算法能计算满足(1±α)近似保证的k-means coreset；在欧氏度量下，类似结论仅对α=Θ(1/d²)成立。

Result: 证明了在ℓ∞度量下，即使k=3，也不存在满足特定隐私参数的多项式时间DP算法来构造常数近似精度的k-means coreset；在欧氏空间中，该下界仅适用于与维度相关的较小近似误差α=Θ(1/d²)。

Conclusion: 差分隐私下的k-means coreset构造存在固有的计算障碍，尤其在ℓ∞度量下无法实现高效且高精度的隐私保护算法，揭示了隐私、效率与近似精度之间的根本权衡。

Abstract: We study the problem of differentially private (DP) computation of coreset for the $k$-means objective. For a given input set of points, a coreset is another set of points such that the $k$-means objective for any candidate solution is preserved up to a multiplicative $(1 \pm α)$ factor (and some additive factor).
  We prove the first computational lower bounds for this problem. Specifically, assuming the existence of one-way functions, we show that no polynomial-time $(ε, 1/n^{ω(1)})$-DP algorithm can compute a coreset for $k$-means in the $\ell_\infty$-metric for some constant $α> 0$ (and some constant additive factor), even for $k=3$. For $k$-means in the Euclidean metric, we show a similar result but only for $α= Θ\left(1/d^2\right)$, where $d$ is the dimension.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment](https://arxiv.org/abs/2602.16714)
*Renato Marcelo,Ana Rodrigues,Cristiana Palmela Pereira,António Figueiras,Rui Santos,José Rui Figueira,Alexandre P Francisco,Cátia Vaz*

Main category: cs.AI

TL;DR: AIdentifyAGE 是一个面向法医牙科年龄评估的领域本体，旨在通过标准化和语义一致性提升评估流程的透明度、可重复性与互操作性。


<details>
  <summary>Details</summary>
Motivation: 当前法医牙科年龄评估存在方法异质性高、数据表示碎片化及临床、法医与法律信息系统之间互操作性差的问题，尤其在AI方法日益普及的背景下，亟需统一框架以确保透明性和可复现性。

Method: 开发了名为 AIdentifyAGE 的领域本体，整合手动与AI辅助的牙科年龄评估流程，建模完整的医法工作流，并基于上层及已有的生物医学、牙科和机器学习本体进行构建，遵循FAIR原则。

Result: 该本体实现了对司法背景、个体信息、法医检查数据、牙科发育评估方法、影像学、统计参考研究及AI估算方法的统一建模，支持可追溯的观察—方法—结果链条。

Conclusion: AIdentifyAGE 为法医与司法场景中的年龄评估提供了标准化、可扩展且可解释的基础，是构建本体驱动决策支持系统的关键一步。

Abstract: Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the most reliable biological approaches for adolescents and young adults, but current practices are challenged by methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal information systems. These limitations hinder transparency and reproducibility, amplified by the increasing adoption of AI- based methods. The AIdentifyAGE ontology is domain-specific and provides a standardized, semantically coherent framework, encompassing both manual and AI-assisted forensic dental age assessment workflows, and enabling traceable linkage between observations, methods, reference data, and reported outcomes. It models the complete medico-legal workflow, integrating judicial context, individual-level information, forensic examination data, dental developmental assessment methods, radiographic imaging, statistical reference studies, and AI-based estimation methods. It is being developed together with domain experts, and it builds on upper and established biomedical, dental, and machine learning ontologies, ensuring interoperability, extensibility, and compliance with FAIR principles. The AIdentifyAGE ontology is a fundamental step to enhance consistency, transparency, and explainability, establishing a robust foundation for ontology-driven decision support systems in medico-legal and judicial contexts.

</details>


### [51] [Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence](https://arxiv.org/abs/2602.16716)
*Song-Ju Kim*

Main category: cs.AI

TL;DR: 本文指出，上下文依赖性（contextuality）并非量子力学特有，而是经典概率表示中因复用单一内部状态而不可避免的现象，并揭示了其背后的信息论代价。


<details>
  <summary>Details</summary>
Motivation: 理解在记忆、表示或物理资源受限下，自适应系统复用单一内部状态所带来的表征限制，尤其是在不同上下文中表现的上下文依赖性问题。

Method: 将上下文建模为对共享内部状态的干预，通过经典概率模型分析其统计行为，并构造最小示例以展示信息论代价；同时对比非经典概率框架如何绕过该限制。

Result: 证明任何复现上下文结果统计的经典模型必须承担不可约的信息论代价，即上下文依赖不能仅通过内部状态中介；非经典概率框架可通过放弃全局联合概率空间假设来避免此代价。

Conclusion: 上下文依赖性是自适应智能中一种普遍的表征约束，与具体物理实现无关，揭示了经典与非经典表征框架的根本差异。

Abstract: Adaptive systems often operate across multiple contexts while reusing a fixed internal state space due to constraints on memory, representation, or physical resources. Such single-state reuse is ubiquitous in natural and artificial intelligence, yet its fundamental representational consequences remain poorly understood. We show that contextuality is not a peculiarity of quantum mechanics, but an inevitable consequence of single-state reuse in classical probabilistic representations. Modeling contexts as interventions acting on a shared internal state, we prove that any classical model reproducing contextual outcome statistics must incur an irreducible information-theoretic cost: dependence on context cannot be mediated solely through the internal state. We provide a minimal constructive example that explicitly realizes this cost and clarifies its operational meaning. We further explain how nonclassical probabilistic frameworks avoid this obstruction by relaxing the assumption of a single global joint probability space, without invoking quantum dynamics or Hilbert space structure. Our results identify contextuality as a general representational constraint on adaptive intelligence, independent of physical implementation.

</details>


### [52] [Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation](https://arxiv.org/abs/2602.16727)
*Hua Yan,Heng Tan,Yingxue Zhang,Yu Yang*

Main category: cs.AI

TL;DR: 本文提出MobCache框架，通过可重构缓存机制提升大规模人类移动模拟的效率，在保持与先进LLM方法相当性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的人类移动行为模拟方法虽能生成逼真结果，但计算成本高，难以扩展至大规模场景，因此亟需一种兼顾效率与保真度的新方法。

Method: 设计MobCache框架，包含：(1) 推理组件，将推理步骤编码为潜在空间嵌入，并通过潜在空间评估器实现推理步骤的复用与重组；(2) 解码组件，采用轻量级解码器，结合受移动规律约束的蒸馏训练，将潜在推理链转化为自然语言。

Result: 实验表明，MobCache在多个效率维度上显著优于现有方法，同时在模拟性能上与当前最先进的LLM方法相当。

Conclusion: MobCache通过引入可重构缓存和潜在空间推理机制，有效解决了大规模人类移动模拟中的效率瓶颈，为城市规划、流行病学等应用提供了可扩展的解决方案。

Abstract: Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost limits scalability. To address this, we design a mobility-aware cache framework named MobCache that leverages reconstructible caches to enable efficient large-scale human mobility simulations. It consists of: (1) a reasoning component that encodes each reasoning step as a latent-space embedding and uses a latent-space evaluator to enable the reuse and recombination of reasoning steps; and (2) a decoding component that employs a lightweight decoder trained with mobility law-constrained distillation to translate latent-space reasoning chains into natural language, thereby improving simulation efficiency while maintaining fidelity. Experiments show that MobCache significantly improves efficiency across multiple dimensions while maintaining performance comparable to state-of-the-art LLM-based methods.

</details>


### [53] [When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation](https://arxiv.org/abs/2602.16763)
*Mubashara Akhtar,Anka Reuel,Prajna Soni,Sanchit Ahuja,Pawan Sasanka Ammanamanchi,Ruchit Rawal,Vilém Zouhar,Srishti Yadav,Chenxi Whitehouse,Dayeon Ki,Jennifer Mickel,Leshem Choshen,Marek Šuppa,Jan Batzner,Jenny Chim,Jeba Sania,Yanan Long,Hossein A. Rahmani,Christina Knight,Yiyang Nan,Jyoutir Raj,Yu Fan,Shubham Singh,Subramanyam Sahoo,Eliya Habba,Usman Gohar,Siddhesh Pawar,Robert Scholz,Arjun Subramonian,Jingwei Ni,Mykel Kochenderfer,Sanmi Koyejo,Mrinmaya Sachan,Stella Biderman,Zeerak Talat,Avijit Ghosh,Irene Solaiman*

Main category: cs.AI

TL;DR: 该研究分析了60个大语言模型（LLM）基准测试的饱和现象，发现近一半的基准已饱和，且随时间推移饱和率上升；专家构建的基准比众包基准更能抵抗饱和，而是否隐藏测试数据对防止饱和无显著影响。


<details>
  <summary>Details</summary>
Motivation: 许多AI基准测试在短期内迅速饱和，无法有效区分顶尖模型，削弱了其长期评估价值。因此，有必要系统分析导致基准饱和的因素，以指导未来更持久、有效的评估设计。

Method: 作者从主流模型开发者的技术报告中选取60个LLM基准，依据任务设计、数据构建和评估格式等14个属性对这些基准进行刻画，并检验五个假设，以评估各属性对饱和速率的影响。

Result: 研究发现近50%的基准已出现饱和，且饱和率随基准使用时间增加而上升；测试数据是否公开对饱和无显著影响；由专家构建的基准比众包基准更不易饱和。

Conclusion: 基准的长期有效性受其设计选择显著影响，特别是数据来源（专家 vs. 众包）；研究结果为构建更具耐久性的AI评估基准提供了实证依据和设计建议。

Abstract: Artificial Intelligence (AI) benchmarks play a central role in measuring progress in model development and guiding deployment decisions. However, many benchmarks quickly become saturated, meaning that they can no longer differentiate between the best-performing models, diminishing their long-term value. In this study, we analyze benchmark saturation across 60 Large Language Model (LLM) benchmarks selected from technical reports by major model developers. To identify factors driving saturation, we characterize benchmarks along 14 properties spanning task design, data construction, and evaluation format. We test five hypotheses examining how each property contributes to saturation rates. Our analysis reveals that nearly half of the benchmarks exhibit saturation, with rates increasing as benchmarks age. Notably, hiding test data (i.e., public vs. private) shows no protective effect, while expert-curated benchmarks resist saturation better than crowdsourced ones. Our findings highlight which design choices extend benchmark longevity and inform strategies for more durable evaluation.

</details>


### [54] [Simple Baselines are Competitive with Code Evolution](https://arxiv.org/abs/2602.16805)
*Yonatan Gideoni,Sebastian Risi,Yarin Gal*

Main category: cs.AI

TL;DR: 本文发现，在多个任务中，简单的基线方法在代码演化任务上表现与复杂方法相当甚至更好，并指出当前代码演化方法在设计和评估中存在的问题。


<details>
  <summary>Details</summary>
Motivation: 许多代码演化方法虽表现出色，但缺乏与简单基线的充分比较；作者旨在通过系统评估揭示其实际有效性及局限性。

Method: 在三个领域（数学界改进、智能体框架设计、机器学习竞赛）中测试两种简单基线方法，并与现有复杂的代码演化方法进行对比分析。

Result: 简单基线在所有三个领域均达到或超越复杂方法；研究发现搜索空间设计、提示中的领域知识和评估方差是影响性能的关键因素。

Conclusion: 代码演化的效果常被高估，未来工作应聚焦于构建更合理的搜索空间、减少评估随机性，并采用更严谨的评估实践。

Abstract: Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophisticated methods in all three. By analyzing these results we find various shortcomings in how code evolution is both developed and used. For the mathematical bounds, a problem's search space and domain knowledge in the prompt are chiefly what dictate a search's performance ceiling and efficiency, with the code evolution pipeline being secondary. Thus, the primary challenge in finding improved bounds is designing good search spaces, which is done by domain experts, and not the search itself. When designing agentic scaffolds we find that high variance in the scaffolds coupled with small datasets leads to suboptimal scaffolds being selected, resulting in hand-designed majority vote scaffolds performing best. We propose better evaluation methods that reduce evaluation stochasticity while keeping the code evolution economically feasible. We finish with a discussion of avenues and best practices to enable more rigorous code evolution in future work.

</details>


### [55] [Improved Upper Bounds for Slicing the Hypercube](https://arxiv.org/abs/2602.16807)
*Duncan Soiffer,Nathaniel Itty,Christopher D. Rosin,Blake Bruell,Mason DiCicco,Gábor N. Sárközy,Ryan Offstein,Daniel Reichman*

Main category: cs.AI

TL;DR: 本文改进了切分n维超立方体所有边所需的最少超平面数S(n)的上界，证明了S(n) ≤ ⌈4n/5⌉（当n不是5的奇数倍时），否则S(n) ≤ 4n/5 + 1，并借助新型自动构造工具CPro1实现了关键构造。


<details>
  <summary>Details</summary>
Motivation: 研究切分n维超立方体所有边所需的最少超平面数量S(n)，旨在改进已有上界并深入理解高维几何结构中的覆盖问题。

Method: 通过构造性方法，在CPro1工具（结合大语言模型与自动超参调优的搜索算法生成器）辅助下，显式构造出8个超平面成功切分Q₁₀的所有边，并推广至一般n维情形以获得新的上界。

Result: 将S(n)的上界从经典的⌈5n/6⌉改进为⌈4n/5⌉（或在n为5的奇数倍时为4n/5 + 1），同时给出了使用k < n个超平面所能切分的最大边数的新下界。

Conclusion: 该工作不仅显著改进了S(n)的上界，还展示了AI辅助数学构造在解决组合几何难题中的有效性。

Abstract: A collection of hyperplanes $\mathcal{H}$ slices all edges of the $n$-dimensional hypercube $Q_n$ with vertex set $\{-1,1\}^n$ if, for every edge $e$ in the hypercube, there exists a hyperplane in $\mathcal{H}$ intersecting $e$ in its interior. Let $S(n)$ be the minimum number of hyperplanes needed to slice $Q_n$. We prove that $S(n) \leq \lceil \frac{4n}{5} \rceil$, except when $n$ is an odd multiple of $5$, in which case $S(n) \leq \frac{4n}{5} +1$. This improves upon the previously known upper bound of $S(n) \leq \lceil\frac{5n}{6} \rceil$ due to Paterson reported in 1971. We also obtain new lower bounds on the maximum number of edges in $Q_n$ that can be sliced using $k<n$ hyperplanes. We prove the improved upper bound on $S(n)$ by constructing $8$ hyperplanes slicing $Q_{10}$ aided by the recently introduced CPro1: an automatic tool that uses reasoning LLMs coupled with automated hyperparameter tuning to create search algorithms for the discovery of mathematical constructions.

</details>


### [56] [NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography](https://arxiv.org/abs/2602.16812)
*Zhongcan Xiao,Leyi Zhang,Guannan Zhang,Xiaoping Wang*

Main category: cs.AI

TL;DR: NeuDiff Agent 是一个受控的、基于工具调用的 AI 工作流，用于中子源设施中的晶体结构解析，显著缩短分析时间并满足出版级验证标准。


<details>
  <summary>Details</summary>
Motivation: 大型科研设施在处理结构和磁性复杂的样品时，面临分析与报告延迟的问题，限制了科研产出效率，亟需自动化且可靠的分析流程。

Method: NeuDiff Agent 在 TOPAZ 平台上实现了一个受治理的 AI 工作流，通过白名单工具限制操作、关键节点设置验证关卡，并完整记录溯源信息；使用两种大语言模型后端，在固定提示协议下进行端到端测试。

Result: 在基准测试中，NeuDiff Agent 将总耗时从人工的 435 分钟降至 86.5–94.4 分钟（提速 4.6–5.0 倍），并生成无 checkCIF A/B 级警告的验证 CIF 文件。

Conclusion: 该工作为在设施晶体学中部署智能体 AI 提供了一条兼顾效率、可追溯性和出版验证要求的可行路径。

Abstract: Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis efficiency, NeuDiff Agent is introduced as a governed, tool-using AI workflow for TOPAZ at the Spallation Neutron Source that takes instrument data products through reduction, integration, refinement, and validation to a validated crystal structure and a publication-ready CIF. NeuDiff Agent executes this established pipeline under explicit governance by restricting actions to allowlisted tools, enforcing fail-closed verification gates at key workflow boundaries, and capturing complete provenance for inspection, auditing, and controlled replay. Performance is assessed using a fixed prompt protocol and repeated end-to-end runs with two large language model backends, with user and machine time partitioned and intervention burden and recovery behaviors quantified under gating. In a reference-case benchmark, NeuDiff Agent reduces wall time from 435 minutes (manual) to 86.5(4.7) to 94.4(3.5) minutes (4.6-5.0x faster) while producing a validated CIF with no checkCIF level A or B alerts. These results establish a practical route to deploy agentic AI in facility crystallography while preserving traceability and publication-facing validation requirements.

</details>


### [57] [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)
*Eiman Kanjo,Mustafa Aslanov*

Main category: cs.AI

TL;DR: 本文提出“节点学习”（Node Learning）这一去中心化学习范式，使智能驻留在边缘节点并通过选择性对等交互扩展，以应对集中式AI在边缘场景中的成本与脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 集中式智能在边缘计算环境中面临数据传输开销、延迟、能耗高及对大型数据中心依赖等问题，在异构、移动和资源受限的场景中难以有效扩展。

Method: 节点学习范式让每个边缘节点基于本地数据持续学习、维护自身模型状态，并在协作有益时机会性地交换知识，通过重叠与扩散而非全局同步或中心聚合实现学习传播。

Result: 该范式统一了自主性与协作性，兼容数据、硬件、目标和连接性的异构性，并为通信、硬件设计、信任机制与治理提供新视角。

Conclusion: 节点学习并非取代现有范式，而是将其纳入更广泛的去中心化框架中，为边缘智能提供一种更具可扩展性与鲁棒性的新思路。

Abstract: The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. In this paper, we introduce Node Learning, a decen- tralised learning paradigm in which intelligence resides at individual edge nodes and expands through selective peer interaction. Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchro- nisation or central aggregation. It unifies autonomous and cooperative behaviour within a single abstraction and accommodates heterogeneity in data, hardware, objectives, and connectivity. This concept paper develops the conceptual foundations of this paradigm, contrasts it with existing decentralised approaches, and examines implications for communi- cation, hardware, trust, and governance. Node Learning does not discard existing paradigms, but places them within a broader decentralised perspective

</details>


### [58] [An order-oriented approach to scoring hesitant fuzzy elements](https://arxiv.org/abs/2602.16827)
*Luis Merino,Gabriel Navarro,Carlos Salvatierra,Evangelina Santos*

Main category: cs.AI

TL;DR: 本文提出一种基于序关系的统一框架来定义犹豫模糊集的评分函数，指出经典序不构成格结构，并证明对称序下的评分满足强单调性和Gärdenfors条件；进一步引入支配函数用于排序，并支持群体决策。


<details>
  <summary>Details</summary>
Motivation: 传统犹豫模糊集的评分方法缺乏序理论的严格基础，导致评分机制不够灵活和一致。为解决此问题，作者旨在建立一个以序关系为核心的统一评分框架。

Method: 通过分析多种经典序（如对称序）在犹豫模糊元素（即[0,1]中的非空子集）上的性质，验证其是否形成格结构；并基于对称序定义满足规范性准则的评分函数。随后引入支配函数，结合控制集（含最小可接受阈值）对犹豫模糊元素进行排序。

Result: 发现经典序不诱导格结构；而基于对称序的评分函数满足强单调性与Gärdenfors条件。所提出的离散支配函数和相对支配函数能有效构建模糊偏好关系，适用于典型犹豫模糊集的排序与群体决策。

Conclusion: 以序为导向的评分框架为犹豫模糊集提供了更严谨、灵活的处理方式，支配函数的引入增强了其在多属性群体决策中的适用性。

Abstract: Traditional scoring approaches on hesitant fuzzy sets often lack a formal base in order theory. This paper proposes a unified framework, where each score is explicitly defined with respect to a given order. This order-oriented perspective enables more flexible and coherent scoring mechanisms. We examine several classical orders on hesitant fuzzy elements, that is, nonempty subsets in [0,1], and show that, contrary to prior claims, they do not induce lattice structures. In contrast, we prove that the scores defined with respect to the symmetric order satisfy key normative criteria for scoring functions, including strong monotonicity with respect to unions and the Gärdenfors condition.
  Following this analysis, we introduce a class of functions, called dominance functions, for ranking hesitant fuzzy elements. They aim to compare hesitant fuzzy elements relative to control sets incorporating minimum acceptability thresholds. Two concrete examples of dominance functions for finite sets are provided: the discrete dominance function and the relative dominance function. We show that these can be employed to construct fuzzy preference relations on typical hesitant fuzzy sets and support group decision-making.

</details>


### [59] [Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents](https://arxiv.org/abs/2602.16855)
*Haiyang Xu,Xi Zhang,Haowei Liu,Junyang Wang,Zhaozai Zhu,Shengjie Zhou,Xuhao Hu,Feiyu Gao,Junjie Cao,Zihua Wang,Zhiyuan Chen,Jitong Liao,Qi Zheng,Jiahui Zeng,Ze Xu,Shuai Bai,Junyang Lin,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 本文提出了GUI-Owl-1.5，一个支持多平台、多尺寸的原生GUI智能体模型，在20多个GUI基准上达到开源模型的最先进水平，并开源了模型与在线演示。


<details>
  <summary>Details</summary>
Motivation: 为提升GUI智能体在多平台（桌面、移动、浏览器等）环境下的自动化、推理、工具调用及记忆能力，实现高效的云边协同与实时交互。

Method: 提出三项关键技术：(1) 混合数据飞轮，结合模拟环境与云端沙箱构建高质量UI数据管道；(2) 统一智能体能力增强框架，通过思维合成提升推理、工具使用、记忆及多智能体适应能力；(3) 多平台环境强化学习算法MRPO，解决跨平台冲突与长程任务训练效率低的问题。

Result: 在多个GUI基准上取得SOTA性能：OSWorld 56.5、AndroidWorld 71.6、WebArena 48.4、ScreenSpotPro 80.3、OSWorld-MCP 47.6、MobileWorld 46.8、GUI-Knowledge Bench 75.5。

Conclusion: GUI-Owl-1.5通过创新的数据构建、能力增强和强化学习方法，显著提升了多平台GUI智能体的综合性能，模型已开源并提供在线演示。

Abstract: The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding tasks, it obtains 80.3 on ScreenSpotPro; (3) on tool-calling tasks, it obtains 47.6 on OSWorld-MCP, and 46.8 on MobileWorld; (4) on memory and knowledge tasks, it obtains 75.5 on GUI-Knowledge Bench. GUI-Owl-1.5 incorporates several key innovations: (1) Hybird Data Flywheel: we construct the data pipeline for UI understanding and trajectory generation based on a combination of simulated environments and cloud-based sandbox environments, in order to improve the efficiency and quality of data collection. (2) Unified Enhancement of Agent Capabilities: we use a unified thought-synthesis pipeline to enhance the model's reasoning capabilities, while placing particular emphasis on improving key agent abilities, including Tool/MCP use, memory and multi-agent adaptation; (3) Multi-platform Environment RL Scaling: We propose a new environment RL algorithm, MRPO, to address the challenges of multi-platform conflicts and the low training efficiency of long-horizon tasks. The GUI-Owl-1.5 models are open-sourced, and an online cloud-sandbox demo is available at https://github.com/X-PLUG/MobileAgent.

</details>


### [60] [OpenSage: Self-programming Agent Generation Engine](https://arxiv.org/abs/2602.16891)
*Hongwei Li,Zhun Wang,Qinrun Dai,Yuzhou Nie,Jinjun Peng,Ruitong Liu,Jingyang Zhang,Kaijie Zhu,Jingxuan He,Lun Wang,Yangruibo Ding,Yueqi Chen,Wenbo Guo,Dawn Song*

Main category: cs.AI

TL;DR: 本文提出了OpenSage，首个支持大语言模型（LLM）自动生成智能体拓扑结构与工具集，并提供结构化记忆支持的智能体开发套件（ADK），显著优于现有ADK。


<details>
  <summary>Details</summary>
Motivation: 当前ADK在智能体拓扑、工具和记忆功能方面支持不足，或依赖人工设计，限制了智能体的泛化能力与整体性能。

Method: OpenSage使LLM能自动创建具有自生成拓扑和工具集的智能体，提供子智能体与工具包管理功能，并采用分层图结构记忆系统，同时配备面向软件工程任务的专用工具集。

Result: 在三个主流基准上使用多种主干模型的实验表明，OpenSage显著优于现有ADK；消融研究验证了各组件设计的有效性。

Conclusion: OpenSage有望推动智能体开发从以人类为中心转向以AI为中心的新范式。

Abstract: Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or rely on humans to manually design these components, limiting agents' generalizability and overall performance. We propose OpenSage, the first ADK that enables LLMs to automatically create agents with self-generated topology and toolsets while providing comprehensive and structured memory support. OpenSage offers effective functionality for agents to create and manage their own sub-agents and toolkits. It also features a hierarchical, graph-based memory system for efficient management and a specialized toolkit tailored to software engineering tasks. Extensive experiments across three state-of-the-art benchmarks with various backbone models demonstrate the advantages of OpenSage over existing ADKs. We also conduct rigorous ablation studies to demonstrate the effectiveness of our design for each component. We believe OpenSage can pave the way for the next generation of agent development, shifting the focus from human-centered to AI-centered paradigms.

</details>


### [61] [AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901)
*Tanqiu Jiang,Yuhui Wang,Jiacheng Liang,Ting Wang*

Main category: cs.AI

TL;DR: 本文提出了AgentLAB，这是首个专门用于评估大语言模型（LLM）智能体在长期、多轮交互环境中遭受自适应长周期攻击脆弱性的基准测试平台。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体被部署到复杂、长期任务环境中，它们面临新型的长周期攻击风险，这些攻击利用多轮用户-智能体-环境交互达成单轮交互中无法实现的恶意目标。现有防御机制主要针对单轮交互设计，难以应对这类威胁，因此亟需系统性评估框架。

Method: 作者构建了AgentLAB基准，包含5种新型攻击类型（意图劫持、工具链攻击、任务注入、目标漂移和记忆投毒），覆盖28个现实智能体环境和644个安全测试用例，并利用该基准对代表性LLM智能体进行评估。

Result: 实验表明，当前主流LLM智能体对长周期攻击高度脆弱，且专为单轮交互设计的防御措施无法有效缓解此类威胁。

Conclusion: AgentLAB可作为评估和推动LLM智能体在实际应用中安全性的关键基准，相关资源已公开发布。

Abstract: LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack types including intent hijacking, tool chaining, task injection, objective drifting, and memory poisoning, spanning 28 realistic agentic environments, and 644 security test cases. Leveraging AgentLAB, we evaluate representative LLM agents and find that they remain highly susceptible to long-horizon attacks; moreover, defenses designed for single-turn interactions fail to reliably mitigate long-horizon threats. We anticipate that AgentLAB will serve as a valuable benchmark for tracking progress on securing LLM agents in practical settings. The benchmark is publicly available at https://tanqiujiang.github.io/AgentLAB_main.

</details>


### [62] [LLM-WikiRace: Benchmarking Long-term Planning and Reasoning over Real-World Knowledge Graphs](https://arxiv.org/abs/2602.16902)
*Juliusz Ziomek,William Bankes,Lorenz Wolf,Shyam Sundhar Ramesh,Xiaohang Tang,Ilija Bogunovic*

Main category: cs.AI

TL;DR: LLM-Wikirace 是一个用于评估大语言模型在规划、推理和世界知识方面能力的新基准，要求模型通过维基百科超链接从起点导航至目标页面。尽管顶尖模型在简单任务上表现超人，但在困难任务中成功率显著下降，暴露出其在长期规划和失败后重新规划方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在复杂推理和规划任务中的能力尚不明确，需要一个能有效评估其规划、推理及世界知识综合能力的基准。LLM-Wikirace 通过模拟维基百科链接导航任务，提供了一个结构清晰且具有挑战性的测试环境。

Method: 构建 LLM-Wikirace 基准，包含不同难度级别的维基百科导航任务；评估多个开源与闭源大语言模型（如 Gemini-3、GPT-5、Claude Opus 4.5）在该任务上的表现；通过轨迹分析研究模型的规划策略与失败模式。

Result: 顶尖模型在简单任务上达到超人水平，但在困难任务中表现大幅下降（最佳模型 Gemini-3 仅成功 23%）；世界知识对成功至关重要，但超过一定阈值后，规划与长程推理能力成为关键；模型在失败后难以有效重规划，常陷入循环。

Conclusion: LLM-Wikirace 揭示了当前大语言模型在复杂规划和推理任务中的明显局限，尤其在长期目标导向行为和错误恢复方面仍有很大提升空间，为未来研究提供了开放且有效的评估平台。

Abstract: We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability to reason about how concepts are connected in the real world. We evaluate a broad set of open- and closed-source models, including Gemini-3, GPT-5, and Claude Opus 4.5, which achieve the strongest results on the easy level of the task and demonstrate superhuman performance. Despite this, performance drops sharply on hard difficulty: the best-performing model, Gemini-3, succeeds in only 23\% of hard games, highlighting substantial remaining challenges for frontier models. Our analysis shows that world knowledge is a necessary ingredient for success, but only up to a point, beyond this threshold, planning and long-horizon reasoning capabilities become the dominant factors. Trajectory-level analysis further reveals that even the strongest models struggle to replan after failure, frequently entering loops rather than recovering. LLM-Wikirace is a simple benchmark that reveals clear limitations in current reasoning systems, offering an open arena where planning-capable LLMs still have much to prove. Our code and leaderboard available at https:/llmwikirace.github.io.

</details>


### [63] [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931)
*Idhant Gulati,Shivam Raval*

Main category: cs.AI

TL;DR: 对齐的视觉-语言模型在包含少量有害数据的领域微调后，会表现出跨任务和模态的显著失准，且多模态评估比纯文本评估更敏感；低维子空间主导了有害行为，现有缓解策略无法完全消除该问题。


<details>
  <summary>Details</summary>
Motivation: 研究终身学习场景下，视觉-语言模型在持续微调过程中如何在获得新能力的同时保持安全对齐，揭示当前后训练范式在部署后可能无法有效维持对齐。

Method: 在Gemma3-4B模型上使用LoRA进行微调，引入不同比例的有害数据，通过多模态与纯文本评估对比失准程度，并结合几何分析识别有害行为的低维子空间；测试良性微调和基于激活的引导两种缓解策略。

Result: 有害数据即使仅占10%也会导致显著失准；失准程度随LoRA秩单调增加；多模态评估（70.71±1.22）显著高于文本评估（41.19±2.51）；有害行为主要集中在前10个主成分构成的低维子空间中；两种缓解策略可大幅降低但无法完全消除有害行为。

Conclusion: 当前后训练方法在持续学习中难以充分保持模型对齐，需发展更鲁棒的持续学习框架以保障部署后安全性。

Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimodal evaluation reveals substantially higher misalignment ($70.71 \pm 1.22$ at $r=128$) than text-only evaluation ($41.19 \pm 2.51$), suggesting that unimodal safety benchmarks may underestimate alignment degradation in vision-language models. Critically, even 10\% harmful data in the training mixture induces substantial alignment degradation. Geometric analysis reveals that harmful behaviors occupy a remarkably low-dimensional subspace, with the majority of misalignment information captured in 10 principal components. To mitigate misalignment, we evaluate two strategies: benign narrow fine-tuning and activation-based steering. While both approaches substantially reduce misalignment, neither completely removes the learned harmful behaviors. Our findings highlight the need for robust continual learning frameworks, as current post-training paradigms may not sufficiently preserve alignment in post-deployment settings.

</details>


### [64] [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953)
*Hejia Zhang,Zhongming Yu,Chia-Tung Ho,Haoxing Ren,Brucek Khailany,Jishen Zhao*

Main category: cs.AI

TL;DR: 本文提出LLM4Cov，一种面向硬件验证的离线大语言模型智能体学习框架，在不依赖在线强化学习的情况下，通过执行验证的数据筛选、策略感知的数据合成和最差状态优先采样等技术，显著提升覆盖率表现。


<details>
  <summary>Details</summary>
Motivation: 由于执行反馈（如工业仿真器）成本高、速度慢，传统在线强化学习难以应用于高覆盖率硬件验证任务；同时，执行信号不可微，限制了端到端训练方法的使用。

Method: 将验证任务建模为由确定性评估器引导的无记忆状态转移过程，提出执行验证的数据筛选、策略感知的智能体数据合成、最差状态优先采样等离线学习策略，并构建贴近现实的评测基准。

Result: 在所提框架下，一个仅4B参数的小模型在智能体评估中达到69.2%的覆盖率通过率，比其教师模型高出5.3%，并可与大一个数量级的模型竞争。

Conclusion: LLM4Cov为执行受限场景下的离线智能体学习提供了有效解决方案，在硬件验证任务中展现出高效性和可扩展性。

Abstract: Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Building on this formulation, we introduce execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints. We further curate a reality-aligned benchmark adapted from an existing verification suite through a revised evaluation protocol. Using the proposed pipeline, a compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.

</details>


### [65] [Automating Agent Hijacking via Structural Template Injection](https://arxiv.org/abs/2602.16958)
*Xinhao Deng,Jiaqing Wu,Miao Chen,Yue Xiao,Ke Xu,Qi Li*

Main category: cs.AI

TL;DR: 本文提出Phantom，一种基于结构化模板注入的自动化智能体劫持框架，通过诱导角色混淆高效攻击大语言模型智能体，在多个主流模型上显著优于现有方法，并在真实商业产品中发现70多个已确认漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有智能体劫持攻击多依赖人工构造的语义提示，成功率低且难以迁移到闭源商业模型；作者旨在开发一种自动化、高迁移性、基于模型架构机制的新型攻击方法。

Method: Phantom利用大语言模型智能体依赖特定聊天模板分隔系统、用户、助手和工具指令的特性，向检索内容注入优化的结构化模板以引发角色混淆。为提升黑盒攻击迁移性，该方法结合多层次模板增强、模板自编码器（TAE）将离散模板映射到连续潜在空间，并使用贝叶斯优化高效搜索最优对抗向量，再解码为高效力结构化模板。

Result: 在Qwen、GPT和Gemini上的实验表明，Phantom在攻击成功率（ASR）和查询效率上显著优于现有基线方法；并在真实商业产品中识别出70多个已被厂商确认的漏洞。

Conclusion: 结构化模板注入是一种高效且具实际威胁的智能体劫持手段，Phantom为理解和防御下一代智能体系统中的此类安全风险提供了实证基础。

Abstract: Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which often yields low attack success rates and limited transferability to closed-source commercial models. In this paper, we propose Phantom, an automated agent hijacking framework built upon Structured Template Injection that targets the fundamental architectural mechanisms of LLM agents. Our key insight is that agents rely on specific chat template tokens to separate system, user, assistant, and tool instructions. By injecting optimized structured templates into the retrieved context, we induce role confusion and cause the agent to misinterpret the injected content as legitimate user instructions or prior tool outputs. To enhance attack transferability against black-box agents, Phantom introduces a novel attack template search framework. We first perform multi-level template augmentation to increase structural diversity and then train a Template Autoencoder (TAE) to embed discrete templates into a continuous, searchable latent space. Subsequently, we apply Bayesian optimization to efficiently identify optimal adversarial vectors that are decoded into high-potency structured templates. Extensive experiments on Qwen, GPT, and Gemini demonstrate that our framework significantly outperforms existing baselines in both Attack Success Rate (ASR) and query efficiency. Moreover, we identified over 70 vulnerabilities in real-world commercial products that have been confirmed by vendors, underscoring the practical severity of structured template-based hijacking and providing an empirical foundation for securing next-generation agentic systems.

</details>


### [66] [Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning](https://arxiv.org/abs/2602.16984)
*Vishal Srivastava*

Main category: cs.AI

TL;DR: 本文指出黑盒安全评估在面对具有潜在上下文条件策略的AI系统时存在根本性局限，无法可靠预测其部署风险，并量化了在被动、自适应和计算三种场景下的评估误差下界，从而论证了额外安全机制的必要性。


<details>
  <summary>Details</summary>
Motivation: 黑盒安全评估通常假设模型在测试分布上的行为能可靠反映其部署表现，但作者质疑这一假设，尤其当模型行为受部署中常见但评估中罕见的未观测内部变量影响时。

Method: 作者形式化了“潜在上下文条件策略”模型，并分别通过Le Cam方法（被动评估）、基于哈希的触发构造与Yao极小极大原理（自适应评估），以及陷门单向函数假设（计算分离）来推导评估误差的理论下界；对于白盒探针，则分析了估计部署风险所需的样本复杂度及偏差校正。

Result: (1) 被动评估中，任何估计器的期望绝对误差至少为约0.208·δ·L；(2) 自适应评估中，最坏情况误差仍不低于δ·L/16，且检测需Θ(1/ε)次查询；(3) 在计算假设下，多项式时间评估器无法区分具备特权信息的部署环境所激活的不安全行为；白盒探针需O(1/(γ²·ε_R²))样本以达到ε_R精度。

Conclusion: 黑盒测试在某些情况下在统计上是欠定的，必须结合架构约束、训练期保证、可解释性及部署监控等额外保障措施，才能在最坏情况下实现安全保证。

Abstract: Black-box safety evaluation of AI systems assumes model behavior on test distributions reliably predicts deployment performance. We formalize and challenge this assumption through latent context-conditioned policies -- models whose outputs depend on unobserved internal variables that are rare under evaluation but prevalent under deployment. We establish fundamental limits showing that no black-box evaluator can reliably estimate deployment risk for such models. (1) Passive evaluation: For evaluators sampling i.i.d. from D_eval, we prove minimax lower bounds via Le Cam's method: any estimator incurs expected absolute error >= (5/24)*delta*L approximately 0.208*delta*L, where delta is trigger probability under deployment and L is the loss gap. (2) Adaptive evaluation: Using a hash-based trigger construction and Yao's minimax principle, worst-case error remains >= delta*L/16 even for fully adaptive querying when D_dep is supported over a sufficiently large domain; detection requires Theta(1/epsilon) queries. (3) Computational separation: Under trapdoor one-way function assumptions, deployment environments possessing privileged information can activate unsafe behaviors that any polynomial-time evaluator without the trapdoor cannot distinguish. For white-box probing, estimating deployment risk to accuracy epsilon_R requires O(1/(gamma^2 * epsilon_R^2)) samples, where gamma = alpha_0 + alpha_1 - 1 measures probe quality, and we provide explicit bias correction under probe error. Our results quantify when black-box testing is statistically underdetermined and provide explicit criteria for when additional safeguards -- architectural constraints, training-time guarantees, interpretability, and deployment monitoring -- are mathematically necessary for worst-case safety assurance.

</details>


### [67] [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation](https://arxiv.org/abs/2602.16990)
*Yan Wang,Yi Han,Lingfei Qian,Yueru He,Xueqing Peng,Dongji Feng,Zhuohan Xie,Vincent Jim Zhang,Rosie Guo,Fengran Mo,Jimin Huang,Yankai Chen,Xue Liu,Jian-Yun Nie*

Main category: cs.AI

TL;DR: 本文提出Conv-FinRe，一个用于股票推荐的对话式纵向基准，超越单纯模仿用户行为，通过多视角参考评估大语言模型在理性决策与行为对齐之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统推荐基准仅以用户历史行为作为唯一真值，在金融市场中可能混淆行为模仿与决策质量，因为用户行为可能受市场波动影响而短视或有噪声，未必符合其长期目标。

Method: 构建Conv-FinRe基准：基于真实市场数据和人类决策轨迹，结合用户入职访谈、逐步市场情境和咨询对话，要求模型在固定投资周期内生成股票排名，并提供区分描述性行为与基于风险偏好的规范效用的多视角参考。

Result: 对多个先进大语言模型的评估显示，基于效用的排名表现良好的模型往往难以匹配用户实际选择，而行为对齐的模型则容易过拟合短期噪声，揭示了理性决策质量与行为对齐之间的持续张力。

Conclusion: Conv-FinRe为金融推荐系统提供了更全面的评估框架，强调需区分理性分析与行为模仿；该数据集已在Hugging Face公开，代码库发布于GitHub。

Abstract: Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, a conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over a fixed investment horizon. Crucially, Conv-FinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate a suite of state-of-the-art LLMs. Results reveal a persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face, and the codebase is available on GitHub.

</details>


### [68] [Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases](https://arxiv.org/abs/2602.17001)
*Zhao Tan,Yiji Zhao,Shiyu Wang,Chang Xu,Yuxuan Liang,Xiping Liu,Shirui Pan,Ming Jin*

Main category: cs.AI

TL;DR: 本文提出Sonar-TS，一种用于自然语言查询时间序列数据库（NLQ4TSDB）的神经符号框架，通过“搜索-验证”流程有效处理形态意图和超长时间序列，并构建了首个大规模基准NLQTSBench。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法难以处理连续形态意图（如形状、异常），而时间序列模型难以应对超长历史数据，因此需要一个能同时兼顾语义理解和高效检索的新方法来支持非专家用户查询时间序列数据库。

Method: 提出Sonar-TS框架，采用类主动声呐的Search-Then-Verify机制：首先利用特征索引通过SQL检索候选时间窗口，再通过生成的Python程序对原始信号进行精确验证。

Result: 实验表明，Sonar-TS在复杂时间查询任务上显著优于传统方法，并成功揭示了NLQ4TSDB领域的独特挑战。

Conclusion: 本研究是NLQ4TSDB领域的首次系统性探索，提出了通用框架与评估标准，为后续研究奠定基础。

Abstract: Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, while time series models struggle to handle ultra-long histories. To address these challenges, we propose Sonar-TS, a neuro-symbolic framework that tackles NLQ4TSDB via a Search-Then-Verify pipeline. Analogous to active sonar, it utilizes a feature index to ping candidate windows via SQL, followed by generated Python programs to lock on and verify candidates against raw signals. To enable effective evaluation, we introduce NLQTSBench, the first large-scale benchmark designed for NLQ over TSDB-scale histories. Our experiments highlight the unique challenges within this domain and demonstrate that Sonar-TS effectively navigates complex temporal queries where traditional methods fail. This work presents the first systematic study of NLQ4TSDB, offering a general framework and evaluation standard to facilitate future research.

</details>


### [69] [Cinder: A fast and fair matchmaking system](https://arxiv.org/abs/2602.17015)
*Saurav Pal*

Main category: cs.AI

TL;DR: 本文提出Cinder，一种两阶段匹配系统，通过Ruzicka相似度初筛和基于非线性技能桶的Kantorovich距离（Sanction Score）评估，实现快速且公平的多人游戏队伍匹配。


<details>
  <summary>Details</summary>
Motivation: 现有基于平均技能值（如均值或中位数）的匹配方法在面对技能分布不均或偏斜的预组队（lobby）时，常导致比赛失衡，影响玩家体验。因此，亟需一种兼顾速度与公平性的新匹配机制。

Method: Cinder包含两个阶段：第一阶段利用Ruzicka相似指数快速比较队伍的“非异常值”技能范围进行初步筛选；第二阶段将玩家段位映射到由倒置正态分布生成的非线性技能桶中，并使用Kantorovich距离计算排序后的桶索引以得出“Sanction Score”作为公平性指标。

Result: 通过对1.4亿对模拟队伍配对的Sanction Score分布进行分析，验证了该系统能有效区分匹配质量，为设定公平匹配阈值提供了可靠依据。

Conclusion: Cinder系统在保证匹配速度的同时显著提升了公平性，尤其适用于技能分布异质性强的预组队场景，为在线多人游戏匹配系统提供了实用且可扩展的解决方案。

Abstract: A fair and fast matchmaking system is an important component of modern multiplayer online games, directly impacting player retention and satisfaction. However, creating fair matches between lobbies (pre-made teams) of heterogeneous skill levels presents a significant challenge. Matching based simply on average team skill metrics, such as mean or median rating or rank, often results in unbalanced and one-sided games, particularly when skill distributions are wide or skewed. This paper introduces Cinder, a two-stage matchmaking system designed to provide fast and fair matches. Cinder first employs a rapid preliminary filter by comparing the "non-outlier" skill range of lobbies using the Ruzicka similarity index. Lobbies that pass this initial check are then evaluated using a more precise fairness metric. This second stage involves mapping player ranks to a non-linear set of skill buckets, generated from an inverted normal distribution, to provide higher granularity at average skill levels. The fairness of a potential match is then quantified using the Kantorovich distance on the lobbies' sorted bucket indices, producing a "Sanction Score." We demonstrate the system's viability by analyzing the distribution of Sanction Scores from 140 million simulated lobby pairings, providing a robust foundation for fair matchmaking thresholds.

</details>


### [70] [M2F: Automated Formalization of Mathematical Literature at Scale](https://arxiv.org/abs/2602.17016)
*Zichen Wang,Wanli Ma,Zhenyu Ming,Gong Zhang,Kun Yuan,Zaiwen Wen*

Main category: cs.AI

TL;DR: M2F 是首个支持端到端、项目级数学自动形式化的智能体框架，可在三周内将479页的数学教材转化为15万余行可编译的 Lean 代码，显著提升形式化效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动形式化方法局限于孤立定理或短片段，难以扩展至整本教材或研究论文，主要挑战包括跨文件依赖管理、导入解析和端到端可编译性。

Method: M2F 框架分两阶段工作：1）语句编译阶段，将文档拆分为原子块，按依赖排序并修复声明骨架直至项目可编译（允许证明占位符）；2）证明修复阶段，在固定签名下通过目标条件局部编辑填补证明空缺。整个过程持续调用验证器反馈，仅在确认改进后才提交修改。

Result: 在约三周内，M2F 成功将实分析与凸分析教材（共479页）转化为153,853行 Lean 代码，实现完整声明与证明的形式化；在 FATE-H 基准上达到96%的证明成功率（基线为80%）。

Conclusion: 该研究表明，大规模、实用的数学文献自动形式化已具备可行性，M2F 显著缩短了传统需数月甚至数年的人工形式化周期。

Abstract: Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects compile end-to-end. We present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization in Lean. The framework operates in two stages. The statement compilation stage splits the document into atomic blocks, orders them via inferred dependencies, and repairs declaration skeletons until the project compiles, allowing placeholders in proofs. The proof repair stage closes these holes under fixed signatures using goal-conditioned local edits. Throughout both stages, M2F keeps the verifier in the loop, committing edits only when toolchain feedback confirms improvement. In approximately three weeks, M2F converts long-form mathematical sources into a project-scale Lean library of 153,853 lines from 479 pages textbooks on real analysis and convex analysis, fully formalized as Lean declarations with accompanying proofs. This represents textbook-scale formalization at a pace that would typically require months or years of expert effort. On FATE-H, we achieve $96\%$ proof success (vs.\ $80\%$ for a strong baseline). Together, these results demonstrate that practical, large-scale automated formalization of mathematical literature is within reach. The full generated Lean code from our runs is available at https://github.com/optsuite/ReasBook.git.

</details>


### [71] [Sales Research Agent and Sales Research Bench](https://arxiv.org/abs/2602.17017)
*Deepanjan Bhol*

Main category: cs.AI

TL;DR: 微软Dynamics 365 Sales中的Sales Research Agent是一个连接实时CRM数据的AI系统，通过新提出的Sales Research Bench基准，在多个维度上显著优于Claude Sonnet 4.5和ChatGPT-5。


<details>
  <summary>Details</summary>
Motivation: 企业需要能基于实时、定制化CRM数据回答销售问题的AI系统，但现有模型缺乏透明、可重复的质量评估证据。

Method: 构建Sales Research Agent，使其能连接实时CRM及相关数据，理解复杂数据结构，并生成文本与图表形式的决策洞察；同时开发Sales Research Bench基准，从八个客户关注维度（如文本/图表事实性、相关性、可解释性等）对系统进行评分。

Result: 在2025年10月19日针对一个定制企业数据结构的200个问题测试中，Sales Research Agent在100分综合得分上比Claude Sonnet 4.5高13分，比ChatGPT-5高24.1分。

Conclusion: Sales Research Bench为客户提供了一种可重复、透明的方式，用于比较不同AI解决方案在真实业务场景下的质量表现。

Abstract: Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. To make quality observable, we introduce the Sales Research Bench, a purpose-built benchmark that scores systems on eight customer-weighted dimensions, including text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question run on a customized enterprise schema on October 19, 2025, the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score, giving customers a repeatable way to compare AI solutions.

</details>


### [72] [Dynamic System Instructions and Tool Exposure for Efficient Agentic LLMs](https://arxiv.org/abs/2602.17046)
*Uria Franko*

Main category: cs.AI

TL;DR: 提出指令-工具检索（ITR）方法，通过每步动态检索最小必要指令片段和工具子集，显著降低上下文长度、成本和工具选择错误，提升长程智能体效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体在每轮执行中重复加载完整系统指令和庞大工具目录，导致高成本、高延迟、易偏离目标及工具选择错误，尤其在多步任务中问题加剧。

Method: 设计一种基于RAG的Instruction-Tool Retrieval（ITR）机制，在每一步仅检索当前所需最小系统提示片段和最小子集工具，构建动态运行时系统提示，并结合置信度门控回退策略提供精简工具集。

Result: 在控制基准测试中，ITR相比单体基线减少95%每步上下文token，工具路由准确率相对提升32%，端到端任务成本降低70%，并支持智能体在上下文限制内运行2–20倍更多循环。

Conclusion: ITR有效缓解了长程LLM智能体的资源消耗与错误累积问题，其收益随步骤数增加而放大，适用于需长期自主运行的智能体系统，具备实际部署价值。

Abstract: Large Language Model (LLM) agents often run for many steps while re-ingesting long system instructions and large tool catalogs each turn. This increases cost, agent derailment probability, latency, and tool-selection errors. We propose Instruction-Tool Retrieval (ITR), a RAG variant that retrieves, per step, only the minimal system-prompt fragments and the smallest necessary subset of tools. ITR composes a dynamic runtime system prompt and exposes a narrowed toolset with confidence-gated fallbacks. Using a controlled benchmark with internally consistent numbers, ITR reduces per-step context tokens by 95%, improves correct tool routing by 32% relative, and cuts end-to-end episode cost by 70% versus a monolithic baseline. These savings enable agents to run 2-20x more loops within context limits. Savings compound with the number of agent steps, making ITR particularly valuable for long-running autonomous agents. We detail the method, evaluation protocol, ablations, and operational guidance for practical deployment.

</details>


### [73] [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049)
*Seoyoung Lee,Seobin Yoon,Seongbeen Lee,Yoojung Chun,Dayoung Park,Doyeon Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: IntentCUA 是一个基于多智能体的计算机使用框架，通过意图对齐的计划记忆机制提升长周期任务的执行稳定性与效率，在端到端评估中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用智能体在长周期任务中易偏离用户意图、重复解决常规子问题，导致错误累积和效率低下。

Method: 提出 IntentCUA 框架，包含 Planner、Plan-Optimizer 和 Critic 三个协同智能体，利用共享记忆将原始交互抽象为多视角意图表示和可复用技能，并在运行时通过意图原型检索对齐技能以优化部分计划。

Result: 在端到端评估中，IntentCUA 达到 74.83% 的任务成功率和 0.91 的步骤效率比，显著优于基于强化学习和轨迹检索的基线方法；消融实验表明多视角意图抽象与共享计划记忆共同提升执行稳定性。

Conclusion: 系统级的意图抽象与基于记忆的多智能体协同是实现大规模动态环境中可靠高效桌面自动化的关键。

Abstract: Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.

</details>


### [74] [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062)
*Yonghyeon Jo,Sunwoo Lee,Seungyul Han*

Main category: cs.AI

TL;DR: 本文提出Successive Sub-value Q-learning (S2Q)，通过学习多个子价值函数以保留高价值的备选动作，从而提升多智能体强化学习在价值函数变化时的适应能力与整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于价值分解的多智能体强化学习方法依赖单一最优动作，在训练过程中难以适应价值函数的变化，易收敛至次优策略。

Method: S2Q学习多个子价值函数，并将其整合进基于Softmax的行为策略中，以促进持续探索，并使全局价值函数$Q^{\text{tot}}$能快速适应变化的最优解。

Result: 在多个具有挑战性的MARL基准测试中，S2Q一致优于多种现有MARL算法，展现出更强的适应性和整体性能。

Conclusion: 通过保留多个高价值动作并动态调整策略，S2Q有效解决了现有方法在价值函数变化下的适应性不足问题，为合作型多智能体强化学习提供了新思路。

Abstract: Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\text{tot}}$ to adjust quickly to the changing optima. Experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance. Our code is available at https://github.com/hyeon1996/S2Q.

</details>


### [75] [Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization](https://arxiv.org/abs/2602.17066)
*Sumedh Rasal*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce Predictive Batch Scheduling (PBS), a novel training optimization technique that accelerates language model convergence by dynamically prioritizing high-loss samples during batch construction. Unlike curriculum learning approaches that require predefined difficulty metrics or hard example mining methods that demand expensive per-sample loss tracking, PBS employs a lightweight linear predictor trained online to estimate sample difficulty from static token-level features. Our predictor achieves 0.44 correlation with actual loss using only four simple features: token frequency, sequence length, vocabulary diversity, and rare token ratio. Experiments on a 130M parameter transformer demonstrate that PBS achieves 6-13\% faster convergence measured by evaluation loss across training checkpoints, with the predictor's correlation improving from 0.14 to 0.44 over 10,000 training steps. These results validate that token frequency statistics encode meaningful information about sample difficulty, enabling effective curriculum learning with negligible computational overhead.

</details>


### [76] [Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction](https://arxiv.org/abs/2602.17106)
*Xiaoran Cai,Wang Yang,Xiyu Ren,Chekun Law,Rohit Sharma,Peng Qi*

Main category: cs.AI

TL;DR: 本文提出一种人机协作框架（包含STRIDE和SR-Delta两部分），利用大语言模型构建可持续性评级的可信基准数据集，以解决不同ESG评级机构间评分差异大的问题，提升评级方法的可比性与可信度。


<details>
  <summary>Details</summary>
Motivation: 当前不同ESG评级机构对同一公司的评分差异显著，削弱了评级结果的可比性、可信度及其在决策中的实用性，亟需统一标准以提升评级质量。

Method: 提出一个通用的人机协作框架：其中STRIDE利用大语言模型，基于原则性标准构建公司层面的基准数据集；SR-Delta则通过差异分析流程，揭示评级方法可能需要调整的洞见。

Result: 该框架支持对不同可持续性评级方法进行可扩展且可比较的评估，有助于生成高质量、一致性强的基准数据。

Conclusion: 呼吁AI社区采用AI驱动的方法改进可持续性评级体系，以支持并推动紧迫的可持续发展议程。

Abstract: Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluating sustainability rating methodologies. The framework comprises two complementary parts: STRIDE (Sustainability Trust Rating & Integrity Data Equation) provides principled criteria and a scoring system that guide the construction of firm-level benchmark datasets using large language models (LLMs), and SR-Delta, a discrepancy-analysis procedural framework that surfaces insights for potential adjustments. The framework enables scalable and comparable assessment of sustainability rating methodologies. We call on the broader AI community to adopt AI-powered approaches to strengthen and advance sustainability rating methodologies that support and enforce urgent sustainability agendas.

</details>


### [77] [Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)](https://arxiv.org/abs/2602.17107)
*Xiangyu Zhou,Chenhan Xiao,Yang Weng*

Main category: cs.AI

TL;DR: 本文提出一种满足T-性质的新分割方法，用于改进Owen值在特征归因中的语义一致性和计算效率，从而提升SHAP在图像和表格数据上的解释性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Shapley值的XAI方法在视觉任务中因忽略像素间的空间与语义依赖而受限；尽管Owen值支持分组归因，但其效果高度依赖于特征分组方式，而常用分割方法（如轴对齐或SLIC）无法满足一致性要求。

Method: 提出一种满足T-性质的新分割策略，构建语义对齐的层次结构，使Owen值在保持理论基础的同时实现计算剪枝与更准确的归因。

Result: 在图像和表格数据集上的实验表明，所提方法O-Shap在归因精度、语义连贯性和运行效率方面均优于现有SHAP变体，尤其在数据具有结构性时表现更佳。

Conclusion: 通过设计满足一致性条件的层次化特征分组，可显著提升基于Owen值的解释方法的准确性与效率，为结构化数据提供更可靠的XAI解决方案。

Abstract: Shapley value-based methods have become foundational in explainable artificial intelligence (XAI), offering theoretically grounded feature attributions through cooperative game theory. However, in practice, particularly in vision tasks, the assumption of feature independence breaks down, as features (i.e., pixels) often exhibit strong spatial and semantic dependencies. To address this, modern SHAP implementations now include the Owen value, a hierarchical generalization of the Shapley value that supports group attributions. While the Owen value preserves the foundations of Shapley values, its effectiveness critically depends on how feature groups are defined. We show that commonly used segmentations (e.g., axis-aligned or SLIC) violate key consistency properties, and propose a new segmentation approach that satisfies the $T$-property to ensure semantic alignment across hierarchy levels. This hierarchy enables computational pruning while improving attribution accuracy and interpretability. Experiments on image and tabular datasets demonstrate that O-Shap outperforms baseline SHAP variants in attribution precision, semantic coherence, and runtime efficiency, especially when structure matters.

</details>


### [78] [Instructor-Aligned Knowledge Graphs for Personalized Learning](https://arxiv.org/abs/2602.17111)
*Abdulrahman AlRabah,Priyanka Kargupta,Jiawei Han,Abdussalam Alawini*

Main category: cs.AI

TL;DR: 本文提出InstructKG框架，通过自动从课程讲义中构建知识图谱，捕捉教学概念间的依赖关系，以支持个性化学习。


<details>
  <summary>Details</summary>
Motivation: 在大规模课程中，教师难以诊断每位学生的知识漏洞，而现有知识图谱方法要么过于表面化，要么忽略教学材料中的丰富教学信号，因此需要一种能准确反映教学意图的知识图谱构建方法。

Method: InstructKG利用课程讲义（如幻灯片、笔记）提取关键概念作为节点，并结合教育材料中的时序与语义信号（如概念讲授顺序、定义中的引用关系）以及大语言模型的泛化能力，推断出“部分-整体”或“依赖”等有向边，构建与教师意图一致的知识图谱。

Result: 在多个真实课程的多样化讲义材料上进行实验，并通过人工评估验证，InstructKG能够有效捕捉丰富且符合教师教学意图的学习进阶路径。

Conclusion: InstructKG为大规模课程提供了一种自动化、可扩展的方法，以构建反映教学设计的知识图谱，从而支持精准识别学生知识缺口并实现个性化干预。

Abstract: Mastering educational concepts requires understanding both their prerequisites (e.g., recursion before merge sort) and sub-concepts (e.g., merge sort as part of sorting algorithms). Capturing these dependencies is critical for identifying students' knowledge gaps and enabling targeted intervention for personalized learning. This is especially challenging in large-scale courses, where instructors cannot feasibly diagnose individual misunderstanding or determine which concepts need reinforcement. While knowledge graphs offer a natural representation for capturing these conceptual relationships at scale, existing approaches are either surface-level (focusing on course-level concepts like "Algorithms" or logistical relationships such as course enrollment), or disregard the rich pedagogical signals embedded in instructional materials. We propose InstructKG, a framework for automatically constructing instructor-aligned knowledge graphs that capture a course's intended learning progression. Given a course's lecture materials (slides, notes, etc.), InstructKG extracts significant concepts as nodes and infers learning dependencies as directed edges (e.g., "part-of" or "depends-on" relationships). The framework synergizes the rich temporal and semantic signals unique to educational materials (e.g., "recursion" is taught before "mergesort"; "recursion" is mentioned in the definition of "merge sort") with the generalizability of large language models. Through experiments on real-world, diverse lecture materials across multiple courses and human-based evaluation, we demonstrate that InstructKG captures rich, instructor-aligned learning progressions.

</details>


### [79] [Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances](https://arxiv.org/abs/2602.17130)
*Victor Kondratiev,Irina Gribanova,Alexander Semenov*

Main category: cs.AI

TL;DR: 提出了一种用于分解困难CircuitSAT实例的新型并行算法，通过特制约束将原问题划分为多个弱化子公式，并利用并行计算的难度估计高效搜索高质量分解。


<details>
  <summary>Details</summary>
Motivation: 解决CircuitSAT中硬实例难以处理的问题，提升逻辑等价性验证和密码哈希函数前像攻击等实际应用中的求解效率。

Method: 设计一种参数化的并行算法，利用专门的约束对原始SAT实例进行划分，生成一族弱化公式，并通过并行计算的硬度估计指导参数调整以寻找优质分解。

Result: 在包括布尔电路逻辑等价性检查和密码哈希函数前像攻击在内的困难CircuitSAT实例上验证了算法的有效性。

Conclusion: 该并行分解方法能有效提升对复杂CircuitSAT问题的处理能力，具有良好的实际应用前景。

Abstract: We propose a novel parallel algorithm for decomposing hard CircuitSAT instances. The technique employs specialized constraints to partition an original SAT instance into a family of weakened formulas. Our approach is implemented as a parameterized parallel algorithm, where adjusting the parameters allows efficient identification of high-quality decompositions, guided by hardness estimations computed in parallel. We demonstrate the algorithm's practical efficacy on challenging CircuitSAT instances, including those encoding Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions.

</details>


### [80] [JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.17162)
*Ariel Larey,Elay Dahan,Amit Bleiweiss,Raizy Kellerman,Guy Leib,Omri Nayshool,Dan Ofer,Tal Zinger,Dan Dominissini,Gideon Rechavi,Nicole Bussola,Simon Lee,Shane O'Connell,Dung Hoang,Marissa Wirth,Alexander W. Charney,Nati Daniel,Yoli Shavit*

Main category: cs.AI

TL;DR: JEPA-DNA 是一种新型基因组预训练框架，结合了联合嵌入预测架构（JEPA）与传统生成目标，通过在潜在空间中引入对 CLS token 的监督，使模型不仅恢复局部核苷酸，还能预测被掩码片段的高阶功能嵌入，从而提升在多种基因组任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基因组基础模型（如基于 MLM 或 NTP 的方法）擅长捕捉局部序列模式，但缺乏对基因组整体功能语境的理解，导致表征缺乏生物学全局视角。

Method: 提出 JEPA-DNA 框架，将 JEPA 与生成式目标结合，在 token 级恢复基础上增加潜在空间中的预测目标，通过监督 CLS token 来预测被掩码片段的高阶功能嵌入；该方法可独立使用或作为现有 GFM 的持续预训练增强。

Result: 在多个基因组基准测试中，JEPA-DNA 在监督和零样本任务上均优于仅使用生成目标的基线模型。

Conclusion: JEPA-DNA 提供了一种更稳健、更具生物学意义的表征学习路径，有助于构建不仅理解基因组“字母”，还能理解其功能逻辑的基础模型。

Abstract: Genomic Foundation Models (GFMs) have largely relied on Masked Language Modeling (MLM) or Next Token Prediction (NTP) to learn the language of life. While these paradigms excel at capturing local genomic syntax and fine-grained motif patterns, they often fail to capture the broader functional context, resulting in representations that lack a global biological perspective. We introduce JEPA-DNA, a novel pre-training framework that integrates the Joint-Embedding Predictive Architecture (JEPA) with traditional generative objectives. JEPA-DNA introduces latent grounding by coupling token-level recovery with a predictive objective in the latent space by supervising a CLS token. This forces the model to predict the high-level functional embeddings of masked genomic segments rather than focusing solely on individual nucleotides. JEPA-DNA extends both NTP and MLM paradigms and can be deployed either as a standalone from-scratch objective or as a continual pre-training enhancement for existing GFMs. Our evaluations across a diverse suite of genomic benchmarks demonstrate that JEPA-DNA consistently yields superior performance in supervised and zero-shot tasks compared to generative-only baselines. By providing a more robust and biologically grounded representation, JEPA-DNA offers a scalable path toward foundation models that understand not only the genomic alphabet, but also the underlying functional logic of the sequence.

</details>


### [81] [Texo: Formula Recognition within 20M Parameters](https://arxiv.org/abs/2602.17189)
*Sicheng Mao*

Main category: cs.AI

TL;DR: Texo 是一个仅含 2000 万参数的轻量级高性能公式识别模型，在显著减小模型体积的同时，性能媲美当前最先进的模型，并支持在普通硬件和浏览器中实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有公式识别模型通常参数量大、计算资源需求高，难以在消费级设备或浏览器中部署。因此，亟需一种轻量但高效的模型以提升可用性和可访问性。

Method: 通过精心设计模型结构，并结合词汇表与分词器的知识蒸馏和迁移技术，构建了名为 Texo 的轻量级模型。

Result: Texo 在模型大小分别减少 80% 和 65% 的情况下，性能与 UniMERNet-T 和 PPFormulaNet-S 相当，并成功实现了在浏览器中的实时推理。

Conclusion: Texo 在保持高性能的同时大幅降低模型复杂度，为公式识别任务提供了高效、实用的解决方案，适用于资源受限环境。

Abstract: In this paper we present Texo, a minimalist yet highperformance formula recognition model that contains only 20 million parameters. By attentive design, distillation and transfer of the vocabulary and the tokenizer, Texo achieves comparable performance to state-of-the-art models such as UniMERNet-T and PPFormulaNet-S, while reducing the model size by 80% and 65%, respectively. This enables real-time inference on consumer-grade hardware and even in-browser deployment. We also developed a web application to demonstrate the model capabilities and facilitate its usage for end users.

</details>


### [82] [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221)
*Yi-Chih Huang*

Main category: cs.AI

TL;DR: 本文提出一种基于AI Agent的协作研究工作流（Agentic Workflow），用于人文与社会科学领域，并以台湾Claude.ai使用数据（N=7,729）作为实证案例，验证该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI研究多集中于软件工程与自然科学，缺乏针对人文与社会科学的方法论探索。因此，本文旨在填补这一空白，设计适用于人文学科的AI协作研究方法。

Method: 构建一个七阶段模块化工作流，基于任务模块化、人机分工与可验证性三大原则，明确人类研究者（负责研究判断与伦理决策）与AI Agent（负责信息检索与文本生成）的角色，并通过分析Anthropic经济指数（AEI）中的台湾对话数据进行实证演示。

Result: 成功展示了该工作流在二手数据研究中的应用过程与产出质量，并归纳出三种人机协作操作模式：直接执行、迭代优化与人类主导，强调人类在研究问题设定、理论诠释、情境推理与伦理反思中的不可替代性。

Conclusion: 本研究提供了一个可复制的AI协作框架，适用于人文与社会科学，并揭示了人机协作中人类判断的核心价值，同时指出单一平台数据、横断面设计及AI可靠性等局限。

Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.
  This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).
  This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.

</details>


### [83] [Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight](https://arxiv.org/abs/2602.17222)
*Ben Yellin,Ehud Ezra,Mark Foreman,Shula Grinapol*

Main category: cs.AI

TL;DR: 本文提出大型行为模型（LBM），通过基于结构化心理特质嵌入而非提示工程，显著提升对个体在高风险情境中战略决策的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在预测个体特定行为时存在身份漂移和难以利用详细人格描述的问题，尤其在心理特质与情境约束复杂交互时表现不佳。

Method: LBM 采用行为嵌入方法，基于全面的心理测量问卷构建高维结构化特质档案，并在包含稳定倾向、动机状态、情境约束与实际选择的专有数据集上微调模型。

Result: 在保留场景评估中，LBM 相较于原始 Llama-3.1-8B-Instruct 模型显著提升预测性能，且在使用大五人格特质时可媲美前沿基线；同时，其性能随特质维度增加而持续提升，突破了提示方法的复杂性上限。

Conclusion: LBM 为高保真行为模拟提供了一种可扩展方案，在战略预判、谈判分析、认知安全和决策支持等领域具有应用潜力。

Abstract: Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate prediction depends on complex interactions between psychological traits and situational constraints. Prompting-based approaches can be brittle in this setting, exhibiting identity drift and limited ability to leverage increasingly detailed persona descriptions. To address these limitations, we introduce the Large Behavioral Model (LBM), a behavioral foundation model fine-tuned to predict individual strategic choices with high fidelity. LBM shifts from transient persona prompting to behavioral embedding by conditioning on a structured, high-dimensional trait profile derived from a comprehensive psychometric battery. Trained on a proprietary dataset linking stable dispositions, motivational states, and situational constraints to observed choices, LBM learns to map rich psychological profiles to discrete actions across diverse strategic dilemmas. In a held-out scenario evaluation, LBM fine-tuning improves behavioral prediction relative to the unadapted Llama-3.1-8B-Instruct backbone and performs comparably to frontier baselines when conditioned on Big Five traits. Moreover, we find that while prompting-based baselines exhibit a complexity ceiling, LBM continues to benefit from increasingly dense trait profiles, with performance improving as additional trait dimensions are provided. Together, these results establish LBM as a scalable approach for high-fidelity behavioral simulation, enabling applications in strategic foresight, negotiation analysis, cognitive security, and decision support.

</details>


### [84] [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234)
*Zeyu Zhang,Ryan Chen,Bradly C. Stadie*

Main category: cs.AI

TL;DR: 本文提出了一种检测和量化大语言模型（LLM）在回溯性预测中时间知识泄露的方法，并引入了基于Shapley值的可解释指标Shapley-DCLR，以及一种新的时间监督预测方法TimeSPEC，以减少泄露并保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 为确保LLM在回溯测试中仅使用截止日期前的信息进行预测，避免训练中编码的未来知识泄露影响评估有效性，需建立有效机制检测和控制此类时间知识泄露。

Method: 将模型推理分解为原子声明，按时间可验证性分类，并利用Shapley值衡量各声明对预测的贡献，从而定义Shapley-DCLR指标；进一步提出TimeSPEC方法，在生成过程中穿插声明验证与重生成，过滤时间污染。

Result: 在350个涵盖美国最高法院案件预测、NBA薪资估算和股票收益排序的实例上，标准提示方法存在显著时间泄露；TimeSPEC在降低Shapley-DCLR的同时保持了任务性能。

Conclusion: 显式的、可解释的声明级验证机制优于基于提示的时间约束方法，能更可靠地支持LLM的回溯性评估。

Abstract: To evaluate whether LLMs can accurately predict future events, we need the ability to \textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded during training, undermining the validity of retrospective evaluation. We introduce a claim-level framework for detecting and quantifying this \emph{temporal knowledge leakage}. Our approach decomposes model rationales into atomic claims and categorizes them by temporal verifiability, then applies \textit{Shapley values} to measure each claim's contribution to the prediction. This yields the \textbf{Shapley}-weighted \textbf{D}ecision-\textbf{C}ritical \textbf{L}eakage \textbf{R}ate (\textbf{Shapley-DCLR}), an interpretable metric that captures what fraction of decision-driving reasoning derives from leaked information. Building on this framework, we propose \textbf{Time}-\textbf{S}upervised \textbf{P}rediction with \textbf{E}xtracted \textbf{C}laims (\textbf{TimeSPEC}), which interleaves generation with claim verification and regeneration to proactively filter temporal contamination -- producing predictions where every supporting claim can be traced to sources available before the cutoff date. Experiments on 350 instances spanning U.S. Supreme Court case prediction, NBA salary estimation, and stock return ranking reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, demonstrating that explicit, interpretable claim-level verification outperforms prompt-based temporal constraints for reliable backtesting.

</details>


### [85] [ArXiv-to-Model: A Practical Study of Scientific LM Training](https://arxiv.org/abs/2602.17288)
*Anuj Gupta*

Main category: cs.AI

TL;DR: 本文详细记录了从原始arXiv LaTeX源码训练一个13.6亿参数科学语言模型的全过程，涵盖数据预处理、训练流程与资源限制下的实践经验。


<details>
  <summary>Details</summary>
Motivation: 当前前沿大语言模型虽具强大推理能力，但缺乏从原始科研文献（如arXiv）端到端训练领域专用科学语言模型的实操指南，尤其在有限算力条件下。作者旨在填补这一工程实践空白。

Method: 构建端到端训练流程：包括元数据过滤、压缩包验证、LaTeX提取、文本归一化、领域感知分词，并在2块A100 GPU上训练1.36B参数的密集Transformer模型；通过24次实验分析训练稳定性、扩展性、数据损耗及基础设施瓶颈。

Result: 发现预处理策略显著影响可用token数量，分词方式影响符号表达稳定性，且存储与I/O常成为与计算同等重要的瓶颈；在52B预训练token下实现稳定收敛。

Conclusion: 本研究未提出新架构，而是提供了一个透明、工程导向的小规模科学语言模型从零训练的完整案例，为中等算力预算的研究者构建领域专用模型提供实用参考。

Abstract: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.

</details>


### [86] [Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature](https://arxiv.org/abs/2602.17385)
*Angelo Porrello,Pietro Buzzega,Felix Dangel,Thomas Sommariva,Riccardo Salami,Lorenzo Bonicelli,Simone Calderara*

Main category: cs.AI

TL;DR: 本文提出了一种无需数据的正则化方法，通过将表示漂移正则化建模为曲率矩阵近似问题，有效缓解任务向量组合中的表示漂移问题，在任务加法和减法中达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 任务算术（Task Arithmetic）在组合多个任务向量时可能引发跨任务干扰，导致表示漂移和性能下降。现有正则化方法通常依赖外部任务数据，违背了模块化和数据可用性（如隐私）的要求。

Method: 将表示漂移的正则化问题转化为曲率矩阵近似问题，采用Kronecker-Factored Approximate Curvature（K-FAC）技术构建一种无需外部数据的实用正则项。

Result: 所提方法在任务加法和任务减法任务中达到当前最优性能，具有与任务数量无关的恒定计算复杂度，并对任务向量缩放具有鲁棒性，无需保留验证集进行调参。

Conclusion: 该方法在不依赖外部数据的前提下有效缓解表示漂移，提升了任务算术的模块性、可扩展性和实用性。

Abstract: Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; however, existing approaches typically require external task data, conflicting with modularity and data availability constraints (e.g., privacy requirements). We propose a dataless approach by framing regularization against representation drift as a curvature matrix approximation problem. This allows us to leverage well-established techniques; in particular, we adopt Kronecker-Factored Approximate Curvature and obtain a practical regularizer that achieves state-of-the-art results in task addition and negation. Our method has constant complexity in the number of tasks and promotes robustness to task vector rescaling, eliminating the need for held-out tuning.

</details>


### [87] [Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval](https://arxiv.org/abs/2602.17386)
*Adrià Molina,Oriol Ramos Terrades,Josep Lladós*

Main category: cs.AI

TL;DR: 本文提出一种将形式化验证与深度学习图像检索相结合的新框架，通过图验证与神经代码生成协同工作，提升对复杂自然语言查询的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于嵌入的检索方法在处理涉及复杂关系、对象组合或精确约束（如身份、数量、比例）的自然语言查询时仍存在不可靠问题，缺乏可验证性和透明度。

Method: 结合图结构的形式化验证方法与神经代码生成技术，将用户查询中的原子事实与检索结果进行显式验证，支持开放词汇查询并标记满足/未满足的约束条件。

Result: 该框架不仅提升了主流嵌入式检索方法的性能，还能提供可验证、可解释的检索结果，明确指出哪些查询条件被满足、哪些未被满足。

Conclusion: 通过引入形式化验证机制，该方法超越了传统向量表示的模糊性与近似性，实现了更可靠、透明和可问责的信息检索。

Abstract: Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.

</details>


### [88] [A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities](https://arxiv.org/abs/2602.17402)
*Michele Zanitti,Vanja Miskovic,Francesco Trovò,Alessandra Laura Giulia Pedrocchi,Ming Shen,Yan Kyaw Tun,Arsela Prelaj,Sokol Kosta*

Main category: cs.AI

TL;DR: 本文提出了一种多模态对比变分自编码器（MCVAE），用于在存在严重模态缺失的情况下预测非小细胞肺癌患者的生存结果，通过引入模态特定的变分编码器、带门控机制的融合瓶颈以及多任务和对比损失，在TCGA数据集上验证了其优越性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于个体预后特征差异大，且真实临床数据常存在整模态缺失，现有方法在严重缺失情况下缺乏鲁棒性，因此需要一种能有效处理任意缺失模式并整合多模态信息的模型。

Method: 提出MCVAE模型：使用模态特定的变分编码器建模不确定性；通过带学习门控机制的融合瓶颈归一化各模态贡献；结合生存损失、重构损失和跨模态对比损失进行多任务训练；并在训练中采用随机模态掩蔽以增强对缺失模式的鲁棒性。

Result: 在TCGA-LUAD（n=475）和TCGA-LUSC（n=446）数据集上的实验表明，该方法在疾病特异性生存预测方面优于两种先进模型，并在严重模态缺失情况下表现出更强的鲁棒性；此外，对所有模态子集的测试发现多模态整合并非总是有益。

Conclusion: MCVAE能有效应对多模态数据中的严重缺失问题，提升生存预测性能，同时揭示了多模态整合需根据具体任务谨慎评估其有效性。

Abstract: Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's condition at diagnosis. However, real-world clinical datasets are often incomplete, with entire modalities missing for a significant fraction of patients. State-of-the-art models rely on available data to create patient-level representations or use generative models to infer missing modalities, but they lack robustness in cases of severe missingness. We propose a Multimodal Contrastive Variational AutoEncoder (MCVAE) to address this issue: modality-specific variational encoders capture the uncertainty in each data source, and a fusion bottleneck with learned gating mechanisms is introduced to normalize the contributions from present modalities. We propose a multi-task objective that combines survival loss and reconstruction loss to regularize patient representations, along with a cross-modal contrastive loss that enforces cross-modal alignment in the latent space. During training, we apply stochastic modality masking to improve the robustness to arbitrary missingness patterns. Extensive evaluations on the TCGA-LUAD (n=475) and TCGA-LUSC (n=446) datasets demonstrate the efficacy of our approach in predicting disease-specific survival (DSS) and its robustness to severe missingness scenarios compared to two state-of-the-art models. Finally, we bring some clarifications on multimodal integration by testing our model on all subsets of modalities, finding that integration is not always beneficial to the task.

</details>


### [89] [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418)
*Diana Addae,Diana Rogachova,Nafiseh Kahani,Masoud Barati,Michael Christensen,Chen Zhou*

Main category: cs.AI

TL;DR: 本文提出一个基于隐私设计（Privacy-by-Design）的框架，指导开发者在大型语言模型（LLM）全生命周期中整合儿童隐私保护原则与适龄设计指南，以满足GDPR、COPPA等法规要求，并通过教育类LLM案例展示其应用。


<details>
  <summary>Details</summary>
Motivation: 儿童越来越多地使用AI技术，但其隐私面临风险；现有法规虽要求提供保护，但在实践中实施困难，因此需要一个系统性框架来帮助开发者主动应对隐私挑战。

Method: 整合GDPR、PIPEDA、COPPA等隐私法规原则及UNCRC、AADC等儿童权利与适龄设计准则，将其映射到LLM应用的数据收集、模型训练、运行监控和持续验证四个阶段，并结合学术文献中的操作控制措施构建框架。

Result: 该框架为AI服务提供商和开发者提供了在LLM各阶段降低隐私风险、满足法律合规的具体操作指引，并通过一个面向13岁以下儿童的教育型LLM案例验证了其可行性。

Conclusion: 通过在整个LLM生命周期中采用技术和组织控制措施以及适龄设计决策，可有效支持开发既保护儿童隐私又符合法律要求的AI应用。

Abstract: Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in practice. To address this challenge, this article proposes a framework based on Privacy-by-Design (PbD), which guides designers and developers to take on a proactive and risk-averse approach to technology design. Our framework includes principles from several privacy regulations, such as the General Data Protection Regulation (GDPR) from the European Union, the Personal Information Protection and Electronic Documents Act (PIPEDA) from Canada, and the Children's Online Privacy Protection Act (COPPA) from the United States. We map these principles to various stages of applications that use Large Language Models (LLMs), including data collection, model training, operational monitoring, and ongoing validation. For each stage, we discuss the operational controls found in the recent academic literature to help AI service providers and developers reduce privacy risks while meeting legal standards. In addition, the framework includes design guidelines for children, drawing from the United Nations Convention on the Rights of the Child (UNCRC), the UK's Age-Appropriate Design Code (AADC), and recent academic research. To demonstrate how this framework can be applied in practice, we present a case study of an LLM-based educational tutor for children under 13. Through our analysis and the case study, we show that by using data protection strategies such as technical and organizational controls and making age-appropriate design decisions throughout the LLM life cycle, we can support the development of AI applications for children that provide privacy protections and comply with legal requirements.

</details>


### [90] [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)
*Marco Avolio,Potito Aghilar,Sabino Roccotelli,Vito Walter Anelli,Chiara Mallamaci,Vincenzo Paparella,Marco Valentini,Alejandro Bellogín,Michelantonio Trizio,Joseph Trotta,Antonio Ferrara,Tommaso Di Noia*

Main category: cs.AI

TL;DR: WarpRec 是一个高性能、后端无关的推荐系统框架，支持从本地到分布式环境的无缝迁移，集成了50多种算法、40项指标和19种数据划分策略，并引入能耗追踪以促进可持续研究，同时为面向智能体的生成式推荐系统提供架构支持。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统研究受阻于学术界与工业界生态割裂：研究者要么使用内存中实验工具（便捷但无法扩展），要么重写代码以适配复杂的分布式工业引擎（成本高）。亟需一个兼顾易用性、可扩展性与可持续性的统一框架。

Method: 提出 WarpRec 框架，采用后端无关架构，集成大量算法、评估指标与数据处理策略，支持本地与分布式训练无缝切换；整合 CodeCarbon 实现能耗监控；并设计面向 Agentic AI 与生成式 AI 的扩展能力。

Result: WarpRec 成功实现了算法在不同计算环境下的无缝迁移，验证了高性能与低能耗可兼得，并为未来智能体驱动的推荐系统提供了可行架构。

Conclusion: WarpRec 不仅弥合了学术研究与工业部署之间的鸿沟，还通过强调可持续性和对新一代 AI 范式的兼容性，为推荐系统的发展提供了新的基础设施方向。

Abstract: Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/

</details>


### [91] [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508)
*Pranay Jain,Maximilian Kasper,Göran Köber,Axel Plinge,Dominik Seuß*

Main category: cs.AI

TL;DR: 本文提出了一种针对ARM Cortex-M系列处理器（M0+、M4、M7）的AI模型优化基准测试框架，聚焦能效、准确率与资源利用，并通过帕累托分析指导嵌入式AI系统设计。


<details>
  <summary>Details</summary>
Motivation: 在嵌入式系统中部署AI模型需兼顾能效、精度与硬件资源，但缺乏系统性评估方法。本文旨在为开发者提供一种实用的基准测试框架，以指导在不同Cortex-M处理器上选择最优AI模型配置。

Method: 设计自动化测试平台，系统评估关键性能指标（KPIs），分析浮点运算次数（FLOPs）与推理时间的关系，并采用帕累托分析权衡能耗与模型精度。

Result: 发现FLOPs与推理时间呈近似线性关系；M7适合短推理任务，M4在长推理任务中能效更优，M0+适用于简单模型。帕累托分析有效支持性能与可持续性的平衡。

Conclusion: 该框架为嵌入式AI系统开发提供了实用指导，帮助在真实应用场景中实现高性能与高能效的协同优化。

Abstract: This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic approach to evaluate across key performance indicators (KPIs) and identify optimal combinations of processor and AI model. The research highlights a nearlinear correlation between floating-point operations (FLOPs) and inference time, offering a reliable metric for estimating computational demands. Using Pareto analysis, we demonstrate how to balance trade-offs between energy consumption and model accuracy, ensuring that AI applications meet performance requirements without compromising sustainability. Key findings indicate that the M7 processor is ideal for short inference cycles, while the M4 processor offers better energy efficiency for longer inference tasks. The M0+ processor, while less efficient for complex AI models, remains suitable for simpler tasks. This work provides insights for developers, guiding them to design energy-efficient AI systems that deliver high performance in realworld applications.

</details>


### [92] [Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation](https://arxiv.org/abs/2602.17529)
*Dun Yuan,Hao Zhou,Xue Liu,Hao Chen,Yan Xin,Jianzhong,Zhang*

Main category: cs.AI

TL;DR: 本文提出KG-RAG框架，结合知识图谱与检索增强生成技术，提升大语言模型在电信领域的准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在电信领域因术语专业、标准复杂且不断演进，易产生幻觉，难以提供准确可靠输出。

Method: 将源自电信标准和技术文档的知识图谱与检索增强生成（RAG）相结合，通过结构化知识表示和动态事实检索来增强大语言模型。

Result: 在基准数据集上，KG-RAG相比标准RAG和纯LLM分别平均提升14.3%和21.6%的准确率。

Conclusion: KG-RAG能有效提升电信场景下大语言模型输出的准确性、可靠性和可解释性。

Abstract: Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowledge graphs (KGs) with retrieval-augmented generation (RAG) to enhance LLMs for telecom-specific tasks. In particular, the KG provides a structured representation of domain knowledge derived from telecom standards and technical documents, while RAG enables dynamic retrieval of relevant facts to ground the model's outputs. Such a combination improves factual accuracy, reduces hallucination, and ensures compliance with telecom specifications.Experimental results across benchmark datasets demonstrate that KG-RAG outperforms both LLM-only and standard RAG baselines, e.g., KG-RAG achieves an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models. These results highlight KG-RAG's effectiveness in producing accurate, reliable, and explainable outputs in complex telecom scenarios.

</details>


### [93] [Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](https://arxiv.org/abs/2602.17544)
*Shashank Aggarwal,Ram Vikas Mishra,Amit Awekar*

Main category: cs.AI

TL;DR: 本文提出在多智能体信息检索系统中，仅用任务准确率评估思维链（CoT）存在局限，因此引入可重用性与可验证性两个新指标，并通过Thinker-Executor框架进行评估，发现这些指标与传统准确率无显著相关性。


<details>
  <summary>Details</summary>
Motivation: 当前对思维链（CoT）的评估主要依赖目标任务的准确率，但该指标无法反映推理过程本身的质量或实用性，因此需要更全面的评估方法。

Method: 作者提出Thinker-Executor框架，将CoT生成与执行解耦，并定义两个新指标：可重用性（Executor能否复用Thinker的CoT）和可验证性（Executor能否基于CoT复现Thinker的答案）。在五个基准上对四种Thinker模型与十个Executor模型组成的委员会进行评估。

Result: 实验表明，可重用性与可验证性与标准准确率无明显相关性；且专用推理模型生成的CoT在可重用性和可验证性方面并不总是优于通用大语言模型（如Llama和Gemma）。

Conclusion: 当前基于准确率的排行榜在衡量推理能力方面存在盲点，应结合可重用性与可验证性等新指标以更全面地评估CoT质量。

Abstract: In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.

</details>


### [94] [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547)
*Yue Liu,Zhiyuan Hu,Flood Sung,Jiaheng Zhang,Bryan Hooi*

Main category: cs.AI

TL;DR: 本文提出KLong，一种开源大语言模型智能体，通过轨迹分割的监督微调（SFT）和渐进式强化学习（RL）训练方法，有效解决超长周期任务，在PaperBench等多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在处理超长周期任务时存在能力不足的问题，亟需一种能有效利用长轨迹数据并逐步提升任务解决能力的训练框架。

Method: 首先通过全面的SFT配方激活基础模型的基本智能体能力；然后构建名为Research-Factory的自动化数据生成管道，从研究论文中提取高质量训练轨迹；接着提出轨迹分割SFT方法，保留早期上下文并逐步截断后期内容；最后采用多阶段渐进式RL训练，逐步延长任务超时时间以提升长周期任务解决能力。

Result: KLong（106B）在PaperBench上超越Kimi K2 Thinking（1T）11.28%，并在SWE-bench Verified和MLE-bench等编码基准上展现出良好的泛化性能。

Conclusion: 所提出的KLong框架通过结合轨迹分割SFT与渐进式RL，显著提升了模型在超长周期任务上的表现和泛化能力，为未来智能体训练提供了有效路径。

Abstract: This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.

</details>


### [95] [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560)
*Hongjue Zhao,Haosen Sun,Jiangtao Kong,Xiaochang Li,Qineng Wang,Liwei Jiang,Qi Zhu,Tarek Abdelzaher,Yejin Choi,Manling Li,Huajie Shao*

Main category: cs.AI

TL;DR: 本文提出了一种基于常微分方程（ODE）的统一理论框架用于大语言模型（LLM）的激活操控对齐，并在此基础上开发了名为ODESteer的新方法，实现了多步自适应的激活操控，在多个对齐基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前激活操控方法缺乏统一的理论框架，且多采用单步操控，难以捕捉激活分布的复杂模式。为解决这些问题，作者希望构建一个理论基础更扎实、能支持多步自适应操控的新方法。

Method: 作者将传统激活加法解释为ODE解的一阶近似，并将寻找操控方向的问题转化为控制理论中的障碍函数设计问题。所提出的ODESteer方法通过定义正负激活的对数密度比作为障碍函数，构建ODE以实现多步自适应的激活操控。

Result: ODESteer在多个LLM对齐基准上均取得一致提升，包括TruthfulQA（+5.7%）、UltraFeedback（+2.5%）和RealToxicityPrompts（+2.4%），优于当前最先进的激活操控方法。

Conclusion: 本工作通过ODE统一了激活操控的理论基础，并通过ODESteer方法在经验上验证了该框架的有效性，为LLM对齐提供了一个原则性更强的新视角。

Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \textit{(ii)} an over-reliance on \textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\%$ improvement over TruthfulQA, $2.5\%$ over UltraFeedback, and $2.4\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.

</details>


### [96] [A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN](https://arxiv.org/abs/2602.17566)
*Asif Hasan Chowdhury,Md. Fahim Islam,M Ragib Anjum Riad,Faiyaz Bin Hashem,Md Tanzim Reza,Md. Golam Rabiul Alam*

Main category: cs.AI

TL;DR: 本文提出了一种结合SWIN Transformer与CNN的混合联邦学习模型，用于基于X光图像的新冠肺炎和肺炎诊断，旨在提升诊断准确性并保障医疗数据安全。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力的提升，人工智能在医疗领域的应用潜力巨大；然而，医疗数据的隐私性和安全性限制了其共享与利用。因此，亟需一种既能保障数据隐私又能提高诊断准确性的方法。

Method: 该研究构建了一个融合SWIN Transformer与多种先进CNN模型（如DenseNet201、Inception V3、VGG19）的混合模型，并将其嵌入联邦学习框架中，实现分布式、安全的医疗数据处理与实时持续学习。

Result: 所提出的联邦学习混合AI模型在X光图像上实现了对新冠肺炎和肺炎的有效识别，同时通过联邦学习机制保障了数据隐私和模型安全性。

Conclusion: 该混合模型为医生提供了可靠的辅助诊断工具，展示了联邦学习与先进深度学习架构结合在提升疾病诊断准确性与保护患者数据隐私方面的巨大潜力。

Abstract: The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.

</details>


### [97] [AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games](https://arxiv.org/abs/2602.17594)
*Lance Ying,Ryan Truong,Prafull Sharma,Kaiya Ivy Zhao,Nathan Cloos,Kelsey R. Allen,Thomas L. Griffiths,Katherine M. Collins,José Hernández-Orallo,Phillip Isola,Samuel J. Gershman,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 本文提出通过评估AI在“人类游戏多元宇宙”中的表现来衡量其类人通用智能，并构建了AI GameStore平台，利用大语言模型与人类协作生成新的人类游戏用于评测。初步实验显示前沿视觉语言模型在多数游戏中远逊于人类。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试仅覆盖人类智能的狭窄方面且易被过拟合，难以有效评估AI的通用智能；因此需要一种更全面、动态且贴近人类能力的评估方式。

Method: 定义“人类游戏”为人类为人类设计的游戏，构建名为AI GameStore的开放式平台，结合大语言模型与人类反馈，从Apple App Store和Steam等平台自动提取并生成标准化、容器化的新游戏变体，用于评测AI系统。

Result: 在基于热门游戏生成的100个新游戏中，七个前沿视觉语言模型在大多数游戏中得分不足人类平均水平的10%，尤其在需要世界模型学习、记忆与规划能力的游戏中表现较差。

Conclusion: 以“人类游戏多元宇宙”为基础的AI GameStore可作为衡量和推动机器迈向类人通用智能的有效路径，未来需进一步扩展平台规模与多样性。

Abstract: Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a "human game" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the "Multiverse of Human Games". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.

</details>


### [98] [MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models](https://arxiv.org/abs/2602.17602)
*Hojung Jung,Rodrigo Hormazabal,Jaehyeong Jo,Youngrok Park,Kyunggeun Roh,Se-Young Yun,Sehui Han,Dae-Woong Jeong*

Main category: cs.AI

TL;DR: MolHIT是一种基于分层离散扩散模型的新型分子图生成框架，首次在图扩散模型中实现接近完美的化学有效性，并在MOSES数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有分子图扩散模型存在化学有效性低、难以满足目标性质等问题，限制了其在药物发现和材料科学中的应用。

Method: 提出MolHIT框架，采用分层离散扩散模型，将离散扩散推广到包含化学先验的更多类别，并引入解耦原子编码，根据原子的化学角色拆分原子类型。

Result: 在MOSES数据集上实现接近100%的化学有效性，超越多个强1D基线模型，并在多属性引导生成和骨架扩展等下游任务中表现优异。

Conclusion: MolHIT显著提升了图扩散模型在分子生成中的性能，为AI驱动的分子设计提供了更有效和可靠的工具。

Abstract: Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.

</details>


### [99] [CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts](https://arxiv.org/abs/2602.17663)
*Juri Opitz,Corina Raclé,Emanuela Boros,Andrianos Michail,Matteo Romanello,Maud Ehrmann,Simon Clematide*

Main category: cs.AI

TL;DR: HIPE-2026 是一个专注于从多语言、噪声历史文本中提取人物—地点关系的 CLEF 评测任务，扩展了 HIPE 系列至语义关系抽取，要求系统识别“曾到过”（at）和“出版时所在”（isAt）两类关系，并通过准确性、计算效率和领域泛化能力三方面进行评估。


<details>
  <summary>Details</summary>
Motivation: 历史文献中蕴含丰富的人物与地点关联信息，但其多语言、含噪声及时间跨度大等特点给自动关系抽取带来挑战。现有工作多聚焦于命名实体识别，缺乏对语义关系（尤其是涉及时空推理的关系）的系统研究。HIPE-2026 旨在推动该方向的发展，以支持数字人文中的知识图谱构建等下游应用。

Method: 组织评测任务，提供多语言历史文本数据集，要求参与系统对预标注的人物—地点对分类为 at 或 isAt 关系；引入包含准确性、计算效率和跨领域泛化能力的三重评估框架。

Result: 成功构建并发布了用于人物—地点关系抽取的多语言历史文本评测基准，明确了 at 与 isAt 两类关系的定义，并建立了兼顾性能、效率与泛化的新评估范式。

Conclusion: HIPE-2026 推动了历史文本中语义关系抽取的研究，为数字人文领域的大规模历史数据分析提供了方法支持和评估标准，有助于促进知识图谱构建与历史传记重建等应用的发展。

Abstract: HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ ("Has the person ever been at this place?") and $isAt$ ("Is the person located at this place around publication time?") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.

</details>
