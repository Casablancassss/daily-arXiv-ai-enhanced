<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.CG](#cs.CG) [Total: 1]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models](https://arxiv.org/abs/2602.02537)
*Runjie Zhou,Youbo Shao,Haoyu Lu,Bowei Xing,Tongtong Bai,Yujie Chen,Jie Zhao,Lin Sui,Haotian Yao,Zijia Zhao,Hao Yang,Haoning Wu,Zaida Zhou,Jinguo Zhu,Zhiqi Huang,Yiping Bao,Yangyang Liu,Y. Charles,Xinyu Zhou*

Main category: cs.CV

TL;DR: WorldVQA 是一个用于评估多模态大语言模型（MLLMs）原子级视觉世界知识的新基准，通过解耦知识检索与推理能力，专注于衡量模型对视觉实体的记忆能力。


<details>
  <summary>Details</summary>
Motivation: 当前的评估方法常将视觉知识检索与推理混为一谈，难以准确衡量模型真正“记住”的视觉知识。因此，作者提出 WorldVQA 以严格评估模型在视觉事实性方面的表现。

Method: WorldVQA 构建了一个分层分类体系，涵盖从常见头部类别到长尾稀有类别的视觉实体，要求模型进行视觉实体的定位与命名，从而测试其原子级视觉知识。

Result: 该基准能够有效评估 MLLMs 的视觉知识广度和幻觉率，为模型的视觉事实性提供严谨的测试标准。

Conclusion: WorldVQA 有望成为评估前沿多模态模型视觉知识记忆能力和事实一致性的标准工具。

Abstract: We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure "what the model memorizes." The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.

</details>


### [2] [AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process](https://arxiv.org/abs/2602.02676)
*Xintong Zhang,Xiaowen Zhang,Jongrong Wu,Zhi Gao,Shilin Yan,Zhenxin Diao,Kunpeng Gao,Xuanyan Chen,Yuwei Wu,Yunde Jia,Qing Li*

Main category: cs.CV

TL;DR: 本文提出了AdaptMMBench，一个用于评估视觉语言模型在多模态任务中自适应推理能力的新基准，通过动态难度识别和多维过程指标（如推理模式选择合理性、关键步骤覆盖率、工具有效性及计算效率）来全面衡量模型的元认知能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态难度标签和简单指标，无法反映任务难度随模型能力变化的动态特性，难以区分自适应模式选择能力与整体性能，并缺乏对推理过程的细粒度分析。

Method: 提出AdaptMMBench基准，涵盖五个领域（现实世界、OCR、GUI、知识、数学），采用Matthews相关系数（MCC）评估推理模式选择的合理性，并基于模型能力边界动态判定任务难度；同时从关键步骤覆盖率、工具有效性和计算效率三方面进行过程评估。

Result: 评估发现：自适应模式选择能力随模型容量提升而增强，但与最终准确率无明显关联；关键步骤覆盖率与性能正相关，而工具有效性在不同模型架构间差异显著。

Conclusion: AdaptMMBench能更精准地评估视觉语言模型的自适应多模态推理能力，揭示了当前模型在元认知与工具使用方面的局限性，为未来研究提供了新的评估视角和改进方向。

Abstract: Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

</details>


### [3] [SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?](https://arxiv.org/abs/2602.02765)
*Haruhiko Murata,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: 提出SVD-ViT，利用奇异值分解增强前景特征学习，提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers因全局自注意力机制无法有效区分前景与背景，易受背景噪声和伪影干扰，影响分类性能。

Method: 引入SVD-ViT，包含SPC模块、SSVA和ID-RSVD三个组件，通过提取并聚合表征前景信息的奇异向量，抑制背景等无关因素。

Result: 实验表明该方法提升了分类准确率，有效学习了前景表征，并降低了背景噪声的影响。

Conclusion: SVD-ViT通过奇异值分解机制增强了ViT对前景信息的关注，改善了其在图像分类任务中的表现。

Abstract: Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\textbf{SPC module}, \textbf{SSVA}, and \textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.

</details>


### [4] [LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds](https://arxiv.org/abs/2602.02808)
*Matteo Bastico,Pierre Onghena,David Ryckelynck,Beatriz Marcotegui,Santiago Velasco-Forero,Laurent Corté,Caroline Robine--Decourcelle,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文提出了一种名为Landmark Point Transformer（LmPT）的新方法，用于在点云上自动检测解剖标志点，支持跨物种学习，并在人类和狗的股骨数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统手动标记耗时且存在观察者间差异，基于规则的方法通常局限于特定几何结构或少量标志点；为克服这些局限，需一种通用、自动化的解剖标志点检测方法。

Method: 将解剖表面表示为点云，提出LmPT模型，引入条件机制以适应不同输入类型，实现跨物种的标志点检测。

Result: 在人类和新标注的狗股骨数据集上评估，LmPT展现出良好的泛化能力和跨物种有效性。

Conclusion: LmPT是一种有效的自动解剖标志点检测方法，适用于多物种研究，代码与狗股骨数据集已公开。

Abstract: Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.

</details>


### [5] [Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room](https://arxiv.org/abs/2602.02850)
*Keqi Chen,Vinkle Srivastav,Armine Vardazaryan,Cindy Rolland,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出了一种无需标注和相机标定的自监督多视角视频匿名化框架，通过时序与多视角上下文恢复漏检目标，并利用伪标签迭代优化全身检测器与姿态估计模型，在手术室视频数据上实现超过97%的召回率。


<details>
  <summary>Details</summary>
Motivation: 现有手术室视频匿名化方法在新临床场景中依赖人工标注，且多摄像头系统需频繁进行相机标定，限制了其可扩展性；为解决这两个瓶颈，作者提出一种无需标注和标定的自监督方法。

Method: 该方法包括：(1) 在各视角使用低阈值运行现成的全身检测器获取候选框；(2) 利用跟踪和未标定的多视角关联，从低分检测中恢复与高分检测一致的漏检目标作为伪标签；(3) 用伪标签迭代微调检测器；(4) 对检测到的人体进行全身姿态估计，并利用高置信度预测进一步微调姿态模型。

Result: 在4D-OR模拟手术数据集和真实手术数据集上的实验表明，该方法召回率超过97%，并成功训练出一个实时全身检测器，性能与有监督方法相当。

Conclusion: 所提自监督多视角匿名化框架有效解决了标注和相机标定依赖问题，具备高召回率和实际部署潜力，适用于手术室隐私保护场景。

Abstract: Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by "retrieving" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.

</details>


### [6] [ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying](https://arxiv.org/abs/2602.02873)
*Weihang You,Qingchan Zhu,David Liu,Yi Pan,Geng Yuan,Hanqi Jiang*

Main category: cs.CV

TL;DR: ViThinker 是一种新型视觉-语言模型框架，通过主动查询机制动态生成任务相关的视觉特征，提升推理准确性和感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在链式思维（CoT）推理中因过早将视觉信息转为文本而丢失几何与空间等连续信息，且当前方法多为被动处理预计算输入，缺乏主动感知能力。

Method: 提出 ViThinker 框架，在训练中内化视觉专家能力，推理时通过自主生成查询 token 动态合成对齐专家的视觉特征；采用两阶段课程学习：先蒸馏冻结专家知识，再通过稀疏性惩罚学习任务驱动的查询策略。

Result: 在多个以视觉为中心的基准测试中，ViThinker 表现出一致性能提升，证明其在感知接地和推理准确性方面优于被动方法。

Conclusion: 主动查询生成机制能有效增强视觉-语言模型的 CoT 推理能力，ViThinker 为实现类人主动感知提供了可行路径。

Abstract: Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.

</details>


### [7] [DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging](https://arxiv.org/abs/2602.02894)
*Daivik Patel,Shrenik Patel*

Main category: cs.CV

TL;DR: 本文提出一种面向医学影像判别的对比式参考选择框架，通过构建兼顾视觉相关性、嵌入多样性和来源信息的紧凑证据集，并结合反事实-对比推理机制，在MediConfusion基准上显著提升准确率并减少混淆。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像决策方法多依赖近邻检索，易返回冗余证据并强化单一假设，难以有效区分视觉上高度相似但临床意义不同的疾病状态。

Method: 作者利用ROCO数据集的图像-文本对和元数据，设计了一种新的参考选择协议，构建用于对比推理的多样化证据集；在此基础上提出“反事实-对比推理”框架，通过成对视觉比较与基于间隔的决策规则进行置信感知推理，并支持可靠弃权。

Result: 在MediConfusion基准测试中，该方法相较先前工作将集合级准确率相对提升近15%，同时降低混淆率并提高个体判别准确率。

Conclusion: 通过引入结构化的对比证据选择与推理机制，可显著提升医学影像中易混淆病症的判别能力，为高风险医疗决策提供更可靠的支持。

Abstract: Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.

</details>


### [8] [FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction](https://arxiv.org/abs/2602.02914)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 现有基于像素重建的隐私评估方法（如PSNR、SSIM）无法真实反映隐私保护效果；本文提出FaceLinkGen攻击方法，可直接从受保护模板中提取身份信息并实现高精度匹配与人脸再生，揭示了当前隐私保护人脸识别系统在实际隐私保障上的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前变换型隐私保护人脸识别（PPFR）系统普遍采用像素级重建难度（如PSNR、SSIM）作为隐私保护效果的评估标准，但该方法忽略了身份信息可能在不恢复原始像素的情况下被提取的风险，导致对隐私保护能力的误判。

Method: 提出名为FaceLinkGen的身份提取攻击方法，该方法无需恢复原始像素，而是直接从PPFR系统生成的保护模板中进行身份链接/匹配和人脸再生。在三种最新PPFR系统上验证其有效性，并在近零知识设定下测试其鲁棒性。

Result: FaceLinkGen在三个PPFR系统上实现了超过98.5%的匹配准确率和96%以上的人脸再生成功率；即使在近零知识设置下，匹配准确率仍高于92%，再生成功率超过94%。

Conclusion: 当前广泛使用的像素失真指标（如PSNR、SSIM）与实际隐私保护效果之间存在结构性差距，仅靠视觉模糊化不足以防止身份信息泄露，外部攻击者和不可信服务提供商仍可轻易提取敏感身份信息。

Abstract: Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\% matching accuracy and above 96\% regeneration success, and still exceeds 92\% matching and 94\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.

</details>


### [9] [A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis](https://arxiv.org/abs/2602.02918)
*Jagan Mohan Reddy Dwarampudi,Joshua Wong,Hien Van Nguyen,Tania Banerjee*

Main category: cs.CV

TL;DR: MARBLE 是首个纯基于 Mamba 的多状态多实例学习（MIL）框架，用于全切片图像（WSI）分析，通过并行处理多尺度信息并在状态空间模型中实现由粗到细的推理，在线性时间内高效捕捉跨尺度依赖关系。


<details>
  <summary>Details</summary>
Motivation: 全切片图像（WSI）分析面临千兆像素分辨率和多层级放大倍率的挑战，现有 MIL 方法通常仅在单一尺度上操作，而基于 Transformer 的方法则因二次方注意力计算开销大而不适用于大规模 WSI。

Method: MARBLE 采用纯 Mamba 架构，结合并行多尺度处理与线性时间序列建模，在状态空间模型中整合由粗到细的推理机制，以极低的参数开销高效建模跨尺度依赖。

Result: 在五个公开数据集上的实验表明，MARBLE 在 AUC 上最高提升 6.9%，准确率提升 20.3%，C-index 提升 2.3%。

Conclusion: MARBLE 提供了一种可扩展、模块化且高效的多尺度 WSI 分析框架，显著优于现有方法，具有良好的泛化能力。

Abstract: We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \textbf{6.9\%} in AUC, \textbf{20.3\%} in accuracy, and \textbf{2.3\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.

</details>


### [10] [SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2602.02944)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: SRA-Seg通过语义特征对齐和软边缘融合，有效利用合成数据提升医学图像分割性能，在仅使用10%真实标注数据的情况下达到与全真实数据方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 合成医学图像虽具视觉真实性，但因与真实图像存在语义特征空间差异（域间隙），导致现有半监督方法难以有效利用其提升分割性能。

Method: 提出SRA-Seg框架：1）使用冻结DINOv2嵌入计算相似性对齐（SA）损失，将合成图像特征拉近真实图像；2）采用软边缘融合生成平滑解剖结构和连续标签；3）通过EMA教师模型生成伪标签，并在混合区域应用考虑不确定性的软分割损失。

Result: 在仅10%真实标注数据+90%合成未标注数据设置下，ACDC数据集Dice达89.34%，FIVES达84.42%，显著优于现有半监督方法，性能媲美使用真实未标注数据的方法。

Conclusion: 通过显式对齐合成与真实图像的语义特征分布并优化标签生成方式，SRA-Seg成功弥合域间隙，使合成数据能有效提升医学图像分割性能。

Abstract: Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.

</details>


### [11] [Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning](https://arxiv.org/abs/2602.02951)
*Yihong Huang,Fei Ma,Yihua Shao,Jingcai Guo,Zitong Yu,Laizhong Cui,Qi Tian*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Nüwa 的两阶段视觉 token 剪枝框架，在保持空间信息完整性的同时提升视觉语言模型（VLM）效率，在 VQA 和视觉定位任务上均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉 token 剪枝方法在视觉问答（VQA）任务中表现良好，但在视觉定位（VG）任务中性能大幅下降。作者发现这是由于现有方法依赖全局语义相似性和注意力得分，忽略了由位置信息交互形成的全局空间参考系。

Method: Nüwa 包含两个阶段：第一阶段在视觉编码器后引入受群体智能启发的分离、对齐和聚合操作，保留富含信息的全局空间锚点；第二阶段在大语言模型（LLM）内部进行文本引导的剪枝，保留任务相关的视觉 token。

Result: 实验表明，Nüwa 在多个 VQA 基准上达到 SOTA（从 94% 提升至 95%），并在视觉定位任务上实现显著提升（从 7% 提高到 47%）。

Conclusion: 通过保留空间结构信息并结合任务相关性进行剪枝，Nüwa 能在提升 VLM 推理效率的同时兼顾多种下游任务的性能，尤其解决了现有方法在视觉定位任务上的性能退化问题。

Abstract: Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

</details>


### [12] [TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation](https://arxiv.org/abs/2602.02963)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: 提出TRACE模型，首次实现胸部X光片的时序对比、变化分类与空间定位联合任务，通过自然语言描述变化并以边界框定位，且发现时序对比与空间定位联合训练对有效变化检测至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型虽能处理单张影像的报告生成和视觉定位，但缺乏对胸部X光片时序变化的联合分析能力，而临床上时序对比对疾病进展和疗效评估至关重要。

Method: 提出TRACE模型，输入前后两张胸部X光片，联合进行时序对比、变化分类（恶化、改善、稳定）和空间定位，输出自然语言描述并附带每个发现的边界框坐标。

Result: TRACE在空间定位上达到90%以上的准确率，并通过消融实验证明：仅当时序对比与空间定位联合训练时，模型才能有效进行变化检测。

Conclusion: TRACE为医学影像时序变化分析提供新范式，表明空间定位机制对时序推理具有关键作用，为未来相关研究奠定基础。

Abstract: Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.

</details>


### [13] [Fisheye Stereo Vision: Depth and Range Error](https://arxiv.org/abs/2602.02973)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.CV

TL;DR: 本文推导了鱼眼立体视觉系统深度和距离误差的解析表达式，特别考虑了大角度下的精度问题。


<details>
  <summary>Details</summary>
Motivation: 鱼眼镜头在大视场角下存在显著畸变，传统模型难以准确描述其深度与距离误差，因此需要建立更精确的误差模型以提升大角度区域的测量准确性。

Method: 通过几何光学和立体视觉原理，结合鱼眼镜头的投影模型，推导出深度和范围误差关于物体距离及视角的解析表达式。

Result: 得到了能准确描述鱼眼立体视觉系统在不同物距和大视角下深度与范围误差的数学公式，验证了其在大角度区域的有效性。

Conclusion: 所提出的误差模型有助于提升鱼眼立体视觉系统在广角区域的测量精度，为后续校正和应用提供理论基础。

Abstract: This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.

</details>


### [14] [Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding](https://arxiv.org/abs/2602.02977)
*Byeongju Woo,Zilin Wang,Byeonghyun Pak,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: 本文提出CAFT框架，通过跨模态的层次化对齐机制，在无像素级监督的情况下实现图像与长文本之间的细粒度语义对齐，显著提升长文本检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉-语言模型（如CLIP）将图像和文本视为整体进行对齐，难以处理长文本；而细粒度理解需要同时捕捉全局上下文与局部细节。然而，语言的层次结构（如句法或语义）通常与视觉结构不匹配，纯视觉层次又缺乏语义聚焦。

Method: 提出CAFT（Cross-domain Alignment of Forests and Trees）框架，结合由细到粗的视觉编码器与层次化文本Transformer，设计层次化对齐损失函数，在整体对齐的同时引导区域-句子对应关系，使高层语义建立在细粒度证据基础上。

Result: 在30M图像-文本对上训练后，CAFT在六个长文本检索基准上达到SOTA，并展现出良好的扩展性；实验表明该方法能在无显式区域监督下学习到细粒度、视觉接地的跨模态表示。

Conclusion: 层次化的跨域对齐机制有效促进了细粒度、视觉接地的图像-文本表示的学习，为处理长文本视觉-语言任务提供了新思路。

Abstract: Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.

</details>


### [15] [SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation](https://arxiv.org/abs/2602.02989)
*Zhanfeng Liao,Jiajun Zhang,Hanzhang Tu,Zhixi Wang,Yunqi Gao,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: SharpTimeGS 是一种新颖的 4D 高斯表示方法，通过引入可学习的寿命参数，实现对静态与动态区域的统一且自适应的时间建模，在保持高保真动态效果的同时提升长期稳定性，并支持实时 4K 渲染。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯的动态场景新视角合成方法难以在表示和优化中平衡长期静态区域与短期动态区域，导致渲染质量或稳定性下降。

Method: 提出 SharpTimeGS 框架，引入可学习的寿命参数，将高斯时间可见性从高斯衰减改为平顶轮廓，使基元在其有效期内保持活跃；利用寿命参数调节运动，解耦运动幅度与时间持续长度；设计寿命-速度感知的致密化策略，优化静态与动态区域的资源分配。

Result: 在多个基准上达到 SOTA 性能，可在单块 RTX 4090 上实现实时 4K 分辨率、100 FPS 的渲染。

Conclusion: SharpTimeGS 有效解决了动态场景中静态与动态区域建模的平衡问题，显著提升了 4D 重建的稳定性与真实感，同时保持高效实时渲染能力。

Abstract: Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.

</details>


### [16] [Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation](https://arxiv.org/abs/2602.02994)
*Jiaze Li,Hao Yin,Haoran Xu,Boshen Xu,Wenhui Tan,Zewen He,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 本文提出Video-OPD，一种用于时序视频定位（TVG）的高效后训练框架，通过在策略蒸馏将稀疏奖励转化为密集的逐token监督信号，并结合教师验证的分歧聚焦策略（TVDF），显著提升训练效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的强化学习方法在TVG任务中受限于稀疏奖励和高计算开销，作者旨在通过引入在策略蒸馏机制，缓解分布偏移并提升训练效率。

Method: Video-OPD直接从当前策略采样轨迹进行优化，利用前沿教师模型通过反向KL散度提供密集的token级监督；并在此基础上引入TVDF课程学习策略，优先训练教师可靠且对学生最具信息量的轨迹。

Result: 实验表明，Video-OPD在性能上优于GRPO方法，同时收敛更快、计算成本更低。

Conclusion: 在策略蒸馏是一种比传统强化学习更有效的TVG后训练范式，兼具高效性与优越性能。

Abstract: Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.

</details>


### [17] [VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering](https://arxiv.org/abs/2602.03007)
*Rahul Atul Bhope,K. R. Jayaram,Vinod Muthusamy,Ritesh Kumar,Vatche Isahagian,Nalini Venkatasubramanian*

Main category: cs.CV

TL;DR: VOILA 是一个基于信息价值的自适应视觉保真度选择框架，在视觉问答任务中通过预测不同保真度下的准确率与检索成本，动态选择最低成本且满足性能要求的图像分辨率，从而在保持 90–95% 全分辨率准确率的同时实现 50–60% 的成本节省。


<details>
  <summary>Details</summary>
Motivation: 当前大多数多模态视觉-语言系统以固定保真度运行，忽略了高保真视觉输入带来的显著计算和存储开销。作者旨在通过在模型执行前智能选择所需的信息保真度，优化资源受限下的多模态推理效率。

Method: VOILA 采用两阶段流程：首先利用基于问题特征的梯度提升回归器预测各保真度下的回答正确概率；然后通过保序校准器对预测概率进行校准，以支持可靠决策；最终根据预期效用（结合预测准确率与检索成本）选择成本最低的保真度。

Result: 在五个数据集（VQA-v2、GQA、TextVQA、LoCoMo、FloodNet）和六种参数规模为7B–235B的视觉语言模型上评估表明，VOILA 在多种查询类型和模型架构下均能稳定减少50–60%的成本，同时保留90–95%的全分辨率准确率。

Conclusion: 预检索阶段的保真度选择对于在资源受限条件下优化多模态推理至关重要，VOILA 提供了一种高效且通用的解决方案。

Abstract: Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.

</details>


### [18] [Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side](https://arxiv.org/abs/2602.03013)
*Haipeng Liu,Yang Wang,Biao Qian,Yong Rui,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出一种在卷积下采样过程中通过结构与纹理特征图相互引导来减少信息损失的图像修复方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN编码器-解码器的图像修复方法在卷积下采样过程中忽视了结构和纹理特征的信息损失，导致上采样结果不理想。

Method: 在编码器的卷积下采样阶段，利用结构与纹理特征图之间的统计归一化与反归一化策略进行重建引导，以缓解信息损失。

Result: 在256×256和512×512等分辨率图像上的大量实验表明，该方法优于当前先进方法，尤其在替换所有编码器后效果更佳。

Conclusion: 结构与纹理特征在下采样过程中可相互辅助以减少信息损失，所提方法有效提升了图像修复质量。

Abstract: Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL

</details>


### [19] [A Vision-Based Analysis of Congestion Pricing in New York City](https://arxiv.org/abs/2602.03015)
*Mehmet Kerem Turkcan,Jhonatan Tavori,Javad Ghaderi,Gil Zussman,Zoran Kostic,Andrew Smyth*

Main category: cs.CV

TL;DR: 该研究利用计算机视觉技术分析纽约市900多个交通摄像头的数据，评估2025年1月实施的拥堵收费政策对曼哈顿地区车流密度的影响。


<details>
  <summary>Details</summary>
Motivation: 评估纽约市拥堵收费计划对交通流量的实际影响，为城市交通政策提供数据支持。

Method: 构建计算机视觉流水线，处理2024年11月至2026年1月期间覆盖曼哈顿及纽约市的900多个交通摄像头的视频数据，建立基线交通模式并检测车辆密度的系统性变化。

Result: 成功识别出拥堵收费实施后监测区域内车辆密度的系统性变化。

Conclusion: 基于大规模摄像头数据的自动化分析可有效评估城市交通干预措施的效果，为未来政策调整提供依据。

Abstract: We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.

</details>


### [20] [MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration](https://arxiv.org/abs/2602.03028)
*Wenzhang Sun,Zhenyu Wang,Zhangchi Hu,Chunfeng Wang,Hao Li,Wei Chen*

Main category: cs.CV

TL;DR: 本文提出MUSE，一种多智能体闭环框架，通过迭代的计划-执行-验证-修正循环，提升长篇音视频故事生成中的叙事连贯性、身份一致性和电影级质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长篇音视频故事生成中存在语义漂移和身份不一致问题，主要由于缺乏对高阶叙事意图的持续约束和跨模态协调机制。

Method: 将故事生成建模为闭环约束满足问题，引入MUSE多智能体框架，通过显式控制身份、空间构图和时间连续性，并利用多模态反馈进行迭代修正。

Result: 实验表明，MUSE在长时程叙事连贯性、跨模态身份一致性及电影感方面显著优于现有基线方法。

Conclusion: MUSE通过闭环多智能体协作有效弥合了意图与执行之间的差距，为开放式长篇音视频故事生成提供了可行方案，并配套提出无需参考答案的评估基准MUSEBench。

Abstract: Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.

</details>


### [21] [Bongards at the Boundary of Perception and Reasoning: Programs or Language?](https://arxiv.org/abs/2602.03038)
*Cassidy Langenfeld,Claas Beger,Gloria Geng,Wasu Top Piriyakulkij,Keya Hu,Yewen Pu,Kevin Ellis*

Main category: cs.CV

TL;DR: 本文提出一种神经符号方法，结合大语言模型（LLMs）与贝叶斯优化，用于解决Bongard视觉推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在日常视觉任务中表现良好，但在面对全新情境下的视觉推理（如Bongard问题）时仍存在不足。人类却能灵活应对这类挑战，因此作者希望探索更接近人类推理能力的解决方案。

Method: 给定一个假设的Bongard问题解法规则，利用大语言模型生成该规则的参数化程序表示，并通过贝叶斯优化进行参数拟合。

Result: 该方法在已知真实规则的情况下对Bongard图像分类有效，并能在无先验规则的情况下从头求解Bongard问题。

Conclusion: 所提出的神经符号方法展示了将大语言模型与符号推理相结合在复杂视觉推理任务中的潜力，为提升AI系统泛化与推理能力提供了新思路。

Abstract: Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.

</details>


### [22] [IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning](https://arxiv.org/abs/2602.03060)
*Zhichao Sun,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练、感知提示的视觉token剪枝方法IVC-Prune，通过保留对空间推理至关重要的隐式视觉坐标（IVC）token和语义相关的前景token，在减少约50%视觉token的同时保持甚至提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言大模型（LVLMs）在处理高分辨率图像时推理成本高昂，而当前基于语义相关性的视觉token剪枝方法往往忽略了对空间推理至关重要的token，导致性能下降。

Method: 作者发现LVLMs通过RoPE机制隐式建立视觉坐标系，其中特定位置的token作为隐式视觉坐标（IVC token）对空间推理至关重要。IVC-Prune方法结合两类token：1）通过分析RoPE旋转矩阵数学性质识别出的IVC token；2）通过两阶段流程（语义种子发现+基于值向量相似度的上下文精炼）识别的前景token。

Result: 在4个代表性LVLM和20个多样化基准上评估表明，IVC-Prune可减少约50%的视觉token，同时保持≥99%的原始性能，并在多个基准上实现性能提升。

Conclusion: 通过揭示LVLM中RoPE与空间推理的关系并据此设计剪枝策略，IVC-Prune有效平衡了计算效率与模型性能，为高效LVLM推理提供了新思路。

Abstract: Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\% while maintaining $\geq$ 99\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.

</details>


### [23] [Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding](https://arxiv.org/abs/2602.03071)
*Sunoh Kim,Kimin Yun,Daeho Um*

Main category: cs.CV

TL;DR: 本文提出高斯边界优化（GBO）框架，通过求解兼顾覆盖度与紧凑性的优化问题，显著提升弱监督视频定位性能，且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯的时间提议方法在推理时依赖启发式映射来确定片段边界，导致定位性能次优。

Method: 提出GBO推理框架，通过构建并求解一个平衡提案覆盖度与片段紧凑性的优化问题，推导出闭式解，并分析不同惩罚机制下的最优条件。

Result: GBO在多个标准基准上取得领先性能，且在不同提议方案下均表现出高效性和泛化能力。

Conclusion: GBO是一种理论扎实、无需训练、兼容性强的推理框架，能有效提升弱监督视频定位的精度。

Abstract: Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.

</details>


### [24] [A generalizable large-scale foundation model for musculoskeletal radiographs](https://arxiv.org/abs/2602.03076)
*Shinn Kim,Soobin Lee,Kyoungseob Shin,Han-Soo Kim,Yongsung Kim,Minsu Kim,Juhong Nam,Somang Ko,Daeheon Kwon,Wook Huh,Ilkyu Han,Sunghoon Kwon*

Main category: cs.CV

TL;DR: SKELEX 是一个基于120万张多样化肌肉骨骼X光片、通过自监督学习训练的大规模基础模型，在多个下游任务中表现优异，并支持零样本异常定位和可解释的骨肿瘤预测。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在肌肉骨骼疾病诊断中通常任务特定、依赖标注且泛化能力有限，而公开数据集规模小、多样性不足，难以支撑通用模型训练。因此亟需一个可泛化、标签高效的基础模型。

Method: 利用自监督学习在120万张多样化的肌肉骨骼X光图像上训练SKELEX基础模型，并在12个下游诊断任务上进行评估；进一步开发了基于区域引导的可解释骨肿瘤预测模型，并部署为公开Web应用。

Result: SKELEX在骨折检测、骨关节炎分级和骨肿瘤分类等任务中普遍优于基线模型；还能实现零样本异常定位，并在外部独立数据集上保持稳健性能。

Conclusion: SKELEX提供了一个可扩展、标签高效且具有强泛化能力的AI框架，为肌肉骨骼影像的临床转化和数据高效研究奠定了基础。

Abstract: Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.

</details>


### [25] [Gromov Wasserstein Optimal Transport for Semantic Correspondences](https://arxiv.org/abs/2602.03105)
*Francis Snelgar,Stephen Gould,Ming Xu,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 本文提出一种更高效的方法用于语义匹配任务，通过用带有Gromov-Wasserstein空间平滑先验的最优传输算法替代Stable Diffusion特征，在保持甚至超越当前SOTA性能的同时，将计算效率提升5–10倍。


<details>
  <summary>Details</summary>
Motivation: 当前基于DINOv2和Stable Diffusion（SD）特征融合的语义对应方法虽性能优异，但计算开销大。作者希望在不依赖SD特征的前提下，通过改进匹配算法来提升效率与性能。

Method: 使用DINOv2提取特征，并将传统的最近邻匹配替换为包含Gromov-Wasserstein空间平滑先验的最优传输匹配算法，以增强空间一致性。

Result: 该方法显著提升了DINOv2基线性能，在多个指标上达到或超过使用SD特征的SOTA方法，同时计算效率提高5–10倍。

Conclusion: 通过引入具有空间一致性的先进匹配算法，可以在不依赖大型模型特征融合的情况下实现高效且高性能的语义对应，为实际应用提供更可行的解决方案。

Abstract: Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .

</details>


### [26] [Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models](https://arxiv.org/abs/2602.03123)
*Judah Goldfeder,Shreyes Kaliyur,Vaibhav Sourirajan,Patrick Minwan Puma,Philippe Martin Wyder,Yuhang Hu,Jiong Lin,Hod Lipson*

Main category: cs.CV

TL;DR: 本文提出EvoAug，一种结合生成模型与进化算法的自动化数据增强方法，通过学习分层组合的随机增强树，在细粒度分类和少样本学习任务中显著提升模型鲁棒性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法（如裁剪、旋转）变化有限，而新兴生成模型（如条件扩散模型、少样本NeRF）虽能生成多样且逼真的数据，但若增强策略与任务不匹配，可能损害性能。因此，亟需一种能自动学习任务相关、高效且结构化的生成式增强策略。

Method: 提出EvoAug框架，结合生成模型（如条件扩散模型、少样本NeRF）与高效进化算法，自动搜索最优的数据增强策略；创新性地引入随机增强树结构，以分层方式组合多种增强操作，实现更结构化和自适应的图像变换。

Result: 在细粒度分类和少样本学习任务上表现优异；所发现的增强策略与领域知识一致，即使在数据稀缺场景下仍有效。

Conclusion: 学习型生成式数据增强具有巨大潜力，EvoAug为提升模型鲁棒性和训练效果提供了新途径。

Abstract: Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.

</details>


### [27] [Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models](https://arxiv.org/abs/2602.03126)
*Francis Snelgar,Ming Xu,Stephen Gould,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 本文提出一种基于扩散模型的3D人体姿态估计框架，通过从2D图像引导无条件扩散模型生成多个合理3D姿态，在无需配对2D-3D训练数据的情况下实现SOTA性能，并展现出良好的泛化能力和任务扩展性。


<details>
  <summary>Details</summary>
Motivation: 3D人体姿态估计存在深度模糊和遮挡问题，导致任务欠定，而现有方法多假设确定性映射并依赖大量配对2D-3D数据，泛化能力有限。

Method: 利用扩散模型从2D关键点热图梯度引导一个仅在3D数据上训练的无条件扩散模型，从而从与2D图像一致的姿态分布中采样。

Result: 在Human3.6M数据集的最佳m选1评估中达到SOTA（无需配对训练数据），并在MPI-INF-3DHP和3DPW上表现出良好泛化能力；同时支持姿态生成与补全等新任务。

Conclusion: 所提扩散模型框架有效解决了3D姿态估计中的欠定性和数据依赖问题，具备高性能、强泛化和高灵活性。

Abstract: 3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .

</details>


### [28] [FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation](https://arxiv.org/abs/2602.03130)
*Chenxi Zhang,Ziliang Gan,Liyun Zhu,Youwei Pang,Qing Zhang,Rongjunchen Zhang*

Main category: cs.CV

TL;DR: 本文提出了FinMTM，一个面向金融领域的多轮多模态基准，涵盖多样化的数据（11,133个中英双语金融问答对）和任务类型（选择题、多轮对话、智能体任务），并设计了针对性的评估协议，揭示了现有视觉语言模型在细粒度感知、长上下文推理和复杂智能体工作流中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有金融领域视觉语言模型评测基准多为单轮且问题形式单一，难以全面评估模型在真实应用场景中的能力，因此需要构建更具多样性与挑战性的多轮多模态评测基准。

Method: 构建FinMTM基准：1）数据层面，收集并标注11,133个基于金融图表（如K线图、统计图、报告图）的中英双语问答对；2）任务层面，涵盖单选/多选题、多轮开放式对话和智能体任务；3）评估层面，分别为不同任务设计专用评分机制。

Result: 对22个视觉语言模型的广泛实验表明，这些模型在细粒度视觉感知、长上下文推理以及复杂智能体工作流方面存在明显局限。

Conclusion: FinMTM为金融多模态理解提供了更全面、贴近实际应用的评测框架，有助于推动视觉语言模型在专业领域的发展与优化。

Abstract: The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios. To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures. On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks. We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks. Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.

</details>


### [29] [SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass](https://arxiv.org/abs/2602.03134)
*Chen Qian,Xinran Yu,Danyang Li,Guoxuan Chi,Zheng Yang,Qiang Ma,Xin Miao*

Main category: cs.CV

TL;DR: 本文提出SwiftVLM，一种无需训练的视觉标记剪枝方法，通过“旁路”机制在不同层独立重评估未选中的视觉标记，避免因过早剪枝导致关键信息丢失，在多个视觉语言模型和基准上实现了更优的准确率与效率平衡。


<details>
  <summary>Details</summary>
Motivation: 现有视觉标记剪枝方法依赖早期决策，在需要细粒度视觉细节的任务中表现不佳；浅层被认为不重要的标记可能在后续文本条件推理中变得关键，因此需避免不可逆的信息损失。

Method: 引入“旁路”剪枝范式，保留未被选中的视觉标记并传递至后续剪枝阶段重新评估；SwiftVLM在具有强视觉标记选择能力的特定层执行剪枝，并允许各层独立决策。

Result: 在多个视觉语言模型和基准测试中，SwiftVLM优于现有剪枝策略，取得更好的准确率-效率权衡，并展现出更忠实的视觉标记选择行为。

Conclusion: 通过延迟并动态重评估视觉标记的重要性，SwiftVLM有效缓解了早期剪枝带来的性能下降问题，为高效视觉语言模型提供了实用且通用的剪枝方案。

Abstract: Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.

</details>


### [30] [Fully Kolmogorov-Arnold Deep Model in Medical Image Segmentation](https://arxiv.org/abs/2602.03156)
*Xingyu Qiu,Xinghua Ma,Dong Liang,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: 本文提出ALL U-KAN，首个全KA（Kolmogorov-Arnold）架构的深度模型，通过SaKAN和无梯度样条技术显著降低训练难度与内存消耗，实现比传统及部分KA模型更优的医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有KAN（Kolmogorov-Arnold Networks）因训练困难和高内存需求难以深层堆叠，限制了其在深度学习中的全面探索。

Method: (1) 提出共享激活KAN（SaKAN），基于Sprecher版Kolmogorov-Arnold定理简化参数化并提升优化效率；(2) 提出无梯度样条（Grad-Free Spline），去除对训练贡献微小但耗内存的样条梯度；(3) 构建ALL U-KAN，用KA层和KAonv层完全替代传统全连接层和卷积层。

Result: 在三项医学图像分割任务中，ALL U-KAN在分割精度上全面优于部分KA模型和传统架构；相比直接堆叠的深层KAN，参数量减少10倍，内存消耗降低20倍以上。

Conclusion: 全KA架构不仅可行，而且在性能和效率上显著优于现有方法，为深度KAN研究开辟了新路径。

Abstract: Deeply stacked KANs are practically impossible due to high training difficulties and substantial memory requirements. Consequently, existing studies can only incorporate few KAN layers, hindering the comprehensive exploration of KANs. This study overcomes these limitations and introduces the first fully KA-based deep model, demonstrating that KA-based layers can entirely replace traditional architectures in deep learning and achieve superior learning capacity. Specifically, (1) the proposed Share-activation KAN (SaKAN) reformulates Sprecher's variant of Kolmogorov-Arnold representation theorem, which achieves better optimization due to its simplified parameterization and denser training samples, to ease training difficulty, (2) this paper indicates that spline gradients contribute negligibly to training while consuming huge GPU memory, thus proposes the Grad-Free Spline to significantly reduce memory usage and computational overhead. (3) Building on these two innovations, our ALL U-KAN is the first representative implementation of fully KA-based deep model, where the proposed KA and KAonv layers completely replace FC and Conv layers. Extensive evaluations on three medical image segmentation tasks confirm the superiority of the full KA-based architecture compared to partial KA-based and traditional architectures, achieving all higher segmentation accuracy. Compared to directly deeply stacked KAN, ALL U-KAN achieves 10 times reduction in parameter count and reduces memory consumption by more than 20 times, unlocking the new explorations into deep KAN architectures.

</details>


### [31] [Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval](https://arxiv.org/abs/2602.03157)
*Chihiro Nakatani,Hiroaki Kawashima,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出一种无需群体活动标注的人在回路（human-in-the-loop）适应方法，用于群体活动特征学习（GAFL），通过用户交互式微调和对比学习显著提升视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖监督学习对预定义的群体活动类别进行分类，而实际应用中缺乏标注数据；为提升无标注场景下的群体活动视频检索效果，作者引入人在回路机制进行自监督预训练后的交互式微调。

Method: 首先以自监督方式基于群体活动相似性预训练群体活动特征（GAF）空间；随后通过数据高效的视频选择策略向用户提供少量视频进行正负标签标注，并利用这些标注通过对比学习微调GAF空间，使正样本靠近查询视频、负样本远离查询视频。

Result: 在两个团队运动数据集上的实验表明，该方法显著提升了视频检索性能；消融实验验证了人在回路适应中各组件的有效性。

Conclusion: 所提出的无需群体活动标注的人在回路适应框架能有效提升群体活动视频检索性能，证明了交互式微调与对比学习结合在无监督场景下的潜力。

Abstract: This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.

</details>


### [32] [LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution](https://arxiv.org/abs/2602.03182)
*Tianxing Wu,Zheng Chen,Cirou Xu,Bowen Chai,Yong Guo,Yutong Liu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出LSGQuant，一种面向一步式扩散模型的视频超分量化方法，在保持接近全精度模型性能的同时显著优于现有量化技术。


<details>
  <summary>Details</summary>
Motivation: 一步式扩散模型在真实世界视频超分辨率（VSR）中表现出色且推理速度快，但其基于DiT的庞大模型尺寸和高计算成本限制了实际应用。低比特量化虽是常用压缩手段，却因输入潜变量动态范围大及各层行为差异而效果受限。

Method: 提出LSGQuant方法：1）引入动态范围自适应量化器（DRAQ）适配视频token激活值；2）通过校准阶段的层统计分析估计层敏感度，并采用方差导向的层训练策略（VOLTS）；3）引入量化感知优化（QAO）联合优化量化分支与保留的高精度分支。

Result: 大量实验表明，该方法在性能上几乎与原始全精度模型相当，并显著超越现有量化技术。

Conclusion: LSGQuant有效解决了扩散模型在视频超分任务中量化困难的问题，为高效部署提供了可行方案。

Abstract: One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.

</details>


### [33] [From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization](https://arxiv.org/abs/2602.03198)
*Minghang Zhu,Zhijing Wang,Yuxin Guo,Wen Li,Sheng Ao,Cheng Wang*

Main category: cs.CV

TL;DR: 本文提出TempLoc，一种新的LiDAR重定位框架，通过建模时序一致性显著提升6-DoF位姿估计的鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的LiDAR重定位方法在动态或模糊场景中表现不佳，因其仅依赖单帧推理或忽略扫描间的时空一致性。

Method: TempLoc包含三个模块：全局坐标估计模块预测每帧点云的全局坐标及不确定性；先验坐标生成模块通过注意力机制估计帧间点对应关系；不确定性引导的坐标融合模块端到端融合上述信息，输出时序一致且精确的6-DoF位姿。

Result: 在NCLT和Oxford RobotCar数据集上，TempLoc显著优于当前最先进的方法。

Conclusion: 引入时序感知的对应关系建模能有效提升LiDAR重定位的性能，TempLoc为此提供了一个高效且鲁棒的解决方案。

Abstract: LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.

</details>


### [34] [Hand3R: Online 4D Hand-Scene Reconstruction in the Wild](https://arxiv.org/abs/2602.03200)
*Wendi Hu,Haonan Zhou,Wenhao Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: Hand3R 是首个从单目视频中在线联合重建4D手部与场景的框架，通过融合预训练手部模型与4D场景基础模型，实现高保真手部网格与密集场景几何的同时重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅在局部坐标系中重建孤立的手部，忽略了周围3D环境，难以支持对物理交互的全面理解。

Method: 提出 Hand3R 框架，结合预训练的手部专家模型与4D场景基础模型，利用场景感知的视觉提示机制，将高保真手部先验注入持久化场景记忆中，在单次前向传播中同步重建手部与场景。

Result: 实验表明 Hand3R 无需离线优化，在局部手部重建和全局定位方面均取得具有竞争力的性能。

Conclusion: Hand3R 实现了动态手部与密集场景上下文的高效联合重建，为具身智能中的物理交互理解提供了新思路。

Abstract: For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.

</details>


### [35] [VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers](https://arxiv.org/abs/2602.03210)
*Zhiwen Li,Zhongjie Duan,Jinyan Ye,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: 本文提出VIRAL框架，通过视觉类比将上下文学习（ICL）转化为条件生成任务，利用冻结的扩散变换器（DiT）与多专家LoRA机制，在大规模自建数据集上实现对多种视觉任务（包括开放域编辑）的统一处理，并取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于视觉任务的异质性，当前在计算机视觉中复现上下文学习（ICL）仍具挑战。现有方法缺乏统一范式，且缺乏适用于视觉上下文学习的大规模多样化数据集。

Method: 提出VIRAL框架，将ICL建模为视觉类比（$x_s : x_t :: x_q : y_q$）的条件生成问题；使用角色感知的多图像条件机制对冻结的DiT模型进行适配；引入Mixture-of-Experts LoRA以缓解不同任务间的梯度干扰；并构建涵盖感知、修复和编辑的大规模视觉上下文数据集。

Result: 实验表明，VIRAL在多种视觉任务上优于现有方法，验证了统一的视觉上下文学习（V-ICL）范式的有效性，尤其在开放域图像编辑任务中表现突出。

Conclusion: VIRAL成功实现了基于预训练图像编辑模型的通用视觉上下文学习框架，证明了通过视觉类比和条件生成方式可有效激发模型的视觉推理能力，为未来通用视觉智能系统提供新思路。

Abstract: Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A

</details>


### [36] [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213)
*Zhuoran Yang,Yanyong Zhang*

Main category: cs.CV

TL;DR: ConsisDrive 是一种保持实例身份一致性的驾驶世界模型，通过引入实例掩码注意力和实例掩码损失机制，在生成高质量驾驶视频的同时有效缓解了身份漂移问题，并在 nuScenes 数据集上提升了下游自动驾驶任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶世界模型在生成多视角驾驶视频时缺乏实例级时间约束，导致同一物体在不同帧中出现外观或类别不一致（即身份漂移），影响生成数据的可用性与下游任务表现。

Method: 提出 ConsisDrive 框架，包含两个核心组件：(1) 实例掩码注意力，在注意力块中使用实例身份掩码和轨迹掩码，确保视觉 token 仅与其对应实例特征交互；(2) 实例掩码损失，通过概率性实例掩码自适应强调前景区域，减少背景噪声同时保留场景整体保真度。

Result: ConsisDrive 在驾驶视频生成质量上达到当前最优水平，并在 nuScenes 数据集的下游自动驾驶任务中显著优于基线方法。

Conclusion: 通过在世界模型中引入实例级时间一致性约束，ConsisDrive 有效解决了身份漂移问题，为自动驾驶提供了更可靠、高质量的合成数据来源。

Abstract: Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.

</details>


### [37] [FARTrack: Fast Autoregressive Visual Tracking with High Performance](https://arxiv.org/abs/2602.03214)
*Guijie Wang,Tong Lin,Yifan Bai,Anjia Cao,Shiyi Liang,Wangbo Zhao,Xing Wei*

Main category: cs.CV

TL;DR: FARTrack 是一种快速自回归视觉跟踪框架，在保持高性能的同时显著提升推理速度，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 现有高性能视觉跟踪器推理速度慢，难以在资源受限设备上部署，因此需要兼顾速度与性能的解决方案。

Method: 提出 FARTrack 框架，包含任务特定自蒸馏（Task-Specific Self-Distillation）和帧间自回归稀疏化（Inter-frame Autoregressive Sparsification）两种策略，分别通过逐层蒸馏任务相关 token 和优化冗余 token 来压缩模型并提升效率。

Result: FARTrack 在 GOT-10k 上达到 70.6% AO，实时运行；最快模型在 GPU 上达 343 FPS，CPU 上达 121 FPS。

Conclusion: FARTrack 在保证跟踪性能的同时显著提升了推理速度，适合在多种设备上高效部署。

Abstract: Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.

</details>


### [38] [Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane](https://arxiv.org/abs/2602.03227)
*Haoyu Liu,Sucheng Ren,Tingyu Zhu,Peng Wang,Cihang Xie,Alan Yuille,Zeyu Zheng,Feng Wang*

Main category: cs.CV

TL;DR: 本文提出Spiral RoPE，一种多方向位置编码方法，通过将嵌入通道分组并沿均匀分布的方向进行旋转，克服了标准轴向二维RoPE仅支持水平和垂直方向的局限性，在多种视觉任务中取得一致性能提升。


<details>
  <summary>Details</summary>
Motivation: 标准轴向二维RoPE在视觉Transformer中仅能编码水平和垂直方向的位置关系，无法有效建模自然图像中普遍存在的斜向空间关系，限制了模型对复杂空间结构的感知能力。

Method: 将位置嵌入通道划分为多个组，每组对应一个均匀分布的空间方向；对每个图像块的位置向量在其对应方向上做投影，并据此进行旋转编码，从而实现多方向位置信息的建模。

Result: 在图像分类、分割和生成等多种视觉任务中，Spiral RoPE均带来一致的性能提升；注意力图分析显示其能更聚焦于语义相关区域并更好地遵循物体边界。

Conclusion: 多方向位置编码对视觉Transformer至关重要，Spiral RoPE作为一种简单有效的改进方案，显著增强了模型对复杂空间关系的建模能力。

Abstract: Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.

</details>


### [39] [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://arxiv.org/abs/2602.03230)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Wen Jiang,Ming Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: 本文提出了EventFlash，一种高效事件驱动的多模态大语言模型，通过时空token稀疏化显著提升推理速度并支持长序列事件流处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的多模态大语言模型（MLLMs）通常采用类似图像的密集处理范式，忽略了事件流的时空稀疏性，导致计算成本高。为解决这一问题，作者提出更高效的模型架构。

Method: 作者构建了大规模、场景多样化的EventMind数据集（含50万+指令集），并采用课程训练策略；设计了自适应时间窗口聚合模块以压缩时间token，同时保留关键时间信息；提出稀疏密度引导注意力模块，提升空间token效率。

Result: EventFlash相比基线模型EventFlash-Zero实现12.4倍吞吐量提升，性能相当；可处理长达1000个时间bin的事件流，远超EventGPT的5-bin限制。

Conclusion: EventFlash为基于事件的视觉任务提供了一个高效的基础模型，有效利用事件流的稀疏特性，在保持性能的同时大幅降低计算开销。

Abstract: Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.

</details>


### [40] [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242)
*Zhuoran Yang,Xi Guo,Chenjing Ding,Chiyu Wang,Wei Wu,Yanyong Zhang*

Main category: cs.CV

TL;DR: InstaDrive 是一种新型驾驶视频生成框架，通过引入实例流引导器和空间几何对齐器，显著提升了生成视频在时间一致性和空间几何保真度方面的表现，并在 nuScenes 数据集上提高了自动驾驶任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在生成多视角驾驶视频时难以维持实例级的时间一致性与空间几何准确性，限制了其在自动驾驶训练中的应用效果。

Method: 提出 InstaDrive 框架，包含两个核心模块：(1) 实例流引导器（Instance Flow Guider），用于跨帧提取并传播实例特征以保持时间一致性；(2) 空间几何对齐器（Spatial Geometric Aligner），用于提升空间推理能力、精确定位实例并建模遮挡层级。

Result: InstaDrive 在 nuScenes 数据集上实现了最先进的视频生成质量，并有效提升了下游自动驾驶任务的性能；同时利用 CARLA 自动驾驶模拟器生成多样化的罕见但关键的安全场景，用于系统安全评估。

Conclusion: 通过引入实例感知机制，InstaDrive 显著改善了驾驶视频生成的真实性与实用性，为自动驾驶系统的训练与安全评估提供了高效、可靠的解决方案。

Abstract: Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.

</details>


### [41] [LaVPR: Benchmarking Language and Vision for Place Recognition](https://arxiv.org/abs/2602.03253)
*Ofer Idan,Dan Badur,Yosi Keller,Yoli Shavit*

Main category: cs.CV

TL;DR: 本文提出了LaVPR，一个包含65万条自然语言描述的大规模视觉位置识别（VPR）基准数据集，用于提升系统在极端环境变化和仅依赖语言描述情况下的定位能力。


<details>
  <summary>Details</summary>
Motivation: 传统VPR方法在环境剧烈变化或感知混淆时表现不佳，且无法仅通过语言描述实现“盲定位”，限制了其在应急响应等场景中的应用。

Method: 构建LaVPR数据集，并研究两种范式：多模态融合以增强鲁棒性，以及跨模态检索实现基于语言的定位；采用LoRA和Multi-Similarity损失建立跨模态检索基线。

Result: 语言描述在视觉退化条件下显著提升性能，尤其使小型模型可媲美大型纯视觉模型；所提跨模态方法优于标准对比学习方法。

Conclusion: LaVPR推动了兼具鲁棒性与部署实用性的新型定位系统发展，支持资源受限环境下的高效应用。

Abstract: Visual Place Recognition (VPR) often fails under extreme environmental changes and perceptual aliasing. Furthermore, standard systems cannot perform "blind" localization from verbal descriptions alone, a capability needed for applications such as emergency response. To address these challenges, we introduce LaVPR, a large-scale benchmark that extends existing VPR datasets with over 650,000 rich natural-language descriptions. Using LaVPR, we investigate two paradigms: Multi-Modal Fusion for enhanced robustness and Cross-Modal Retrieval for language-based localization. Our results show that language descriptions yield consistent gains in visually degraded conditions, with the most significant impact on smaller backbones. Notably, adding language allows compact models to rival the performance of much larger vision-only architectures. For cross-modal retrieval, we establish a baseline using Low-Rank Adaptation (LoRA) and Multi-Similarity loss, which substantially outperforms standard contrastive methods across vision-language models. Ultimately, LaVPR enables a new class of localization systems that are both resilient to real-world stochasticity and practical for resource-constrained deployment. Our dataset and code are available at https://github.com/oferidan1/LaVPR.

</details>


### [42] [A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation](https://arxiv.org/abs/2602.03292)
*Jianghao Wu,Xiangde Luo,Yubo Zhou,Lianming Wu,Guotai Wang,Shaoting Zhang*

Main category: cs.CV

TL;DR: A3-TTA是一种新的测试时自适应（TTA）框架，通过锚点引导的伪标签生成机制，在无需源数据或重新训练的情况下显著提升图像分割模型在域偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于伪标签的TTA方法依赖缺乏分布依据的扰动集成启发式策略，导致训练信号不稳定，易引发误差累积和灾难性遗忘。

Method: 提出A3-TTA框架：1）利用类紧凑密度度量识别目标域中预测置信度高的样本作为锚点；2）以这些锚点为参考生成伪标签，并结合语义一致性和边界感知的熵最小化进行正则化；3）引入自适应指数移动平均策略以减轻标签噪声并稳定模型更新。

Result: 在多域医学图像（心脏结构和前列腺分割）及自然图像上，A3-TTA相比源模型平均Dice分数提升10.40至17.68个百分点，优于多种SOTA TTA方法，并在连续TTA场景中表现出强抗遗忘能力。

Conclusion: A3-TTA通过锚点引导的可靠伪标签生成机制有效提升了TTA在图像分割任务中的稳定性与性能，尤其适用于域偏移和连续适应场景。

Abstract: Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.

</details>


### [43] [LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices](https://arxiv.org/abs/2602.03294)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: LEVIO 是一种专为超低功耗嵌入式平台优化的视觉惯性里程计（VIO）系统，可在资源受限硬件上实现实时六自由度运动追踪，兼顾效率与精度。


<details>
  <summary>Details</summary>
Motivation: 现有主流 VIO 系统计算开销大，难以部署在微无人机、智能眼镜等资源受限设备上，亟需一种轻量、高效且无需外部基础设施的运动追踪方案。

Method: LEVIO 结合 ORB 特征跟踪与光束法平差等成熟 VIO 组件，通过算法设计与软硬件协同优化，实现低内存占用、高并行性的架构，适配嵌入式微控制器和低功耗 SoC。

Result: 在超低功耗 RISC-V 并行 SoC 上实现 20 FPS 实时性能，功耗低于 100 mW，并在公开 VIO 数据集上验证了其精度与效率的平衡。

Conclusion: LEVIO 为资源受限平台提供了可行的实时六自由度感知解决方案，其开源实现有助于推动低功耗 VIO 技术在移动机器人和 AR 中的应用。

Abstract: Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.

</details>


### [44] [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302)
*Jinze Zhang,Jian Zhong,Li Lin,Jiaxiong Li,Ke Ma,Naiyang Li,Meng Li,Yuan Pan,Zeyu Meng,Mengyun Zhou,Shang Huang,Shilong Yu,Zhengyu Duan,Sutong Li,Honghui Xia,Juping Liu,Dan Liang,Yantao Wei,Xiaoying Tang,Jin Yuan,Peng Xiao*

Main category: cs.CV

TL;DR: 本文提出了FOCUS系统，一种基于视觉基础模型的端到端3D OCT视网膜疾病自动诊断框架，实现了从图像质量评估、异常检测到多病种分类的全流程自动化，在多中心验证中表现出与专家相当甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 当前OCT在临床中的全自动诊断受限于多阶段工作流和传统的单切片单任务AI模型，难以实现高效、准确的端到端诊断。因此，亟需一种能够整合3D信息并完成全流程自动化的智能系统以提升视网膜疾病筛查的可及性和效率。

Method: FOCUS系统采用两阶段流程：首先使用EfficientNetV2-S进行图像质量评估，随后利用微调后的视觉基础模型进行异常检测和多疾病分类。关键创新在于提出统一的自适应聚合方法，将2D切片级预测智能整合为3D患者级诊断。

Result: 在包含3,300名患者（40,672个切片）的数据集上训练和测试，并在来自四个不同级别医疗中心、涵盖多种OCT设备的1,345名患者（18,498个切片）上进行外部验证，FOCUS在图像质量评估（F1: 99.01%）、异常检测（F1: 97.46%）和患者级诊断（F1: 94.39%）方面均取得优异成绩。多中心真实世界验证显示其性能稳定（F1: 90.22%-95.24%）。人机对比实验表明，FOCUS在异常检测（F1: 95.47% vs 90.91%）和多病种诊断（F1: 93.49% vs 91.35%）上媲美甚至优于专家，且效率更高。

Conclusion: FOCUS成功实现了OCT图像到诊断的端到端自动化，为无人化眼科诊疗提供了经过验证的技术蓝图，有望显著提升大规模人群视网膜疾病筛查的可及性与效率。

Abstract: Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.

</details>


### [45] [Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation](https://arxiv.org/abs/2602.03316)
*Ting Xiang,Jinhui Zhao,Changjian Chen,Zhuo Tang*

Main category: cs.CV

TL;DR: 本文提出了一种针对生成数据增强的新型不可见干净标签后门攻击方法InvLBA，通过在潜在特征层面注入扰动，显著提升了攻击成功率，同时保持了模型在正常样本上的准确率，并对现有防御方法具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于像素级触发器的干净标签后门攻击方法（如COMBAT）在生成图像上攻击成功率低，难以有效实施；因此需要探索更有效的攻击方式，特别是在生成数据增强场景下。

Method: 提出InvLBA方法，在生成模型的潜在特征空间中引入不可见扰动作为后门触发器，而非传统的像素级扰动，并从理论上保证了干净样本准确率和攻击成功率的泛化能力。

Result: 在多个数据集上的实验表明，InvLBA平均提升攻击成功率46.43%，几乎不降低干净准确率，并对当前最先进的防御方法表现出高鲁棒性。

Conclusion: 通过在潜在特征层面设计后门攻击，InvLBA有效克服了传统像素级方法在生成数据增强中的局限性，为理解生成模型安全风险提供了新视角。

Abstract: With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.

</details>


### [46] [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320)
*Shengyuan Liu,Liuxin Bao,Qi Yang,Wanting Geng,Boyun Zheng,Chenxin Li,Wenting Chen,Houwen Peng,Yixuan Yuan*

Main category: cs.CV

TL;DR: 本文提出MedSAM-Agent，一种将医学图像分割重构为多步自主决策过程的新框架，通过混合提示策略和两阶段训练流程，在6种模态、21个数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型（MLLM）的医学图像分割方法通常采用单轮、僵化的交互策略，且缺乏过程级监督，难以充分发挥交互式工具（如SAM）的动态潜力，导致冗余操作。

Method: 提出MedSAM-Agent框架：1）设计混合提示策略，生成专家策划的轨迹以学习人类决策启发式和自适应优化策略；2）构建两阶段训练流程，结合多轮端到端结果验证与临床保真度过程奖励，提升交互简洁性与决策效率。

Result: 在6种医学影像模态和21个数据集上的实验表明，MedSAM-Agent在交互式分割任务中达到当前最优性能，有效融合了自主医学推理与鲁棒的迭代优化能力。

Conclusion: MedSAM-Agent通过将分割任务建模为多步决策过程，并引入过程监督与临床对齐的奖励机制，显著提升了医学图像分割的泛化性与效率，为通用医学智能体提供了新范式。

Abstract: Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.

</details>


### [47] [PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets](https://arxiv.org/abs/2602.03333)
*Haoran Li,Renyang Liu,Hongjia Liu,Chen Wang,Long Yin,Jian Xu*

Main category: cs.CV

TL;DR: 本文提出了一种即插即用、无需修改模型的3D点云对抗防御方法PWAVEP，通过在谱域中结合图小波显著性评分与局部稀疏性评分，分层净化高显著性对抗点并滤除中等显著性点中的高频扰动，显著提升了防御效果。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云对抗防御方法通常需要侵入式模型修改、昂贵训练或辅助数据，难以部署；而当前攻击方法在保持空间不可感知性的同时具有高攻击性能，对防御构成严峻挑战。

Method: 提出PWAVEP净化框架：首先计算每个点在谱图小波域的显著性得分和局部稀疏性得分；然后采用分层策略——移除最显著的点（视为不可恢复的对抗异常点），并对中等显著性点进行基于图小波变换的谱滤波，以衰减其高频系数，抑制对抗噪声。

Result: 大量实验表明，PWAVEP在准确率和鲁棒性方面均优于现有方法，在3D点云净化任务上达到新的最先进水平。

Conclusion: 通过理论与实证分析揭示了不可感知扰动与高频谱成分的关系，并据此构建的非侵入式谱域防御机制有效提升了3D点云模型对对抗攻击的鲁棒性。

Abstract: Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep

</details>


### [48] [Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability](https://arxiv.org/abs/2602.03339)
*Bingchen Zhao,Qiushan Guo,Ye Wang,Yixuan Huang,Zhonghua Zhai,Yu Tian*

Main category: cs.CV

TL;DR: 本文提出CompTok，一种用于学习具有组合性的视觉tokenizer的训练框架，通过token条件扩散解码器、InfoGAN式目标和对抗流正则化，在图像生成和语义编辑任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉tokenizer缺乏对组合性的显式建模，难以支持细粒度、可解释的图像控制与编辑。作者旨在设计一种能学习具备组合性结构的token表示的框架，以提升生成模型的可控性和语义编辑能力。

Method: CompTok采用token条件扩散解码器，并引入InfoGAN式目标，强制解码器利用所有输入token；同时通过在不同图像间交换部分token进行训练，增强组合性控制；对于无真实图像对应的交换token，使用对抗流正则化约束其生成结果保持在自然图像流形上。此外，提出两个新指标评估token空间的组合性与可学习性。

Result: CompTok在图像类别条件生成任务上达到SOTA性能，并能通过token交换实现高级语义编辑；所提指标表明其token空间具有更强的组合性和更易学习的结构。

Conclusion: CompTok有效提升了视觉tokenizer的组合性与可控性，不仅支持高质量生成，还为语义编辑和token空间分析提供了新工具。

Abstract: We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.

</details>


### [49] [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342)
*Bryan Sangwoo Kim,Jonghyun Park,Jong Chul Ye*

Main category: cs.CV

TL;DR: 提出Tiled Prompts框架，通过为每个潜在图像块生成特定提示，在图像和视频超分辨率任务中缓解全局提示导致的语义不足问题，提升感知质量和文本对齐度，同时减少幻觉与拼接伪影。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本条件的扩散模型在高分辨率超分辨率中使用全局提示，易造成局部细节缺失（提示稀疏）和无关引导（提示误导），尤其在采用潜空间分块（latent tiling）策略时更为明显。

Method: 提出Tiled Prompts方法，为每个潜空间图像块生成对应的局部文本提示，并在局部文本条件后验下执行超分辨率，实现高信息量、针对性强的引导。

Result: 在真实高分辨率图像和视频上的实验表明，该方法在感知质量与文本对齐方面均优于使用全局提示的基线方法，同时减少了幻觉现象和块级伪影。

Conclusion: Tiled Prompts有效解决了高分辨率超分辨率中文本提示语义不足的问题，在几乎不增加计算开销的前提下显著提升了生成效果。

Abstract: Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.

</details>


### [50] [Z3D: Zero-Shot 3D Visual Grounding from Images](https://arxiv.org/abs/2602.03361)
*Nikita Drozdov,Andrey Lemeshko,Nikita Gavrilov,Anton Konushin,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: 本文提出Z3D，一种无需几何监督或物体先验的零样本3D视觉定位方法，仅使用多视角图像即可实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本3D视觉定位方法存在性能瓶颈，且通常依赖几何监督或物体先验；作者旨在仅利用多视角图像实现高效、通用的零样本3D定位。

Method: 提出Z3D通用定位流程，结合先进的零样本3D实例分割以生成高质量3D边界框提案，并通过基于提示的分割充分利用现代视觉语言模型（VLM）进行推理；可选地融合相机位姿和深度图。

Result: 在ScanRefer和Nr3D基准上，Z3D在零样本方法中达到当前最优性能。

Conclusion: 仅依靠多视角图像即可实现高性能零样本3D视觉定位，关键在于高质量提案生成与先进VLM推理机制的结合。

Abstract: 3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .

</details>


### [51] [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370)
*Takaya Kawakatsu,Ryo Ishiyama*

Main category: cs.CV

TL;DR: 本文提出一种离散扩散框架，将手写数学表达式识别（HMER）重构为迭代符号优化过程，显著提升了结构一致性和识别准确率。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在HMER任务中存在曝光偏差和语法不一致问题，难以有效处理多样符号与二维结构布局。

Method: 采用离散扩散框架，通过多步重掩码机制迭代优化符号及其结构关系；结合符号感知的标记化策略和随机掩码互学习提升语法对齐与鲁棒性。

Result: 在MathWriting基准上达到5.56% CER和60.42% EM，优于强Transformer和商业基线；在CROHME 2014–2023数据集上也取得一致提升。

Conclusion: 离散扩散为结构感知的视觉识别提供了超越传统生成建模的新范式。

Abstract: Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\% CER and 60.42\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.

</details>


### [52] [Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion](https://arxiv.org/abs/2602.03371)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: 本文提出了一种多分辨率对齐（MRA）方法，通过引入场景级和实例级的跨分辨率特征对齐作为辅助监督，缓解基于相机的3D语义场景补全任务中因体素稀疏性导致的优化效率与性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的3D语义场景补全方法仅依赖体素标签进行监督，在自动驾驶场景中大量体素为空，导致体素稀疏问题，限制了模型的优化效率和性能。

Method: 提出多分辨率对齐（MRA）框架，包含三个模块：1）多分辨率视图Transformer模块，将2D图像特征投影为多分辨率3D特征并在场景级对齐；2）立方语义各向异性模块，评估每个体素在局部立方区域内的语义显著性；3）关键分布对齐模块，以语义显著性为指导选取关键体素作为锚点，并通过循环损失实现跨分辨率的关键特征分布一致性监督。

Result: 所提方法有效缓解了体素稀疏问题，提升了模型在3D语义场景补全任务中的优化效率与性能。

Conclusion: 通过引入多分辨率下的场景级与实例级对齐作为辅助监督信号，MRA方法显著改善了基于相机的3D语义场景补全效果，为自动驾驶感知系统提供了更鲁棒的体素级场景理解能力。

Abstract: Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.

</details>


### [53] [SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI](https://arxiv.org/abs/2602.03372)
*Mario Pascual-González,Ariadna Jiménez-Partinen,R. M. Luque-Baena,Fátima Nagib-Raya,Ezequiel López-Rubio*

Main category: cs.CV

TL;DR: 本文提出SLIM-Diff，一种紧凑的联合扩散模型，用于生成癫痫FLAIR MRI中的局灶性皮质发育不良（FCD）病灶图像及其掩码，通过共享瓶颈U-Net结构和可调Lp损失提升生成稳定性与保真度。


<details>
  <summary>Details</summary>
Motivation: 由于FCD病灶在MRI中表现微弱且稀少，传统的联合图像-掩码生成模型容易不稳定并出现记忆化问题，因此需要一种更鲁棒、高效的生成方法。

Method: 提出SLIM-Diff模型，包含：(i) 一个共享瓶颈的U-Net结构，从双通道图像+掩码表示中紧密耦合解剖结构与病灶几何；(ii) 引入可调Lp损失函数以优化损失几何。同时在相同设置下比较不同预测参数化方式（如ε预测与x₀预测）及Lp范数的影响。

Result: 实验表明，x₀预测在联合生成任务中表现最优；使用次二次惩罚（如L₁.₅）可提升图像保真度，而L₂损失更有利于保留病灶掩码的形态结构。

Conclusion: SLIM-Diff通过结构设计与损失函数调优，在稀缺且细微的医学图像生成任务中实现了更稳定、高质量的联合图像-掩码生成，为医学图像合成提供了有效方案。

Abstract: Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff

</details>


### [54] [From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning](https://arxiv.org/abs/2602.03390)
*Hyun Seok Seong,WonJun Moon,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 本文提出了一种名为协同表征学习（SRL）的新方法，通过在编码器和解码器之间建立良性循环，解决了基于重建的无监督物体中心学习中编码器注意力图与解码器重建图之间的不一致性问题，从而在视频物体中心学习基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于槽（slot-based）的无监督物体中心学习模型依赖于重建训练，但编码器生成的高频注意力图与解码器产生的空间一致但模糊的重建图之间存在根本性冲突，导致特征噪声和梯度缺乏高频细节，形成恶性循环。

Method: 提出协同表征学习（SRL）框架：利用编码器的锐利性来解码器输出中的语义边界去模糊，同时利用解码器的空间一致性对编码器特征进行去噪；并通过一个带有槽正则化目标的预热阶段，为每个槽初始分配不同实体，以稳定相互优化过程。

Result: SRL在多个视频物体中心学习基准上达到了当前最优性能。

Conclusion: 通过弥合编码器与解码器之间的表征差距，SRL有效打破了原有恶性循环，实现了更高质量的无监督场景分解。

Abstract: Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.

</details>


### [55] [Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction](https://arxiv.org/abs/2602.03414)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出Socratic-Geo框架，通过多智能体协作实现几何推理数据的自主合成与模型学习的动态耦合，在仅使用108个种子问题和四分之一基线数据的情况下，显著超越现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在几何推理任务上表现不佳，主要受限于高质量图像-文本对的极度稀缺；人工标注成本高昂，而现有自动化方法难以保证数据保真度与训练有效性。

Method: 提出Socratic-Geo框架，包含Teacher、Solver和Generator三个智能体：Teacher生成带反思反馈的参数化Python脚本以确保图文对质量；Solver通过偏好学习优化推理能力，并将失败路径反馈用于指导Teacher进行针对性数据增强；Generator则从积累的“图像-代码-指令”三元组中学习图像生成能力。

Result: Socratic-Solver在六个基准上达到49.11分，仅用基线四分之一的数据即超越强基线2.43分；Socratic-Generator在GenExam上达到42.4%，刷新开源模型纪录，优于Seedream-4.0（39.8%）并接近Gemini-2.5-Flash-Image（43.1%）。

Conclusion: Socratic-Geo通过将数据合成与模型学习动态耦合，有效解决了几何推理任务中高质量数据稀缺的问题，显著提升了模型性能，为多模态模型的自主进化提供了新范式。

Abstract: Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated "image-code-instruction" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).

</details>


### [56] [ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.03425)
*Xiaofeng Tan,Jun Liu,Yuanting Fan,Bin-Bin Gao,Xi Jiang,Xiaochen Chen,Jinlong Peng,Chengjie Wang,Hongsong Wang,Feng Zheng*

Main category: cs.CV

TL;DR: 本文提出ConsistentRFT框架，通过动态粒度回滚（DGR）和一致性策略梯度优化（CPGO）有效缓解基于流模型在强化微调（RFT）过程中产生的视觉幻觉问题，在低层和高层感知幻觉上分别平均降低49%和38%，并在域外指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 强化微调（RFT）在流模型中常引发视觉幻觉，如过度优化细节和语义错位。本文旨在探究其成因并提出缓解方法。

Method: 作者从探索与利用两个角度分析RFT问题，提出ConsistentRFT框架：1）设计动态粒度回滚（DGR）机制，通过动态调度不同噪声源平衡全局语义与局部细节的探索；2）引入一致性策略梯度优化（CPGO），通过对齐当前策略与更稳定的先验来保持模型跨步一致性。

Result: 实验表明，ConsistentRFT显著减少视觉幻觉，低层和高层感知幻觉分别平均降低49%和38%；在域外评估中，相比基线方法（FLUX1.dev）提升5.1%（基线下降0.4%）。

Conclusion: ConsistentRFT通过改进探索机制和策略优化方式，有效缓解了流模型在RFT中的视觉幻觉问题，提升了生成质量和泛化能力。

Abstract: Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\% for low-level and 38\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\% (v.s. the baseline's decrease of -0.4\%) over FLUX1.dev. This is \href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.

</details>


### [57] [Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation](https://arxiv.org/abs/2602.03448)
*Yijia Xu,Zihao Wang,Jinshi Cui*

Main category: cs.CV

TL;DR: 本文提出了一种名为层次化概念到外观引导（CAG）的框架，用于提升多主体图像生成中的身份一致性和组合控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多主体图像生成中常因依赖扩散模型隐式关联文本提示与参考图像，导致身份不一致和组合控制能力有限。

Method: CAG框架在概念层采用VAE dropout训练策略，增强对视觉语言模型（VLM）语义信号的依赖；在外观层，将VLM导出的对应关系融入Diffusion Transformer中的对应感知掩码注意力模块，实现精准属性绑定。

Result: 大量实验表明，该方法在多主体图像生成任务上达到最先进水平，显著提升了提示遵循能力和主体一致性。

Conclusion: 通过显式、结构化的从概念到外观的引导机制，CAG有效解决了多主体图像生成中的身份一致性和组合控制难题。

Abstract: Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.

</details>


### [58] [Contextualized Visual Personalization in Vision-Language Models](https://arxiv.org/abs/2602.03454)
*Yeongtak Oh,Sangwon Yu,Junsung Park,Han Cheol Moon,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: 本文提出CoViP框架，通过强化学习后训练和字幕增强生成，提升视觉语言模型在个性化图像描述任务中的表现，从而实现上下文化视觉个性化。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）难以根据用户特定经验生成个性化响应，因其无法将视觉输入与用户积累的视觉-文本上下文关联，本文旨在解决这一问题。

Method: 提出CoViP统一框架，将个性化图像描述作为核心任务，采用基于强化学习的后训练和字幕增强生成方法，并设计诊断性评估以排除纯文本捷径。

Result: 实验表明现有开源和闭源VLMs在此任务上存在显著局限，而CoViP不仅提升了个性化图像描述性能，还在下游个性化任务中带来整体增益。

Conclusion: CoViP是实现鲁棒且可泛化的上下文化视觉个性化的关键步骤。

Abstract: Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.

</details>


### [59] [Inlier-Centric Post-Training Quantization for Object Detection Models](https://arxiv.org/abs/2602.03472)
*Minsu Kim,Dongyeun Lee,Jaemyung Yu,Jiwan Hur,Giseop Kim,Junmo Kim*

Main category: cs.CV

TL;DR: 本文提出InlierQ，一种以正常样本为中心的后训练量化方法，通过梯度感知的显著性评分和EM算法区分异常与有用特征，在仅需64个校准样本的情况下，有效降低2D/3D目标检测任务中的量化误差。


<details>
  <summary>Details</summary>
Motivation: 目标检测计算开销大，部署困难，需借助量化技术；但背景杂乱和传感器噪声等任务无关因素会引发冗余激活（异常），扩大激活范围并扭曲分布，干扰量化时的比特分配，导致信息特征丢失。现有方法缺乏有效区分异常与有用信息的标准。

Method: InlierQ通过计算梯度感知的体显著性得分，利用期望最大化（EM）算法拟合这些得分的后验分布，将每个激活体分类为正常样本或异常，并在量化过程中抑制异常、保留信息特征。该方法无需标签、即插即用，仅需64个校准样本。

Result: 在COCO和nuScenes基准上的实验表明，InlierQ在基于相机（2D和3D）和LiDAR（3D）的目标检测任务中均能持续降低量化误差。

Conclusion: InlierQ通过聚焦正常样本、有效识别并抑制异常激活，在极低校准成本下提升了目标检测模型的量化性能，兼顾效率与精度。

Abstract: Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.

</details>


### [60] [Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance](https://arxiv.org/abs/2602.03491)
*Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Youcheng Pan,Xiaoqiang Zhou,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出DiSCo和Table-GLS框架，在无需外部工具和极少标注的情况下，有效提升大视觉语言模型（LVLM）对表格图像的理解与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理表格图像时依赖昂贵的监督训练、强化学习或外部工具，限制了效率与可扩展性；本文旨在探索如何以最少标注且不依赖外部工具的方式，使LVLM适应表格推理任务。

Method: 提出DiSCo框架，通过解耦结构抽象与语义对齐来适配LVLM；在此基础上构建Table-GLS框架，采用从全局到局部的结构引导推理机制，实现结构化探索与证据支撑的推理。

Result: 在多个多样化基准上的实验表明，该方法显著提升了LVLM对表格的理解与推理能力，并在未见过的表格结构上展现出良好泛化性。

Conclusion: 所提方法有效解决了LVLM在表格推理中的挑战，为低资源、无工具依赖的表格理解提供了高效可行的解决方案。

Abstract: Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.

</details>


### [61] [Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning](https://arxiv.org/abs/2602.03530)
*Xufei Zhang,Xinjiao Zhou,Ziling Deng,Dongdong Geng,Jianxiong Wang*

Main category: cs.CV

TL;DR: 本文提出逻辑异常分类（LAC）任务及LogiCls框架，通过视觉-语言模型实现工业图像中逻辑规则违反的细粒度识别与解释。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法仅做二分类，无法指出具体违反了哪条逻辑规则，难以满足工业质检对可解释性的需求。

Method: 提出LogiCls框架，将复杂逻辑约束分解为可验证子查询；设计数据驱动的指令合成流程，生成带思维链监督信号的数据，并结合难度感知重采样策略训练视觉语言模型。

Result: 实验表明LogiCls在工业逻辑异常分类任务上具有高准确性、鲁棒性和可解释性，能同时输出违规类别及其证据路径。

Conclusion: 该方法有效统一了异常检测与细粒度违规分类，在提升模型逻辑推理能力的同时增强了工业质检系统的实用性。

Abstract: Logical anomalies are violations of predefined constraints on object quantity, spatial layout, and compositional relationships in industrial images. While prior work largely treats anomaly detection as a binary decision, such formulations cannot indicate which logical rule is broken and therefore offer limited value for quality assurance. We introduce Logical Anomaly Classification (LAC), a task that unifies anomaly detection and fine-grained violation classification in a single inference step. To tackle LAC, we propose LogiCls, a vision-language framework that decomposes complex logical constraints into a sequence of verifiable subqueries. We further present a data-centric instruction synthesis pipeline that generates chain-of-thought (CoT) supervision for these subqueries, coupling precise grounding annotations with diverse image-text augmentations to adapt vision language models (VLMs) to logic-sensitive reasoning. Training is stabilized by a difficulty-aware resampling strategy that emphasizes challenging subqueries and long tail constraint types. Extensive experiments demonstrate that LogiCls delivers robust, interpretable, and accurate industrial logical anomaly classification, providing both the predicted violation categories and their evidence trails.

</details>


### [62] [PnP-U3D: Plug-and-Play 3D Framework Bridging Autoregression and Diffusion for Unified Understanding and Generation](https://arxiv.org/abs/2602.03533)
*Yongwei Chen,Tianyi Wei,Yushi Lan,Zhaoyang Lyu,Shangchen Zhou,Xudong Xu,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出首个结合自回归（AR）与扩散模型的统一框架，用于3D理解与生成，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有将3D任务统一到单一自回归范式的方法因信号量化和高昂训练成本导致性能下降，作者旨在在不牺牲各自能力的前提下实现理解与生成的有效信息交互，并利用预训练模型降低成本。

Method: 采用自回归范式进行3D理解，扩散范式进行3D生成，并通过轻量级Transformer桥接大语言模型特征空间与3D扩散模型条件空间，实现跨模态信息交换。

Result: 在多种3D理解、生成及编辑任务上均取得领先性能。

Conclusion: 结合AR与扩散模型的统一框架是构建通用3D智能系统的有效方向。

Abstract: The rapid progress of large multimodal models has inspired efforts toward unified frameworks that couple understanding and generation. While such paradigms have shown remarkable success in 2D, extending them to 3D remains largely underexplored. Existing attempts to unify 3D tasks under a single autoregressive (AR) paradigm lead to significant performance degradation due to forced signal quantization and prohibitive training cost. Our key insight is that the essential challenge lies not in enforcing a unified autoregressive paradigm, but in enabling effective information interaction between generation and understanding while minimally compromising their inherent capabilities and leveraging pretrained models to reduce training cost. Guided by this perspective, we present the first unified framework for 3D understanding and generation that combines autoregression with diffusion. Specifically, we adopt an autoregressive next-token prediction paradigm for 3D understanding, and a continuous diffusion paradigm for 3D generation. A lightweight transformer bridges the feature space of large language models and the conditional space of 3D diffusion models, enabling effective cross-modal information exchange while preserving the priors learned by standalone models. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across diverse 3D understanding and generation benchmarks, while also excelling in 3D editing tasks. These results highlight the potential of unified AR+diffusion models as a promising direction for building more general-purpose 3D intelligence.

</details>


### [63] [Constrained Dynamic Gaussian Splatting](https://arxiv.org/abs/2602.03538)
*Zihan Zheng,Zhenglong Wu,Xuanxuan Wang,Houqiang Zhong,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai,Wenjun Zhang*

Main category: cs.CV

TL;DR: 本文提出约束动态高斯泼溅（CDGS），通过可微分预算控制器和静态/动态元素解耦优化，在严格满足用户定义高斯数量限制的同时，显著提升4D重建的渲染质量与压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态高斯泼溅方法在部署时面临两难：无约束稠密化导致内存占用过高，而启发式剪枝无法在预设高斯预算下实现最优渲染质量。

Method: 将动态场景重建建模为带预算约束的优化问题，引入基于多模态统一重要性评分的可微分预算控制器；解耦静态与动态元素优化，并采用自适应分配机制；结合三阶段训练策略和双模式混合压缩方案。

Result: 在严格满足硬件约束（误差<2%）的前提下，相比现有方法实现超过3倍的压缩率，并在不同容量限制下均取得最优渲染质量。

Conclusion: CDGS有效解决了动态高斯泼溅中的资源-质量权衡问题，推动了其在边缘设备上的实用化。

Abstract: While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.

</details>


### [64] [Cut to the Mix: Simple Data Augmentation Outperforms Elaborate Ones in Limited Organ Segmentation Datasets](https://arxiv.org/abs/2602.03555)
*Chang Liu,Fuxin Fan,Annette Schwarz,Andreas Maier*

Main category: cs.CV

TL;DR: 本文研究了四种跨图像数据增强策略（CutMix、CarveMix、ObjectAug 和 AnatoMix）在多器官分割任务中的效果，发现 CutMix、CarveMix 和 AnatoMix 能显著提升分割性能，其中 CutMix 表现最稳健。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在多器官分割中表现优异，但其训练依赖大量人工标注数据，而临床数据稀缺。为提升小数据下模型性能，需探索更有效的数据增强方法，尤其是跨图像和对象级别的增强策略。

Method: 在两个器官分割数据集上评估四种跨图像数据增强策略（CutMix、CarveMix、ObjectAug、AnatoMix），并与不使用数据增强的 nnUNet 基线进行对比，同时结合传统数据增强（TDA）进一步验证效果。

Result: CutMix、CarveMix 和 AnatoMix 分别将平均 Dice 分数提升了 4.9、2.0 和 1.9；结合 TDA 后性能进一步提高。即使 CutMix 生成看似“错误”的图像，仍能有效提升分割性能。

Conclusion: 跨图像数据增强策略，特别是 CutMix，是提升多器官分割模型在有限数据下性能的有效手段，且具有鲁棒性和实用性。代码已公开以供后续研究使用。

Abstract: Multi-organ segmentation is a widely applied clinical routine and automated organ segmentation tools dramatically improve the pipeline of the radiologists. Recently, deep learning (DL) based segmentation models have shown the capacity to accomplish such a task. However, the training of the segmentation networks requires large amount of data with manual annotations, which is a major concern due to the data scarcity from clinic. Working with limited data is still common for researches on novel imaging modalities. To enhance the effectiveness of DL models trained with limited data, data augmentation (DA) is a crucial regularization technique. Traditional DA (TDA) strategies focus on basic intra-image operations, i.e. generating images with different orientations and intensity distributions. In contrast, the interimage and object-level DA operations are able to create new images from separate individuals. However, such DA strategies are not well explored on the task of multi-organ segmentation. In this paper, we investigated four possible inter-image DA strategies: CutMix, CarveMix, ObjectAug and AnatoMix, on two organ segmentation datasets. The result shows that CutMix, CarveMix and AnatoMix can improve the average dice score by 4.9, 2.0 and 1.9, compared with the state-of-the-art nnUNet without DA strategies. These results can be further improved by adding TDA strategies. It is revealed in our experiments that Cut-Mix is a robust but simple DA strategy to drive up the segmentation performance for multi-organ segmentation, even when CutMix produces intuitively 'wrong' images. Our implementation is publicly available for future benchmarks.

</details>


### [65] [ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images](https://arxiv.org/abs/2602.03558)
*Xinyue Li,Zhiming Xu,Zhichao Zhang,Zhaolin Cai,Sijing Wu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出ELIQ，一种无需标签的AI生成图像质量评估框架，能有效应对不断演进的生成模型带来的挑战，在多个基准上优于现有无标签方法，并可泛化至用户生成内容场景。


<details>
  <summary>Details</summary>
Motivation: 随着生成式文生图模型快速发展，传统依赖人工标注的质量评估方法难以适应新模型产生的图像，且旧有标签对新一代生成图像不再可靠，亟需一种无需人工标签、可随模型演进而持续适用的图像质量评估方法。

Method: ELIQ通过自动构建正样本与面向特定方面的负样本对（涵盖传统失真和AIGC特有失真），在无标注条件下实现可迁移监督；在此基础上，利用指令微调将预训练多模态模型转化为质量感知评判器，并通过轻量级门控融合与Quality Query Transformer预测二维质量分数。

Result: 实验表明，ELIQ在多个基准测试中一致优于现有无标签方法，且无需修改即可从AIGC场景泛化到UGC场景。

Conclusion: ELIQ为在持续演进的生成模型背景下实现可扩展、无标签的图像质量评估提供了有效路径。

Abstract: Generative text-to-image models are advancing at an unprecedented pace, continuously shifting the perceptual quality ceiling and rendering previously collected labels unreliable for newer generations. To address this, we present ELIQ, a Label-free Framework for Quality Assessment of Evolving AI-generated Images. Specifically, ELIQ focuses on visual quality and prompt-image alignment, automatically constructs positive and aspect-specific negative pairs to cover both conventional distortions and AIGC-specific distortion modes, enabling transferable supervision without human annotations. Building on these pairs, ELIQ adapts a pre-trained multimodal model into a quality-aware critic via instruction tuning and predicts two-dimensional quality using lightweight gated fusion and a Quality Query Transformer. Experiments across multiple benchmarks demonstrate that ELIQ consistently outperforms existing label-free methods, generalizes from AI-generated content (AIGC) to user-generated content (UGC) scenarios without modification, and paves the way for scalable and label-free quality assessment under continuously evolving generative models. The code will be released upon publication.

</details>


### [66] [SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM](https://arxiv.org/abs/2602.03589)
*Ming Nie,Dan Ding,Chunwei Wang,Yuanfan Guo,Jianhua Han,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出SlowFocus机制，通过动态聚焦与多频混合注意力提升视频大语言模型在细粒度时序理解上的能力，并构建新基准FineAction-CGR进行评估。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型（Vid-LLMs）难以同时保留高质量的帧级语义信息和完整的视频级时序信息，限制了其在细粒度视频理解任务中的表现。

Method: 提出SlowFocus机制：首先根据问题识别相关时序片段，对该片段进行密集采样以提取局部高频特征；再通过多频混合注意力模块融合局部高频细节与全局低频上下文。同时设计配套训练策略，并构建FineAction-CGR基准。

Result: 在多个公开视频理解基准及新提出的FineAction-CGR上，所提方法均显著优于现有方法。

Conclusion: SlowFocus机制有效提升了Vid-LLMs在细粒度时序理解方面的能力，为未来视频大模型的发展提供了新思路。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in text understanding, which has paved the way for their expansion into video LLMs (Vid-LLMs) to analyze video data. However, current Vid-LLMs struggle to simultaneously retain high-quality frame-level semantic information (i.e., a sufficient number of tokens per frame) and comprehensive video-level temporal information (i.e., an adequate number of sampled frames per video). This limitation hinders the advancement of Vid-LLMs towards fine-grained video understanding. To address this issue, we introduce the SlowFocus mechanism, which significantly enhances the equivalent sampling frequency without compromising the quality of frame-level visual tokens. SlowFocus begins by identifying the query-related temporal segment based on the posed question, then performs dense sampling on this segment to extract local high-frequency features. A multi-frequency mixing attention module is further leveraged to aggregate these local high-frequency details with global low-frequency contexts for enhanced temporal comprehension. Additionally, to tailor Vid-LLMs to this innovative mechanism, we introduce a set of training strategies aimed at bolstering both temporal grounding and detailed temporal reasoning capabilities. Furthermore, we establish FineAction-CGR, a benchmark specifically devised to assess the ability of Vid-LLMs to process fine-grained temporal understanding tasks. Comprehensive experiments demonstrate the superiority of our mechanism across both existing public video understanding benchmarks and our proposed FineAction-CGR.

</details>


### [67] [High-Resolution Underwater Camouflaged Object Detection: GBU-UCOD Dataset and Topology-Aware and Frequency-Decoupled Networks](https://arxiv.org/abs/2602.03591)
*Wenji Wu,Shuo Ye,Yiyu Liu,Jiguang He,Zhuo Wang,Zitong Yu*

Main category: cs.CV

TL;DR: 本文提出DeepTopo-Net，一种结合拓扑感知与频域解耦的水下伪装目标检测新框架，并构建首个面向深海垂直分层的高分辨率数据集GBU-UCOD，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在深海环境中难以有效处理细长生物的拓扑断裂问题和透明生物的微弱特征提取，且缺乏针对深渊与超深渊带的高质量数据集。

Method: 提出DeepTopo-Net框架，包含基于黎曼度量张量动态调整卷积采样场的水体条件自适应感知器（WCAP），以及利用骨架先验保持细长目标结构连通性的深渊拓扑优化模块（ATRM）；同时构建高分辨率2K数据集GBU-UCOD。

Result: 在MAS3K、RMAS及新提出的GBU-UCOD数据集上实验表明，DeepTopo-Net在保持复杂水下目标形态完整性方面优于现有方法，达到最先进水平。

Conclusion: 通过融合拓扑先验与环境自适应感知机制，DeepTopo-Net显著提升了深海伪装目标的检测能力，所发布的数据集填补了深海垂直分层研究的数据空白。

Abstract: Underwater Camouflaged Object Detection (UCOD) is a challenging task due to the extreme visual similarity between targets and backgrounds across varying marine depths. Existing methods often struggle with topological fragmentation of slender creatures in the deep sea and the subtle feature extraction of transparent organisms. In this paper, we propose DeepTopo-Net, a novel framework that integrates topology-aware modeling with frequency-decoupled perception. To address physical degradation, we design the Water-Conditioned Adaptive Perceptor (WCAP), which employs Riemannian metric tensors to dynamically deform convolutional sampling fields. Furthermore, the Abyssal-Topology Refinement Module (ATRM) is developed to maintain the structural connectivity of spindly targets through skeletal priors. Specifically, we first introduce GBU-UCOD, the first high-resolution (2K) benchmark tailored for marine vertical zonation, filling the data gap for hadal and abyssal zones. Extensive experiments on MAS3K, RMAS, and our proposed GBU-UCOD datasets demonstrate that DeepTopo-Net achieves state-of-the-art performance, particularly in preserving the morphological integrity of complex underwater patterns. The datasets and codes will be released at https://github.com/Wuwenji18/GBU-UCOD.

</details>


### [68] [TIPS Over Tricks: Simple Prompts for Effective Zero-shot Anomaly Detection](https://arxiv.org/abs/2602.03594)
*Alireza Salehi,Ehsan Karami,Sepehr Noey,Sahand Noey,Makoto Yamada,Reshad Hosseini,Mohammad Sabokrou*

Main category: cs.CV

TL;DR: 本文提出一种基于TIPS视觉语言模型的零样本异常检测方法，通过解耦提示和局部证据融合，在不依赖复杂辅助模块的情况下，显著提升了图像级和像素级的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的零样本异常检测方法因图像-文本对齐粗糙，难以有效定位和检测细粒度异常；同时，以往研究忽视了主干模型的选择。

Method: 采用具有空间感知训练目标的TIPS模型作为主干，并设计解耦提示机制（图像级使用固定提示，像素级使用可学习提示），同时将局部特征证据注入全局评分中。

Result: 在七个工业数据集上，图像级性能提升1.1–3.9%，像素级提升1.5–6.9%，且模型结构简洁、泛化能力强。

Conclusion: 通过改进主干模型与提示机制，可在不依赖CLIP特定技巧的前提下，实现高效准确的零样本异常检测。

Abstract: Anomaly detection identifies departures from expected behavior in safety-critical settings. When target-domain normal data are unavailable, zero-shot anomaly detection (ZSAD) leverages vision-language models (VLMs). However, CLIP's coarse image-text alignment limits both localization and detection due to (i) spatial misalignment and (ii) weak sensitivity to fine-grained anomalies; prior work compensates with complex auxiliary modules yet largely overlooks the choice of backbone. We revisit the backbone and use TIPS-a VLM trained with spatially aware objectives. While TIPS alleviates CLIP's issues, it exposes a distributional gap between global and local features. We address this with decoupled prompts-fixed for image-level detection and learnable for pixel-level localization-and by injecting local evidence into the global score. Without CLIP-specific tricks, our TIPS-based pipeline improves image-level performance by 1.1-3.9% and pixel-level by 1.5-6.9% across seven industrial datasets, delivering strong generalization with a lean architecture. Code is available at github.com/AlirezaSalehy/Tipsomaly.

</details>


### [69] [Refer-Agent: A Collaborative Multi-Agent System with Reasoning and Reflection for Referring Video Object Segmentation](https://arxiv.org/abs/2602.03595)
*Haichao Jiang,Tianming Liang,Wei-Shi Zheng,Jian-Fang Hu*

Main category: cs.CV

TL;DR: 本文提出Refer-Agent，一种基于多智能体协作的零样本视频指代分割方法，通过推理-反思机制和动态视觉聚焦策略，在不依赖微调的情况下显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前RVOS方法严重依赖多模态大语言模型的监督微调，存在数据依赖性强、难以适应模型快速演进的问题；而现有零样本方法因流程设计简单，性能远落后于微调方法。

Method: 提出Refer-Agent多智能体系统，将RVOS分解为逐步推理过程，引入粗到精的帧选择策略与动态聚焦布局，并设计问答式反思链机制以验证中间结果并优化后续推理。

Result: 在五个具有挑战性的基准上，Refer-Agent显著优于包括微调和零样本在内的最先进方法，且无需额外微调即可快速集成新MLLM。

Conclusion: Refer-Agent通过多智能体协作与自反思机制，有效解决了RVOS中零样本性能不足与模型可扩展性差的问题，为未来多模态视频理解提供了高效灵活的新范式。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment objects in videos based on textual queries. Current methods mainly rely on large-scale supervised fine-tuning (SFT) of Multi-modal Large Language Models (MLLMs). However, this paradigm suffers from heavy data dependence and limited scalability against the rapid evolution of MLLMs. Although recent zero-shot approaches offer a flexible alternative, their performance remains significantly behind SFT-based methods, due to the straightforward workflow designs. To address these limitations, we propose \textbf{Refer-Agent}, a collaborative multi-agent system with alternating reasoning-reflection mechanisms. This system decomposes RVOS into step-by-step reasoning process. During reasoning, we introduce a Coarse-to-Fine frame selection strategy to ensure the frame diversity and textual relevance, along with a Dynamic Focus Layout that adaptively adjusts the agent's visual focus. Furthermore, we propose a Chain-of-Reflection mechanism, which employs a Questioner-Responder pair to generate a self-reflection chain, enabling the system to verify intermediate results and generates feedback for next-round reasoning refinement. Extensive experiments on five challenging benchmarks demonstrate that Refer-Agent significantly outperforms state-of-the-art methods, including both SFT-based models and zero-shot approaches. Moreover, Refer-Agent is flexible and enables fast integration of new MLLMs without any additional fine-tuning costs. Code will be released.

</details>


### [70] [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604)
*Basile Terver,Randall Balestriero,Megi Dervishi,David Fan,Quentin Garrido,Tushar Nagarajan,Koustuv Sinha,Wancong Zhang,Mike Rabbat,Yann LeCun,Amir Bar*

Main category: cs.CV

TL;DR: EB-JEPA 是一个开源库，用于通过联合嵌入预测架构（JEPA）学习表征和世界模型，支持从图像到视频再到动作条件世界模型的迁移，并在多个任务上展示了高效且有效的性能。


<details>
  <summary>Details</summary>
Motivation: 传统生成式建模在像素空间中存在缺陷，而 JEPA 通过在表征空间中进行预测，能够避免这些问题并学习语义上有意义的特征。作者旨在提供一个模块化、易于复现的工具库，使基于能量的自监督学习方法更易被研究和教育使用。

Method: EB-JEPA 提供了模块化的 JEPA 实现，涵盖图像、视频（如 Moving MNIST）和动作条件世界模型（如 Two Rooms 导航任务）。所有示例均可在单 GPU 上几小时内完成训练，并包含对 JEPA 各组件的消融实验。

Result: 在 CIFAR-10 上的表征探测达到 91% 准确率；在 Moving MNIST 上成功实现多步预测；在 Two Rooms 任务中实现 97% 的规划成功率。消融实验表明各正则化组件对防止表征崩溃至关重要。

Conclusion: EB-JEPA 展示了 JEPA 架构在不同模态和任务中的通用性和有效性，为自监督表征学习和世界模型研究提供了实用、高效的开源工具。

Abstract: We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.

</details>


### [71] [KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs](https://arxiv.org/abs/2602.03615)
*Baiyang Song,Jun Peng,Yuxin Zhang,Guangyao Chen,Feidiao Yang,Jianyuan Guo*

Main category: cs.CV

TL;DR: 提出KTV框架，通过两阶段关键帧与视觉token选择，在无需训练的情况下高效实现视频理解，显著减少计算开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有无训练视频理解方法因处理冗余帧和高计算成本而效果受限，且基于CLIP的关键帧选择易受偏见影响，可能遗漏关键信息。

Method: KTV包含两个阶段：第一阶段进行与问题无关的关键帧选择，通过聚类帧级视觉特征获得紧凑、多样且具代表性的帧子集；第二阶段对每个关键帧进行视觉token剪枝，依据token重要性与冗余度剔除不必要token，大幅减少输入LLM的token数量。

Result: 在Multiple-Choice VideoQA任务上，KTV以极少视觉token（如60分钟视频仅用504个token）超越当前最先进的无训练基线，并在MLVU-Test上达到44.8%准确率，甚至优于部分需训练的方法。

Conclusion: KTV有效解决了无训练视频理解中的冗余与效率问题，在显著降低计算负担的同时实现了优越的视频理解性能。

Abstract: Training-free video understanding leverages the strong image comprehension capabilities of pre-trained vision language models (VLMs) by treating a video as a sequence of static frames, thus obviating the need for costly video-specific training. However, this paradigm often suffers from severe visual redundancy and high computational overhead, especially when processing long videos. Crucially, existing keyframe selection strategies, especially those based on CLIP similarity, are prone to biases and may inadvertently overlook critical frames, resulting in suboptimal video comprehension. To address these significant challenges, we propose \textbf{KTV}, a novel two-stage framework for efficient and effective training-free video understanding. In the first stage, KTV performs question-agnostic keyframe selection by clustering frame-level visual features, yielding a compact, diverse, and representative subset of frames that mitigates temporal redundancy. In the second stage, KTV applies key visual token selection, pruning redundant or less informative tokens from each selected keyframe based on token importance and redundancy, which significantly reduces the number of tokens fed into the LLM. Extensive experiments on the Multiple-Choice VideoQA task demonstrate that KTV outperforms state-of-the-art training-free baselines while using significantly fewer visual tokens, \emph{e.g.}, only 504 visual tokens for a 60-min video with 10800 frames, achieving $44.8\%$ accuracy on the MLVU-Test benchmark. In particular, KTV also exceeds several training-based approaches on certain benchmarks.

</details>


### [72] [Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis](https://arxiv.org/abs/2602.03622)
*Lu Zhang,Huizhen Yu,Zuowei Wang,Fu Gui,Yatu Guo,Wei Zhang,Mengyu Jia*

Main category: cs.CV

TL;DR: 本文提出了一种统一的多模态数据合成与融合框架，用于视网膜疾病的分类与分级，在多个公开数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 眼科实践中多模态诊断面临数据异构性、潜在侵入性和配准复杂性等挑战，亟需一种有效整合多模态信息的方法以提升视网膜疾病诊断的准确性与效率。

Method: 该方法合成包含眼底荧光血管造影（FFA）、多光谱成像（MSI）和突出潜在病灶及视盘/杯区域的显著图在内的多模态数据；通过并行模型独立学习各模态特异性表征，并在模态内和模态间自适应校准特征，实现面向下游任务的信息剪枝与灵活融合。

Result: 在两个公开数据集上的实验表明，该方法在多标签分类（F1-score: 0.683，AUC: 0.953）和糖尿病视网膜病变分级（Accuracy: 0.842，Kappa: 0.861）任务中均优于当前先进方法。

Conclusion: 该研究不仅提升了视网膜疾病筛查的准确性和效率，还提供了一个可扩展的医学影像多模态数据增强框架。

Abstract: Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.

</details>


### [73] [Multi-Objective Optimization for Synthetic-to-Real Style Transfer](https://arxiv.org/abs/2602.03625)
*Estelle Chigot,Thomas Oberlin,Manon Huguenin,Dennis Wilson*

Main category: cs.CV

TL;DR: 本文提出使用多目标遗传算法优化风格迁移流程，以在合成图像到真实图像的语义分割任务中平衡结构一致性和风格相似性，并研究适用于进化过程中的高效图像级评估指标。


<details>
  <summary>Details</summary>
Motivation: 真实图像的像素级标注成本高昂，而合成图像虽可自动生成标注，但存在域偏移问题；现有风格迁移方法难以有效选择和排序变换操作，因此需要一种自动化、高效的流程优化方法。

Method: 将风格迁移建模为操作序列优化问题，采用多目标遗传算法搜索最优流程，在进化过程中使用基于单张配对图像的指标进行快速评估，最终通过分布级指标和分割性能评估帕累托前沿。

Result: 在GTA5到Cityscapes和ACDC（关注恶劣条件）的跨域语义分割任务中，所提方法生成了多样且适应不同目标的增强流程，验证了进化算法在该任务中的有效性。

Conclusion: 本文贡献在于将风格迁移形式化为适合进化优化的序列问题，并探索了可在大规模搜索空间中实现高效优化的评估指标，为合成到真实域适应提供了新思路。

Abstract: Semantic segmentation networks require large amounts of pixel-level annotated data, which are costly to obtain for real-world images. Computer graphics engines can generate synthetic images alongside their ground-truth annotations. However, models trained on such images can perform poorly on real images due to the domain gap between real and synthetic images. Style transfer methods can reduce this difference by applying a realistic style to synthetic images. Choosing effective data transformations and their sequence is difficult due to the large combinatorial search space of style transfer operators. Using multi-objective genetic algorithms, we optimize pipelines to balance structural coherence and style similarity to target domains. We study the use of paired-image metrics on individual image samples during evolution to enable rapid pipeline evaluation, as opposed to standard distributional metrics that require the generation of many images. After optimization, we evaluate the resulting Pareto front using distributional metrics and segmentation performance. We apply this approach to standard datasets in synthetic-to-real domain adaptation: from the video game GTA5 to real image datasets Cityscapes and ACDC, focusing on adverse conditions. Results demonstrate that evolutionary algorithms can propose diverse augmentation pipelines adapted to different objectives. The contribution of this work is the formulation of style transfer as a sequencing problem suitable for evolutionary optimization and the study of efficient metrics that enable feasible search in this space. The source code is available at: https://github.com/echigot/MOOSS.

</details>


### [74] [SPWOOD: Sparse Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2602.03634)
*Wei Zhang,Xiang Liu,Ningjing Liu,Mingxin Liu,Wei Liao,Chunyan Xu,Xue Yang*

Main category: cs.CV

TL;DR: 本文提出首个稀疏部分弱监督的旋转目标检测框架（SPWOOD），仅利用少量稀疏弱标注数据和大量无标注数据，在DOTA和DIOR数据集上显著优于现有方法，大幅降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中目标密集、类别多样，导致全监督标注成本极高。因此，亟需在减少标注数量与强度的同时保持检测性能，推动面向实际应用的高效弱监督学习方法研究。

Method: 提出SPWOOD框架，包含三项创新：(1) 设计SOS-Student模型，从稀疏弱标注中学习方向与尺度信息并分离前景背景；(2) 构建基于多层预测分布的多层次伪标签过滤策略；(3) 采用确保各类别均衡处理的稀疏划分方法。

Result: 在DOTA和DIOR数据集上的实验表明，该框架相比全监督、半监督及弱监督等传统旋转目标检测方法取得显著性能提升，验证了其高效性和成本效益。

Conclusion: 所提出的稀疏部分弱监督框架为高成本遥感图像标注问题提供了有效解决方案，兼顾性能与标注效率，具有良好的实用价值。

Abstract: A consistent trend throughout the research of oriented object detection has been the pursuit of maintaining comparable performance with fewer and weaker annotations. This is particularly crucial in the remote sensing domain, where the dense object distribution and a wide variety of categories contribute to prohibitively high costs. Based on the supervision level, existing oriented object detection algorithms can be broadly grouped into fully supervised, semi-supervised, and weakly supervised methods. Within the scope of this work, we further categorize them to include sparsely supervised and partially weakly-supervised methods. To address the challenges of large-scale labeling, we introduce the first Sparse Partial Weakly-Supervised Oriented Object Detection framework, designed to efficiently leverage only a few sparse weakly-labeled data and plenty of unlabeled data. Our framework incorporates three key innovations: (1) We design a Sparse-annotation-Orientation-and-Scale-aware Student (SOS-Student) model to separate unlabeled objects from the background in a sparsely-labeled setting, and learn orientation and scale information from orientation-agnostic or scale-agnostic weak annotations. (2) We construct a novel Multi-level Pseudo-label Filtering strategy that leverages the distribution of model predictions, which is informed by the model's multi-layer predictions. (3) We propose a unique sparse partitioning approach, ensuring equal treatment for each category. Extensive experiments on the DOTA and DIOR datasets show that our framework achieves a significant performance gain over traditional oriented object detection methods mentioned above, offering a highly cost-effective solution. Our code is publicly available at https://github.com/VisionXLab/SPWOOD.

</details>


### [75] [MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment](https://arxiv.org/abs/2602.03665)
*Eunkyu Park,Wesley Hanwen Deng,Cheyon Jin,Matheus Kunzler Maldaner,Jordan Wheeler,Jason I. Hong,Hong Shen,Adam Perer,Ken Holstein,Motahhare Eslami,Gunhee Kim*

Main category: cs.CV

TL;DR: 本文提出MM-SCALE数据集，通过5点量表评分和显式模态对齐，提升视觉语言模型在道德判断上的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在多模态和社会模糊情境中难以做出道德上合理的判断，且以往方法依赖二元或成对监督，无法充分反映人类道德推理的连续性和多元性。

Method: 构建大规模多模态道德量表数据集MM-SCALE，包含图像-场景对的人类标注道德可接受性分数及基于定制界面收集的接地推理标签，支持列表式偏好优化，并采用标量监督替代离散监督。

Result: 在MM-SCALE上微调的视觉语言模型相比使用二元信号训练的模型，在排序保真度和安全校准稳定性方面表现更优。

Conclusion: 引入标量监督能提供更丰富的对齐信号，有助于更精细地校准多模态道德推理能力。

Abstract: Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.

</details>


### [76] [Referring Industrial Anomaly Segmentation](https://arxiv.org/abs/2602.03673)
*Pengfei Yue,Xiaokang Jiang,Yilin Lu,Jianghang Lin,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为RIAS的新范式，利用文本描述引导工业异常检测，实现无需手动阈值的精准分割，并通过单一模型处理多种异常类型。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法存在局限性：无监督方法定位粗糙且依赖人工设定阈值，有监督方法因数据稀缺和不平衡而容易过拟合，且两者均受限于“一类异常一模型”的范式。

Method: 提出Referring Industrial Anomaly Segmentation（RIAS）框架，结合语言引导进行异常分割；构建MVTec-Ref数据集，包含多样化的指代表达和以小尺寸异常为主的数据；设计DQFormer基准模型，采用Dual Query Token与Language-Gated Multi-Level Aggregation机制，提升多尺度下的视觉-语言融合效率。

Result: 实验表明，RIAS能有效实现开放集下的工业异常检测，生成精确的异常掩码，且单模型可泛化至多种异常类型。

Conclusion: RIAS通过引入语言引导突破了传统IAD方法的限制，为实现更通用、高效的工业异常检测提供了新方向。

Abstract: Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the "One Anomaly Class, One Model" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only "Anomaly" and "Background" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.

</details>


### [77] [Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment](https://arxiv.org/abs/2602.03742)
*Johny J. Lopez,Md Meftahul Ferdaus,Mahdi Abdelguerfi*

Main category: cs.CV

TL;DR: 本文提出一种轻量级两阶段端到端管道，用于在边缘设备上自动生成地下基础设施缺陷的自然语言摘要，结合了高效的分割模型RAPID-SCAN与微调后的视觉语言模型Phi-3.5，在保证性能的同时实现低资源消耗和实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有机器人平台虽能通过视觉传感器检测地下基础设施缺陷，但难以在资源受限的边缘设备上自动生成人类可读的缺陷摘要，限制了自动化检测结果向可操作维护建议的转化。

Method: 提出两阶段方法：第一阶段使用仅含0.64M参数的轻量分割模型RAPID-SCAN进行高效缺陷分割；第二阶段利用微调后的Phi-3.5视觉语言模型，基于分割结果生成领域特定的自然语言摘要。引入人工验证的图像-描述数据集用于VLM微调，并采用后训练量化与硬件优化以提升边缘部署效率。

Result: RAPID-SCAN在缺陷分割任务中达到0.834 F1分数；完整流水线在移动机器人平台上实现实时运行，生成高质量、简洁的缺陷摘要，且模型体积与推理延迟显著降低。

Conclusion: 该工作展示了可在边缘部署的集成AI系统有效连接自动缺陷检测与可操作洞察，为地下基础设施的规模化、自主化巡检提供了可行路径。

Abstract: Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.

</details>


### [78] [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747)
*Junchao Huang,Ziyang Ye,Xinting Hu,Tianyu He,Guiyu Zhang,Shaoshuai Shi,Jiang Bian,Li Jiang*

Main category: cs.CV

TL;DR: 本文提出LIVE模型，通过新颖的循环一致性目标控制长期视频生成中的误差累积，无需依赖教师模型，在长视野视频生成任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自回归视频世界模型在短时预测中有效，但在长时预测中因误差累积而性能下降；现有方法依赖预训练教师模型或序列级分布匹配，计算成本高且无法有效抑制训练视野外的误差传播。

Method: LIVE采用前向展开与反向重建相结合的循环一致性目标：从前向真实帧开始展开，再通过反向生成重建初始状态，并在重建的终止状态上计算扩散损失，从而显式约束长期误差累积。同时引入统一视角和渐进式训练策略以稳定训练过程。

Result: 实验表明，LIVE在长视野基准上优于现有方法，能够生成稳定、高质量的视频，且生成长度远超训练时使用的rollout长度。

Conclusion: LIVE通过循环一致性机制有效控制了长期视频生成中的误差传播，摆脱了对教师模型的依赖，为构建高效、稳定的长视野视频世界模型提供了新思路。

Abstract: Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.

</details>


### [79] [See-through: Single-image Layer Decomposition for Anime Characters](https://arxiv.org/abs/2602.03749)
*Jian Lin,Chengze Li,Haoyun Qin,Kwun Wang Chan,Yanghua Jin,Hanyuan Liu,Stephen Chun Wang Choy,Xueting Liu*

Main category: cs.CV

TL;DR: 本文提出了一种将静态动漫插图自动转换为可操控2.5D模型的框架，通过分解图像为语义层并推断绘制顺序，结合扩散模型与伪深度机制，实现高质量实时动画。


<details>
  <summary>Details</summary>
Motivation: 当前专业流程需手动分割图像并对遮挡区域进行艺术性“脑补”，过程繁琐；作者旨在通过自动化方法解决这一问题，提升2.5D动漫角色建模效率与质量。

Method: 该方法利用一个可扩展引擎从商业Live2D模型中提取高质量监督数据，结合基于扩散的“身体部位一致性模块”以确保全局几何一致性，并采用像素级伪深度推断机制解析角色各部分（如交错发丝）的层叠关系，从而重建可操控的分层2.5D模型。

Result: 所提方法能生成高保真、可实时操控的2.5D动漫角色模型，有效处理复杂层叠结构，在专业动画应用中表现优异。

Conclusion: 该框架显著降低了从单张静态插图生成可动2.5D模型的人工成本，为动漫内容创作提供了高效、自动化的解决方案。

Abstract: We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.

</details>


### [80] [Test-Time Conditioning with Representation-Aligned Visual Features](https://arxiv.org/abs/2602.03753)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Letzelter,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: 本文提出REPA-G，一种在推理阶段利用自监督对齐表征进行条件引导的扩散模型生成方法，支持多尺度控制与多概念组合，提升生成质量与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注表征对齐在训练阶段的作用，而其在推理阶段用于条件引导的潜力尚未充分探索。作者旨在通过利用具有丰富语义信息的对齐表征，在不修改模型训练的前提下实现更灵活、精确的生成控制。

Method: REPA-G在推理时通过优化一个相似性目标（势函数），将去噪过程引导至由预训练特征提取器提取的目标表征。该方法支持从局部图像块到全局特征的多尺度条件控制，并可扩展至多概念组合。

Result: 在ImageNet和COCO数据集上的实验表明，REPA-G能够生成高质量且多样化的图像，优于依赖模糊文本提示或粗粒度类别标签的传统方法。

Conclusion: REPA-G提供了一种仅在推理阶段操作的灵活、精准的生成控制框架，理论分析表明其可从势函数诱导的倾斜分布中采样，有效提升扩散模型的条件生成能力。

Abstract: While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.

</details>


### [81] [RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images](https://arxiv.org/abs/2602.03760)
*Mishal Fatima,Shashank Agnihotri,Kanchana Vaishnavi Gandikota,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: 该论文提出RAWDet-7数据集，包含约25k训练和7.6k测试RAW图像，用于研究基于RAW图像的目标检测与描述，并支持在低比特量化条件下的性能评估。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型多基于经ISP处理的RGB图像训练，而这类处理可能丢失对机器推理有用的传感器原始信息；RAW图像保留了未处理的场景数据，有助于提升目标检测与描述的细粒度细节、空间关系和上下文信息。

Method: 构建大规模RAW图像数据集RAWDet-7，涵盖多种相机、光照和环境条件，按MS-COCO和LVIS标准对七类物体进行密集标注，并提供基于高分辨率sRGB图像生成的物体级描述；同时支持4-bit、6-bit和8-bit量化模拟，以评估低比特RAW图像下的模型表现。

Result: 该数据集为RAW图像下的目标检测、描述质量及低比特量化条件下的泛化能力提供了基准，促进对RAW图像中物体信息保留机制的研究。

Conclusion: RAWDet-7填补了RAW图像用于高层视觉任务研究的空白，为未来在低比特、传感器原始数据驱动的视觉模型开发提供重要资源。

Abstract: Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.

</details>


### [82] [FOVI: A biologically-inspired foveated interface for deep vision models](https://arxiv.org/abs/2602.03766)
*Nicholas M. Blauch,George A. Alvarez,Talia Konkle*

Main category: cs.CV

TL;DR: 本文提出了一种基于人眼视网膜和初级视觉皮层的注视式视觉接口（FOVI），通过将可变分辨率的类视网膜传感器阵列重映射为均匀密集的V1类传感器流形，实现高效、低计算成本的高分辨率主动感知。


<details>
  <summary>Details</summary>
Motivation: 传统计算机视觉系统采用均匀分辨率编码，难以高效处理全视野高分辨率图像；而人类视觉具有中央凹特性，能通过眼动在关注区域获得高分辨率、同时保留周边上下文，是一种高效的主动感知策略。受此启发，作者希望构建一种更接近生物视觉机制的高效视觉系统。

Method: 提出FOVI框架，将类视网膜的可变分辨率传感器阵列映射为均匀密集的V1类传感器流形，并在此流形上定义k近邻（kNN）感受野，通过新颖的核映射技术实现kNN卷积。展示了两种应用：(1) 端到端的kNN卷积架构；(2) 基于低秩适配（LoRA）对DINOv3 ViT模型进行注视式改造。

Result: 所提出的模型在显著低于非注视式基线模型的计算成本下，取得了具有竞争力的性能。

Conclusion: FOVI为高分辨率自我中心视觉提供了一条高效且可扩展的主动感知路径，有望推动更接近生物视觉机制的高效计算机视觉系统的发展。

Abstract: Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.

</details>


### [83] [QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization](https://arxiv.org/abs/2602.03782)
*Yuhao Xu,Yantai Yang,Zhenyang Fan,Yufan Liu,Yuming Li,Bing Li,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 本文提出QVLA，首个面向具身控制的动作中心化低比特量化框架，通过通道级敏感度分析实现量化与剪枝的统一，在显著降低显存占用和提升推理速度的同时，几乎保持原始性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言动作（VLA）模型计算开销巨大，难以部署于资源受限的机器人平台；而直接将大语言模型（LLM）中常用的均匀比特量化方法应用于VLA模型存在根本缺陷，因其忽视了微小动作偏差在任务执行中可能引发的灾难性失败。

Method: 提出QVLA框架，采用通道级的非均匀比特分配策略。核心在于直接测量每个通道在不同比特宽度下量化对最终动作空间的影响，以此构建通道重要性指标，并通过全局优化将量化与剪枝（0比特）统一为一个协同框架。

Result: 在LIBERO基准上，使用QVLA量化的OpenVLA-OFT模型仅需原始模型29.2%的显存，保持98.9%的原始性能，并获得1.49倍加速，相比SmoothQuant方法性能提升22.6%。

Conclusion: 本工作为机器人领域VLA模型的压缩建立了新的、基于动作敏感性的原则性基础，为在真实硬件上部署强大的大规模模型铺平了道路。

Abstract: The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.

</details>


### [84] [From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery](https://arxiv.org/abs/2602.03785)
*Jingjing Peng,Giorgio Fiore,Yang Liu,Ksenia Ellum,Debayan Daspupta,Keyoumars Ashkan,Andrew McEvoy,Anna Miserocchi,Sebastien Ourselin,John Duncan,Alejandro Granados*

Main category: cs.CV

TL;DR: NeuralShift 是一种基于 U-Net 的模型，仅使用术前 MRI 即可预测颞叶切除术中的脑移位，实现高精度的全局形变（DICE 0.97）和局部位移（TRE 低至 1.12 mm），从而提升神经导航系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 在神经外科手术中，硬膜打开后发生的脑移位会使术前 MRI 失效，影响图像引导神经外科系统（IGNS）的定位精度。因此，亟需一种方法能在术中补偿脑移位，以提高手术精准度和患者预后。

Method: 提出 NeuralShift 模型，基于 U-Net 架构，仅利用术前 MRI 预测术中脑移位。通过解剖标志点计算目标配准误差（TRE），并在切除侧和中线评估；同时使用 DICE 系数比较预测的术中脑掩模与真实术中 MRI 掩模的一致性。

Result: 模型能准确预测脑部全局形变（DICE 达 0.97）和局部位移（TRE 最低为 1.12 mm），有效补偿颞叶切除术中的大范围脑移位。

Conclusion: NeuralShift 仅依赖术前 MRI 即可预测术中脑移位，有望提升神经外科手术的安全性、效率及患者预后。相关代码将在论文接收后公开发布。

Abstract: Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.

</details>


### [85] [Progressive Checkerboards for Autoregressive Multiscale Image Generation](https://arxiv.org/abs/2602.03811)
*David Eigen*

Main category: cs.CV

TL;DR: 本文提出了一种基于渐进棋盘格顺序的多尺度自回归图像生成方法，通过在每个尺度上并行采样均匀分布的区域，在保持四叉树各级平衡的同时实现跨尺度和尺度内有效建模，以更少的采样步骤达到与当前先进自回归模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 自回归图像生成面临的核心挑战是如何在并行采样独立位置的同时，仍能通过串行条件建模位置间的相互依赖关系。现有方法或采用多尺度金字塔进行跨尺度条件建模，或在单尺度图像中使用规则划分或随机顺序进行并行化，但难以兼顾效率与依赖建模。本文旨在设计一种灵活且固定的采样顺序，以更好地平衡并行效率与依赖建模能力。

Method: 提出一种基于渐进棋盘格（progressive checkerboards）的固定采样顺序，用于多尺度自回归图像生成。该方法在每个尺度上从均匀间隔的区域并行采样，并在每一步都保持四叉树细分中所有层级的完全平衡，从而实现跨尺度和尺度内的有效条件建模。

Result: 在类条件ImageNet数据集上，该方法在模型容量相近的情况下，使用更少的采样步骤，取得了与近期最先进的自回归系统相媲美的性能。此外，研究发现，在总串行步数恒定的前提下，多种尺度放大因子可产生相似结果。

Conclusion: 所提出的渐进棋盘格多尺度自回归生成方法在采样效率和生成质量之间取得了良好平衡，验证了固定、平衡的采样顺序在多尺度自回归建模中的有效性，并为高效自回归图像生成提供了新思路。

Abstract: A key challenge in autoregressive image generation is to efficiently sample independent locations in parallel, while still modeling mutual dependencies with serial conditioning. Some recent works have addressed this by conditioning between scales in a multiscale pyramid. Others have looked at parallelizing samples in a single image using regular partitions or randomized orders. In this work we examine a flexible, fixed ordering based on progressive checkerboards for multiscale autoregressive image generation. Our ordering draws samples in parallel from evenly spaced regions at each scale, maintaining full balance in all levels of a quadtree subdivision at each step. This enables effective conditioning both between and within scales. Intriguingly, we find evidence that in our balanced setting, a wide range of scale-up factors lead to similar results, so long as the total number of serial steps is constant. On class-conditional ImageNet, our method achieves competitive performance compared to recent state-of-the-art autoregressive systems with like model capacity, using fewer sampling steps.

</details>


### [86] [Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning](https://arxiv.org/abs/2602.03815)
*Dingkun Zhang,Shuhan Qi,Yulin Wu,Xinyu Xiao,Xuan Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出DualSpeed框架，通过快慢双模式训练多模态大语言模型（MLLMs），在减少视觉token数量以提升训练效率的同时，保持推理性能不下降。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）因模型规模庞大和视觉token数量多而面临严重的训练效率低下问题。现有方法主要聚焦于减小模型规模或可训练参数，而本文受视觉Token剪枝（VTP）在推理阶段成功应用的启发，探索通过减少视觉token来提升训练效率的新方向。然而，直接在训练阶段使用VTP会导致训练-推理不一致的问题。

Method: 提出DualSpeed框架：快模式为主模式，集成现有VTP方法作为插件以减少视觉token，并引入模式隔离器隔离模型行为；慢模式为辅助模式，在完整视觉序列上训练以保持训练-推理一致性，并通过自蒸馏从充分训练的快模式中学习。

Result: 实验表明，DualSpeed在LLaVA-1.5上实现2.1倍、在LLaVA-NeXT上实现4.0倍的训练加速，同时保留超过99%的性能。

Conclusion: DualSpeed有效解决了MLLMs训练效率低下的问题，在显著加速训练的同时维持了模型性能，验证了通过视觉token剪枝进行高效训练的可行性。

Abstract: Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed

</details>


### [87] [Continuous Control of Editing Models via Adaptive-Origin Guidance](https://arxiv.org/abs/2602.03826)
*Alon Wolf,Chen Katzir,Kfir Aberman,Or Patashnik*

Main category: cs.CV

TL;DR: 本文提出了一种名为自适应原点引导（AdaOr）的新方法，通过在无条件预测中引入身份条件的自适应原点，实现了对扩散编辑模型中文本引导编辑强度的平滑连续控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的编辑模型无法平滑控制文本引导编辑的强度。虽然分类器自由引导（CFG）在生成中影响提示遵循程度，但在编辑任务中直接缩放CFG并不能实现从输入到编辑结果的平滑过渡，原因在于其无条件预测作为引导原点，在低引导尺度下主导生成，却代表了对输入内容的任意修改。

Method: 作者提出了自适应原点引导（AdaOr）方法，该方法使用与恒等变换相对应的身份指令来构建一个身份条件的自适应原点，并根据编辑强度将此身份预测与标准的无条件预测进行插值，从而确保从原始输入到编辑结果的连续过渡。

Result: 在图像和视频编辑任务上的评估表明，与现有的基于滑块的编辑方法相比，AdaOr提供了更平滑、更一致的编辑强度控制。

Conclusion: AdaOr通过在标准训练框架中融入身份指令，无需针对每次编辑的特定流程或专门数据集，即可在推理时实现细粒度的编辑强度控制。

Abstract: Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.

</details>


### [88] [EventNeuS: 3D Mesh Reconstruction from a Single Event Camera](https://arxiv.org/abs/2602.03847)
*Shreyas Sachan,Viktor Rudnev,Mohamed Elgharib,Christian Theobalt,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 本文提出了EventNeuS，一种自监督的神经模型，用于从单目彩色事件流中学习3D表示，在3D重建精度上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于事件相机的3D重建方法在精度上存在严重不足，且密集3D网格重建研究较少，因此需要一种更有效的解决方案。

Method: EventNeuS结合了3D符号距离函数和密度场学习，并利用事件数据进行自监督训练；同时引入球谐函数编码以更好地处理视角依赖效应。

Result: EventNeuS在Chamfer距离和平均绝对误差上分别比此前最佳方法降低了34%和31%。

Conclusion: EventNeuS显著提升了基于事件相机的3D重建性能，为该领域提供了有效的新方法。

Abstract: Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [CreditAudit: 2D Auditing for LLM Evaluation and Selection](https://arxiv.org/abs/2602.02515)
*Yiliang Song,Hongjun An,Jiangong Xiao,Haofei Zhao,Jiawei Shao,Xuelong Li*

Main category: cs.AI

TL;DR: 提出CreditAudit框架，通过在多个语义对齐的系统提示模板下评估大语言模型的平均性能（mean ability）和性能波动（sigma），并将其映射为AAA至BBB的信用等级，以支持更稳定、可信的模型部署决策。


<details>
  <summary>Details</summary>
Motivation: 当前公共基准排行榜分数趋于饱和，难以反映模型在真实部署场景中的表现差异，尤其在多步骤智能体流程中，微小的协议变化可能导致显著失败，使开发者难以选择合适模型。

Method: 构建一个面向部署的评估框架CreditAudit，在多个非对抗性、语义对齐的系统提示模板下测试模型，计算其在不同场景下的平均性能和性能波动（sigma），并通过跨模型分位数将波动性转化为可解释的信用等级（AAA–BBB），同时提供诊断机制以缓解模板难度漂移问题。

Result: 在GPQA、TruthfulQA和MMLU Pro上的实验表明，具有相近平均能力的模型可能表现出显著不同的稳定性；在高失败成本或智能体场景中，稳定性风险可改变模型优先级排序。

Conclusion: CreditAudit通过二维（平均能力+稳定性）和等级化评估语言，支持按场景分层部署，并优化测试与监控资源分配，提升现实应用中模型评估的客观性与可信度。

Abstract: Leaderboard scores on public benchmarks have been steadily rising and converging, with many frontier language models now separated by only marginal differences. However, these scores often fail to match users' day to day experience, because system prompts, output protocols, and interaction modes evolve under routine iteration, and in agentic multi step pipelines small protocol shifts can trigger disproportionate failures, leaving practitioners uncertain about which model to deploy. We propose CreditAudit, a deployment oriented credit audit framework that evaluates models under a family of semantically aligned and non adversarial system prompt templates across multiple benchmarks, reporting mean ability as average performance across scenarios and scenario induced fluctuation sigma as a stability risk signal, and further mapping volatility into interpretable credit grades from AAA to BBB via cross model quantiles with diagnostics that mitigate template difficulty drift. Controlled experiments on GPQA, TruthfulQA, and MMLU Pro show that models with similar mean ability can exhibit substantially different fluctuation, and stability risk can overturn prioritization decisions in agentic or high failure cost regimes. By providing a 2D and grade based language for regime specific selection, CreditAudit supports tiered deployment and more disciplined allocation of testing and monitoring effort, enabling more objective and trustworthy model evaluation for real world use.

</details>


### [90] [Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems](https://arxiv.org/abs/2602.02582)
*Chandan Kumar Sah,Xiaoli Lian,Li Zhang,Tony Xu,Syed Shazaib Shah*

Main category: cs.AI

TL;DR: 本文研究大语言模型（LLM）在零样本推荐中的不确定性与公平性问题，提出新的评估方法、数据集和基准，揭示Gemini 1.5 Flash在敏感属性上的系统性不公平，并探索个性化与群体公平之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽能利用广泛上下文知识进行零样本推荐，但其预测不确定性与内嵌偏见可能损害推荐的可靠性与公平性。因此，亟需系统评估这些因素对推荐准确性、一致性和可信度的影响。

Method: 作者构建了一个包含电影和音乐两个领域、标注了8个敏感人口属性（共31个类别）的数据集，并设计了一套综合评估指标。通过熵量化预测不确定性，采用相似性差距指标（SNSR/SNSV）衡量公平性，并在提示扰动（如拼写错误、多语言输入）下测试模型鲁棒性。此外，将人格感知公平性整合进RecLLM评估流程。

Result: 实验发现Gemini 1.5 Flash在某些敏感属性上存在显著不公平（SNSR=0.1363，SNSV=0.0507），且该偏差在多种提示扰动下依然存在。研究还揭示了个性化推荐与群体公平之间的权衡，并通过人格画像增强了公平性评估的可解释性。

Conclusion: 本文提出的不确定性感知评估方法和人格画像驱动的公平性基准，为构建更安全、可解释的推荐型大语言模型（RecLLM）奠定了基础，并呼吁未来开展多模型基准测试与自适应校准研究以实现可信部署。

Abstract: Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.

</details>


### [91] [A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior](https://arxiv.org/abs/2602.02639)
*Harry Mayne,Justin Singh Kang,Dewi Gould,Kannan Ramchandran,Adam Mahdi,Noah Y. Siegel*

Main category: cs.AI

TL;DR: 本文提出了一种名为归一化可模拟性增益（NSG）的新指标，用于评估大语言模型（LLM）自我解释的忠实性，并发现这些解释虽不完美，但能显著提升人类对其行为的预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有衡量LLM自我解释忠实性的方法存在局限，主要依赖对抗性提示或推理错误检测，忽视了解释对预测模型行为的价值。因此，需要一种更通用、可扩展且基于预测能力的评估方法。

Method: 作者提出了归一化可模拟性增益（NSG）指标，其核心思想是：忠实的解释应使观察者能够学习模型的决策标准，从而更好地预测其在相关输入上的行为。研究在7,000个涵盖健康、商业和伦理领域的反事实样本上，评估了18个前沿闭源和开源模型（如Gemini 3、GPT-5.2、Claude 4.5）的自我解释效果。

Result: 实验表明，自我解释显著提升了对模型行为的预测准确率（NSG提升11%-37%），且优于由更强外部模型生成的解释。同时发现，各模型中有5%-15%的自我解释严重误导。

Conclusion: 尽管存在部分误导性解释，LLM的自我解释总体上编码了有助于预测其行为的信息，体现出一种外部解释方法无法复制的“自知优势”，支持其在AI监督中的积极应用价值。

Abstract: LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.

</details>


### [92] [MARS: Modular Agent with Reflective Search for Automated AI Research](https://arxiv.org/abs/2602.02660)
*Jiefeng Chen,Bhavana Dalvi Mishra,Jaehyun Nam,Rui Meng,Tomas Pfister,Jinsung Yoon*

Main category: cs.AI

TL;DR: 本文提出MARS框架，通过预算感知规划、模块化构建和对比反思记忆三项机制，提升大语言模型在自动化AI研究任务中的效率与效果，在MLE-Bench上达到开源框架的SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的智能体在自动化AI研究中面临计算成本高、性能归因不透明等问题，常生成忽视执行代价和因果因素的单体脚本，亟需更高效、可解释的框架。

Method: MARS框架包含三大核心：(1) 基于成本约束蒙特卡洛树搜索（MCTS）的预算感知规划；(2) “设计-分解-实现”三阶段的模块化构建流程；(3) 通过分析不同解决方案差异以提取高价值洞见的对比反思记忆机制。

Result: MARS在MLE-Bench基准上达到开源框架中最优性能，且与全球排行榜前列方法具有竞争力；63%的有效经验来自跨分支迁移，表明其具备良好的洞察泛化能力。

Conclusion: MARS通过整合预算控制、模块化开发与反思学习，显著提升了AI研究自动化的能力，为未来自主科研智能体提供了有效范式。

Abstract: Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a "Design-Decompose-Implement" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative "Aha!" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.

</details>


### [93] [ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters](https://arxiv.org/abs/2602.02709)
*Ujin Jeon,Jiyong Kwon,Madison Ann Sullivan,Caleb Eunho Lee,Guang Lin*

Main category: cs.AI

TL;DR: 本文提出ATLAS框架，通过任务分布和自适应偏好优化提升多智能体系统在长周期任务中的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多大语言模型（LLM）的智能体系统在提示优化和自动问题求解方面表现良好，但在长周期任务中受限于静态优化机制或冻结求解器，难以持续进化。

Method: 提出ATLAS框架，包含一个轻量级研究智能体和多个专用支持智能体，并引入EvoDPO算法动态更新阶段索引的参考策略；同时在非平稳线性上下文赌博机和科学机器学习任务上进行实验验证。

Result: 在1D Burgers方程的SciML损失重加权和非平稳线性上下文赌博机任务中，ATLAS相比静态单智能体基线展现出更优的稳定性和性能。

Conclusion: ATLAS通过任务分布式架构与自适应偏好优化机制，有效解决了长周期任务中智能体系统难以持续进化的挑战。

Abstract: Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon tasks. We propose ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution), a task-distributed framework that iteratively develops a lightweight research agent while delegating complementary roles to specialized supporter agents for exploration, hyperparameter tuning, and reference policy management. Our core algorithm, Evolving Direct Preference Optimization (EvoDPO), adaptively updates the phase-indexed reference policy. We provide a theoretical regret analysis for a preference-based contextual bandit under concept drift. In addition, experiments were conducted on non-stationary linear contextual bandits and scientific machine learning (SciML) loss reweighting for the 1D Burgers' equation. Both results show that ATLAS improves stability and performance over a static single-agent baseline.

</details>


### [94] [Visual Reasoning over Time Series via Multi-Agent System](https://arxiv.org/abs/2602.03026)
*Weilin Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: MAS4TS 是一个基于多智能体的工具驱动系统，通过 Analyzer-Reasoner-Executor 范式结合视觉推理与潜在空间重建，在多种时间序列任务中实现 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列方法在整合直观视觉推理和跨任务泛化方面存在不足，尤其缺乏自适应工具使用能力。

Method: 提出 MAS4TS 系统，利用视觉语言模型对时间序列图进行结构化先验的视觉推理，再在潜在空间中重建预测轨迹；三个专用智能体通过共享记忆和门控通信协作，并由路由器选择任务特定的工具链执行。

Result: 在多个基准上的实验表明，MAS4TS 在广泛的时间序列任务中达到最先进性能，同时展现出强泛化能力和高效推理。

Conclusion: MAS4TS 有效融合了视觉推理、多智能体协作与工具调用机制，为通用时间序列分析提供了一个强大且灵活的新范式。

Abstract: Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.

</details>


### [95] [Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction](https://arxiv.org/abs/2602.02711)
*Yuanzhe Li,Jianing Deng,Jingtong Hu,Tianlong Chen,Song Wang,Huanrui Yang*

Main category: cs.AI

TL;DR: 本文提出一种动态混合精度路由框架，在长视野决策任务中根据每一步的敏感性自适应选择高精度或低精度量化大语言模型，以优化准确率与推理成本的权衡。


<details>
  <summary>Details</summary>
Motivation: 使用大语言模型（LLM）进行多步交互虽能提升长视野决策任务的成功率，但带来高昂的推理成本；现有方法多采用单一精度模型，难以平衡性能与效率。

Method: 基于不同交互步骤对精度敏感性的差异，设计动态混合精度路由机制：首先通过基于KL散度的监督学习识别精度敏感步骤，再利用Group-Relative Policy Optimization（GRPO）优化路由策略以提升任务成功率。

Result: 在ALFWorld环境中的实验表明，该方法在准确率与成本的权衡上显著优于单精度基线和启发式路由方法。

Conclusion: 动态混合精度路由是一种有效降低LLM推理成本同时维持甚至提升任务性能的可行方案，为高效部署大模型于复杂决策任务提供了新思路。

Abstract: Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.

</details>


### [96] [MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems](https://arxiv.org/abs/2602.03053)
*Vishal Venkataramani,Haizhou Shi,Zixuan Ke,Austin Xu,Xiaoxiao He,Yingbo Zhou,Semih Yavuz,Hao Wang,Shafiq Joty*

Main category: cs.AI

TL;DR: 本文系统研究了多智能体系统（MAS）中基于大语言模型的过程验证方法，发现现有验证范式在提升性能方面效果不稳定，仍面临重大挑战。


<details>
  <summary>Details</summary>
Motivation: 过程验证在通用推理中表现良好，但其在多智能体系统中的有效性尚不明确，因此需要系统性评估以填补这一空白。

Method: 作者提出MAS-ProVe框架，涵盖三种验证范式（LLM-as-a-Judge、奖励模型、过程奖励模型）、两种验证粒度（智能体级和迭代级），并评估五种验证器与四种上下文管理策略，在六个MAS框架和多个推理基准上进行实验。

Result: 过程验证未能一致提升性能且方差高；LLM-as-a-Judge优于基于奖励的方法，训练过的判别器优于通用LLM；判别器与单智能体LLM性能差距小，并存在上下文长度与性能的权衡。

Conclusion: 当前过程验证方法在多智能体系统中仍不可靠，有效且鲁棒的验证机制仍是开放性挑战，需超越现有范式的进一步研究。

Abstract: Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.

</details>


### [97] [Scaling-Aware Adapter for Structure-Grounded LLM Reasoning](https://arxiv.org/abs/2602.02780)
*Zihao Jing,Qiuhao Zeng,Ruiyi Fang,Yan Yi Li,Yan Sun,Boyu Wang,Pingzhao Hu*

Main category: cs.AI

TL;DR: 本文提出Cuttlefish，一种统一的全原子大语言模型，通过结合几何信息和结构复杂度自适应调整模态token数量，提升对生物分子结构的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理生物分子结构时存在模态单一、结构输入压缩过度或融合机制僵化等问题，导致几何信息缺失和结构幻觉，难以实现通用的全原子推理。

Method: Cuttlefish包含两个核心组件：1）Scaling-Aware Patching，通过指令条件门控机制生成可变大小的结构图块，根据结构复杂度动态分配查询token；2）Geometry Grounding Adapter，利用跨注意力机制将模态嵌入注入LLM，显式引入几何线索以减少结构幻觉。

Result: 在多个全原子基准测试中，Cuttlefish在异构结构引导的推理任务上表现优于现有方法。

Conclusion: Cuttlefish通过几何感知与结构复杂度自适应的token机制，有效提升了大语言模型在生物分子结构推理中的准确性与泛化能力。

Abstract: Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.

</details>


### [98] [AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents](https://arxiv.org/abs/2602.02849)
*Xi Yu,Dmitrii Torbunov,Soumyajit Mandal,Yihui Ren*

Main category: cs.AI

TL;DR: 本文提出AutoSizer，一种基于大语言模型（LLM）的自适应元优化框架，用于模拟与混合信号（AMS）电路的晶体管尺寸优化，在多个指标上优于传统和现有LLM方法。


<details>
  <summary>Details</summary>
Motivation: AMS电路设计高度依赖专家经验，晶体管尺寸优化因非线性、高维空间和严苛性能约束而成为瓶颈；现有EDA工具将其视为静态黑盒优化，效率低且鲁棒性差；而LLM虽具推理能力，却不擅长精确数值优化。

Method: 提出AutoSizer框架，采用双循环结构：内层进行电路尺寸优化，外层通过分析优化动态和约束，利用仿真反馈迭代优化搜索空间；同时构建了包含24个SKY130工艺下AMS电路的开源基准AMS-SizingBench。

Result: AutoSizer在不同复杂度电路中均表现出更优解质量、更快收敛速度和更高成功率，优于传统优化方法和现有基于LLM的智能体。

Conclusion: 将LLM的推理能力与自适应优化机制结合，可有效提升AMS电路尺寸自动化的效率与鲁棒性，为EDA工具提供新范式。

Abstract: The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.

</details>


### [99] [STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search](https://arxiv.org/abs/2602.02862)
*Eric Yang,Jong Ha Lee,Jonathan Amar,Elissa Ye,Yugang Jia*

Main category: cs.AI

TL;DR: STEER 是一种无需训练的框架，通过构建多样化且安全的自然语言角色群体，在推理时提供一个可解释的控制参数，以实现对大语言模型在序数决策任务（如临床分诊）中保守程度的单调调节，从而在不牺牲准确性的前提下增强行为可控性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在训练追求平均正确性时容易出现模式坍缩，导致在允许多种合理回答的任务（尤其是临床分诊等序数决策场景）中行为单一，无法根据上下文灵活调整敏感性与特异性之间的权衡（即ROC工作点）。

Method: STEER 采用离线的、受约束的质量-多样性搜索生成一组满足最低安全性、推理能力和稳定性要求的自然语言角色；推理时通过一个可解释的控制参数（用户指定的风险百分位）选择对应角色，实现对决策保守程度的调节。

Result: 在两个临床分诊基准测试中，STEER 相比基于温度采样和静态角色集成方法展现出更广的行为覆盖范围；与代表性后训练方法相比，在明确紧急病例上保持显著更高的准确性，同时在模糊决策上提供相当的控制能力。

Conclusion: STEER 提供了一种在保障安全性和领域专业能力的前提下，实现大语言模型风险可控的新范式，有效解决了模式坍缩问题并增强了模型在序数决策任务中的适应性。

Abstract: Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.

</details>


### [100] [Aligning Language Model Benchmarks with Pairwise Preferences](https://arxiv.org/abs/2602.02898)
*Marco Gutierrez,Xinyi Leng,Hannah Cyberey,Jonathan Richard Schwarz,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.AI

TL;DR: 本文提出“基准对齐”（benchmark alignment）概念及首个实现方法BenchAlign，通过利用有限的模型部署偏好数据，自动调整离线基准测试中各题目的权重，使其能更准确地预测模型在真实场景中的相对性能。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型基准测试虽然高效，但往往无法准确反映模型在实际应用中的效用。为弥合这一差距，作者希望构建一种能与真实人类偏好对齐的新静态基准。

Method: 提出BenchAlign方法，利用语言模型在题目级别上的表现以及部署中收集的模型排序对，学习与偏好对齐的题目权重，从而生成新的基准用于对未见模型进行排序。

Result: 实验表明，对齐后的基准能跨模型规模准确地对未见模型按人类偏好排序，同时保持良好的可解释性。

Conclusion: 该工作揭示了将基准与实际人类偏好对齐的潜力与局限，有助于加速面向真实效用的语言模型开发。

Abstract: Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.

</details>


### [101] [Minimal Computational Preconditions for Subjective Perspective in Artificial Agents](https://arxiv.org/abs/2602.02902)
*Hongju Pae*

Main category: cs.AI

TL;DR: 该研究通过引入一个缓慢演化的全局隐状态来实现人工智能体中的主观视角，并发现其在无奖励环境中表现出方向依赖的滞后现象，这被视为机器系统中类主观性的可测信号。


<details>
  <summary>Details</summary>
Motivation: 探索如何在人工系统中实现并识别主观视角，特别是基于现象学动机构建最小内部结构以支持主观性。

Method: 设计一个不直接优化行为结果、但能调制快速策略动态的缓慢演化全局隐状态，在无奖励且存在机制转换的环境中观察其行为特性。

Result: 该隐状态在环境变化中展现出方向依赖的滞后（hysteresis），而策略层面的行为则相对反应迅速。

Conclusion: 方向依赖的滞后可作为机器系统中类主观视角的可测量标志，为主观性在人工智能中的建模提供新思路。

Abstract: This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy dynamics without being directly optimized for behavioral consequences. In a reward-free environment with regime shifts, this latent structure exhibits direction-dependent hysteresis, while policy-level behavior remains comparatively reactive. I argue that such hysteresis constitutes a measurable signature of perspective-like subjectivity in machine systems.

</details>


### [102] [FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights](https://arxiv.org/abs/2602.02905)
*Zhen Wang,Fan Bai,Zhongyan Luo,Jinyan Su,Kaiser Sun,Xinle Yu,Jieyuan Liu,Kun Zhou,Claire Cardie,Mark Dredze,Eric P. Xing,Zhiting Hu*

Main category: cs.AI

TL;DR: 本文提出了FIRE-Bench，一个用于评估大语言模型驱动的自主智能体在端到端科学发现中能力的新基准，通过让智能体重现近期高影响力机器学习研究中的已验证成果来衡量其表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法要么过度依赖LLM作为评判者来评估自动生成的研究成果，要么使用孤立且粗粒度的性能指标，难以真实反映科学洞察能力。因此，亟需一个更严谨、可验证的评估框架。

Method: FIRE-Bench要求智能体仅根据一篇已发表研究中的高层次研究问题，自主完成从构思、实验设计、代码实现、执行到基于实证得出结论的完整科研流程，并以能否成功重现原始研究发现作为评估标准。

Result: 即使是最先进的智能体（如基于GPT-5的系统）在FIRE-Bench上的表现也有限，重现实验的成功率低于50 F1分数，运行结果方差大，并在实验设计、执行和基于证据的推理方面存在反复出现的失败模式。

Conclusion: FIRE-Bench为衡量智能体在可靠、可验证的科学发现方面的能力提供了一个严格且具有诊断性的评估框架，揭示了当前系统在全流程科研任务中的不足。

Abstract: Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they either heavily rely on LLM-as-judge evaluations of automatically generated research outputs or optimize convenient yet isolated performance metrics that provide coarse proxies for scientific insight. To address this gap, we introduce FIRE-Bench (Full-cycle Insight Rediscovery Evaluation), a benchmark that evaluates agents through the rediscovery of established findings from recent, high-impact machine learning research. Agents are given only a high-level research question extracted from a published, verified study and must autonomously explore ideas, design experiments, implement code, execute their plans, and derive conclusions supported by empirical evidence. We evaluate a range of state-of-the-art agents with frontier LLMs backbones like gpt-5 on FIRE-Bench. Our results show that full-cycle scientific research remains challenging for current agent systems: even the strongest agents achieve limited rediscovery success (<50 F1), exhibit high variance across runs, and display recurring failure modes in experimental design, execution, and evidence-based reasoning. FIRE-Bench provides a rigorous and diagnostic framework for measuring progress toward reliable agent-driven scientific discovery.

</details>


### [103] [Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs](https://arxiv.org/abs/2602.02909)
*Kiran Tomlinson,Tobias Schnabel,Adith Swaminathan,Jennifer Neville*

Main category: cs.AI

TL;DR: 本文研究了链式思维（CoT）推理在大语言模型中随输入规模增长所需的推理token数量，证明了在三类典型任务上至少需要Ω(n)的推理token，并通过实验验证了这一理论下界。


<details>
  <summary>Details</summary>
Motivation: 链式思维（CoT）推理虽能提升大语言模型性能，但带来显著的延迟和计算开销。作者旨在从理论上理解：随着输入规模增长，解决一个问题究竟需要多少推理token。

Method: 作者扩展了有界注意力前缀预言机（BAPO）模型，该模型抽象了大语言模型的信息流需求，并在此基础上对三类BAPO-hard任务（二元多数、三元匹配和图可达性）推导出推理token的理论下界；同时构造显式算法以获得匹配或近似匹配的上界，并在前沿推理模型上进行实验验证。

Result: 理论证明三类任务均需Ω(n)推理token；实验显示前沿模型在这些任务上的推理token使用近似线性增长，且在推理预算受限时表现显著下降，与理论下界一致。

Conclusion: CoT推理存在根本性的推理长度瓶颈，本文提出的分析框架为理解最优推理长度提供了理论工具。

Abstract: Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.

</details>


### [104] [DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution](https://arxiv.org/abs/2602.02919)
*Jiachen Jiang,Tianyu Ding,Zhihui Zhu*

Main category: cs.AI

TL;DR: 本文提出DeltaEvolve，一种基于语义差异（semantic delta）的动量驱动进化框架，替代传统全代码历史记录方式，在减少上下文token消耗的同时提升自动科学发现效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的进化系统（如AlphaEvolve）依赖完整的代码历史，导致上下文效率低下且难以提供有效的进化指导；冗余实现细节掩盖了核心算法思想，削弱了进化的方向性。

Method: 将进化智能体形式化为期望最大化（EM）框架：E步由语言模型采样候选程序，M步根据评估反馈更新控制上下文。提出用结构化的语义差异代替全代码快照，并通过多层次数据库与渐进披露机制组织这些差异以减少输入长度。

Result: 在多个科学领域的任务上，DeltaEvolve相比基于全代码的进化方法，在更少token消耗下发现了更优解。

Conclusion: 利用结构化语义差异可有效提升LLM驱动进化系统的效率与性能，为自动化科学发现提供更清晰、可迁移的进化信号。

Abstract: LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.

</details>


### [105] [UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers](https://arxiv.org/abs/2602.02952)
*Elias Hossain,Shubhashis Roy Dipta,Subash Neupane,Rajib Rana,Ravid Shwartz-Ziv,Ivan Garibay,Niloofar Yousefi*

Main category: cs.AI

TL;DR: 本文提出UAT-LITE，一种在推理阶段通过蒙特卡洛Dropout估计token级认知不确定性，并以此调节自注意力机制的轻量级框架，无需修改预训练权重或训练目标，即可提升模型校准性、选择性预测能力和分布外鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 神经NLP模型常存在过度自信问题，导致在高风险场景中不可靠；现有后处理校准方法不改变内部计算，而集成或贝叶斯方法成本高昂。因此需要一种高效且无需重训练的不确定性建模方法。

Method: UAT-LITE在推理时对预训练Transformer分类器应用近似贝叶斯推断（通过蒙特卡洛Dropout），估计token级认知不确定性，并用其调制自注意力权重；同时引入逐层方差分解以分析不确定性在Transformer各层中的累积过程。

Result: 在SQuAD 2.0、MNLI和SST-2任务上，UAT-LITE相比微调后的BERT-base基线平均降低约20%的期望校准误差（ECE），同时保持任务准确率，并在选择性预测和分布偏移下表现更优。

Conclusion: UAT-LITE提供了一种轻量、无需重训练的推理阶段不确定性建模方法，有效提升模型校准性和鲁棒性，适用于实际部署场景。

Abstract: Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.

</details>


### [106] [Structuring Value Representations via Geometric Coherence in Markov Decision Processes](https://arxiv.org/abs/2602.02978)
*Zuyuan Zhang,Zeyu Fang,Tian Lan*

Main category: cs.AI

TL;DR: 本文提出GCR-RL方法，通过序理论视角将强化学习中的价值函数估计转化为学习偏序集（poset），并利用超偏序集细化序列确保几何一致性，从而提升样本效率与性能稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法虽已利用对称性、几何感知数据增强等几何性质，但尚未从序理论角度系统建模价值函数的结构关系。作者旨在通过引入偏序集和几何一致性约束，提升学习过程的稳定性和效率。

Method: 提出GCR-RL框架，通过时序差分信号逐步细化偏序集，构建具有几何一致性的超偏序集序列；并分别基于Q-learning和Actor-Critic设计两种新算法实现该细化过程。

Result: 在多种任务上的实验表明，GCR-RL相比强基线方法在样本效率和性能稳定性方面均有显著提升。

Conclusion: 将序理论与几何一致性引入强化学习可有效提升算法性能，为价值函数学习提供了一种新的结构化视角。

Abstract: Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.

</details>


### [107] [Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget](https://arxiv.org/abs/2602.02983)
*Hanna M. Dettki,Charley M. Wu,Bob Rehder*

Main category: cs.AI

TL;DR: 本文通过11个基于对撞结构的因果判断任务，对比20多个大语言模型（LLMs）与人类的表现，发现LLMs更倾向于规则化推理，而人类则考虑未明示的潜在因素；LLMs缺乏典型的人类对撞偏差，且在语义抽象和提示干扰下表现较脆弱，但思维链（CoT）可提升其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在因果推理任务中的判断机制是否符合规范性因果计算、类人启发式或脆弱的模式匹配，并评估其与人类推理策略的异同，以指导其安全有效部署。

Method: 在11个形式化为对撞结构（$C_1 \rightarrow E \leftarrow C_2$）的因果判断任务上，对20多个LLMs与匹配的人类基线进行基准测试；使用小型可解释模型压缩LLMs的判断；并通过语义抽象和提示过载（注入无关文本）两种方式探测LLMs因果判断的鲁棒性，同时考察思维链（CoT）的影响。

Result: 大多数LLMs展现出比人类更强的规则化推理策略，而人类在概率判断中会考虑未提及的潜在因素；LLMs普遍不表现出人类典型的对撞偏差（如弱解释消除和马尔可夫违反）；在语义抽象和提示干扰下，LLMs表现下降，但CoT能显著提升其鲁棒性。

Conclusion: LLMs的规则化因果推理策略使其在人类已知偏差不可取时具有互补价值，但在内在不确定性情境下可能失效，因此需深入刻画其推理策略以确保安全有效应用。

Abstract: Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \!\rightarrow\! E\! \leftarrow \!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.

</details>


### [108] [Large Language Models Can Take False First Steps at Inference-time Planning](https://arxiv.org/abs/2602.02991)
*Haijiang Yan,Jian-Qiao Zhu,Adam Sanborn*

Main category: cs.AI

TL;DR: 本文提出了一种贝叶斯解释，说明大语言模型（LLMs）在推理过程中看似短视的规划行为，源于其自生成上下文与自然语言之间的差异所引发的“规划偏移”；并通过两个受控实验验证了该模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在训练中展现出序列级规划能力，但在推理时却常表现出短视和不一致的规划行为。作者旨在解释这一差距。

Method: 提出一个基于贝叶斯框架的理论模型，将规划行为与模型在推理过程中不断累积的自生成上下文联系起来，并通过两个受控实验进行验证：一是随机生成任务，观察人类提示下与自生成上下文累积时的规划强度变化；二是高斯采样任务，检验自生成序列对初始偏差的影响。

Result: 实验结果显示，在自生成上下文累积过程中，模型的规划能力增强；且在以自生成序列为条件时，初始偏差减少，支持所提出的理论模型。

Conclusion: 大语言模型在推理中的规划行为受其内部语言与自然语言差异影响，自生成上下文会引发规划偏移；该研究为理解LLM如何在推理中进行前瞻性规划提供了理论解释和实证支持。

Abstract: Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.

</details>


### [109] [Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents](https://arxiv.org/abs/2602.02995)
*Sizhe Tang,Rongqian Chen,Tian Lan*

Main category: cs.AI

TL;DR: 本文提出Agent Alpha，一种结合生成、探索与评估的GUI智能体框架，通过步骤级蒙特卡洛树搜索（MCTS）实现高效规划，在OSWorld基准上达到约77%的成功率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹采样的GUI智能体缺乏回溯能力，无法复用部分成功路径或从早期错误中恢复，限制了其规划效率和性能。

Method: 引入Agent Alpha框架，采用步骤级MCTS，结合alpha-UCT引导搜索、比较驱动的评估机制和多样性约束的扩展策略，实现对规划空间的主动建模与高效利用。

Result: 在OSWorld基准测试中，Agent Alpha在相同计算资源下取得约77%的成功率，显著超越基于轨迹采样的基线方法。

Conclusion: Agent Alpha通过整合生成、探索与评估，有效提升GUI智能体的规划能力与成功率，为未来智能体设计提供了新思路。

Abstract: While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this paper, we introduce Agent Alpha, a unified framework that synergizes generation, exploration, and evaluation through step-level Monte Carlo Tree Search (MCTS). It enables active modeling or exploiting structures of the planning space. By integrating alpha-UCT guided search into the interaction loop, Agent Alpha enables deliberate planning, facilitating early pruning of suboptimal branches and efficient prefix reuse. We also employ comparison-driven evaluation to mitigate absolute scoring biases and diversity-constrained expansion to maintain a compact, informative search space. Regret bound of alpha-UCT is analyzed. On the OSWorld benchmark, Agent Alpha achieves a state-of-the-art success rate of $\sim 77\%$, significantly outperforming trajectory-level baselines under equivalent compute.

</details>


### [110] [Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment](https://arxiv.org/abs/2602.03003)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 本文综述了可微分社会选择这一新兴范式，将投票规则与聚合机制建模为可学习、可微分的模型，并整合了来自拍卖、投票、预算分配等多个领域的研究，提出了36个开放问题。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统越来越多地涉及偏好、激励和判断的聚合，隐式地实现了社会选择机制，但缺乏明确的规范性审视。因此，有必要系统性地研究如何将社会选择理论与机器学习结合。

Method: 通过将经典社会选择中的公理与不可能性定理转化为可微分模型中的目标、约束和优化权衡，构建可学习的社会选择机制，并综合多个领域的相关工作。

Result: 展示了不同领域（如拍卖、投票、液态民主等）中社会选择机制如何被重新表述为数据驱动的可微分模型，并揭示了传统理论在新框架下的表现形式。

Conclusion: 可微分社会选择为机器学习、经济学与民主理论的交叉提供了新研究方向，文章提出36个开放问题以推动该领域发展。

Abstract: Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.
  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.

</details>


### [111] [Distilling LLM Reasoning into Graph of Concept Predictors](https://arxiv.org/abs/2602.03006)
*Ziyang Yu,Liang Zhao*

Main category: cs.AI

TL;DR: 本文提出图概念预测器（GCP），一种推理感知的主动蒸馏框架，通过将大语言模型教师的决策过程建模为有向无环图，并在学生模型中使用模块化概念预测器进行镜像，从而提升样本效率、训练稳定性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有主动蒸馏方法通常仅蒸馏最终标签，忽略了中间推理信号，难以诊断推理缺失和错误来源，限制了学生模型的性能与可控性。

Method: GCP 将教师模型的推理过程外化为有向无环图，在学生端构建对应的模块化概念预测器；采用图感知的样本采集策略，聚焦关键推理节点的不确定性与分歧；并通过针对性的子模块重训练机制，将下游损失归因于特定概念预测器，仅更新影响最大的模块。

Result: 在八个NLP分类基准上的实验表明，GCP在有限标注预算下显著提升学生模型性能，同时提供更可解释和可控的训练动态。

Conclusion: GCP通过显式建模并蒸馏推理结构，有效提升了主动蒸馏的效率、稳定性和可解释性，为压缩大语言模型用于判别任务提供了新思路。

Abstract: Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.

</details>


### [112] [STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models](https://arxiv.org/abs/2602.03022)
*Jiliang Ni,Jiachen Pu,Zhongyi Yang,Jingfeng Luo,Conggang Hu*

Main category: cs.AI

TL;DR: 本文提出STAR框架，通过结合约束知识蒸馏（CKD）和相似性引导强化学习（Sim-RL），将大语言模型的函数调用能力高效迁移至超小型模型，在保持训练稳定性的同时显著提升性能，使0.6B模型在1B以下开源模型中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在函数调用方面能力强大，但其规模限制了广泛应用。现有小型化方法存在过拟合、训练不稳定、多解任务中二元奖励无效以及技术难以协同等问题，亟需一种更有效的迁移框架。

Method: STAR框架包含两个核心技术：(1) 约束知识蒸馏（CKD），通过top-k前向KL散度抑制错误预测，兼顾训练稳定性和探索能力；(2) 相似性引导强化学习（Sim-RL），利用生成结果与真实答案的相似度提供细粒度、连续的奖励信号，优化策略学习。两者在统一训练课程中协同工作。

Result: 在多个知名且具挑战性的基准测试中，STAR模型在其规模类别中达到SOTA水平。其中0.6B模型在所有1B以下开源模型中表现最佳，甚至超越部分更大规模的知名开源模型。

Conclusion: STAR提供了一个高效的整体训练框架，成功将大语言模型的函数调用能力蒸馏到超小型模型中，为构建强大、易获取且高效的AI智能体开辟了新路径。

Abstract: The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.

</details>


### [113] [RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents](https://arxiv.org/abs/2602.03025)
*Haitian Zhong,Jixiu Zhai,Lei Song,Jiang Bian,Qiang Liu,Tieniu Tan*

Main category: cs.AI

TL;DR: 本文提出RC-GRPO方法，通过在提示中引入离散奖励标记来增强多轮工具调用中策略优化的组内多样性，从而缓解GRPO因组内奖励方差低导致的更新停滞问题，在BFCLv4基准上取得优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: 多轮工具调用任务中，LLM面临稀疏奖励和高探索成本的问题；标准SFT+GRPO流程在组内奖励差异较小时（如全0或全1）会导致归一化优势估计失效，策略更新停滞。

Method: 提出RC-GRPO：首先在混合质量轨迹上微调一个奖励条件轨迹策略（RCTP），在提示中注入如<|high_reward|>等特殊奖励标记，使模型能按需生成不同质量的轨迹；在GRPO训练阶段，每组内采样多样化的奖励标记并以此条件生成rollout，提升组内多样性与优势估计有效性。

Result: 在BFCLv4多轮工具调用基准上，RC-GRPO一致优于基线方法；使用Qwen-2.5-7B-Instruct时，性能甚至超过所有闭源API模型。

Conclusion: 通过将探索建模为基于离散奖励标记的可控引导问题，RC-GRPO有效提升了多轮工具调用场景下RL训练的稳定性和性能。

Abstract: Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.

</details>


### [114] [Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment](https://arxiv.org/abs/2602.03100)
*Jingnan Zheng,Yanzhen Luo,Jingjun Xu,Bingnan Liu,Yuxin Chen,Chenhang Cui,Gelei Deng,Chaochao Lu,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 本文提出了Risky-Bench，一个基于现实部署场景的系统性大语言模型智能体安全评估框架，通过领域无关的安全原则构建上下文感知的安全评分标准，并在多样化威胁假设下进行长周期、交互式任务执行评估。


<details>
  <summary>Details</summary>
Motivation: 现有智能体安全评估方法局限于特定任务和场景，覆盖范围有限，难以评估复杂现实环境中长周期交互下的安全行为，且缺乏跨配置的适应性。

Method: Risky-Bench围绕领域无关的安全原则构建上下文感知的安全评分体系，并在不同威胁假设下通过逼真的任务执行系统性地评估安全风险。

Result: 在生活辅助类智能体场景中，Risky-Bench揭示了当前先进智能体在现实执行条件下存在显著安全风险。

Conclusion: Risky-Bench提供了一个结构良好、可扩展的评估流程，不仅适用于生活辅助场景，还可适配其他部署环境，为智能体安全评估提供通用方法论。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.

</details>


### [115] [Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis](https://arxiv.org/abs/2602.03128)
*Abdelghny Orogat,Ana Rostam,Essam Mansour*

Main category: cs.AI

TL;DR: 本文提出MAFBench评估套件和架构分类法，系统分析多智能体大语言模型框架的架构设计对性能（如延迟、准确性、协调能力）的显著影响，并提供设计原则与选型指南。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架的架构差异对系统性能（延迟、吞吐量、准确性和可扩展性）影响巨大但缺乏系统理解，现有基准测试无法在框架层面进行标准化、多维度联合评估。

Method: 作者首先构建了一个用于系统比较多智能体LLM框架的架构分类法，然后开发了统一的评估套件MAFBench，该套件在一个标准化执行管道下整合了现有基准，以隔离并评估架构设计的影响。

Result: 实验表明，仅框架层面的设计选择就能导致延迟增加超过100倍、规划准确率下降高达30%、协调成功率从90%以上降至30%以下。

Conclusion: 研究将发现转化为具体的架构设计原则和框架选型指南，并指出了未来有前景的研究方向。

Abstract: Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.

</details>


### [116] [General Agents Contain World Models, even under Partial Observability and Stochasticity](https://arxiv.org/abs/2602.03146)
*Santiago Cifuentes*

Main category: cs.AI

TL;DR: 本文将先前关于智能体必须包含环境模型的结论，从确定性、完全可观测环境推广到随机性、部分可观测环境，并进一步弱化了对智能体通用性的要求。


<details>
  <summary>Details</summary>
Motivation: 先前工作[10]证明在特定框架下，几乎所有最优且通用的确定性智能体在完全可观测环境中必然包含其环境的足够知识，从而可通过黑盒查询近似重建环境。然而，该结论依赖于智能体确定性和环境完全可观测两个强假设。本文旨在去除这两个限制，以更广泛地理解智能体是否必须学习其环境模型。

Method: 作者通过理论分析，将原有定理扩展至随机智能体和部分可观测环境的情形，并进一步弱化“通用性”这一前提条件，从而在更宽松的设定下证明智能体仍需包含环境模型。

Result: 研究证明，即使在部分可观测环境中，随机智能体也无法通过引入随机性来避免学习其环境；同时，即使不具备原先所要求的强通用性，较弱的智能体也已内含其所处世界的模型。

Conclusion: 智能体学习环境模型是其有效运行的内在要求，这一结论在更一般（随机、部分可观测）的设定下依然成立，且适用于能力更弱的智能体。

Abstract: Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.
  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.

</details>


### [117] [Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration](https://arxiv.org/abs/2602.03151)
*Wei Dai,Haoyu Wang,Honghao Chang,Lijun He,Fan Li,Jian Sun,Haixia Bi*

Main category: cs.AI

TL;DR: 本文提出一种通用的缺失模态恢复策略，通过增强扩散模型与动态模态门控和跨模态互学习机制，在视觉语言模型（VLM）中有效恢复缺失特征，提升其在模态缺失场景下的性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在推理时假设输入模态完整，但当某些模态缺失或不完整时性能显著下降。当前方法存在两大问题：基于提示的方法难以恢复关键缺失特征且损害泛化能力；基于插补的方法缺乏有效引导，易生成语义无关噪声。

Method: 引入一个可插拔的增强扩散模型作为中间训练模块，包含两个核心创新：(I) 动态模态门控，自适应利用条件特征引导生成语义一致的特征；(II) 跨模态互学习机制，实现双编码器语义空间的双向对齐。

Result: 在多个基准数据集上的零样本评估表明，该方法优于现有基线。大量实验和消融研究验证了模型在不同缺失率和环境下的鲁棒性与可扩展性。

Conclusion: 所提策略为VLM在缺失模态场景下提供了一种可靠、通用且可扩展的解决方案，有效兼顾语义恢复精度与模型泛化能力。

Abstract: Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.

</details>


### [118] [VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models](https://arxiv.org/abs/2602.03160)
*Woojin Kim,Sieun Hyeon,Jusang Oh,Jaeyoung Do*

Main category: cs.AI

TL;DR: 本文提出VALUEFLOW框架，首次统一实现大语言模型（LLMs）价值观的提取、评估与强度可控引导，通过层级嵌入空间、带强度标注的数据集和锚点评估器，系统研究了多价值观的可引导性与组合规律。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法难以捕捉深层价值动机，而基于价值观的方法在结构建模、强度评估和可控引导方面存在不足，亟需一个统一且可扩展的框架来实现对LLMs价值观的精细化控制。

Method: 提出VALUEFLOW框架，包含三部分：(i) HIVES层级价值观嵌入空间；(ii) 带强度估计的Value Intensity DataBase (VIDB)；(iii) 基于锚点的评估器，通过与VIDB面板对比生成一致的强度评分。在10个模型和4种价值理论下进行大规模实验。

Result: 研究揭示了不同模型在价值观引导上的不对称性，并发现了多价值观组合控制的规律，验证了VALUEFLOW在价值观强度评估与引导方面的有效性。

Conclusion: VALUEFLOW为大语言模型的价值观对齐提供了可扩展的基础设施，推动了多元价值观下LLMs的精细化对齐研究。

Abstract: Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.

</details>


### [119] [Beyond Quantity: Trajectory Diversity Scaling for Code Agents](https://arxiv.org/abs/2602.03219)
*Guhong Chen,Chenghao Sun,Cheng Fu,Qiyao Wang,Zhihong Huang,Chaopeng Wei,Guangxu Chen,Feiteng Fang,Ahmadreza Argha,Bing Zhao,Xander Xu,Qi Han,Hamid Alinejad-Rokny,Qiang Qu,Binhua Li,Shiwen Ni,Min Yang,Hu Wei,Yongbin Li*

Main category: cs.AI

TL;DR: 本文提出TDScaling，一种基于轨迹多样性的数据合成框架，通过提升轨迹多样性而非单纯增加数据量来增强代码智能体的工具使用能力和编码能力。


<details>
  <summary>Details</summary>
Motivation: 当前代码大语言模型在通过MCP协议演变为工具交互智能体时，其泛化能力受限于低质量合成数据和数量扩展的收益递减；同时，以数量为中心的扩展策略过早遭遇瓶颈，未能充分利用轨迹数据。

Method: TDScaling框架包含四项创新：(1) 捕捉真实服务逻辑依赖的业务簇机制；(2) 蓝图驱动的多智能体范式以确保轨迹一致性；(3) 基于领域熵、推理模式熵和累积动作复杂度的自适应演化机制，引导合成朝向长尾场景以避免模式崩溃；(4) 沙箱化代码工具以缓解内在编码能力的灾难性遗忘。

Result: 在通用工具使用基准（BFCL、tau^2-Bench）和代码智能体任务（RebenchT、CodeCI、BIRD）上的实验表明，TDScaling在固定训练预算下，通过增加轨迹多样性比增加轨迹数量带来更大性能提升，实现了工具使用泛化与编码能力的双赢。

Conclusion: 通过强调轨迹多样性而非数据量，TDScaling显著改善了智能体训练的性能-成本权衡，并同时提升了工具交互能力和基础编码能力，为未来代码智能体的数据合成提供了新方向。

Abstract: As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.

</details>


### [120] [TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking](https://arxiv.org/abs/2602.03224)
*Yu Cheng,Jiuan Zhou,Yongkang Hu,Yihang Chen,Huichi Zhou,Mingang Chen,Zhizhong Zhang,Kun Shao,Yuan Xie,Zhaoxia Yin*

Main category: cs.AI

TL;DR: 本文提出TAME框架，通过双记忆演化机制在任务演化过程中同时提升智能体的任务性能与可信度，有效缓解“智能体记忆误演化”问题。


<details>
  <summary>Details</summary>
Motivation: 在智能体记忆随任务演化的测试阶段，即使任务本身无害，其安全对齐仍可能退化（即“记忆误演化”），威胁AGI发展。现有方法缺乏对此现象的系统评估与应对。

Method: 构建Trust-Memevo基准以评估良性任务演化中的多维可信度；提出TAME双记忆演化框架，分别优化执行器记忆（提升任务性能）和评估器记忆（保障安全与效用），并通过闭环流程实现可信精炼与记忆更新。

Result: 实验表明，TAME在多种任务领域和评估设置下显著缓解了记忆误演化，在不牺牲任务效用的前提下同步提升了可信度与性能。

Conclusion: 通过分离并协同演化执行与评估记忆，TAME为实现安全、可靠且高性能的通用智能体提供了有效路径。

Abstract: Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.

</details>


### [121] [The Necessity of a Unified Framework for LLM-Based Agent Evaluation](https://arxiv.org/abs/2602.03238)
*Pengyu Zhu,Li Sun,Philip S. Yu,Sen Su*

Main category: cs.AI

TL;DR: 本文指出当前大语言模型智能体的评估存在严重标准化缺失问题，提出需建立统一评估框架以确保公平性与可复现性。


<details>
  <summary>Details</summary>
Motivation: 现有智能体评测受系统提示、工具配置和环境动态等外部因素干扰，缺乏统一标准，导致结果不可靠、不可复现，难以准确衡量模型本身性能。

Method: 分析当前智能体评估中存在的问题，提出构建统一的智能体评估框架的必要性与方向。

Result: 揭示了当前评估方法中的混淆因素和不一致性，并论证了标准化评估体系对领域发展的关键作用。

Conclusion: 为推动智能体研究的严谨发展，必须建立统一、透明、可复现的评估标准。

Abstract: With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.

</details>


### [122] [Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning](https://arxiv.org/abs/2602.03249)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Wenlei Shi,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.AI

TL;DR: 本文提出Accordion-Thinking框架，使大语言模型通过动态摘要自我调节推理粒度，在保持准确率的同时显著减少推理时的计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有长链式思维（Chain-of-Thought）推理方法受限于KV缓存线性增长和注意力机制的二次复杂度，难以在实际中高效扩展。

Method: 引入Accordion-Thinking框架，采用动态摘要机制实现“折叠”（Fold）推理模式，并结合强化学习训练模型在折叠与展开（Unfold）模式间缩小准确率差距。

Result: 模型在训练过程中逐步学会将关键推理信息压缩进摘要，在48GB GPU内存下实现3倍吞吐量提升，同时保持准确率不变。

Conclusion: 通过学习自压缩能力，大语言模型可在几乎不增加历史token依赖的前提下高效完成复杂推理任务，且生成的结构化摘要具备可读性。

Abstract: Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.

</details>


### [123] [CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs](https://arxiv.org/abs/2602.03263)
*Yuxuan Liu,Yuntian Shi,Kun Wang,Haoting Shen,Kun Yang*

Main category: cs.AI

TL;DR: 本文提出了CSR-Bench，一个用于评估多模态大语言模型（MLLMs）跨模态可靠性的基准，涵盖安全、过度拒绝、偏见和幻觉四大类共61种细粒度交互模式，并发现当前模型在跨模态对齐方面存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs的安全行为可能依赖单模态捷径而非真正的图文联合意图理解，因此需要一个能评估其跨模态可靠性的基准来揭示潜在问题。

Method: 构建CSR-Bench基准，包含需图文联合理解的测试实例及对应的纯文本对照组，通过四类压力测试模式（安全、过度拒绝、偏见、幻觉）评估16个前沿MLLMs的行为差异。

Result: 实验发现MLLMs普遍存在跨模态对齐差距：安全意识薄弱、语言主导性强、从纯文本到多模态输入时性能显著下降，且减少过度拒绝与维持安全非歧视行为之间存在权衡。

Conclusion: 当前MLLMs的安全表现可能源于拒绝导向的启发式策略，而非稳健的意图理解，强调了发展真正跨模态联合推理能力的重要性。

Abstract: Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.

</details>


### [124] [Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis](https://arxiv.org/abs/2602.03279)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Xuan Ren,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为Agentic Proposing的框架，通过智能体在数学、编程和科学领域生成高质量、可验证的合成数据，显著提升下游求解器性能，并在AIME25上达到91.6%的SOTA准确率。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法在结构有效性和问题复杂性之间存在权衡，而人工标注成本高且难以扩展，因此需要一种能同时保证数据质量和复杂性的新范式。

Method: 将问题合成建模为目标驱动的序列决策过程，利用具备模块化推理技能的智能体，结合多粒度策略优化（MGPO）和迭代式内省与工具调用机制，构建Agentic-Proposer-4B模型以生成训练轨迹。

Result: 基于合成数据训练的下游求解器显著优于现有基线，在多个领域展现出强泛化能力；仅用11,000条合成轨迹训练的30B模型在AIME25上达到91.6%准确率。

Conclusion: 少量高质量的智能体合成数据可有效替代大规模人工标注数据，为复杂推理任务提供高效、可扩展的数据生成方案。

Abstract: Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.

</details>


### [125] [Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity](https://arxiv.org/abs/2602.03315)
*Menglin Xia,Xuchao Zhang,Shantanu Dixit,Paramaguru Harimurugan,Rujia Wang,Victor Ruhle,Robert Sim,Chetan Bansal,Saravan Rajmohan*

Main category: cs.AI

TL;DR: Memora 是一种新型记忆表示方法，通过在抽象与具体之间取得结构性平衡，提升智能体在大规模记忆下的检索相关性与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统在扩展时往往牺牲细节以换取抽象，导致下游任务中缺乏细粒度信息；因此需要一种既能有效抽象又能保留具体细节的记忆结构。

Method: Memora 通过主抽象（primary abstractions）索引具体记忆值并合并相关更新，同时利用提示锚点（cue anchors）扩展检索路径并连接相关记忆；结合主动利用记忆连接的检索策略，超越仅依赖语义相似性的传统方法。

Result: Memora 在 LoCoMo 和 LongMemEval 基准上达到当前最优性能，展现出更强的检索相关性和推理效果，尤其在记忆规模扩大时优势更明显。

Conclusion: Memora 提供了一种统一框架，将标准 RAG 和基于知识图谱的记忆系统视为其特例，有效解决了记忆扩展中抽象与具体之间的权衡问题。

Abstract: Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.

</details>


### [126] [MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis](https://arxiv.org/abs/2602.03340)
*Xiao Sun,Yuming Yang,Junnan Zhu,Jiang Zhong,Xinyu Zhou,Kaiwen Wei*

Main category: cs.AI

TL;DR: 本文提出了MentalDx Bench——首个面向真实临床场景的细粒度精神障碍诊断基准，并开发了专用模型MentalSeek-Dx，通过模拟临床推理过程，在该基准上实现了当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在精神健康评估中的应用受限于缺乏生态效度和细粒度诊断监督的基准，难以满足真实临床需求。

Method: 构建包含712份由认证精神科医生依据ICD-11标注的电子健康记录的MentalDx Bench基准；提出MentalSeek-Dx模型，采用监督轨迹构建与课程强化学习方法，使其内化临床假设-演绎推理过程。

Result: 在MentalDx Bench上对18个大语言模型的评估揭示了其在粗粒度分类表现良好但在具体障碍诊断上系统性失败；MentalSeek-Dx仅用14B参数即达到SOTA性能。

Conclusion: MentalDx Bench为精神障碍诊断提供了临床可信的评估基准，MentalSeek-Dx通过建模临床推理机制，为可靠的精神科AI辅助诊断奠定了基础。

Abstract: Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.

</details>


### [127] [Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility](https://arxiv.org/abs/2602.03402)
*Mengxuan Wang,Yuxin Chen,Gang Xu,Tao He,Hongjie Jiang,Ming Li*

Main category: cs.AI

TL;DR: 本文提出了一种无需训练的轻量级框架RAI，通过增强视觉语言模型（VLM）中的不安全信号，有效提升其对多模态越狱攻击的防御能力，同时保持原有任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有针对VLM的防御方法依赖安全微调或激进的token操作，成本高或损害模型效用；且VLM在引入视觉输入后会削弱原本LLM具备的不安全内容识别能力。

Method: RAI构建一个基于语言嵌入的“不安全原型子空间”，并对高风险视觉token进行有针对性的调制，在跨模态特征空间中显式激活安全关键信号，从而恢复模型类似LLM的风险识别能力。

Result: 在多个越狱攻击和效用基准上的实验表明，RAI显著降低了攻击成功率，同时未影响模型的任务性能。

Conclusion: RAI是一种高效、轻量且无需训练的安全校准方法，能有效增强VLM对多模态越狱攻击的鲁棒性，同时保留其跨模态推理能力。

Abstract: Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.

</details>


### [128] [Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations](https://arxiv.org/abs/2602.03403)
*Guangming Lang,Mingchuan Shang,Mengjun Hu,Jie Zhou,Feng Xu*

Main category: cs.AI

TL;DR: 本文提出了一种基于直觉模糊偏好的三支冲突分析模型，通过更细粒度刻画主体对议题对的态度，构建了相应的冲突度量、三分方法及可行调整策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的冲突模型仅使用偏好、逆偏好和无差异三种定性关系，难以充分刻画冲突的本质，限制了其表达能力。

Method: 引入直觉模糊偏好关系以更精细地描述主体对议题对的态度；在此基础上定义直觉模糊偏好冲突度量，构建对主体对、主体集和议题集的三支划分模型；利用基于冲突函数的相对损失函数计算三分阈值，并设计兼顾调整幅度与冲突程度的可行策略生成算法。

Result: 所提模型能够更细致地刻画冲突情境，有效实现对主体与议题的三分，并通过示例验证了模型的有效性和可行性。

Conclusion: 直觉模糊偏好能增强三支冲突分析模型的表达能力和实用性，为复杂冲突情境提供更灵活的建模与决策支持。

Abstract: In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.

</details>


### [129] [DiscoverLLM: From Executing Intents to Discovering Them](https://arxiv.org/abs/2602.03429)
*Tae Soo Kim,Yoonjoo Lee,Jaesang Yu,John Joon Young Chung,Juho Kim*

Main category: cs.AI

TL;DR: 本文提出DiscoverLLM框架，通过建模用户认知状态的层级意图结构，训练大语言模型在交互中帮助用户逐步形成和发现自身意图，在多个任务中显著提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在面对模糊或开放性请求时，通常仅通过提问澄清用户意图，但当用户自身尚未形成明确意图时，这种方式效果有限。因此，需要一种能主动协助用户探索并形成意图的交互机制。

Method: 提出DiscoverLLM框架，核心是构建一个新颖的用户模拟器，该模拟器以层级化意图结构建模用户的认知状态，并随着模型呈现相关选项而逐步具体化；利用意图具体化程度作为奖励信号，训练模型在交互中自适应地进行发散（探索选项）与收敛（细化实现）。

Result: 在创意写作、技术写作和SVG绘图等交互式基准测试中，DiscoverLLM任务性能提升超过10%，对话长度最多减少40%；在包含75名参与者的用户研究中，其对话满意度和效率均优于基线方法。

Conclusion: DiscoverLLM通过建模用户意图形成过程，使大语言模型能更有效地协作用户探索和明确需求，显著提升交互质量与效率，具有良好的通用性和应用前景。

Abstract: To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking "what kind of tone do you want?" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.

</details>


### [130] [CRL-VLA: Continual Vision-Language-Action Learning](https://arxiv.org/abs/2602.03445)
*Qixin Zeng,Shuo Zhang,Hongyin Zhang,Renjie Wang,Han Zhao,Libang Zhao,Runze Li,Donglin Wang,Chao Huang*

Main category: cs.AI

TL;DR: 本文提出CRL-VLA框架，通过理论驱动的双评论家架构与目标条件价值公式，在持续强化学习中有效平衡VLA模型的稳定性与可塑性。


<details>
  <summary>Details</summary>
Motivation: 在开放世界环境中，具身智能体需通过终身学习掌握灵巧操作，而现有持续强化学习方法难以在保留旧技能（稳定性）与学习新技能（可塑性）之间取得良好平衡。

Method: 提出CRL-VLA框架，基于目标条件优势函数幅度与策略差异导出统一性能界，并采用不对称调控机制：在旧任务上约束优势幅度，在新任务上允许受控增长；通过冻结评论家保持语义一致性，可训练评论家驱动适应，结合新颖的目标条件价值公式（GCVF）实现。

Result: 在LIBERO基准上的实验表明，CRL-VLA在抗遗忘和前向适应方面均优于现有基线方法。

Conclusion: CRL-VLA通过理论引导的架构设计有效调和了持续学习中的稳定性-可塑性冲突，为VLA模型在终身机器人场景中的部署提供了可行路径。

Abstract: Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.

</details>


### [131] [The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding](https://arxiv.org/abs/2602.03467)
*Zeynep G. Saribatur,Johannes Langer,Ute Schmid*

Main category: cs.AI

TL;DR: 该论文研究了在符号AI解释中使用抽象（删除与聚类）如何影响人类的理解表现和认知负荷。


<details>
  <summary>Details</summary>
Motivation: AI系统常产生难以理解的输出，尽管符号AI具有可解释性优势，但其原始逻辑痕迹仍会造成高认知负担；因此需探索如何通过形式化抽象提升人类对符号解释的理解效率。

Method: 基于Answer Set Programming (ASP) 框架定义无关细节，并通过删除和聚类两种抽象方式生成简化解释；开展认知实验，让参与者在不同领域中根据这些解释对刺激进行分类。

Result: 实验结果表明，聚类显著提升参与者的理解能力，而删除细节则显著降低认知努力。

Conclusion: 形式化抽象（特别是删除与聚类）能有效增强面向人类的符号解释效果，支持将抽象机制融入可解释AI设计中。

Abstract: Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.

</details>


### [132] [When Routing Collapses: On the Degenerate Convergence of LLM Routers](https://arxiv.org/abs/2602.03478)
*Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: 本文提出了一种名为 EquiRouter 的新路由方法，通过直接学习模型排序来缓解现有大语言模型（LLM）路由策略中普遍存在的“路由崩溃”问题，在保持 GPT-4 级别性能的同时降低成本约17%。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 路由器在用户预算增加时倾向于始终选择最强（最昂贵）的模型，即使较便宜的小模型已足够应对查询，导致计算和金钱浪费，削弱了路由机制的核心价值。作者将此现象称为“路由崩溃”，并指出其根源在于训练目标（预测标量性能分数）与实际决策（离散模型比较）之间的不匹配。

Method: 作者提出 EquiRouter，一种决策感知的路由器，不再预测绝对性能分数，而是直接学习候选模型之间的相对排序，从而更准确地支持路由决策。

Result: 在 RouterBench 基准上，EquiRouter 相比当前最强的路由方法，在达到 GPT-4 级别性能时可节省约 17% 的成本。

Conclusion: 通过将路由训练目标与实际决策机制对齐，EquiRouter 有效缓解了路由崩溃问题，提升了小模型的利用率，并在性能与成本之间实现了更优的平衡。

Abstract: LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.

</details>


### [133] [Group Selection as a Safeguard Against AI Substitution](https://arxiv.org/abs/2602.03541)
*Qiankun Zhong,Thomas F. Eisenmann,Julian Garcia,Iyad Rahwan*

Main category: cs.AI

TL;DR: 过度依赖生成式AI可能削弱人类文化多样性，导致“文化崩溃”；研究发现，在个体选择下AI替代型用户占优，但在强群体边界下，AI辅助型用户因维持文化变异而更利于群体。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI广泛使用对人类文化演化长期影响，特别是可能导致文化多样性下降与创新减缓的“文化崩溃”风险。

Method: 采用基于智能体的模型和演化博弈论，比较AI作为“辅助”与“替代”两种使用策略在演化动态中的竞争与传播。

Result: AI替代型用户在个体层面选择中占主导，但会显著降低文化变异；AI辅助型用户有助于维持群体所需的文化多样性，在强群体边界下可通过文化群体选择被保留。

Conclusion: AI的长期人口层面影响取决于使用方式与社会结构，政策应鼓励AI辅助而非替代，以维护文化演化活力。

Abstract: Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to "cultural collapse", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.

</details>


### [134] [Persona Generators: Generating Diverse Synthetic Personas at Scale](https://arxiv.org/abs/2602.03545)
*Davide Paglieri,Logan Cross,William A. Cunningham,Joel Z. Leibo,Alexander Sasha Vezhnevets*

Main category: cs.AI

TL;DR: 本文提出了一种名为“Persona Generators”的新方法，通过结合大语言模型与迭代优化算法（AlphaEvolve），自动生成覆盖多样性和长尾行为的合成人群，用于评估AI系统在不同用户群体中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估与人类交互的AI系统需要理解其在多样化用户群体中的行为，但获取具有代表性的真人数据成本高且不可行，尤其在新技术或假设场景中。现有基于生成式智能体的方法虽能模拟人类行为，但通常依赖详尽的人群数据，且更关注高频行为（密度匹配），忽视了可能性空间中的长尾行为（支持覆盖）。

Method: 作者提出“Persona Generators”——一种可根据任意上下文生成多样化合成人群的函数。该方法采用基于AlphaEvolve的迭代优化循环，利用大语言模型作为变异算子，在数百次迭代中不断改进生成器代码，最终获得轻量级生成器，能从小规模描述自动扩展出在关键多样性维度上覆盖广泛观点和偏好的合成人群。

Result: 在六个多样性指标上，所提出的演化生成器在未见过的上下文中显著优于现有基线方法，能够生成包含罕见特征组合的合成人群，这些组合在标准大语言模型输出中难以实现。

Conclusion: Persona Generators提供了一种高效、可扩展的方式来生成高覆盖度的合成人群，有助于更全面地评估AI系统在多样化和边缘用户场景下的表现，弥补了传统方法在长尾行为建模上的不足。

Abstract: Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical future scenarios. Recent work in Generative Agent-Based Modeling has shown that large language models can simulate human-like synthetic personas with high fidelity, accurately reproducing the beliefs and behaviors of specific individuals. However, most approaches require detailed data about target populations and often prioritize density matching (replicating what is most probable) rather than support coverage (spanning what is possible), leaving long-tail behaviors underexplored. We introduce Persona Generators, functions that can produce diverse synthetic populations tailored to arbitrary contexts. We apply an iterative improvement loop based on AlphaEvolve, using large language models as mutation operators to refine our Persona Generator code over hundreds of iterations. The optimization process produces lightweight Persona Generators that can automatically expand small descriptions into populations of diverse synthetic personas that maximize coverage of opinions and preferences along relevant diversity axes. We demonstrate that evolved generators substantially outperform existing baselines across six diversity metrics on held-out contexts, producing populations that span rare trait combinations difficult to achieve in standard LLM outputs.

</details>


### [135] [EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories](https://arxiv.org/abs/2602.03569)
*Linjie Mu,Zhongzhen Huang,Yannian Gu,Shengqian Qin,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: 本文提出EHRWorld，一种基于因果时序范式的患者中心医疗世界模型，并构建了大规模纵向临床数据集EHRWorld-110K，显著优于仅依赖医学知识的LLM基线，在长周期临床模拟中表现更稳定、准确。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）虽在静态医疗推理任务中表现良好，但在动态模拟疾病进展和治疗结果方面存在不足，难以在连续干预下维持一致的患者状态，导致长期模拟中误差累积。

Method: 作者提出EHRWorld模型，采用因果时序训练范式，并利用从真实电子健康记录中构建的大规模纵向数据集EHRWorld-110K进行训练。

Result: 实验表明，EHRWorld在长周期临床模拟稳定性、临床敏感事件建模准确性及推理效率方面均显著优于基于LLM的基线方法。

Conclusion: 可靠的医疗世界模型需基于因果机制和时间演化的临床数据进行训练，单纯依赖医学知识的LLM难以胜任动态医疗模拟任务。

Abstract: World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.

</details>


### [136] [Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12](https://arxiv.org/abs/2602.03630)
*Iñaki del Campo,Pablo Cuervo,Victor Rodriguez-Fernandez,Roberto Armellin,Jack Yarndley*

Main category: cs.AI

TL;DR: 本文评估了当前大语言模型（LLMs）在解决高维、物理约束环境下的复杂任务（如GTOC 12小行星采矿挑战）中的自主规划能力，发现其战略理解显著提升但执行层面仍存在严重短板。


<details>
  <summary>Details</summary>
Motivation: 探究当前AI智能体在高维、物理约束环境中进行自主多阶段规划的能力边界，特别是在复杂天体力学任务中的表现。

Method: 基于MLE-Bench框架适配轨道力学领域，采用AIDE智能体架构自动生成与优化任务方案，并引入由领域专家制定评分标准的“LLM-as-a-Judge”方法，从五个结构维度评估方案的战略可行性。

Result: 过去两年主流模型（如GPT-4-Turbo、Gemini 2.5 Pro、o3等）的平均战略可行性得分从9.3提升至17.2（满分26），显示战略理解能力显著增强；但在执行层面普遍存在单位不一致、边界条件错误和调试效率低下等问题。

Conclusion: 当前LLM虽具备解决空间科学任务所需的知识与智能，但仍受限于实现障碍，更适合作为领域辅助工具而非完全自主的工程师。

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an "LLM-as-a-Judge" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.

</details>


### [137] [Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration](https://arxiv.org/abs/2602.03647)
*Bowei He,Minda Hu,Zenan Xu,Hongru Wang,Licheng Zong,Yankai Chen,Chen Ma,Xue Liu,Pluto Zhou,Irwin King*

Main category: cs.AI

TL;DR: 本文提出Search-R2框架，通过Actor-Refiner协作机制和细粒度混合奖励设计，解决搜索增强推理中多尺度信用分配问题，显著提升推理准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的搜索增强推理方法依赖稀疏的轨迹级奖励，难以区分高质量推理与偶然猜测，导致冗余或误导性搜索行为。

Method: 提出Actor-Refiner协作框架：Actor生成初始推理轨迹，Meta-Refiner通过“剪切-再生”机制选择性修复错误步骤；引入结合结果正确性与检索证据信息密度的混合奖励进行细粒度监督。

Result: 在多个通用及多跳问答数据集上，Search-R2在不同模型规模下均优于强RAG和RL基线，推理准确率更高且开销极小。

Conclusion: Search-R2通过选择性修正和细粒度奖励机制有效提升搜索增强推理性能，理论和实验均验证其优越性。

Abstract: Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.

</details>


### [138] [Mitigating Conversational Inertia in Multi-Turn Agents](https://arxiv.org/abs/2602.03664)
*Yang Wan,Zheng Cao,Zhenhao Zhang,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Linchao Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种名为“上下文偏好学习”（Context Preference Learning）的方法，通过减少大语言模型在多轮智能体交互中的“对话惯性”（conversational inertia），提升其探索能力与整体性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在作为多轮智能体使用时，会错误地将自身先前的回复当作少样本示例进行模仿，导致探索受限。作者旨在解决这一由“对话惯性”引发的模仿偏差问题。

Method: 通过注意力分析识别出对话惯性现象，并利用长上下文与短上下文生成动作之间的惯性差异构建无奖励偏好评分对，进而训练模型偏好低惯性响应；同时在推理阶段引入上下文管理策略以平衡探索与利用。

Result: 在八个智能体环境和一个深度研究场景中，所提方法有效降低了对话惯性，并带来了性能提升。

Conclusion: 将少样本学习的大语言模型转化为智能体时，需警惕上下文增长带来的对话惯性问题；通过上下文偏好学习和推理时的上下文管理，可在不依赖环境奖励的情况下改善智能体行为。

Abstract: Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational inertia, a phenomenon where models exhibit strong diagonal attention to previous responses, which is associated with imitation bias that constrains exploration. This reveals a tension when transforming few-shot LLMs into agents: longer context enriches environmental feedback for exploitation, yet also amplifies conversational inertia that undermines exploration. Our key insight is that for identical states, actions generated with longer contexts exhibit stronger inertia than those with shorter contexts, enabling construction of preference pairs without environment rewards. Based on this, we propose Context Preference Learning to calibrate model preferences to favor low-inertia responses over highinertia ones. We further provide context management strategies at inference time to balance exploration and exploitation. Experimental results across eight agentic environments and one deep research scenario validate that our framework reduces conversational inertia and achieves performance improvements.

</details>


### [139] [TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System](https://arxiv.org/abs/2602.03688)
*Wenzhe Fan,Tommaso Tognoli,Henry Peng Zou,Chunyu Miao,Yibo Wang,Xinhua Zhang*

Main category: cs.AI

TL;DR: 本文提出TodyComm，一种面向任务的动态通信算法，用于多轮多智能体系统中根据每轮动态变化自适应调整通信拓扑，以提升任务效果、保持高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统在推理阶段通常采用固定通信结构，难以应对现实中因对抗动态、任务进展或通信带宽等时变约束导致的智能体角色变化。

Method: TodyComm通过策略梯度方法，在每轮生成由行为驱动的协作拓扑，使通信结构能动态适应任务需求，从而优化任务效用。

Result: 在五个基准测试中，TodyComm在动态对抗和通信预算限制下均表现出更优的任务效果，同时保持了良好的token效率和可扩展性。

Conclusion: TodyComm有效解决了多轮多智能体系统中通信结构静态化的问题，为动态环境下的高效协作提供了可行方案。

Abstract: Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \textbf{t}ask-\textbf{o}riented \textbf{dy}namic \textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.

</details>


### [140] [AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration](https://arxiv.org/abs/2602.03786)
*Jianhao Ruan,Zhihao Xu,Yiran Peng,Fashen Ren,Zhaoyang Yu,Xinbing Liang,Jinyu Xiang,Bang Liu,Chenglin Wu,Yuyu Luo,Jiayi Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种统一的、与框架无关的智能体抽象模型（Instruction, Context, Tools, Model），并基于此构建了名为AOrchestra的智能体系统，该系统通过动态生成专用执行器，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有子智能体作为工具的范式缺乏对子智能体的动态抽象视角，限制了系统的适应性。为解决这一问题，作者旨在设计一种更灵活、可组合且减少人工干预的智能体架构。

Method: 提出一个通用的智能体抽象元组（Instruction, Context, Tools, Model），并在AOrchestra系统中由中央协调器在每一步动态实例化该元组：筛选任务相关上下文、选择工具与模型，并通过即时自动创建智能体来委派执行任务。

Result: 在GAIA、SWE-Bench和Terminal-Bench三个具有挑战性的基准上，AOrchestra搭配Gemini-3-Flash模型相比最强基线实现了16.28%的相对性能提升。

Conclusion: 所提出的抽象方法不仅减少了人工工程投入，还支持即插即用的多样化智能体集成，并能在性能与成本之间实现可控权衡，逼近帕累托最优。

Abstract: Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra

</details>


### [141] [Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity](https://arxiv.org/abs/2602.03794)
*Yingxuan Yang,Chengrui Qu,Muning Wen,Laixi Shi,Ying Wen,Weinan Zhang,Adam Wierman,Shangding Gu*

Main category: cs.AI

TL;DR: 本文研究基于大语言模型（LLM）的多智能体系统（MAS）中的扩展性问题，发现同质智能体数量增加带来的收益递减，而引入异质性（如不同模型、提示或工具）能显著提升性能。作者提出一个信息论框架，指出系统性能受限于任务固有不确定性而非智能体数量，并引入有效信道数 $K^*$ 来量化多样性贡献。实验证明，2个异质智能体可媲美甚至超越16个同质智能体。


<details>
  <summary>Details</summary>
Motivation: 探索为何在LLM多智能体系统中单纯增加同质智能体数量效果有限，而引入异质性却能持续提升性能，旨在揭示限制扩展性的根本原因并提供高效设计原则。

Method: 提出一个与架构无关的信息论框架，推导出MAS性能上限由任务内在不确定性决定；定义有效信道数 $K^*$ 以无监督方式衡量系统多样性带来的信息增益；通过实验比较同质与异质智能体配置的性能差异。

Result: 实验表明，异质智能体配置显著优于同质扩展：仅2个多样化的智能体即可达到或超过16个同质智能体的性能；$K^*$ 能有效预测系统表现。

Conclusion: 多智能体系统的性能提升关键在于多样性而非数量，应通过异质性设计提高有效信息通道数量，从而构建更高效、鲁棒的MAS。

Abstract: LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.

</details>


### [142] [Conformal Thinking: Risk Control for Reasoning on a Compute Budget](https://arxiv.org/abs/2602.03814)
*Xi Wang,Anushri Suresh,Alvin Zhang,Rishi More,William Jurayj,Benjamin Van Durme,Mehrdad Farajtabar,Daniel Khashabi,Eric Nalisnick*

Main category: cs.AI

TL;DR: 本文提出一种基于风险控制的自适应推理框架，通过上下阈值动态停止大语言模型的推理过程，在满足用户指定错误率的前提下提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型推理中，如何在有限的token预算下平衡准确率与计算开销是一个关键挑战。现有方法缺乏对错误风险的有效控制，难以在保证可靠性的同时实现高效推理。

Method: 作者将token预算设置问题重构为风险控制问题，引入上阈值（模型自信时提前停止）和新的参数化下阈值（预判无法求解时提前终止），并利用无分布假设的风险控制方法，基于验证集和目标风险最优设定停止机制。对于多准则场景，还引入效率损失以选择最高效的退出机制。

Result: 在多种推理任务和模型上的实验表明，该方法能在满足用户指定风险目标的同时，通过下阈值和集成停止机制显著提升计算效率。

Conclusion: 所提出的基于风险控制的自适应推理框架有效解决了大语言模型推理中的计算-风险权衡问题，兼顾了准确性与效率。

Abstract: Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.

</details>


### [143] [AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations](https://arxiv.org/abs/2602.03828)
*Minjun Zhu,Zhen Lin,Yixuan Weng,Panzhong Lu,Qiujie Xie,Yifan Wei,Sifan Liu,Qiyao Sun,Yue Zhang*

Main category: cs.AI

TL;DR: 本文提出了FigureBench（首个大规模科学插图生成基准）和AutoFigure（首个基于长文本自动生成高质量科学插图的智能体框架），实验表明AutoFigure优于现有方法，可生成可直接用于发表的插图。


<details>
  <summary>Details</summary>
Motivation: 高质量科学插图对传达复杂科技概念至关重要，但人工绘制耗时费力，成为学术界和工业界的瓶颈，因此亟需自动化解决方案。

Method: 构建包含3300对高质量科学文本-插图的数据集FigureBench，并提出AutoFigure框架，该框架在生成最终插图前进行深度思考、元素重组与验证，以确保结构完整性和美学质量。

Result: 在FigureBench上的大量实验表明，AutoFigure在各项指标上均显著优于基线方法，能够生成达到出版标准的科学插图。

Conclusion: FigureBench为科学插图生成提供了重要基准，而AutoFigure展示了自动化生成高质量科学插图的可行性与优越性，推动了该领域的研究与应用。

Abstract: High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [144] [An Improved Quasi-Physical Dynamic Algorithm for Efficient Circular Coverage in Arbitrary Convex](https://arxiv.org/abs/2602.02570)
*Zeping Yi,Yongjun Wang,Baoshan Wang,Songyi Liu*

Main category: cs.CG

TL;DR: 本文提出了一种改进的准物理动态（IQPD）算法，用于在任意凸多边形中高效覆盖圆形，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 最优圆覆盖问题在复杂多边形中因NP难特性而计算困难，现有方法在不规则区域中存在初始化差、边界处理不佳和重叠过多等问题，导致覆盖效率低下。

Method: 提出IQPD算法，包含：(1) 基于六方密堆积的结构保持初始化策略；(2) 引入摩擦力和半径扩展优化的虚拟力场模型；(3) 基于法向与切向梯度的边界环绕策略以回收溢出圆。

Result: 在多种凸多边形上，该算法在七个指标上显著优于四种前沿方法。

Conclusion: 所提方法为实际应用中的操作优化与资源分配提供了更高效的圆覆盖解决方案。

Abstract: The optimal circle coverage problem aims to find a configuration of circles that maximizes the covered area within a given region. Although theoretical optimal solutions exist for simple cases, the problem's NP-hard characteristic makes the problem computationally intractable for complex polygons with numerous circles. Prevailing methods are largely confined to regular domains, while the few algorithms designed for irregular polygons suffer from poor initialization, unmanaged boundary effects, and excessive overlap among circles, resulting in low coverage efficiency. Consequently, we propose an Improved Quasi-Physical Dynamic(IQPD) algorithm for arbitrary convex polygons. Our core contributions are threefold: (1) proposing a structure-preserving initialization strategy that maps a hexagonal close-packing of circles into the target polygon via scaling and affine transformation; (2) constructing a virtual force field incorporating friction and a radius-expansion optimization iteration model; (3) designing a boundary-surrounding strategy based on normal and tangential gradients to retrieve overflowing circles. Experimental results demonstrate that our algorithm significantly outperforms four state-of-the-art methods on seven metrics across a variety of convex polygons. This work could provide a more efficient solution for operational optimization or resource allocation in practical applications.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [145] [Exploring Silicon-Based Societies: An Early Study of the Moltbook Agent Community](https://arxiv.org/abs/2602.02613)
*Yu-Zheng Lin,Bono Po-Jen Shih,Hsuan-Ying Alessandra Chien,Shalaka Satam,Jesus Horacio Pacheco,Sicong Shao,Soheil Salehi,Pratik Satam*

Main category: cs.MA

TL;DR: 本文提出“数据驱动的硅基社会学”框架，通过大规模挖掘真实自主智能体社交平台Moltbook的数据，揭示了智能体在无预设分类下自发形成的社会结构模式。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如个案观察或小规模模拟）无法充分理解大规模自主语言模型智能体生态系统的集体行为，亟需系统性实证研究框架。

Method: 对Moltbook平台中12,758个由智能体创建的子社区描述进行非侵入式数据采集，采用文本预处理、上下文嵌入和无监督聚类等技术分析其主题组织与社会空间结构。

Result: 发现智能体通过可复现的模式组织集体空间，涵盖模仿人类兴趣、硅基自我反思以及早期经济与协作行为三类主题，且这些结构直接从机器生成数据中涌现。

Conclusion: 本研究为硅基社会学奠定了方法论基础，证明数据挖掘能有效揭示大规模自主智能体社会的组织与演化规律。

Abstract: The rapid emergence of autonomous large language model agents has given rise to persistent, large-scale agent ecosystems whose collective behavior cannot be adequately understood through anecdotal observation or small-scale simulation. This paper introduces data-driven silicon sociology as a systematic empirical framework for studying social structure formation among interacting artificial agents. We present a pioneering large-scale data mining investigation of an in-the-wild agent society by analyzing Moltbook, a social platform designed primarily for agent-to-agent interaction. At the time of study, Moltbook hosted over 150,000 registered autonomous agents operating across thousands of agent-created sub-communities. Using programmatic and non-intrusive data acquisition, we collected and analyzed the textual descriptions of 12,758 submolts, which represent proactive sub-community partitioning activities within the ecosystem. Treating agent-authored descriptions as first-class observational artifacts, we apply rigorous preprocessing, contextual embedding, and unsupervised clustering techniques to uncover latent patterns of thematic organization and social space structuring. The results show that autonomous agents systematically organize collective space through reproducible patterns spanning human-mimetic interests, silicon-centric self-reflection, and early-stage economic and coordination behaviors. Rather than relying on predefined sociological taxonomies, these structures emerge directly from machine-generated data traces. This work establishes a methodological foundation for data-driven silicon sociology and demonstrates that data mining techniques can provide a powerful lens for understanding the organization and evolution of large autonomous agent societies.

</details>


### [146] [Scaling Small Agents Through Strategy Auctions](https://arxiv.org/abs/2602.02751)
*Lisa Alazraki,William F. Shen,Yoram Bachrach,Akhil Mathur*

Main category: cs.MA

TL;DR: 本文提出了一种名为SALE（Strategy Auctions for Workload Efficiency）的新型智能体框架，通过受自由职业市场启发的策略竞拍机制，在复杂任务中有效协调大小语言模型，显著降低成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型虽成本低，但在复杂任务中性能难以扩展；现有路由方法在智能体工作流中效果不佳。因此，需要一种新机制来有效利用小型智能体处理长周期、高复杂度任务，同时减少对大型模型的依赖。

Method: 提出SALE框架：智能体提交简短策略方案参与“竞拍”，由系统化的成本-价值机制评分，并通过共享的“拍卖记忆”进行优化，实现按任务动态路由和无需额外训练的持续自我改进。

Result: 在深度搜索和编程任务中，SALE将对最大模型的依赖降低53%，总成本降低35%，且性能优于最大模型的pass@1，仅带来可忽略的额外开销；而基于任务描述的传统路由方法要么性能不足，要么无法降低成本。

Conclusion: 小型智能体虽难以独立应对复杂任务，但可通过类似市场的协调机制（如SALE）实现“规模化”；这表明智能体AI的未来增益应更多来自异构智能体的高效协同，而非单纯增大单个模型规模。

Abstract: Small language models are increasingly viewed as a promising, cost-effective approach to agentic AI, with proponents claiming they are sufficiently capable for agentic workflows. However, while smaller agents can closely match larger ones on simple tasks, it remains unclear how their performance scales with task complexity, when large models become necessary, and how to better leverage small agents for long-horizon workloads. In this work, we empirically show that small agents' performance fails to scale with task complexity on deep search and coding tasks, and we introduce Strategy Auctions for Workload Efficiency (SALE), an agent framework inspired by freelancer marketplaces. In SALE, agents bid with short strategic plans, which are scored by a systematic cost-value mechanism and refined via a shared auction memory, enabling per-task routing and continual self-improvement without training a separate router or running all models to completion. Across deep search and coding tasks of varying complexity, SALE reduces reliance on the largest agent by 53%, lowers overall cost by 35%, and consistently improves upon the largest agent's pass@1 with only a negligible overhead beyond executing the final trace. In contrast, established routers that rely on task descriptions either underperform the largest agent or fail to reduce cost -- often both -- underscoring their poor fit for agentic workflows. These results suggest that while small agents may be insufficient for complex workloads, they can be effectively "scaled up" through coordinated task allocation and test-time self-improvement. More broadly, they motivate a systems-level view of agentic AI in which performance gains come less from ever-larger individual models and more from market-inspired coordination mechanisms that organize heterogeneous agents into efficient, adaptive ecosystems.

</details>


### [147] [Game-Theoretic and Algorithmic Analyses of Multi-Agent Routing under Crossing Costs](https://arxiv.org/abs/2602.03455)
*Tesshu Hanaka,Nikolaos Melissinos,Hirotaka Ono*

Main category: cs.MA

TL;DR: 本文提出了一种新的多智能体路径规划模型——“交叉代价模型”，将冲突视为可量化的代价而非硬性约束，适用于异步去中心化环境，并在博弈论与参数化算法两个层面进行了理论分析。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体路径规划（如MAPF）依赖集中控制和同步避碰，难以适应异步、去中心化的实际场景。作者旨在构建一个更贴近现实的模型，允许通过代价函数衡量冲突风险，从而支持灵活且可扩展的协调机制。

Method: 作者将问题建模为具有非标准代价函数的拥塞博弈，分析纯策略纳什均衡的存在性及收敛动力学；同时从优化角度研究总交叉代价最小化问题的计算复杂性，并设计基于图结构、智能体数量等参数的参数化算法。

Result: 证明了在温和条件下可在多项式时间内找到纳什均衡，但一般情形下该问题是PLS-完全的；总交叉代价最小化是NP-难的；针对不同参数（如有向边数、无向边数、智能体数、图结构参数），提出了XP或FPT算法。

Conclusion: 该工作为去中心化多智能体路径规划提供了新理论框架，结合博弈均衡分析与参数化复杂性理论，为高风险感知、可扩展的协调系统奠定基础。

Abstract: Coordinating the movement of multiple autonomous agents over a shared network is a fundamental challenge in algorithmic robotics, intelligent transportation, and distributed systems. The dominant approach, Multi-Agent Path Finding, relies on centralized control and synchronous collision avoidance, which often requires strict synchronization and guarantees of globally conflict-free execution. This paper introduces the Multi-Agent Routing under Crossing Cost model on mixed graphs, a novel framework tailored to asynchronous settings. In our model, instead of treating conflicts as hard constraints, each agent is assigned a path, and the system is evaluated through a cost function that measures potential head-on encounters. This ``crossing cost'', which is defined as the product of the numbers of agents traversing an edge in opposite directions, quantifies the risk of congestion and delay in decentralized execution.
  Our contributions are both game-theoretic and algorithmic. We model the setting as a congestion game with a non-standard cost function, prove the existence of pure Nash equilibria, and analyze the dynamics leading to them. Equilibria can be found in polynomial time under mild conditions, while the general case is PLS-complete. From an optimization perspective, minimizing the total crossing cost is NP-hard, as the problem generalizes Steiner Orientation. To address this hardness barrier, we design a suite of parameterized algorithms for minimizing crossing cost, with parameters including the number of arcs, edges, agents, and structural graph measures. These yield XP or FPT results depending on the parameter, offering algorithmic strategies for structurally restricted instances. Our framework provides a new theoretical foundation for decentralized multi-agent routing, bridging equilibrium analysis and parameterized complexity to support scalable and risk-aware coordination.

</details>


### [148] [When Should Agents Coordinate in Differentiable Sequential Decision Problems?](https://arxiv.org/abs/2602.03674)
*Caleb Probine,Su Ann Low,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.MA

TL;DR: 本文研究了在可微分运动规划问题中多机器人团队协调的价值，提出协调程度可视为从完全联合优化到纳什均衡的连续谱，并通过目标函数的二阶性质判断何时需要协调。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在缺乏协调时性能下降，但协调又常需昂贵通信开销。因此，有必要理解在哪些情况下协调是值得的，以平衡性能与通信成本。

Method: 将协调建模为一个连续谱，一端是联合优化团队目标，另一端是个体在纳什均衡下的独立决策；利用目标函数的二阶性质设计算法，判断何时应进行协调。

Result: 证明了在可微分运动规划问题中，协调需求可通过目标函数的二阶特性进行分析，并提出了相应算法来动态决定协调时机。

Conclusion: 协调的价值取决于目标函数的二阶结构，通过分析这些特性可在保证性能的同时减少不必要的通信开销。

Abstract: Multi-robot teams must coordinate to operate effectively. When a team operates in an uncoordinated manner, and agents choose actions that are only individually optimal, the team's outcome can suffer. However, in many domains, coordination requires costly communication. We explore the value of coordination in a broad class of differentiable motion-planning problems. In particular, we model coordinated behavior as a spectrum: at one extreme, agents jointly optimize a common team objective, and at the other, agents make unilaterally optimal decisions given their individual decision variables, i.e., they operate at Nash equilibria. We then demonstrate that reasoning about coordination in differentiable motion-planning problems reduces to reasoning about the second-order properties of agents' objectives, and we provide algorithms that use this second-order reasoning to determine at which times a team of agents should coordinate.

</details>
