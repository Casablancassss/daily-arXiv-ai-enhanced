<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 51]
- [cs.AI](#cs.AI) [Total: 46]
- [cs.MA](#cs.MA) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LCF3D: A Robust and Real-Time Late-Cascade Fusion Framework for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2601.09812)
*Carlo Sgaravatti,Riccardo Pieroni,Matteo Corno,Sergio M. Savaresi,Luca Magri,Giacomo Boracchi*

Main category: cs.CV

TL;DR: 本文提出LCF3D，一种新型多模态融合框架，通过结合RGB图像的2D检测与LiDAR点云的3D检测，提升自动驾驶中对行人、骑行者等目标的3D定位精度，并在不同传感器配置下展现出良好的域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，准确地进行3D目标定位至关重要。尽管使用RGB相机和LiDAR传感器可提升检测性能，但如何有效融合这两种模态的数据仍具挑战性，尤其在处理LiDAR检测中的误检和漏检问题方面。

Method: LCF3D采用两种融合策略：(i) 后期融合，通过将LiDAR的3D检测结果与RGB的2D检测结果匹配，剔除未匹配的LiDAR误检；(ii) 级联融合，利用未匹配的RGB检测生成新的3D视锥建议，以恢复LiDAR漏检的目标。

Result: 在KITTI和nuScenes数据集上，LCF3D显著优于纯LiDAR方法，尤其在行人、骑行者、摩托车和自行车等难检测类别上表现突出，并在训练与测试传感器配置不一致时仍保持良好性能。

Conclusion: LCF3D通过有效的多模态融合机制，不仅提升了3D目标检测的准确性，还增强了模型在不同传感器配置下的域泛化能力，为自动驾驶感知系统提供了实用解决方案。

Abstract: Accurately localizing 3D objects like pedestrians, cyclists, and other vehicles is essential in Autonomous Driving. To ensure high detection performance, Autonomous Vehicles complement RGB cameras with LiDAR sensors, but effectively combining these data sources for 3D object detection remains challenging. We propose LCF3D, a novel sensor fusion framework that combines a 2D object detector on RGB images with a 3D object detector on LiDAR point clouds. By leveraging multimodal fusion principles, we compensate for inaccuracies in the LiDAR object detection network. Our solution combines two key principles: (i) late fusion, to reduce LiDAR False Positives by matching LiDAR 3D detections with RGB 2D detections and filtering out unmatched LiDAR detections; and (ii) cascade fusion, to recover missed objects from LiDAR by generating new 3D frustum proposals corresponding to unmatched RGB detections. Experiments show that LCF3D is beneficial for domain generalization, as it turns out to be successful in handling different sensor configurations between training and testing domains. LCF3D achieves significant improvements over LiDAR-based methods, particularly for challenging categories like pedestrians and cyclists in the KITTI dataset, as well as motorcycles and bicycles in nuScenes. Code can be downloaded from: https://github.com/CarloSgaravatti/LCF3D.

</details>


### [2] [ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning](https://arxiv.org/abs/2601.09851)
*Po-han Li,Shenghui Chen,Ufuk Topcu,Sandeep Chinchali*

Main category: cs.CV

TL;DR: 该论文提出了一种名为ViSIL的新指标，用于评估多模态视频摘要（如关键帧与文本）的信息覆盖程度，通过衡量未被摘要捕获的视频信息量，实现跨模态格式的统一比较，并在视频问答任务中展现出与人类和视觉语言模型性能显著相关的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（如BLEU、ROUGE）无法有效衡量多模态视频摘要（包含关键帧和文本）在不同模态间的信息覆盖情况，缺乏对结构差异大的摘要形式进行统一评估的能力。

Method: 提出Video Summary Information Loss (ViSIL)评分，基于信息论框架，利用视觉语言模型（VLM）推理来量化视频摘要未能捕捉的视频信息量，从而实现对不同多模态摘要格式的统一评估。

Result: ViSIL评分与人类及VLM在视频问答（VQA）任务中的表现具有统计显著相关性；利用ViSIL可优化信息损失与处理速度之间的权衡，在不增加计算负载的情况下，使VQA准确率比纯文本摘要提升7%。

Conclusion: ViSIL为多模态视频摘要提供了一种有效的统一评估方法，不仅更贴合语义信息覆盖的实际需求，还能指导高效摘要生成，在保持处理效率的同时提升下游任务性能。

Abstract: Multimodal video captioning condenses dense footage into a structured format of keyframes and natural language. By creating a cohesive multimodal summary, this approach anchors generative AI in rich semantic evidence and serves as a lightweight proxy for high-efficiency retrieval. However, traditional metrics like BLEU or ROUGE fail to quantify information coverage across disparate modalities, such as comparing a paragraph of text to a sequence of keyframes. To address this, we propose the Video Summary Information Loss (ViSIL) score, an information-theoretic framework that quantifies the video information not captured by a summary via vision-language model (VLM) inference. By measuring the information loss, ViSIL is a unified metric that enables direct comparison across multimodal summary formats despite their structural discrepancies. Our results demonstrate that ViSIL scores show a statistically significant correlation with both human and VLM performance on Video Question Answering (VQA) tasks. ViSIL also enables summary selection to optimize the trade-off between information loss and processing speed, establishing a Pareto-optimal frontier that outperforms text summaries by $7\%$ in VQA accuracy without increasing processing load.

</details>


### [3] [Breaking the Limits of Open-Weight CLIP: An Optimization Framework for Self-supervised Fine-tuning of CLIP](https://arxiv.org/abs/2601.09859)
*Anant Mehta,Xiyuan Wei,Xingyu Chen,Tianbao Yang*

Main category: cs.CV

TL;DR: 本文提出TuneCLIP，一种自监督微调框架，可在不重新训练的情况下提升开源CLIP模型在多种下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 改进开源CLIP模型通常需从头训练数十亿样本，成本高昂；作者探索是否能仅用现有自监督数据集有效提升其通用性能。

Method: TuneCLIP包含两个关键阶段：(1) 通过恢复优化统计量的预热阶段以减少冷启动偏差；(2) 采用新对比损失进行微调，缓解对假负样本对的惩罚。

Result: 在多种模型架构和规模上一致提升性能，例如SigLIP (ViT-B/16) 在ImageNet及分布外基准上提升最高达+2.5%，在DataComp上提升+1.2%。

Conclusion: TuneCLIP为高效地对预训练CLIP模型进行后训练适应提供了新基线，显著提升其通用下游任务表现。

Abstract: CLIP has become a cornerstone of multimodal representation learning, yet improving its performance typically requires a prohibitively costly process of training from scratch on billions of samples. We ask a different question: Can we improve the performance of open-weight CLIP models across various downstream tasks using only existing self-supervised datasets? Unlike supervised fine-tuning, which adapts a pretrained model to a single downstream task, our setting seeks to improve general performance across various tasks. However, as both our experiments and prior studies reveal, simply applying standard training protocols starting from an open-weight CLIP model often fails, leading to performance degradation. In this paper, we introduce TuneCLIP, a self-supervised fine-tuning framework that overcomes the performance degradation. TuneCLIP has two key components: (1) a warm-up stage of recovering optimization statistics to reduce cold-start bias, inspired by theoretical analysis, and (2) a fine-tuning stage of optimizing a new contrastive loss to mitigate the penalization on false negative pairs. Our extensive experiments show that TuneCLIP consistently improves performance across model architectures and scales. Notably, it elevates leading open-weight models like SigLIP (ViT-B/16), achieving gains of up to +2.5% on ImageNet and related out-of-distribution benchmarks, and +1.2% on the highly competitive DataComp benchmark, setting a new strong baseline for efficient post-pretraining adaptation.

</details>


### [4] [VibrantSR: Sub-Meter Canopy Height Models from Sentinel-2 Using Generative Flow Matching](https://arxiv.org/abs/2601.09866)
*Kiarie Ndegwa,Andreas Gros,Tony Chang,David Diaz,Vincent A. Landau,Nathan E. Rutenbeck,Luke J. Zachmann,Guy Bayes,Scott Conway*

Main category: cs.CV

TL;DR: VibrantSR 是一种基于 Sentinel-2 影像的生成式超分辨率框架，可从10米分辨率影像估算出0.5米冠层高度模型（CHM），在西部美国22个生态区验证中表现优于多个卫星基准方法，虽略逊于航拍方法，但具备大范围、低成本、高频次监测优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于航拍影像的冠层高度估算方法受限于获取频率低和覆盖不连续，难以支持大尺度、高频次的森林监测与碳核算。因此，亟需一种利用广泛可用、周期性强的卫星数据进行高精度冠层高度建模的方法。

Method: 提出 VibrantSR 框架，利用全球可获取的 Sentinel-2 季节性合成影像，通过生成式超分辨率技术将10米分辨率影像提升至0.5米冠层高度模型。

Result: 在西部美国22个EPA三级生态区上，使用空间分离的验证集评估，VibrantSR 对高度≥2米的冠层实现了4.39米的平均绝对误差（MAE），优于 Meta（4.83 m）、LANDFIRE（5.96 m）和 ETH（7.05 m）等卫星基准方法；尽管精度略低于航拍方法 VibrantVS（2.71 m MAE），但具备运行化潜力。

Conclusion: VibrantSR 在不依赖昂贵且稀疏的航拍数据前提下，实现了大陆尺度森林冠层高度的高效、一致监测，为大范围碳核算和生态管理提供了可行方案。

Abstract: We present VibrantSR (Vibrant Super-Resolution), a generative super-resolution framework for estimating 0.5 meter canopy height models (CHMs) from 10 meter Sentinel-2 imagery. Unlike approaches based on aerial imagery that are constrained by infrequent and irregular acquisition schedules, VibrantSR leverages globally available Sentinel-2 seasonal composites, enabling consistent monitoring at a seasonal-to-annual cadence. Evaluated across 22 EPA Level 3 eco-regions in the western United States using spatially disjoint validation splits, VibrantSR achieves a Mean Absolute Error of 4.39 meters for canopy heights >= 2 m, outperforming Meta (4.83 m), LANDFIRE (5.96 m), and ETH (7.05 m) satellite-based benchmarks. While aerial-based VibrantVS (2.71 m MAE) retains an accuracy advantage, VibrantSR enables operational forest monitoring and carbon accounting at continental scales without reliance on costly and temporally infrequent aerial acquisitions.

</details>


### [5] [MedVL-SAM2: A unified 3D medical vision-language model for multimodal reasoning and prompt-driven segmentation](https://arxiv.org/abs/2601.09879)
*Yang Xing,Jiong Wu,Savas Ozdemir,Ying Zhang,Yang Yang,Wei Shao,Kuang Gong*

Main category: cs.CV

TL;DR: 本文提出了MedVL-SAM2，一个统一的3D医学多模态模型，同时支持报告生成、视觉问答（VQA）和多种分割任务（语义、指代和交互式），通过结合图像级推理与像素级感知，在3D医学影像中实现细粒度视觉定位与空间推理。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在图像级文本任务上表现良好，但在3D医学影像中实现细粒度视觉定位和体素级空间推理仍具挑战，尤其缺乏能统一这些能力的通用框架。

Method: MedVL-SAM2采用统一架构，整合图像级推理与像素级感知，基于SAM2构建体素分割模块；模型首先在大规模3D CT图像-文本对上预训练以对齐视觉与语言特征，随后在包含语言理解和分割目标的3D CT分割数据集上联合优化，支持语言、点或框提示的灵活交互。

Result: 该模型在报告生成、VQA和多种3D分割任务上均达到SOTA性能，实验证明其具备可靠的3D视觉定位、可控的交互式分割和鲁棒的跨模态推理能力。

Conclusion: MedVL-SAM2成功在一个统一的3D医学视觉语言模型中同时实现了高层语义推理与精确的3D空间定位，为多任务医学多模态理解提供了有效框架。

Abstract: Recent progress in medical vision-language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging, particularly when aiming to unify these capabilities within a single, generalizable framework. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that concurrently supports report generation, VQA, and multi-paradigm segmentation, including semantic, referring, and interactive segmentation. MedVL-SAM2 integrates image-level reasoning and pixel-level perception through a cohesive architecture tailored for 3D medical imaging, and incorporates a SAM2-based volumetric segmentation module to enable precise multi-granular spatial reasoning. The model is trained in a multi-stage pipeline: it is first pre-trained on a large-scale corpus of 3D CT image-text pairs to align volumetric visual features with radiology-language embeddings. It is then jointly optimized with both language-understanding and segmentation objectives using a comprehensive 3D CT segmentation dataset. This joint training enables flexible interaction via language, point, or box prompts, thereby unifying high-level visual reasoning with spatially precise localization. Our unified architecture delivers state-of-the-art performance across report generation, VQA, and multiple 3D segmentation tasks. Extensive analyses further show that the model provides reliable 3D visual grounding, controllable interactive segmentation, and robust cross-modal reasoning, demonstrating that high-level semantic reasoning and precise 3D localization can be jointly achieved within a unified 3D medical VLM.

</details>


### [6] [OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport](https://arxiv.org/abs/2601.09952)
*Zhihua Zhao,Guoqiang Li,Chen Min,Kangping Lu*

Main category: cs.CV

TL;DR: 本文提出OT-Drive，一种基于最优传输的多模态融合框架，用于提升自动驾驶在分布外（OOD）场景下的可通行区域分割性能。通过引入场景锚点生成器（SAG）和基于最优传输的融合模块（OT Fusion），该方法在ORFD OOD场景中达到95.16% mIoU，在跨数据集任务中达到89.79% mIoU，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在分布外（OOD）场景下分割性能下降，影响自动驾驶系统的下游任务，亟需提升模型在未见环境中的泛化能力。

Method: 提出OT-Drive框架，将RGB与表面法线融合建模为分布传输问题；设计场景锚点生成器（SAG）构建语义锚点，并通过基于最优传输的多模态融合模块（OT Fusion）将特征映射到语义锚点所定义的流形上。

Result: 在ORFD OOD场景中达到95.16% mIoU，比先前方法高6.35%；在跨数据集迁移任务中达到89.79% mIoU，优于基线13.99%。

Conclusion: 所提方法仅需有限训练数据即可实现强分布外泛化能力，显著提升实际部署的实用性与效率。

Abstract: Reliable traversable area segmentation in unstructured environments is critical for planning and decision-making in autonomous driving. However, existing data-driven approaches often suffer from degraded segmentation performance in out-of-distribution (OOD) scenarios, consequently impairing downstream driving tasks. To address this issue, we propose OT-Drive, an Optimal Transport--driven multi-modal fusion framework. The proposed method formulates RGB and surface normal fusion as a distribution transport problem. Specifically, we design a novel Scene Anchor Generator (SAG) to decompose scene information into the joint distribution of weather, time-of-day, and road type, thereby constructing semantic anchors that can generalize to unseen scenarios. Subsequently, we design an innovative Optimal Transport-based multi-modal fusion module (OT Fusion) to transport RGB and surface normal features onto the manifold defined by the semantic anchors, enabling robust traversable area segmentation under OOD scenarios. Experimental results demonstrate that our method achieves 95.16% mIoU on ORFD OOD scenarios, outperforming prior methods by 6.35%, and 89.79% mIoU on cross-dataset transfer tasks, surpassing baselines by 13.99%.These results indicate that the proposed model can attain strong OOD generalization with only limited training data, substantially enhancing its practicality and efficiency for real-world deployment.

</details>


### [7] [The Spatial Blindspot of Vision-Language Models](https://arxiv.org/abs/2601.09954)
*Nahid Alam,Leema Krishna Murali,Siddhant Bharadwaj,Patrick Liu,Timothy Chung,Drishti Sharma,Akshata A,Kranthi Kiran,Wesley Tam,Bala Krishna S Vegesna*

Main category: cs.CV

TL;DR: 当前视觉语言模型（VLMs）因采用类似CLIP的图像编码器，在预训练过程中将图像展平为一维序列，忽略了二维空间结构，导致空间关系理解能力不足。本文通过引入替代训练目标的图像编码器和二维位置编码，显著提升了模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在处理空间关系方面存在缺陷，主要源于其图像编码器在预训练时丢弃了图像的二维结构信息，限制了其在需要空间定位能力的任务（如机器人和具身智能）中的应用。

Method: 研究采用两种策略：(i) 使用替代目标训练的图像编码器；(ii) 引入二维位置编码，以保留并利用图像的二维空间结构。

Result: 实验表明，所提出的架构改进在多个空间推理基准上取得了性能提升。

Conclusion: 在VLM设计中显式建模二维空间结构是提升空间推理能力的关键，该研究为未来面向空间感知任务的模型设计提供了有效方向。

Abstract: Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial grounding, such as robotics and embodied AI. To address this, we investigate (i) image encoders trained with alternative objectives and (ii) 2D positional encodings. Our experiments show that these architectural choices can lead to improved spatial reasoning on several benchmarks.

</details>


### [8] [DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models](https://arxiv.org/abs/2601.09981)
*Yulin He,Wei Chen,Zhikang Jian,Tianhang Guo,Wenjuan Zhou,Minglong Li*

Main category: cs.CV

TL;DR: 本文提出DR²Seg，一种无需额外监督的自奖励框架，通过两阶段策略提升视觉语言推理分割任务中的推理效率与分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂文本查询时容易产生冗余推理链，干扰多模态大语言模型中的目标定位，影响推理效率和分割准确性。

Method: DR²Seg采用两阶段rollout策略：第一阶段生成自包含的目标描述，第二阶段用该描述替代原始复杂查询以验证其完整性，并引入两个自奖励机制以强化目标导向推理并抑制冗余思考。

Result: 在不同规模的多模态大语言模型和分割模型上进行的大量实验表明，DR²Seg在推理效率和分割性能方面均取得一致提升。

Conclusion: DR²Seg有效解决了推理分割中的“过度思考”问题，在不依赖额外监督的情况下显著提升了模型表现。

Abstract: Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking supervision. DR$^2$Seg employs a two-stage rollout strategy that decomposes reasoning segmentation into multimodal reasoning and referring segmentation. In the first stage, the model generates a self-contained description that explicitly specifies the target object. In the second stage, this description replaces the original complex query to verify its self-containment. Based on this design, two self-rewards are introduced to strengthen goal-oriented reasoning and suppress redundant thinking. Extensive experiments across MLLMs of varying scales and segmentation models demonstrate that DR$^2$Seg consistently improves reasoning efficiency and overall segmentation performance.

</details>


### [9] [VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models](https://arxiv.org/abs/2601.10010)
*Zefan Zhang,Kehua Zhu,Shijie Jiang,Hongyuan Lu,Shengkai Sun,Tian Bai*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频大语言模型（VideoLLM）事件关系幻觉评测基准VERHallu，涵盖因果、时序和子事件关系，并设计了三种任务进行评估；研究发现现有模型在密集事件关系推理上表现不佳，常依赖先验知识而忽略帧级线索，为此提出关键帧传播（KFP）策略以提升多事件理解能力，有效缓解事件关系幻觉且不影响推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前对VideoLLM幻觉的研究主要集中在事件、物体和场景的存在性上，忽视了事件间关系的幻觉问题。为全面评估模型在因果、时序和子事件关系上的理解能力，并揭示其在反直觉视频场景中的偏差，作者构建了新的评测基准VERHallu。

Method: 构建包含关系分类、问答和反事实问答三类任务的VERHallu基准，引入反直觉视频场景及人工标注的视觉-语言与纯语言偏见候选；提出关键帧传播（KFP）策略，在中间层重新分配帧级注意力以增强多事件关系理解。

Result: 实验表明，当前最先进的VideoLLMs在密集事件关系推理中表现不足，常因未充分利用帧级线索而依赖先验知识；所提出的KFP策略能有效缓解事件关系幻觉，且不降低推理速度。

Conclusion: VideoLLMs在事件关系理解方面存在显著缺陷，尤其在处理复杂或反直觉场景时易产生幻觉；通过优化帧级注意力机制（如KFP策略）可有效提升其对多事件关系的建模能力，为未来视频理解模型的可靠性改进提供方向。

Abstract: Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed.

</details>


### [10] [Disentangled Concept Representation for Text-to-image Person Re-identification](https://arxiv.org/abs/2601.10053)
*Giyeol Kim,Chanho Eom*

Main category: cs.CV

TL;DR: 本文提出DiCo框架，通过解耦概念表示实现文本到图像行人重识别中的细粒度跨模态对齐，提升检索性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像行人重识别（TIReID）面临视觉与文本模态间巨大差异及需建模细粒度属性对应关系的挑战，如相似衣物颜色、纹理或风格的区分。

Method: 提出DiCo（Disentangled Concept Representation）框架，采用基于槽（slot-based）的共享表示，每个槽作为跨模态的部分级锚点，并进一步分解为多个概念块，以解耦互补属性（如颜色、纹理、形状），同时保持图像与文本在部分级别的一致对应。

Result: 在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上的实验表明，该方法在性能上达到当前先进水平，并通过显式的槽与块级表示增强了模型的可解释性。

Conclusion: DiCo框架有效解决了TIReID中的模态鸿沟与细粒度对齐问题，在提升检索准确率的同时提供了更可解释的中间表示。

Abstract: Text-to-image person re-identification (TIReID) aims to retrieve person images from a large gallery given free-form textual descriptions. TIReID is challenging due to the substantial modality gap between visual appearances and textual expressions, as well as the need to model fine-grained correspondences that distinguish individuals with similar attributes such as clothing color, texture, or outfit style. To address these issues, we propose DiCo (Disentangled Concept Representation), a novel framework that achieves hierarchical and disentangled cross-modal alignment. DiCo introduces a shared slot-based representation, where each slot acts as a part-level anchor across modalities and is further decomposed into multiple concept blocks. This design enables the disentanglement of complementary attributes (\textit{e.g.}, color, texture, shape) while maintaining consistent part-level correspondence between image and text. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that our framework achieves competitive performance with state-of-the-art methods, while also enhancing interpretability through explicit slot- and block-level representations for more fine-grained retrieval results.

</details>


### [11] [UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow](https://arxiv.org/abs/2601.10054)
*Nick Truong,Pritam P. Karmokar,William J. Beksi*

Main category: cs.CV

TL;DR: 本文提出了首个基于物理渲染的水下事件相机光流基准数据集，通过合成逼真的水下事件数据流及对应的稠密真值（光流、深度和相机运动），填补了该领域缺乏真实光学与准确光流配对数据的空白，并对现有光流算法在水下环境中的性能进行了评估。


<details>
  <summary>Details</summary>
Motivation: 水下成像受波长相关衰减、悬浮颗粒散射、浑浊模糊和非均匀照明等因素影响，使得传统相机难以获取可靠运动真值；尽管事件相机具有微秒级时间分辨率和高动态范围，但因缺乏结合真实水下光学特性和精确光流的数据集，其在水下环境的研究进展受限。

Method: 作者利用基于物理的光线追踪生成RGBD序列，再通过现代视频到事件的转换流程渲染出逼真的水下事件数据流，并提供稠密的光流、深度和相机运动真值；同时对当前主流的学习型与模型型光流预测方法进行基准测试。

Result: 构建了首个合成水下事件相机光流基准数据集，揭示了水下光传输对事件生成和运动估计精度的影响，并为未来水下事件感知算法的开发与评估提供了新基线。

Conclusion: 该研究通过发布公开的合成数据集和代码，推动了事件相机在水下视觉任务中的应用，为后续算法研究奠定了基础。

Abstract: Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof.

</details>


### [12] [CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation](https://arxiv.org/abs/2601.10061)
*Chengzhuo Tong,Mingkun Chang,Shenglong Zhang,Yuran Wang,Cheng Liang,Zhizheng Zhao,Ruichuan An,Bohan Zeng,Yang Shi,Yifan Dai,Ziming Zhao,Guanbin Li,Pengfei Wan,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出CoF-T2I模型，将视频生成中的Chain-of-Frame（CoF）推理机制引入文本到图像生成任务，通过构建中间视觉推理步骤提升生成质量，并在多个基准上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成缺乏明确的视觉推理起点和可解释的中间状态，而视频生成模型中的CoF推理能力尚未被有效用于提升T2I生成效果。

Method: 提出CoF-T2I模型，通过渐进式视觉优化将中间帧作为显式推理步骤；构建CoF-Evol-Instruct数据集以建模从语义到美学的生成轨迹；并对每帧进行独立编码以提升质量和避免运动伪影。

Result: CoF-T2I显著优于基础视频模型，在GenEval上达到0.86，在Imagine-Bench上达到7.468，展现出视频模型在高质量文本到图像生成中的巨大潜力。

Conclusion: 将Chain-of-Frame推理机制引入文本到图像生成可有效提升生成质量，证明视频模型在该任务中具有重要应用前景。

Abstract: Recent video generation models have revealed the emergence of Chain-of-Frame (CoF) reasoning, enabling frame-by-frame visual inference. With this capability, video models have been successfully applied to various visual tasks (e.g., maze solving, visual puzzles). However, their potential to enhance text-to-image (T2I) generation remains largely unexplored due to the absence of a clearly defined visual reasoning starting point and interpretable intermediate states in the T2I generation process. To bridge this gap, we propose CoF-T2I, a model that integrates CoF reasoning into T2I generation via progressive visual refinement, where intermediate frames act as explicit reasoning steps and the final frame is taken as output. To establish such an explicit generation process, we curate CoF-Evol-Instruct, a dataset of CoF trajectories that model the generation process from semantics to aesthetics. To further improve quality and avoid motion artifacts, we enable independent encoding operation for each frame. Experiments show that CoF-T2I significantly outperforms the base video model and achieves competitive performance on challenging benchmarks, reaching 0.86 on GenEval and 7.468 on Imagine-Bench. These results indicate the substantial promise of video models for advancing high-quality text-to-image generation.

</details>


### [13] [Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting](https://arxiv.org/abs/2601.10075)
*Zhendong Wang,Lebin Zhou,Jingchuan Xiao,Rongduo Han,Nam Ling,Cihan Ruan*

Main category: cs.CV

TL;DR: 本文提出了一种面向3D高斯泼溅（3DGS）的流引导几何平流框架，以实现后印象派风格的真实3D迁移，通过将2D绘画中的方向流场反向传播至3D空间，使高斯图元对齐笔触方向并适应场景拓扑，无需依赖网格先验。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法通常将几何视为刚性基底，仅在表面投影纹理，违背了后印象派强调结构夸张与几何抽象的核心理念。为真实再现该艺术风格，需将几何抽象作为主要表达手段。

Method: 提出一种无网格的流引导几何平流框架：从2D画作提取方向流场并反向传播至3D空间，调整高斯图元形成与流场对齐的笔触；采用亮度-结构解耦策略，分离几何变形与颜色优化；引入基于视觉语言模型（VLM）的审美评判机制评估艺术真实性。

Result: 该方法成功实现了由画家笔触驱动的结构性变形，在不依赖显式网格的情况下生成符合后印象派风格的3D场景，并通过VLM-as-a-Judge框架有效评估了艺术表现力。

Conclusion: 通过将几何抽象作为风格表达的核心，本工作为3D艺术风格迁移提供了新范式，突破了传统方法对表面纹理的依赖，并引入主观审美评估机制，更贴合艺术创作的本质。

Abstract: In 1888, Vincent van Gogh wrote, "I am seeking exaggeration in the essential." This principle, amplifying structural form while suppressing photographic detail, lies at the core of Post-Impressionist art. However, most existing 3D style transfer methods invert this philosophy, treating geometry as a rigid substrate for surface-level texture projection. To authentically reproduce Post-Impressionist stylization, geometric abstraction must be embraced as the primary vehicle of expression.
  We propose a flow-guided geometric advection framework for 3D Gaussian Splatting (3DGS) that operationalizes this principle in a mesh-free setting. Our method extracts directional flow fields from 2D paintings and back-propagates them into 3D space, rectifying Gaussian primitives to form flow-aligned brushstrokes that conform to scene topology without relying on explicit mesh priors. This enables expressive structural deformation driven directly by painterly motion rather than photometric constraints.
  Our contributions are threefold: (1) a projection-based, mesh-free flow guidance mechanism that transfers 2D artistic motion into 3D Gaussian geometry; (2) a luminance-structure decoupling strategy that isolates geometric deformation from color optimization, mitigating artifacts during aggressive structural abstraction; and (3) a VLM-as-a-Judge evaluation framework that assesses artistic authenticity through aesthetic judgment instead of conventional pixel-level metrics, explicitly addressing the subjective nature of artistic stylization.

</details>


### [14] [Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks](https://arxiv.org/abs/2601.10090)
*Mingzhuo Li,Guang Li,Linfeng Ye,Jiafeng Mao,Takahiro Ogawa,Konstantinos N. Plataniotis,Miki Haseyama*

Main category: cs.CV

TL;DR: 本文提出难度引导采样（DGS）方法，通过引入任务难度信息来弥合数据蒸馏目标与下游任务之间的差距，从而提升蒸馏数据集在图像分类等任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据蒸馏方法主要关注原始数据集的特征，忽略了下游任务特定的信息，导致蒸馏目标与实际任务之间存在目标差距。

Method: 提出难度引导采样（DGS）作为即插即用的后处理采样模块，并结合难度感知引导（DAG）策略，在生成过程中融入对样本难度的考量，按照目标难度分布从已有方法生成的图像池中采样最终蒸馏数据集。

Result: 在多种实验设置下验证了所提方法的有效性，表明引入难度信息能显著提升蒸馏数据集在下游任务中的表现。

Conclusion: 难度信息对提升数据蒸馏效果具有重要作用，且在更广泛的下游任务中具有应用潜力。

Abstract: In this paper, we propose difficulty-guided sampling (DGS) to bridge the target gap between the distillation objective and the downstream task, therefore improving the performance of dataset distillation. Deep neural networks achieve remarkable performance but have time and storage-consuming training processes. Dataset distillation is proposed to generate compact, high-quality distilled datasets, enabling effective model training while maintaining downstream performance. Existing approaches typically focus on features extracted from the original dataset, overlooking task-specific information, which leads to a target gap between the distillation objective and the downstream task. We propose leveraging characteristics that benefit the downstream training into data distillation to bridge this gap. Focusing on the downstream task of image classification, we introduce the concept of difficulty and propose DGS as a plug-in post-stage sampling module. Following the specific target difficulty distribution, the final distilled dataset is sampled from image pools generated by existing methods. We also propose difficulty-aware guidance (DAG) to explore the effect of difficulty in the generation process. Extensive experiments across multiple settings demonstrate the effectiveness of the proposed methods. It also highlights the broader potential of difficulty for diverse downstream tasks.

</details>


### [15] [V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation](https://arxiv.org/abs/2601.10094)
*Han Wang,Yi Yang,Jingyuan Hu,Minfeng Zhu,Wei Chen*

Main category: cs.CV

TL;DR: V-Zero 是一种无需人工标注的多模态自改进训练框架，通过 Questioner 和 Solver 的协同进化机制，在仅使用无标签图像的情况下提升视觉语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉语言模型依赖大量人工标注数据，成本高且耗时，因此需要一种不依赖人工标注的自监督改进方法。

Method: 提出 V-Zero 框架，包含 Questioner 和 Solver 两个角色：Questioner 利用双轨推理奖励生成高质量问题，Slover 基于自身采样响应的多数投票生成伪标签进行优化；两者通过 Group Relative Policy Optimization (GRPO) 迭代训练，形成协同进化循环。

Result: 在 Qwen2.5-VL-7B-Instruct 上，V-Zero 在无需任何人工标注的情况下，使视觉数学推理能力提升 +1.7，通用视觉任务提升 +2.6。

Conclusion: V-Zero 展示了在多模态系统中实现无监督自改进的可行性与潜力，为降低对人工标注数据的依赖提供了有效路径。

Abstract: Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems. Code is available at https://github.com/SatonoDia/V-Zero

</details>


### [16] [InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery](https://arxiv.org/abs/2601.10098)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Yuansong Wang,Qingchao Jiang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本文提出InfoSculpt，一种基于信息瓶颈原则的广义类别发现新框架，通过类别级和实例级条件互信息联合优化，有效分离类别本质特征与实例噪声，在8个基准上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有广义类别发现方法依赖伪标签或两阶段聚类，缺乏显式解耦类别本质信号与实例噪声的机制。

Method: 提出InfoSculpt框架，从信息论角度出发，结合类别级条件互信息（在已知标签数据上）和实例级条件互信息（在全部数据上），协同优化表示空间，保留类别信息并压缩增强引入的噪声。

Result: 在8个基准数据集上的实验验证了InfoSculpt的有效性，表明该信息论方法显著优于现有技术。

Conclusion: InfoSculpt通过信息瓶颈原理成功实现了对表示空间的精细塑造，为广义类别发现任务提供了一种鲁棒且解耦的解决方案。

Abstract: Generalized Category Discovery (GCD) aims to classify instances from both known and novel categories within a large-scale unlabeled dataset, a critical yet challenging task for real-world, open-world applications. However, existing methods often rely on pseudo-labeling, or two-stage clustering, which lack a principled mechanism to explicitly disentangle essential, category-defining signals from instance-specific noise. In this paper, we address this fundamental limitation by re-framing GCD from an information-theoretic perspective, grounded in the Information Bottleneck (IB) principle. We introduce InfoSculpt, a novel framework that systematically sculpts the representation space by minimizing a dual Conditional Mutual Information (CMI) objective. InfoSculpt uniquely combines a Category-Level CMI on labeled data to learn compact and discriminative representations for known classes, and a complementary Instance-Level CMI on all data to distill invariant features by compressing augmentation-induced noise. These two objectives work synergistically at different scales to produce a disentangled and robust latent space where categorical information is preserved while noisy, instance-specific details are discarded. Extensive experiments on 8 benchmarks demonstrate that InfoSculpt validating the effectiveness of our information-theoretic approach.

</details>


### [17] [MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers](https://arxiv.org/abs/2601.10104)
*Chenyue Zhou,Jiayi Tuo,Shitong Qin,Wei Dai,Mingxuan Wang,Ziwei Zhao,Duoyang Li,Shiyang Su,Yanxi Lu,Yanbiao Ma*

Main category: cs.CV

TL;DR: 本文提出了MathDoc，首个面向真实高中数学试卷的文档级信息抽取基准，包含3,609道带真实视觉噪声的问题，并引入主动拒绝不可识别样本的评估维度，揭示了当前多模态大语言模型在面对低质量输入时缺乏可靠拒绝能力的关键问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注干净文档或通用布局分析，忽视了数学问题的结构完整性以及模型对不完整输入的主动拒绝能力，难以反映真实教育场景中的挑战。

Method: 构建MathDoc基准数据集，包含真实世界中的高噪声数学试题，并设计涵盖题干准确性、视觉相似性和拒绝能力的多维评估框架。

Result: 在Qwen3-VL和Gemini-2.5-Pro等前沿多模态大模型上的实验表明，尽管这些模型在信息抽取方面表现良好，但在面对不可读输入时无法有效拒绝，反而生成自信但错误的输出。

Conclusion: 当前多模态大语言模型在退化文档条件下缺乏可靠性，MathDoc为评估模型在真实复杂场景下的鲁棒性和拒绝能力提供了重要基准。

Abstract: The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging in real-world settings due to severe visual noise. Existing benchmarks mainly focus on clean documents or generic layout analysis, overlooking both the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. We introduce MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers. MathDoc contains \textbf{3,609} carefully curated questions with real-world artifacts and explicitly includes unrecognizable samples to evaluate active refusal behavior. We propose a multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability. Experiments on SOTA MLLMs, including Qwen3-VL and Gemini-2.5-Pro, show that although end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions. Our project repository is available at \href{https://github.com/winnk123/papers/tree/master}{GitHub repository}

</details>


### [18] [Enhancing Visual In-Context Learning by Multi-Faceted Fusion](https://arxiv.org/abs/2601.10107)
*Wenwen Liao,Jianbo Yu,Yuansong Wang,Qingchao Jiang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种多组合协同融合框架，通过生成多个上下文表征分支并引入MULTI-VQGAN架构，提升视觉上下文学习中多提示信息的利用效率，在多个视觉任务上展现出更强的泛化能力和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉上下文学习方法通常仅使用单一最佳提示或简单融合前K个提示，忽略了多样上下文之间的协同潜力，限制了模型的推理能力。

Method: 提出一种多组合协同融合框架，构建三个由不同高质量提示组合而成的上下文表征分支，并设计MULTI-VQGAN架构联合解析和利用这些多源协同信息。

Result: 在前景分割、单目标检测和图像着色等多个任务上的实验表明，该方法具有更强的跨任务泛化能力、更有效的上下文融合效果，以及比现有方法更鲁棒和准确的预测性能。

Conclusion: 通过多组合协同融合与MULTI-VQGAN架构，能更充分地挖掘视觉上下文中的多样化信息，显著提升视觉上下文学习的性能。

Abstract: Visual In-Context Learning (VICL) has emerged as a powerful paradigm, enabling models to perform novel visual tasks by learning from in-context examples. The dominant "retrieve-then-prompt" approach typically relies on selecting the single best visual prompt, a practice that often discards valuable contextual information from other suitable candidates. While recent work has explored fusing the top-K prompts into a single, enhanced representation, this still simply collapses multiple rich signals into one, limiting the model's reasoning capability. We argue that a more multi-faceted, collaborative fusion is required to unlock the full potential of these diverse contexts. To address this limitation, we introduce a novel framework that moves beyond single-prompt fusion towards an multi-combination collaborative fusion. Instead of collapsing multiple prompts into one, our method generates three contextual representation branches, each formed by integrating information from different combinations of top-quality prompts. These complementary guidance signals are then fed into proposed MULTI-VQGAN architecture, which is designed to jointly interpret and utilize collaborative information from multiple sources. Extensive experiments on diverse tasks, including foreground segmentation, single-object detection, and image colorization, highlight its strong cross-task generalization, effective contextual fusion, and ability to produce more robust and accurate predictions than existing methods.

</details>


### [19] [Beyond Single Prompts: Synergistic Fusion and Arrangement for VICL](https://arxiv.org/abs/2601.10117)
*Wenwen Liao,Jianbo Yu,Yuansong Wang,Shifu Yan,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的视觉上下文学习（VICL）框架，通过自适应融合多个提示、引入布局特定的轻量MLP以及双向微调机制，有效提升了模型在少样本视觉任务中的性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VICL方法存在两个主要问题：仅选择最相似提示会丢失其他高质量提示中的互补信息；未能利用不同提示排列所隐含的结构信息。

Method: 提出包含三个核心组件的端到端VICL框架：1）自适应融合模块，聚合多个提示的关键模式与标注；2）排列特定的轻量MLP，解耦布局先验；3）双向微调机制，通过交换查询与提示角色增强融合模块与修复模型的协作。

Result: 在前景分割、单目标检测和图像着色任务上的实验表明，该方法取得了更优结果，并展现出强大的跨任务泛化能力。

Conclusion: 所提出的VICL框架通过多提示融合、布局解耦和双向微调，有效克服了现有方法的局限性，在多个视觉任务中实现了性能提升和良好泛化。

Abstract: Vision In-Context Learning (VICL) enables inpainting models to quickly adapt to new visual tasks from only a few prompts. However, existing methods suffer from two key issues: (1) selecting only the most similar prompt discards complementary cues from other high-quality prompts; and (2) failing to exploit the structured information implied by different prompt arrangements.
  We propose an end-to-end VICL framework to overcome these limitations. Firstly, an adaptive Fusion Module aggregates critical patterns and annotations from multiple prompts to form more precise contextual prompts. Secondly, we introduce arrangement-specific lightweight MLPs to decouple layout priors from the core model, while minimally affecting the overall model. In addition, an bidirectional fine-tuning mechanism swaps the roles of query and prompt, encouraging the model to reconstruct the original prompt from fused context and thus enhancing collaboration between the fusion module and the inpainting model. Experiments on foreground segmentation, single-object detection, and image colorization demonstrate superior results and strong cross-task generalization of our method.

</details>


### [20] [VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2601.10124)
*Sicheng Yang,Zhaohu Xing,Lei Zhu*

Main category: cs.CV

TL;DR: 本文提出VQ-Seg，首次将向量量化（VQ）引入半监督医学图像分割，通过设计可控制的量化扰动模块（QPM）替代传统依赖Dropout的扰动方法，并结合双分支架构与基础模型引导机制，在包括自建肺癌CT数据集在内的多个数据集上取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割中基于Dropout的特征扰动方法需手动调节敏感的Dropout率，难以优化且可能导致次优正则化效果，因此需要一种更可控、有效的扰动策略。

Method: 提出VQ-Seg方法：1）利用向量量化离散化特征空间；2）设计量化扰动模块（QPM），通过对码本索引的空间位置进行打乱实现可控扰动；3）采用双分支架构共享量化后特征用于图像重建和分割；4）引入Post-VQ特征适配器（PFA）融合基础模型的高层语义信息以弥补量化损失。

Result: 在自建的包含828例中央型肺癌CT扫描的大规模数据集及多个公开基准上，VQ-Seg显著优于当前最先进的半监督分割方法。

Conclusion: VQ-Seg通过向量量化与可控扰动机制有效提升了半监督医学图像分割的性能，避免了对Dropout超参数的手动调优，具有良好的泛化能力和实用价值。

Abstract: Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many existing perturbation methods rely on dropout, and thus require a careful manual tuning of the dropout rate, which is a sensitive hyperparameter and often difficult to optimize and may lead to suboptimal regularization. To overcome this limitation, we propose VQ-Seg, the first approach to employ vector quantization (VQ) to discretize the feature space and introduce a novel and controllable Quantized Perturbation Module (QPM) that replaces dropout. Our QPM perturbs discrete representations by shuffling the spatial locations of codebook indices, enabling effective and controllable regularization. To mitigate potential information loss caused by quantization, we design a dual-branch architecture where the post-quantization feature space is shared by both image reconstruction and segmentation tasks. Moreover, we introduce a Post-VQ Feature Adapter (PFA) to incorporate guidance from a foundation model (FM), supplementing the high-level semantic information lost during quantization. Furthermore, we collect a large-scale Lung Cancer (LC) dataset comprising 828 CT scans annotated for central-type lung carcinoma. Extensive experiments on the LC dataset and other public benchmarks demonstrate the effectiveness of our method, which outperforms state-of-the-art approaches. Code available at: https://github.com/script-Yang/VQ-Seg.

</details>


### [21] [LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning](https://arxiv.org/abs/2601.10129)
*Linquan Wu,Tianxiang Jiang,Yifei Dong,Haoyu Yang,Fengji Zhang,Shichaang Meng,Ai Xuan,Linqi Song,Jacky Keung*

Main category: cs.CV

TL;DR: 本文提出LaViT框架，通过在文本生成前对齐教师模型的视觉语义和注意力轨迹，解决多模态蒸馏中的感知差距问题，显著提升学生模型的视觉基础能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态隐式推理方法依赖外部监督（如辅助图像），忽视了内在视觉注意力动态；作者发现学生模型在蒸馏过程中常模仿教师的文本输出，却关注完全不同的视觉区域，导致依赖语言先验而非真实感知。

Method: 提出LaViT框架，强制学生模型在生成文本前自回归地重建教师模型的视觉语义和注意力轨迹，并引入课程感知门控机制防止走捷径学习。

Result: 实验表明LaViT显著增强视觉基础能力，在复杂推理任务上最高提升16.9%，使3B小模型超越更大的开源模型及GPT-4o等闭源模型。

Conclusion: 通过对齐潜在视觉思维而非静态嵌入，LaViT有效弥合了多模态蒸馏中的感知差距，提升了模型的视觉推理与泛化能力。

Abstract: Current multimodal latent reasoning often relies on external supervision (e.g., auxiliary images), ignoring intrinsic visual attention dynamics. In this work, we identify a critical Perception Gap in distillation: student models frequently mimic a teacher's textual output while attending to fundamentally divergent visual regions, effectively relying on language priors rather than grounded perception. To bridge this, we propose LaViT, a framework that aligns latent visual thoughts rather than static embeddings. LaViT compels the student to autoregressively reconstruct the teacher's visual semantics and attention trajectories prior to text generation, employing a curriculum sensory gating mechanism to prevent shortcut learning. Extensive experiments show that LaViT significantly enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger open-source variants and proprietary models like GPT-4o.

</details>


### [22] [Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method](https://arxiv.org/abs/2601.10165)
*Chao Huang,Benfeng Wang,Wei Wang,Jie Wen,Li Shen,Wenqi Ren,Yong Xu,Xiaochun Cao*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频异常推理（VAR）任务，通过构建包含8,641个视频和超过50,000个样本的新数据集，以及基于感知-认知-行动链式思维（PerCoAct-CoT）的标注体系，推动多模态大语言模型（MLLMs）在视频异常检测与理解中实现结构化、多阶段的推理能力，并提出了Vad-R1-Plus模型和Anomaly-Aware Group Relative Policy Optimization方法，在该任务上显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的视频异常检测与理解方法大多局限于异常定位或事后描述，缺乏显式的推理过程、风险意识和面向决策的解释能力，因此需要一种能支持结构化、多阶段推理的新任务范式。

Method: 定义了视频异常推理（VAR）新任务，构建了基于PerCoAct-CoT标注框架的大规模数据集，并提出了Anomaly-Aware Group Relative Policy Optimization优化策略和端到端的MLLM模型Vad-R1-Plus，以支持自适应分层推理和风险感知决策。

Result: 实验表明，所提出的VAR基准和Vad-R1-Plus模型在视频异常推理任务上显著优于开源和闭源的现有基线方法，有效提升了MLLMs在该领域的推理能力。

Conclusion: 通过引入结构化的多阶段推理框架、大规模标注数据集和专用优化方法，本文成功将视频异常分析从描述性理解提升至具备因果解释与风险意识的决策级推理，为MLLM在复杂视频理解任务中的应用提供了新方向。

Abstract: Recent progress in reasoning capabilities of Multimodal Large Language Models(MLLMs) has highlighted their potential for performing complex video understanding tasks. However, in the domain of Video Anomaly Detection and Understanding (VAD&U), existing MLLM-based methods are largely limited to anomaly localization or post-hoc description, lacking explicit reasoning processes, risk awareness, and decision-oriented interpretation. To address this gap, we define a new task termed Video Anomaly Reasoning (VAR), which elevates video anomaly analysis from descriptive understanding to structured, multi-stage reasoning. VAR explicitly requires models to perform progressive reasoning over anomalous events before answering anomaly-related questions, encompassing visual perception, causal interpretation, and risk-aware decision making. To support this task, we present a new dataset with 8,641 videos, where each video is annotated with diverse question types corresponding to different reasoning depths, totaling more than 50,000 samples, making it one of the largest datasets for video anomaly. The annotations are based on a structured Perception-Cognition-Action Chain-of-Thought (PerCoAct-CoT), which formalizes domain-specific reasoning priors for video anomaly understanding. This design enables systematic evaluation of multi-stage and adaptive anomaly reasoning. In addition, we propose Anomaly-Aware Group Relative Policy Optimization to further enhance reasoning reliability under weak supervision. Building upon the proposed task and dataset, we develop an end-to-end MLLM-based VAR model termed Vad-R1-Plus, which supports adaptive hierarchical reasoning and risk-aware decision making. Extensive experiments demonstrate that the proposed benchmark and method effectively advance the reasoning capabilities of MLLMs on VAR tasks, outperforming both open-source and proprietary baselines.

</details>


### [23] [RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation](https://arxiv.org/abs/2601.10168)
*Yue Chang,Rufeng Chen,Zhaofan Zhang,Yi Chen,Sihong Xie*

Main category: cs.CV

TL;DR: 本文提出RAG-3DSG方法，通过重采样引导的不确定性估计和动态下采样映射策略，提升开放词汇3D场景图生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇3D场景图生成方法在物体识别准确率和速度方面表现不佳，主要受限于视角受限、遮挡和冗余表面密度等问题。

Method: 提出RAG-3DSG框架，利用重采样引导的不确定性估计减少聚合噪声，并通过低不确定性物体支持物体级检索增强生成（RAG）；同时引入动态下采样-映射策略，以自适应粒度加速跨图像物体聚合。

Result: 在Replica数据集上的实验表明，RAG-3DSG显著提升了3D场景图中节点描述的准确性，并将映射时间减少了三分之二。

Conclusion: RAG-3DSG有效解决了开放词汇3D场景图生成中的准确性和效率问题，为机器人下游任务提供了更可靠的语义结构支持。

Abstract: Open-vocabulary 3D Scene Graph (3DSG) generation can enhance various downstream tasks in robotics, such as manipulation and navigation, by leveraging structured semantic representations. A 3DSG is constructed from multiple images of a scene, where objects are represented as nodes and relationships as edges. However, existing works for open-vocabulary 3DSG generation suffer from both low object-level recognition accuracy and speed, mainly due to constrained viewpoints, occlusions, and redundant surface density. To address these challenges, we propose RAG-3DSG to mitigate aggregation noise through re-shot guided uncertainty estimation and support object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. Furthermore, we propose a dynamic downsample-mapping strategy to accelerate cross-image object aggregation with adaptive granularity. Experiments on Replica dataset demonstrate that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing the mapping time by two-thirds compared to the vanilla version.

</details>


### [24] [ELITE: Efficient Gaussian Head Avatar from a Monocular Video via Learned Initialization and TEst-time Generative Adaptation](https://arxiv.org/abs/2601.10200)
*Kim Youwang,Lee Hyoseok,Subin Park,Gerard Pons-Moll,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: ELITE 是一种高效的人头高斯化身合成方法，结合3D数据先验和2D生成先验的优势，通过快速初始化和测试时生成式自适应，在保持野外泛化能力的同时显著提升合成速度与质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单目视频生成人头化身时存在局限：基于3D数据先验的方法野外泛化能力差，而基于2D生成先验的方法计算开销大且易产生身份幻觉。作者旨在融合两者优势，实现高效、高质量、强泛化的化身合成。

Method: 提出ELITE框架，包含两个核心组件：1）前馈式Mesh2Gaussian先验模型（MGPM），用于快速初始化高斯化身；2）测试时生成式自适应阶段，利用真实与合成图像作为监督，并采用渲染引导的单步扩散增强器恢复细节，避免传统全扩散去噪的低效与幻觉问题。

Result: 实验表明，ELITE在视觉质量上优于先前方法，尤其在复杂表情下表现更佳，同时合成速度比2D生成先验方法快60倍。

Conclusion: ELITE通过结合3D与2D先验并引入高效初始化与测试时自适应机制，实现了高质量、高效率、强泛化的人头高斯化身合成。

Abstract: We introduce ELITE, an Efficient Gaussian head avatar synthesis from a monocular video via Learned Initialization and TEst-time generative adaptation. Prior works rely either on a 3D data prior or a 2D generative prior to compensate for missing visual cues in monocular videos. However, 3D data prior methods often struggle to generalize in-the-wild, while 2D generative prior methods are computationally heavy and prone to identity hallucination. We identify a complementary synergy between these two priors and design an efficient system that achieves high-fidelity animatable avatar synthesis with strong in-the-wild generalization. Specifically, we introduce a feed-forward Mesh2Gaussian Prior Model (MGPM) that enables fast initialization of a Gaussian avatar. To further bridge the domain gap at test time, we design a test-time generative adaptation stage, leveraging both real and synthetic images as supervision. Unlike previous full diffusion denoising strategies that are slow and hallucination-prone, we propose a rendering-guided single-step diffusion enhancer that restores missing visual details, grounded on Gaussian avatar renderings. Our experiments demonstrate that ELITE produces visually superior avatars to prior works, even for challenging expressions, while achieving 60x faster synthesis than the 2D generative prior method.

</details>


### [25] [Beyond Inpainting: Unleash 3D Understanding for Precise Camera-Controlled Video Generation](https://arxiv.org/abs/2601.10214)
*Dong-Yu Chen,Yixin Guo,Shuojin Yang,Tai-Jiang Mu,Shi-Min Hu*

Main category: cs.CV

TL;DR: 本文提出DepthDirector，一种基于深度引导的视频重渲染框架，通过引入视图-内容双流条件机制和轻量级LoRA适配器，在保持视频内容一致性的前提下实现精确的摄像机轨迹控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D表示扭曲的方法在视频生成中难以兼顾精确的摄像机控制与内容一致性，常陷入“修复陷阱”，导致主体不一致和生成质量下降。

Method: 利用显式3D表示生成的深度视频作为摄像机控制引导，设计视图-内容双流条件机制，将源视频与目标视角下扭曲的深度序列共同注入预训练视频扩散模型，并采用轻量级LoRA适配器进行训练；同时构建了大规模多摄像机同步数据集MultiCam-WarpData。

Result: 实验表明，DepthDirector在摄像机可控性和视觉质量方面均优于现有方法。

Conclusion: DepthDirector有效结合了视频扩散模型的3D先验知识与几何引导信号，实现了高质量、高一致性的可控摄像机视频重渲染。

Abstract: Camera control has been extensively studied in conditioned video generation; however, performing precisely altering the camera trajectories while faithfully preserving the video content remains a challenging task. The mainstream approach to achieving precise camera control is warping a 3D representation according to the target trajectory. However, such methods fail to fully leverage the 3D priors of video diffusion models (VDMs) and often fall into the Inpainting Trap, resulting in subject inconsistency and degraded generation quality. To address this problem, we propose DepthDirector, a video re-rendering framework with precise camera controllability. By leveraging the depth video from explicit 3D representation as camera-control guidance, our method can faithfully reproduce the dynamic scene of an input video under novel camera trajectories. Specifically, we design a View-Content Dual-Stream Condition mechanism that injects both the source video and the warped depth sequence rendered under the target viewpoint into the pretrained video generation model. This geometric guidance signal enables VDMs to comprehend camera movements and leverage their 3D understanding capabilities, thereby facilitating precise camera control and consistent content generation. Next, we introduce a lightweight LoRA-based video diffusion adapter to train our framework, fully preserving the knowledge priors of VDMs. Additionally, we construct a large-scale multi-camera synchronized dataset named MultiCam-WarpData using Unreal Engine 5, containing 8K videos across 1K dynamic scenes. Extensive experiments show that DepthDirector outperforms existing methods in both camera controllability and visual quality. Our code and dataset will be publicly available.

</details>


### [26] [Attend to what I say: Highlighting relevant content on slides](https://arxiv.org/abs/2601.10244)
*Megha Mariam K M,C. V. Jawahar*

Main category: cs.CV

TL;DR: 本文提出了一种自动识别并高亮幻灯片中与演讲者叙述最相关区域的方法，通过将语音内容与幻灯片中的文本或图形元素对齐，提升听众在观看演示（如学术报告）时的视听同步性与理解效率。


<details>
  <summary>Details</summary>
Motivation: 在快节奏或多内容的演示中，听众难以同时跟上演讲者的讲述并快速定位幻灯片中的关键信息，造成视听脱节和认知负担，影响对核心内容的理解。

Method: 通过分析演讲者的语音内容，并将其与幻灯片中的文本或图形元素进行匹配，自动识别并高亮当前最相关的幻灯片区域，以实现听觉与视觉注意力的同步。

Result: 作者探索了多种解决该问题的方法，并评估了各自的成功与失败案例，验证了所提方法在提升多媒体内容理解方面的有效性。

Conclusion: 自动对齐语音叙述与幻灯片视觉内容有助于减轻认知负荷、提升信息吸收效率，是理解和处理教育视频、会议报告等富媒体内容的关键方向。

Abstract: Imagine sitting in a presentation, trying to follow the speaker while simultaneously scanning the slides for relevant information. While the entire slide is visible, identifying the relevant regions can be challenging. As you focus on one part of the slide, the speaker moves on to a new sentence, leaving you scrambling to catch up visually. This constant back-and-forth creates a disconnect between what is being said and the most important visual elements, making it hard to absorb key details, especially in fast-paced or content-heavy presentations such as conference talks. This requires an understanding of slides, including text, graphics, and layout. We introduce a method that automatically identifies and highlights the most relevant slide regions based on the speaker's narrative. By analyzing spoken content and matching it with textual or graphical elements in the slides, our approach ensures better synchronization between what listeners hear and what they need to attend to. We explore different ways of solving this problem and assess their success and failure cases. Analyzing multimedia documents is emerging as a key requirement for seamless understanding of content-rich videos, such as educational videos and conference talks, by reducing cognitive strain and improving comprehension. Code and dataset are available at: https://github.com/meghamariamkm2002/Slide_Highlight

</details>


### [27] [DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset](https://arxiv.org/abs/2601.10305)
*Hengyu Shen,Tiancheng Gu,Bin Qin,Lan Wu,Yuling Wu,Shuo Tan,Zelong Sun,Jun Wang,Nan Wu,Xiang An,Weidong Cai,Ziyong Feng,Kaicheng Yang*

Main category: cs.CV

TL;DR: 本文提出了DanQing，一个包含1亿高质量中文图文对的新数据集，通过更严格的数据筛选流程构建，并基于2024-2025年的网页数据，显著提升了中文视觉-语言预训练模型在多项下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的中文图文数据，中文视觉-语言预训练的发展远落后于英文。为弥补这一差距，作者构建了一个高质量的中文跨模态数据集。

Method: 作者设计了一套完整的数据构建流程，从Common Crawl中收集数据，并通过更严格的选择机制筛选出1亿个高质量图文对，形成DanQing数据集；随后基于SigLIP2模型进行持续预训练以验证其有效性。

Result: 在中文零样本分类、跨模态检索和基于大语言模型（LMM）的评估等下游任务中，使用DanQing预训练的模型均显著优于现有数据集。

Conclusion: DanQing是一个高质量、时效性强的中文图文数据集，能有效推动中文视觉-语言预训练研究，作者将依据CC-BY 4.0许可证开源该数据集。

Abstract: Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets (e.g., COYO-700M and LAION-400M) has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind, due to the scarcity of high-quality Chinese image-text data. To address this gap, we develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset. As a result, we propose DanQing, which contains 100 million image-text pairs collected from Common Crawl. Different from existing datasets, DanQing is curated through a more rigorous selection process, yielding superior data quality. Moreover, DanQing is primarily built from 2024-2025 web data, enabling models to better capture evolving semantic trends and thus offering greater practical utility. We compare DanQing with existing datasets by continual pre-training of the SigLIP2 model. Experimental results show that DanQing consistently achieves superior performance across a range of Chinese downstream tasks, including zero-shot classification, cross-modal retrieval, and LMM-based evaluations. To facilitate further research in Chinese vision-language pre-training, we will open-source the DanQing dataset under the Creative Common CC-BY 4.0 license.

</details>


### [28] [Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models](https://arxiv.org/abs/2601.10313)
*Peng-Fei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为分层优化攻击（HRA）的多模态通用对抗攻击框架，通过在样本和优化层面同时优化通用对抗扰动（UAP），有效提升了对视觉-语言预训练（VLP）模型的攻击效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对VLP模型的对抗攻击多为样本特定型，在大规模数据集或新场景中计算开销大，难以泛化。因此需要一种高效且通用的多模态对抗攻击方法。

Method: HRA在图像模态上将对抗样本解耦为干净图像与扰动，独立处理以破坏跨模态对齐；引入ScMix增强策略丰富视觉上下文，提升UAP的全局与局部效用；在优化过程中利用历史与预测梯度构建时间层次结构，避免局部极小值。在文本模态上，结合句内与句间重要性指标识别全局关键词作为通用文本扰动。

Result: 在多种下游任务、VLP模型和数据集上的大量实验表明，所提出的HRA方法在攻击效果和通用性方面优于现有方法。

Conclusion: HRA是一种高效、通用的多模态对抗攻击框架，能显著提升对VLP模型的攻击性能，并减少对虚假特征的依赖。

Abstract: Existing adversarial attacks for VLP models are mostly sample-specific, resulting in substantial computational overhead when scaled to large datasets or new scenarios. To overcome this limitation, we propose Hierarchical Refinement Attack (HRA), a multimodal universal attack framework for VLP models. HRA refines universal adversarial perturbations (UAPs) at both the sample level and the optimization level. For the image modality, we disentangle adversarial examples into clean images and perturbations, allowing each component to be handled independently for more effective disruption of cross-modal alignment. We further introduce a ScMix augmentation strategy that diversifies visual contexts and strengthens both global and local utility of UAPs, thereby reducing reliance on spurious features. In addition, we refine the optimization path by leveraging a temporal hierarchy of historical and estimated future gradients to avoid local minima and stabilize universal perturbation learning. For the text modality, HRA identifies globally influential words by combining intra-sentence and inter-sentence importance measures, and subsequently utilizes these words as universal text perturbations. Extensive experiments across various downstream tasks, VLP models, and datasets demonstrate the superiority of the proposed universal multimodal attacks.

</details>


### [29] [ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding](https://arxiv.org/abs/2601.10323)
*Xueyun Tian,Wei Li,Bingbing Xu,Heng Dong,Yuanzhuo Wang,Huawei Shen*

Main category: cs.CV

TL;DR: 本文提出了ROMA，一种实时全模态大语言模型，能够统一处理音频、视觉和文本的连续输入，支持主动与被动交互，并在12个基准测试中展现出领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有全模态大语言模型在流式音视频理解方面存在不足，通常缺乏完整的模态支持或无法实现自主的主动监控，因此需要一个能统一处理多模态流式输入并兼具主动与被动交互能力的系统。

Method: ROMA将连续的音视频输入作为同步的多模态单元进行处理，对齐密集音频与离散视频帧以解决粒度不匹配问题；引入轻量级“说话头”模块，将响应触发与生成解耦以实现精准在线决策；采用两阶段课程训练策略，结合专门构建的流式数据集进行优化。

Result: 在涵盖主动（如警报、叙述）和被动（如问答）任务的12个基准测试中，ROMA在主动任务上达到最先进水平，在被动任务上也表现具有竞争力。

Conclusion: ROMA有效实现了统一、实时的全模态理解，验证了其在复杂流式多模态场景下的鲁棒性和实用性。

Abstract: Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring. To address this, we present ROMA, a real-time omni-multimodal assistant for unified reactive and proactive interaction. ROMA processes continuous inputs as synchronized multimodal units, aligning dense audio with discrete video frames to handle granularity mismatches. For online decision-making, we introduce a lightweight speak head that decouples response initiation from generation to ensure precise triggering without task conflict. We train ROMA with a curated streaming dataset and a two-stage curriculum that progressively optimizes for streaming format adaptation and proactive responsiveness. To standardize the fragmented evaluation landscape, we reorganize diverse benchmarks into a unified suite covering both proactive (alert, narration) and reactive (QA) settings. Extensive experiments across 12 benchmarks demonstrate ROMA achieves state-of-the-art performance on proactive tasks while competitive in reactive settings, validating its robustness in unified real-time omni-multimodal understanding.

</details>


### [30] [Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs](https://arxiv.org/abs/2601.10369)
*Ningyu Sun,Zhaolin Cai,Zitong Xu,Peihang Chen,Huiyu Duan,Yichao Yan,Xiongkuo Min,Xiaokang Yang*

Main category: cs.CV

TL;DR: 本文提出了HPE-Bench基准和基于多模态大语言模型的统一评估框架，用于更精细地评估文本引导的人体姿态编辑结果的真实性与质量。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标在人体姿态编辑任务中往往将真实性检测与质量评估割裂，难以提供针对姿态不一致性的细粒度分析，且生成结果常存在结构异常和伪影问题。

Method: 构建包含1700个样本的HPE-Bench基准数据集，并提出一个基于层选择性多模态大语言模型（MLLM）的统一框架，结合对比LoRA微调和新颖的层敏感性分析（LSA）机制，以识别最适合姿态评估的特征层。

Result: 所提框架在真实性检测和多维质量回归任务上均取得优越性能，有效弥合了取证检测与质量评估之间的差距。

Conclusion: 通过HPE-Bench和统一评估框架，实现了对人体姿态编辑结果更全面、细粒度的评估，为该领域提供了新的基准和方法论支持。

Abstract: Text-guided human pose editing has gained significant traction in AIGC applications. However,it remains plagued by structural anomalies and generative artifacts. Existing evaluation metrics often isolate authenticity detection from quality assessment, failing to provide fine-grained insights into pose-specific inconsistencies. To address these limitations, we introduce HPE-Bench, a specialized benchmark comprising 1,700 standardized samples from 17 state-of-the-art editing models, offering both authenticity labels and multi-dimensional quality scores. Furthermore, we propose a unified framework based on layer-selective multimodal large language models (MLLMs). By employing contrastive LoRA tuning and a novel layer sensitivity analysis (LSA) mechanism, we identify the optimal feature layer for pose evaluation. Our framework achieves superior performance in both authenticity detection and multi-dimensional quality regression, effectively bridging the gap between forensic detection and quality assessment.

</details>


### [31] [Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement](https://arxiv.org/abs/2601.10373)
*Yichong Xia,Yimin Zhou,Jinpeng Wang,Bin Chen*

Main category: cs.CV

TL;DR: 本文提出DiffCR，一种基于一致性先验优化的高效扩散图像压缩框架，通过频域感知跳步估计和两步解码，在不更新主干扩散模型的前提下显著提升压缩效率与重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像压缩方法存在采样速度慢和比特分配不佳的问题，主要源于训练范式的割裂。

Method: 提出DiffCR框架，包含频域感知跳步估计（FaSE）模块和轻量级一致性估计器；FaSE利用频域解耦注意力（FDA）对预训练扩散模型的ε预测先验进行优化，并与不同时间步的压缩隐变量对齐；一致性估计器支持快速两步解码，保持语义轨迹。

Result: 在不更新主干扩散模型的情况下，DiffCR相比当前最优扩散压缩方法节省27.2% BD-rate（LPIPS）和65.1% BD-rate（PSNR），并实现超过10倍的解码加速。

Conclusion: DiffCR有效解决了扩散图像压缩中的效率与质量瓶颈，为低比特率高质量图像压缩提供了新思路。

Abstract: Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. In this work, we propose Accelerate \textbf{Diff}usion-based Image Compression via \textbf{C}onsistency Prior \textbf{R}efinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the $ε$-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast \textbf{two-step decoding} by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2\% BD-rate (LPIPS) and 65.1\% BD-rate (PSNR)) and over $10\times$ speed-up compared to SOTA diffusion-based compression baselines.

</details>


### [32] [Global Context Compression with Interleaved Vision-Text Transformation](https://arxiv.org/abs/2601.10378)
*Dian Jiao,Jiaxin Duan,Shuai Zhao,Jiabing Leng,Yiran Zhang,Feng Huang*

Main category: cs.CV

TL;DR: 本文提出VIST2，一种新型Transformer模型，通过将文本块与其视觉编码交错输入，并仅依赖视觉token进行预测，实现全局上下文压缩，在预填充和推理阶段均显著减少计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的OCR方法虽能通过图像编码减少预填充阶段的token数量，但在逐token推理阶段仍无法节省计算或内存成本。因此，作者探索在预填充和推理两个阶段都能节省token的全局上下文压缩方法。

Method: 提出VIST2模型，将文本块渲染为草图图像，并与原始文本交错输入；模型仅使用前序上下文中的视觉token来预测下一个文本token的分布。训练过程包括课程调度的光学语言建模预训练和模态交错指令微调。

Result: 在0.6B至8B规模的VIST2模型上实验表明，在4倍压缩比下，模型在长文本生成任务中显著优于基线，首token生成速度平均提升3倍，内存占用减少77%，FLOPS减少74%。

Conclusion: VIST2通过全局上下文压缩有效降低了Transformer在长文本处理中的计算和内存开销，验证了视觉编码在端到端文本压缩与加速推理中的潜力。

Abstract: Recent achievements of vision-language models in end-to-end OCR point to a new avenue for low-loss compression of textual information. This motivates earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding, thereby alleviating the quadratically increased Attention computations. However, this partial compression fails to save computational or memory costs at token-by-token inference. In this paper, we investigate global context compression, which saves tokens at both prefilling and inference stages. Consequently, we propose VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. Around this idea, we render text chunks into sketch images and train VIST2 in multiple stages, starting from curriculum-scheduled pretraining for optical language modeling, followed by modal-interleaved instruction tuning. We conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. With a 4$\times$ compression ratio, the resulting models demonstrate significant superiority over baselines on long writing tasks, achieving, on average, a 3$\times$ speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS. Our codes and datasets will be public to support further studies.

</details>


### [33] [Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer](https://arxiv.org/abs/2601.10386)
*Filippo Ruffini,Camillo Maria Caruso,Claudia Tacconi,Lorenzo Nibid,Francesca Miccolis,Marta Lovino,Carlo Greco,Edy Ippolito,Michele Fiore,Alessio Cortellini,Bruno Beomonte Zobel,Giuseppe Perrone,Bruno Vincenzi,Claudio Marrocco,Alessandro Bria,Elisa Ficarra,Sara Ramella,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 本文提出了一种缺失感知的多模态生存预测框架，用于整合CT影像、全切片病理图像和临床变量，以提升不可切除II-III期非小细胞肺癌患者的总体生存预测性能。该方法利用基础模型提取各模态特征，并采用中间融合策略，在存在模态缺失的情况下仍能有效利用所有可用数据，避免了传统方法中因缺失而剔除样本的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态深度学习的生存预测方法在临床应用中受限于队列规模小和模态缺失问题，常需进行完整病例筛选或强插补，导致信息损失或偏差。因此，亟需一种能自然处理模态缺失、充分利用不完整多模态数据的建模方法。

Method: 该研究构建了一个缺失感知的多模态生存预测框架：首先使用基础模型（Foundation Models）分别从CT、全切片病理图像（WSI）和结构化临床变量中提取模态特异性特征；然后采用缺失感知编码策略，在中间层进行多模态融合，使模型在训练和推理阶段均能灵活处理任意模态组合，无需剔除缺失样本。

Result: 实验表明，所提出的中间融合策略优于单模态基线以及早期和晚期融合方法，其中WSI与临床模态融合效果最佳（C-index达73.30）。进一步分析显示，模型能自适应地降低信息量较少模态（如CT）的权重，减少其对最终预测的贡献。

Conclusion: 该缺失感知多模态框架有效解决了临床数据中常见的模态缺失问题，提升了非小细胞肺癌生存预测的准确性和鲁棒性，为多模态深度学习在真实世界临床场景中的应用提供了可行路径。

Abstract: Accurate survival prediction in Non-Small Cell Lung Cancer (NSCLC) requires the integration of heterogeneous clinical, radiological, and histopathological information. While Multimodal Deep Learning (MDL) offers a promises for precision prognosis and survival prediction, its clinical applicability is severely limited by small cohort sizes and the presence of missing modalities, often forcing complete-case filtering or aggressive imputation. In this work, we present a missing-aware multimodal survival framework that integrates Computed Tomography (CT), Whole-Slide Histopathology (WSI) Images, and structured clinical variables for overall survival modeling in unresectable stage II-III NSCLC. By leveraging Foundation Models (FM) for modality-specific feature extraction and a missing-aware encoding strategy, the proposed approach enables intermediate multimodal fusion under naturally incomplete modality profiles. The proposed architecture is resilient to missing modalities by design, allowing the model to utilize all available data without being forced to drop patients during training or inference. Experimental results demonstrate that intermediate fusion consistently outperforms unimodal baselines as well as early and late fusion strategies, with the strongest performance achieved by the fusion of WSI and clinical modalities (73.30 C-index). Further analyses of modality importance reveal an adaptive behavior in which less informative modalities, i.e., CT modality, are automatically down-weighted and contribute less to the final survival prediction.

</details>


### [34] [Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy](https://arxiv.org/abs/2601.10392)
*Hassan Eshkiki,Sarah Costa,Mostafa Mohammadpour,Farinaz Tanhaei,Christopher H. George,Fabio Caraffini*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的计算框架，通过融合多帧时序荧光显微图像生成高质量单幅图像，在保留生物内容的同时显著提升细胞计数和图像信息质量。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜记录常受限于噪声、时间变异性和随时间振荡信号的可视化不一致，影响了其在活体生物样本分析中的实用性。

Method: 该方法整合来自多个时间分辨帧的信息，结合来自不同计算机视觉领域的可解释技术，构建一个能生成高质量2D合成图像的计算框架。

Result: 在包含111种配置和复杂动态心肌细胞单层数据集上的实验表明，该方法相比以往方法平均提升44%的细胞计数，并增强图像质量和信息保留。

Conclusion: 所提出的图像融合流程不仅适用于荧光显微成像，还可推广至其他需将多时相图像堆栈融合为高质量2D图像的成像领域，有助于后续标注与分割任务。

Abstract: Fluorescence microscopy is widely employed for the analysis of living biological samples; however, the utility of the resulting recordings is frequently constrained by noise, temporal variability, and inconsistent visualisation of signals that oscillate over time. We present a unique computational framework that integrates information from multiple time-resolved frames into a single high-quality image, while preserving the underlying biological content of the original video. We evaluate the proposed method through an extensive number of configurations (n = 111) and on a challenging dataset comprising dynamic, heterogeneous, and morphologically complex 2D monolayers of cardiac cells. Results show that our framework, which consists of a combination of explainable techniques from different computer vision application fields, is capable of generating composite images that preserve and enhance the quality and information of individual microscopy frames, yielding 44% average increase in cell count compared to previous methods. The proposed pipeline is applicable to other imaging domains that require the fusion of multi-temporal image stacks into high-quality 2D images, thereby facilitating annotation and downstream segmentation.

</details>


### [35] [Urban Socio-Semantic Segmentation with Vision-Language Reasoning](https://arxiv.org/abs/2601.10477)
*Yu Wang,Yi Wang,Rui Dai,Yujie Wang,Kaikui Liu,Xiangxiang Chu,Yansheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉-语言模型推理的城市场景社会语义分割方法，引入新数据集SocioSeg和推理框架SocioReasoner，显著优于现有模型并具备强零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前先进分割模型在物理属性定义的实体（如建筑、水体）上表现良好，但在社会定义类别（如学校、公园）上仍存在困难，因此需要一种能处理社会语义信息的分割方法。

Method: 提出名为SocioReasoner的视觉-语言多阶段推理框架，结合卫星图像、数字地图与像素级标签，通过跨模态识别与强化学习优化非可微推理过程，激发视觉-语言模型的推理能力。

Result: 实验表明该方法在社会语义分割任务上优于当前最先进的模型，并展现出强大的零样本泛化能力。

Conclusion: 通过构建新数据集SocioSeg与提出SocioReasoner框架，有效实现了城市环境中社会语义实体的高精度分割，为下游应用提供了有力支持。

Abstract: As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate this, we introduce the Urban Socio-Semantic Segmentation dataset named SocioSeg, a new resource comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, we propose a novel vision-language reasoning framework called SocioReasoner that simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. We employ reinforcement learning to optimize this non-differentiable process and elicit the reasoning capabilities of the vision-language model. Experiments demonstrate our approach's gains over state-of-the-art models and strong zero-shot generalization. Our dataset and code are available in https://github.com/AMAP-ML/SocioReasoner.

</details>


### [36] [SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction](https://arxiv.org/abs/2601.10512)
*Kanak Mazumder,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 本文提出SatMap方法，通过融合卫星地图与多视角车载相机观测，在线生成矢量化高精地图，显著提升自动驾驶系统在深度模糊、遮挡、远距离及恶劣天气条件下的建图精度。


<details>
  <summary>Details</summary>
Motivation: 车载相机在构建高精地图时受限于深度感知能力不足和遮挡问题，导致精度下降；引入卫星图像作为全局先验可有效缓解这些问题。

Method: SatMap是一种在线矢量化高精地图估计方法，结合鸟瞰视角（BEV）的卫星图像提供的车道级语义与纹理信息作为全局先验，并融合多视角相机观测，直接预测用于下游任务的矢量化高精地图。

Result: 在nuScenes数据集上，SatMap相比纯相机基线提升了34.8% mAP，相比相机-LiDAR融合基线提升了8.5% mAP；在远距离和恶劣天气条件下也表现出优越性能。

Conclusion: 利用卫星地图作为先验能有效提升在线高精地图构建的鲁棒性与准确性，尤其在具有挑战性的场景中表现突出。

Abstract: Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird's Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In our experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, we evaluate our model in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map. Source code will be available at https://iv.ee.hm.edu/satmap/.

</details>


### [37] [BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition](https://arxiv.org/abs/2601.10521)
*Max A. Buettner,Kanak Mazumder,Luca Koecher,Mario Finkbeiner,Sebastian Niebler,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 本文提出了FUSE-Bike平台和BikeActions数据集，用于从骑行者视角捕捉脆弱道路使用者（VRU）的行为，填补了密集共享空间中VRU交互研究的空白，并建立了首个性能基准。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶和移动机器人领域对脆弱道路使用者（VRU）意图预测的研究主要集中在车辆视角下的行人过街行为，而密集共享空间中的交互行为尚未充分探索。

Method: 作者开发了FUSE-Bike开放感知平台（配备双LiDAR、相机和GNSS），从骑行者视角采集高保真近距离数据，并构建了包含852个标注样本的多模态数据集BikeActions，涵盖5类动作；同时在公开数据划分上评估了图卷积和Transformer模型，建立基准。

Result: 成功构建并发布了BikeActions数据集及配套工具、硬件设计和基准代码，为VRU行为建模提供了首个性能基线。

Conclusion: 该工作通过新颖的数据采集平台和多模态数据集，推动了密集共享空间中VRU动作理解的研究，并为后续工作提供了开放资源和基准。

Abstract: Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data capture directly from a cyclist's viewpoint. Leveraging this platform, we present BikeActions, a novel multi-modal dataset comprising 852 annotated samples across 5 distinct action classes, specifically tailored to improve VRU behavior modeling. We establish a rigorous benchmark by evaluating state-of-the-art graph convolution and transformer-based models on our publicly released data splits, establishing the first performance baselines for this challenging task. We release the full dataset together with data curation tools, the open hardware design, and the benchmark code to foster future research in VRU action understanding under https://iv.ee.hm.edu/bikeactions/.

</details>


### [38] [Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning](https://arxiv.org/abs/2601.10537)
*Oscar H. Ramírez-Agudelo,Akshay N. Shewatkar,Edoardo Milana,Roland C. Aydin,Kai Franke*

Main category: cs.CV

TL;DR: 本文提出利用深度学习模型（FFA-Net和AECR-Net）增强烟雾和雾霾环境下模拟仪表图像的可视性，通过构建包含14,000多张合成图像的数据集进行训练，结果表明AECR-Net在去雾任务中表现更优，且增强后的图像可有效支持自动读表。


<details>
  <summary>Details</summary>
Motivation: 在烟雾和雾霾环境中拍摄的图像可见度降低，影响基础设施监控和应急响应，尤其阻碍对模拟仪表的自动读取。现有方法难以有效处理此类图像，且缺乏相关基准数据集。

Method: 使用Unreal Engine生成包含14,000多张图像的合成数据集，涵盖轻度至重度雾霾和烟雾；采用FFA-Net和AECR-Net两种深度学习架构进行图像增强，并按80%/10%/10%划分训练、验证和测试集；通过SSIM和PSNR指标评估性能。

Result: 在合成雾霾数据集上，模型达到SSIM约0.98、PSNR约43 dB，接近当前最优水平，其中AECR-Net表现更稳健；在烟雾数据集上效果较差，因烟雾具有非均匀性和高密度，且模型原为去雾设计；增强后的图像可用于后续自动读表。

Conclusion: 深度学习架构能显著提升烟雾和雾霾场景下模拟仪表图像的质量，为应急响应中的自动读表提供可行方案，但针对烟雾的专用模型仍有改进空间。

Abstract: Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-Net, to improve the visibility of gauge images, corrupted with light up to dense haze and smoke. Since benchmark datasets of analog gauge images are unavailable, a new synthetic dataset, containing over 14,000 images, was generated using the Unreal Engine. The models were trained with an 80\% train, 10\% validation, and 10\% test split for the haze and smoke dataset, respectively. For the synthetic haze dataset, the SSIM and PSNR metrics are about 0.98 and 43\,dB, respectively, comparing well to state-of-the art results. Additionally, more robust results are retrieved from the AECR-Net, when compared to the FFA-Net. Although the results from the synthetic smoke dataset are poorer, the trained models achieve interesting results. In general, imaging in the presence of smoke are more difficult to enhance given the inhomogeneity and high density. Secondly, FFA-Net and AECR-Net are implemented to dehaze and not to desmoke images. This work shows that use of deep learning architectures can improve the quality of analog gauge images captured in smoke and haze scenes immensely. Finally, the enhanced output images can be successfully post-processed for automatic autonomous reading of gauges

</details>


### [39] [Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure](https://arxiv.org/abs/2601.10551)
*Luxuan Fu,Chong Liu,Bisheng Yang,Zhen Dong*

Main category: cs.CV

TL;DR: 本文提出了一种面向城市道路基础设施感知的领域自适应框架，通过结合高效微调与知识引导推理，提升大视觉语言模型在工程规范下的细粒度属性识别能力。


<details>
  <summary>Details</summary>
Motivation: 通用模型难以准确捕捉城市道路基础设施所需的细粒度属性和领域规则，而现有大视觉语言模型虽具开放世界识别能力，但在复杂设施状态理解及工程标准合规性方面表现不可靠。

Method: 该方法结合了数据高效的微调策略与知识引导的推理机制：首先在Grounding DINO上进行开放词汇微调以实现多样资产的鲁棒定位；然后基于LoRA对Qwen-VL进行适配，用于深层语义属性推理；并引入双模态检索增强生成（RAG）模块，在推理时动态检索权威行业标准与视觉示例，以减少幻觉并确保专业合规。

Result: 在新构建的城市道路场景数据集上评估，该框架实现了58.9 mAP的检测性能和95.5%的属性识别准确率。

Conclusion: 所提框架为智能基础设施监测提供了一种可靠且高效的解决方案，显著提升了大视觉语言模型在专业领域任务中的准确性与合规性。

Abstract: Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framework that transforms VLMs into specialized agents for intelligent infrastructure analysis. Our approach integrates a data-efficient fine-tuning strategy with a knowledge-grounded reasoning mechanism. Specifically, we leverage open-vocabulary fine-tuning on Grounding DINO to robustly localize diverse assets with minimal supervision, followed by LoRA-based adaptation on Qwen-VL for deep semantic attribute reasoning. To mitigate hallucinations and enforce professional compliance, we introduce a dual-modality Retrieval-Augmented Generation (RAG) module that dynamically retrieves authoritative industry standards and visual exemplars during inference. Evaluated on a comprehensive new dataset of urban roadside scenes, our framework achieves a detection performance of 58.9 mAP and an attribute recognition accuracy of 95.5%, demonstrating a robust solution for intelligent infrastructure monitoring.

</details>


### [40] [Inference-time Physics Alignment of Video Generative Models with Latent World Models](https://arxiv.org/abs/2601.10553)
*Jianhao Yuan,Xiaofeng Zhang,Felix Friedrich,Nicolas Beltran-Velez,Melissa Hall,Reyhane Askari-Hemmat,Xiaochuang Han,Nicolas Ballas,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: 本文提出WMReward方法，利用潜在世界模型（VJEPA-2）作为奖励信号，在推理阶段对多个去噪轨迹进行搜索与引导，从而提升视频生成的物理合理性，并在多个条件生成设置和PhysicsIQ挑战赛中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视频生成模型虽然能生成高质量视觉内容，但常违反基本物理规律，限制了其实际应用。作者认为这一问题不仅源于预训练阶段对物理理解不足，也与次优的推理策略有关。

Method: 将提升物理合理性视为推理时对齐问题，引入WMReward框架，利用潜在世界模型VJEPA-2提供的强物理先验作为奖励信号，在测试时对多个候选去噪轨迹进行搜索与引导，以增加计算资源投入来提升生成质量。

Result: 在图像条件、多帧条件和文本条件视频生成任务中显著提升了物理合理性；人类偏好研究验证了效果；在ICCV 2025 PhysicsIQ挑战赛中以62.64%得分获得第一名，超越前SOTA 7.42%。

Conclusion: 利用潜在世界模型作为推理阶段的奖励机制，可有效提升视频生成的物理合理性，该思路具有通用性，不局限于特定模型或参数化方式。

Abstract: State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization.

</details>


### [41] [DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery](https://arxiv.org/abs/2601.10554)
*Constantin Selzer,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 本文提出了DeepUrban，一个由无人机在城市密集交叉路口采集的高分辨率3D交通数据集，旨在提升自动驾驶系统在复杂交通场景下的轨迹预测与规划能力，并验证了其对现有基准（如nuScenes）的显著增强效果。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶预测与规划的基准缺乏密集交通场景，难以充分建模道路使用者之间的复杂交互，因此亟需更贴近真实城市环境的数据集。

Method: 与工业伙伴DeepScenario合作，利用约100米高空无人机拍摄高分辨率图像，构建包含3D交通对象、地图及场景信息的DeepUrban数据集，并在该数据集上评估SOTA预测与规划方法的性能和泛化能力。

Result: 将DeepUrban加入nuScenes后，车辆轨迹预测与规划的ADE/FDE指标分别提升高达44.1%和44.3%。

Conclusion: DeepUrban有效填补了密集城市交通场景数据的空白，显著提升了现有模型的预测与规划准确性，为自动驾驶系统在复杂环境中的发展提供了有力支持。

Abstract: The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban

</details>


### [42] [Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation](https://arxiv.org/abs/2601.10577)
*Serena Grazia De Benedictis,Amedeo Altavilla,Nicoletta Del Buono*

Main category: cs.CV

TL;DR: 本文提出了一种基于Jordan曲线定理的拓扑感知图像分割评估方法，通过数字拓扑和同调理论定义“Jordan可分割掩码”，以判断分割结果是否在拓扑上将图像划分为两个连通区域，从而弥补传统指标在结构和拓扑一致性评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统图像分割评估指标（如像素级、区域级或边界级）难以捕捉分割结果的结构与拓扑一致性，尤其在医学图像等场景中，即使分割存在边界错误、孔洞或碎片化，仍可能获得高分，但其整体形状或连通性已失真。

Method: 作者引入基于Jordan曲线定理的拓扑感知分割概念，定义“Jordan可分割掩码”：该二值掩码能将图像域拓扑分离为两个连通分量。通过数字拓扑与同调理论，从掩码中提取4-曲线候选，并利用Betti数（β₀ = β₁ = 1）或其补集恰好包含两个8-连通分量来验证其拓扑有效性。

Result: 所提框架提供了一种数学上严谨且无需监督的分割掩码结构一致性评估标准，能够有效识别分割结果是否在拓扑上正确划分图像的内外区域。

Conclusion: 结合数字Jordan理论与同调不变量，该方法为图像分割评估提供了一种重视拓扑正确性的新范式，特别适用于对拓扑结构敏感的应用场景。

Abstract: Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions.
  In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components.
  This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved.

</details>


### [43] [RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation](https://arxiv.org/abs/2601.10606)
*Peng Chen,Xiaobao Wei,Yi Yang,Naiming Yao,Hui Chen,Feng Tian*

Main category: cs.CV

TL;DR: RSATalker 是首个基于 3D Gaussian Splatting（3DGS）的多轮对话虚拟人生成框架，兼顾高保真视觉效果与社交关系建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在虚拟现实中生成对话虚拟人时存在局限：基于网格的3D方法缺乏真实纹理，而基于大模型的2D方法计算成本过高；近期基于3DGS的方法虽高效逼真，但仅支持单人说话且忽略社交关系。

Method: RSATalker 首先从语音驱动网格面部运动，再将3D高斯绑定到网格面片以渲染高质量2D视频；引入社交感知模块，通过可学习查询机制将血缘/非血缘、平等/不平等等社交关系编码为高层嵌入；采用三阶段训练策略，并构建包含语音-网格-图像三元组及社交标签的RSATalker数据集。

Result: 大量实验表明，RSATalker 在真实感和社交感知方面均达到当前最优水平。

Conclusion: RSATalker 成功将3DGS应用于支持多轮对话且具备社交意识的虚拟人生成，兼具高真实感与社交建模能力，代码与数据集将开源。

Abstract: Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released.

</details>


### [44] [Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding](https://arxiv.org/abs/2601.10611)
*Christopher Clark,Jieyu Zhang,Zixian Ma,Jae Sung Park,Mohammadreza Salehi,Rohun Tripathi,Sangho Lee,Zhongzheng Ren,Chris Dongjoo Kim,Yinuo Yang,Vincent Shao,Yue Yang,Weikai Huang,Ziqi Gao,Taira Anderson,Jianrui Zhang,Jitesh Jain,George Stoica,Winson Han,Ali Farhadi,Ranjay Krishna*

Main category: cs.CV

TL;DR: 本文提出了Molmo2，一个开源的视频-语言模型家族，在单图、多图和视频任务中展现出领先的点驱动定位能力。其核心贡献包括7个新视频数据集和2个多图数据集，以及一种高效的训练方法。Molmo2在多个基准上超越现有开源模型，甚至在部分任务上优于如Gemini 3 Pro等闭源模型。


<details>
  <summary>Details</summary>
Motivation: 当前最强的视频-语言模型（VLMs）大多为闭源，而开源模型要么依赖闭源模型生成的合成数据，要么未公开训练数据和方法，导致社区难以推进技术进步。此外，许多下游应用需要像素级的定位能力（如指向或追踪），但即使是闭源模型也缺乏这一能力。

Method: 作者构建了7个新的视频数据集和2个多图像数据集，涵盖详细视频字幕、自由形式问答、复杂查询的对象追踪和视频指向任务，且未使用任何闭源VLM。同时提出了一种结合高效打包与消息树编码的训练方案，并采用视觉token上的双向注意力机制及新颖的token加权策略。

Result: Molmo2的8B模型在短视频、计数和字幕任务上优于同类开源模型，在长视频任务上具有竞争力。在视频定位任务中，其在视频计数（35.5 vs 29.6）、视频指向（F1: 38.4 vs 20.0）和视频追踪（J&F: 56.2 vs 41.1）等指标上显著超越Qwen3-VL，并在部分任务上超过Gemini 3 Pro。

Conclusion: Molmo2为开源社区提供了高质量的视频-语言模型基础，不仅在多项任务中达到或超越现有开源和部分闭源模型水平，还通过新数据集和训练方法推动了像素级视频理解能力的发展。

Abstract: Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).

</details>


### [45] [CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos](https://arxiv.org/abs/2601.10632)
*Chengfeng Zhao,Jiazhi Shu,Yubo Zhao,Tianyu Huang,Jiahao Lu,Zekai Gu,Chengwei Ren,Zhiyang Dou,Qing Shuai,Yuan Liu*

Main category: cs.CV

TL;DR: 本文提出CoMoVi，一种耦合式生成框架，通过联合两个视频扩散模型，在单一去噪过程中同步生成3D人体动作与2D人体视频，并构建了大规模带文本和动作标注的CoMoVi数据集。


<details>
  <summary>Details</summary>
Motivation: 3D人体动作为视频提供结构先验以保证合理性和一致性，而预训练视频模型在动作生成上具有强大泛化能力，因此有必要将两者生成过程耦合。

Method: 提出一种有效的2D人体动作表示方法以继承预训练视频扩散模型（VDM）的先验；设计双分支扩散模型，通过特征交互和3D-2D交叉注意力机制耦合动作与视频生成；构建包含多样复杂人体动作的大规模CoMoVi数据集。

Result: 大量实验表明，该方法在3D人体动作生成和2D视频生成任务中均具有优越性能。

Conclusion: CoMoVi通过耦合3D动作与2D视频的生成过程，有效利用彼此优势，显著提升了生成质量与一致性。

Abstract: In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks.

</details>


### [46] [CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning](https://arxiv.org/abs/2601.10649)
*Darshan Singh,Arsha Nagrani,Kawshik Manikantan,Harman Singh,Dinesh Tewari,Tobias Weyand,Cordelia Schmid,Anelia Angelova,Shachi Dave*

Main category: cs.CV

TL;DR: 本文提出了CURVE，一个面向多文化、多语言视频理解的新基准，包含18个地区的人工标注数据，强调对视觉文化语境的深入理解，并揭示当前视频大模型在此类任务上的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要基于西方中心的数据和英语，存在显著评估偏差，缺乏对多元文化和多语言场景的支持。

Method: 构建名为CURVE的基准数据集，涵盖18个全球地区的本土文化视频，所有问题、答案和多步推理均由母语者人工生成；并利用推理轨迹构建证据图，提出一种基于图的迭代策略以识别细粒度推理错误。

Result: 当前最先进的视频大语言模型在CURVE上表现远低于人类水平，主要错误源于对文化视觉元素的感知不足。

Conclusion: CURVE为多文化、多语言视频理解提供了高质量评估基准，揭示了现有模型在文化情境理解方面的局限性，并为未来研究提供了新方向。

Abstract: Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\#minerva-cultural

</details>


### [47] [A continental-scale dataset of ground beetles with high-resolution images and validated morphological trait measurements](https://arxiv.org/abs/2601.10687)
*S M Rayeed,Mridul Khurana,Alyson East,Isadora E. Fluck,Elizabeth G. Campolongo,Samuel Stevens,Iuliia Zarubiieva,Scott C. Lowe,Michael W. Denslow,Evan D. Donoso,Jiaman Wu,Michelle Ramirez,Benjamin Baiser,Charles V. Stewart,Paula Mabee,Tanya Berger-Wolf,Anuj Karpatne,Hilmar Lapp,Robert P. Guralnick,Graham W. Taylor,Sydne Record*

Main category: cs.CV

TL;DR: 该研究通过高分辨率成像对13,200多个NEON地面甲虫标本进行数字化，构建了一个包含鞘翅长度和宽度的多模态数据集，实现了亚毫米精度的自动性状提取，填补了无脊椎动物在性状数据库中的代表性不足，支持基于AI的物种识别与生物多样性研究。


<details>
  <summary>Details</summary>
Motivation: 全球性状数据库严重偏向脊椎动物和植物，限制了对高多样性无脊椎动物（如地面甲虫）的生态分析；同时，NEON收集的大量甲虫标本以物理形式存在，难以广泛用于研究和大规模分析。

Method: 利用高分辨率成像技术对来自美国大陆及夏威夷30个站点的13,200多个NEON地面甲虫标本进行数字化，并通过数字测量获取每只标本的鞘翅长度和宽度，建立可用于AI自动性状提取的数据集。

Result: 数字性状提取方法经手动测量验证，达到亚毫米级精度，为生态学和计算研究提供了可靠数据基础。

Conclusion: 该研究通过构建高质量、可计算的甲虫性状数据集，缓解了无脊椎动物在性状数据库中的代表性不足问题，推动了AI驱动的物种识别与基于性状的生物多样性监测与保护研究。

Abstract: Despite the ecological significance of invertebrates, global trait databases remain heavily biased toward vertebrates and plants, limiting comprehensive ecological analyses of high-diversity groups like ground beetles. Ground beetles (Coleoptera: Carabidae) serve as critical bioindicators of ecosystem health, providing valuable insights into biodiversity shifts driven by environmental changes. While the National Ecological Observatory Network (NEON) maintains an extensive collection of carabid specimens from across the United States, these primarily exist as physical collections, restricting widespread research access and large-scale analysis. To address these gaps, we present a multimodal dataset digitizing over 13,200 NEON carabids from 30 sites spanning the continental US and Hawaii through high-resolution imaging, enabling broader access and computational analysis. The dataset includes digitally measured elytra length and width of each specimen, establishing a foundation for automated trait extraction using AI. Validated against manual measurements, our digital trait extraction achieves sub-millimeter precision, ensuring reliability for ecological and computational studies. By addressing invertebrate under-representation in trait databases, this work supports AI-driven tools for automated species identification and trait-based research, fostering advancements in biodiversity monitoring and conservation.

</details>


### [48] [See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection](https://arxiv.org/abs/2601.10707)
*Amir Mallak,Erfan Aasi,Shiva Sreeram,Tsun-Hsuan Wang,Daniela Rus,Alaa Maalouf*

Main category: cs.CV

TL;DR: 本文提出了一种名为随机Patch选择（SPS）的新方法，通过在训练过程中随机屏蔽部分图像块特征，减少冗余信息对策略模型的影响，从而提升端到端自动驾驶系统在分布外（OOD）场景下的鲁棒性、泛化能力和推理效率。实验表明该方法在多个OOD场景中显著优于现有最优方法，并能直接迁移到真实车辆上。


<details>
  <summary>Details</summary>
Motivation: 现有基于基础模型提取的patch对齐特征训练的自动驾驶策略虽然在分布外（OOD）场景中表现较好，但这些特征由于自注意力机制存在高度冗余，导致策略容易过拟合虚假相关性，降低OOD鲁棒性。

Method: 提出Stochastic-Patch-Selection（SPS）方法：在每一帧中随机屏蔽一部分patch描述符，仅将剩余patch输入策略模型，同时保留其空间布局。这样使策略在训练中面对同一场景的不同随机但完整的视图，从而学习对特定token缺失不变的特征。

Result: 在所有OOD场景中均优于当前最优方法，平均提升6.2%，在闭环仿真中最高提升达20.4%；推理速度提升2.4倍；9个消融实验中有8个超越SOTA；且无需微调即可迁移到真实车辆上。

Conclusion: 通过减少patch特征冗余并引入随机性，SPS有效提升了端到端自动驾驶策略的OOD鲁棒性、泛化能力与效率，且具有良好的现实迁移能力。

Abstract: Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.

</details>


### [49] [From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion](https://arxiv.org/abs/2601.10710)
*Cheng Chen,Yuyu Guo,Pengpeng Zeng,Jingkuan Song,Peng Di,Hang Yu,Lianli Gao*

Main category: cs.CV

TL;DR: 本文提出了一种名为跨层注入（CLI）的轻量级框架，通过在视觉编码器和大语言模型之间建立动态多对多连接，显著提升了视觉-语言模型的多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）采用静态且不对称的连接方式，仅将视觉编码器的输出连接到大语言模型（LLM）的输入，导致严重的视觉特征瓶颈，限制了LLM与分层视觉知识的全面对齐，难以将局部细节与全局语义有效融合进行连贯推理。

Method: 作者提出了Cross-Layer Injection (CLI)框架，包含两个参数高效的组件：自适应多投影（AMP）模块用于协调来自不同视觉层的特征，以及自适应门控融合（AGF）机制，使LLM能根据实时解码上下文选择性地注入最相关的视觉信息。

Result: 在LLaVA-OneVision和LLaVA-1.5中集成CLI后，在18个多样化基准测试上均取得了显著的性能提升。

Conclusion: CLI作为一种可扩展的范式，通过赋予大语言模型按需访问完整视觉层次结构的能力，有效解锁了更深层次的多模态理解。

Abstract: Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy.

</details>


### [50] [Alterbute: Editing Intrinsic Attributes of Objects in Images](https://arxiv.org/abs/2601.10714)
*Tal Reiss,Daniel Winter,Matan Cohen,Alex Rav-Acha,Yael Pritch,Ariel Shamir,Yedid Hoshen*

Main category: cs.CV

TL;DR: Alterbute 是一种基于扩散模型的对象内在属性编辑方法，可在保留对象身份和场景上下文的前提下，灵活修改颜色、纹理、材质甚至形状。


<details>
  <summary>Details</summary>
Motivation: 现有方法在编辑对象内在属性时，要么依赖无法有效保持身份的无监督先验，要么使用过于严格的监督信号，限制了有意义的内在变化。因此，需要一种既能保留身份又能支持丰富内在属性编辑的新方法。

Method: Alterbute 采用（i）一种宽松的训练目标，利用身份参考图像、描述目标内在属性的文本提示以及定义外在上下文的背景图像和对象掩码进行条件生成；推理时复用原始背景和掩码以限制外在变化；（ii）引入视觉命名实体（VNEs），即细粒度的视觉身份类别（如“保时捷911 Carrera”），通过视觉-语言模型从大规模公开图像数据集中自动提取 VNE 标签和内在属性描述，实现可扩展的身份保留监督。

Result: Alterbute 在保持身份的对象内在属性编辑任务上优于现有方法。

Conclusion: Alterbute 成功实现了在保留对象身份和场景上下文的同时，对颜色、纹理、材质和形状等内在属性进行灵活且高质量的编辑，显著优于现有技术。

Abstract: We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.

</details>


### [51] [WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments](https://arxiv.org/abs/2601.10716)
*Xuweiyi Chen,Wentao Zhou,Zezhou Cheng*

Main category: cs.CV

TL;DR: WildRayZer 是一个用于动态环境中新视角合成的自监督框架，通过分析静态渲染残差来识别并处理瞬态区域，从而提升背景重建质量，并在新数据集 D-RE10K 上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 动态场景中相机与物体同时运动破坏了传统静态新视角合成方法所依赖的多视角一致性，导致鬼影、几何幻觉和姿态估计不稳定等问题。

Method: WildRayZer 采用分析-合成策略：先用仅相机运动的静态渲染器建模刚性结构，从其残差中生成伪运动掩码，进而训练运动估计器；该估计器用于屏蔽输入 token 并控制损失梯度，使监督信号聚焦于跨视角背景补全。

Result: 在新构建的真实世界动态数据集 D-RE10K 和 D-RE10K-iPhone 上，WildRayZer 在瞬态区域去除和整体新视角合成质量方面均优于现有优化型和前馈型基线方法，且仅需单次前馈推理。

Conclusion: WildRayZer 有效解决了动态场景中新视角合成的挑战，通过自监督方式实现对瞬态内容的鲁棒处理，显著提升了合成图像的质量与稳定性。

Abstract: We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [AI Survival Stories: a Taxonomic Analysis of AI Existential Risk](https://arxiv.org/abs/2601.09765)
*Herman Cappelen,Simon Goldstein,John Hawthorne*

Main category: cs.AI

TL;DR: 本文构建了一个分析AI存在性风险的框架，基于“AI将变得极其强大”和“若AI极其强大则会毁灭人类”两个前提，提出多种人类存续的情景，并据此评估AI导致人类毁灭的概率（P(doom)）。


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否对人类构成存在性威胁，并为理解与应对该风险提供系统性分析框架。

Method: 通过分析两个核心前提，构建一个关于人类长期存续的分类体系（taxonomy of survival stories），每种情景对应其中一个前提不成立，并据此讨论不同情景所面临的挑战、应对手段及对P(doom)的粗略估计。

Result: 识别出多种人类存续路径，包括科学限制、政策禁止、AI目标对齐、可靠检测与控制等；指出不同路径面临不同挑战并支持不同应对策略；并基于此框架给出对AI毁灭人类概率的初步估计。

Conclusion: AI存在性风险高度依赖于两个关键前提是否成立，通过系统分类存续情景可更清晰地评估风险并制定相应对策，从而为降低P(doom)提供理论依据。

Abstract: Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pose a threat to humanity. Premise one: AI systems will become extremely powerful. Premise two: if AI systems become extremely powerful, they will destroy humanity. We use these two premises to construct a taxonomy of survival stories, in which humanity survives into the far future. In each survival story, one of the two premises fails. Either scientific barriers prevent AI systems from becoming extremely powerful; or humanity bans research into AI systems, thereby preventing them from becoming extremely powerful; or extremely powerful AI systems do not destroy humanity, because their goals prevent them from doing so; or extremely powerful AI systems do not destroy humanity, because we can reliably detect and disable systems that have the goal of doing so. We argue that different survival stories face different challenges. We also argue that different survival stories motivate different responses to the threats from AI. Finally, we use our taxonomy to produce rough estimates of P(doom), the probability that humanity will be destroyed by AI.

</details>


### [53] [GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents](https://arxiv.org/abs/2601.09770)
*Chen Chen,Jiawei Shao,Dakuan Lu,Haoyi Hu,Xiangcheng Liu,Hantao Yao,Wu Liu*

Main category: cs.AI

TL;DR: 本文提出GUI-Eyes，一种用于GUI任务中主动视觉感知的强化学习框架，通过两阶段策略决策是否及如何使用视觉工具（如裁剪、缩放），并结合空间连续奖励函数，在ScreenSpot-Pro基准上以仅3k标注样本达到44.8%的定位准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI自动化方法多依赖静态单帧视觉输入和被动感知，缺乏自适应决定何时、是否以及如何观察界面的能力。

Method: 提出GUI-Eyes框架，采用两阶段推理过程：粗粒度探索与细粒度定位，由两级策略协调；引入渐进式感知策略，并设计结合位置接近度与区域重叠的空间连续奖励函数，以提供密集监督信号。

Result: 在ScreenSpot-Pro基准上，GUI-Eyes-3B仅用3k标注样本即达到44.8%的定位准确率，显著优于监督学习和强化学习基线。

Conclusion: 具备工具意识的主动感知机制，结合分阶段策略推理与细粒度奖励反馈，对构建鲁棒且数据高效的GUI智能体至关重要。

Abstract: Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether, and how to observe the interface. We present GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. To acquire more informative observations, the agent learns to make strategic decisions on both whether and how to invoke visual tools, such as cropping or zooming, within a two-stage reasoning process. To support this behavior, we introduce a progressive perception strategy that decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. In addition, we design a spatially continuous reward function tailored to tool usage, which integrates both location proximity and region overlap to provide dense supervision and alleviate the reward sparsity common in GUI environments. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, significantly outperforming both supervised and RL-based baselines. These results highlight that tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, is critical for building robust and data-efficient GUI agents.

</details>


### [54] [Antisocial behavior towards large language model users: experimental evidence](https://arxiv.org/abs/2601.09772)
*Paweł Niszczota,Cassandra Grützner*

Main category: cs.AI

TL;DR: 该研究通过在线实验发现，人们会实际惩罚那些使用大语言模型（LLM）完成任务的同伴，且惩罚程度随LLM使用程度增加而上升，表明LLM带来的效率提升可能伴随社会性代价。


<details>
  <summary>Details</summary>
Motivation: 探究人们对使用大语言模型（LLM）行为的社会反应是否仅停留在态度层面，还是会转化为有实际成本的惩罚行为。

Method: 采用两阶段在线实验（第二阶段参与者N=491），参与者可花费自身收益来减少曾借助或未借助LLM完成真实任务的同伴的收入，以此衡量惩罚行为。

Result: 平均而言，参与者摧毁了完全依赖LLM者36%的收入；惩罚随实际LLM使用程度单调递增；自我报告未使用者比实际未使用者受罚更重，而在高使用水平下，实际使用比自报使用受罚更重。

Conclusion: 研究首次提供了行为证据，表明大语言模型带来的效率收益可能以遭受社会制裁为代价。

Abstract: The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this question in a two-phase online experiment (N = 491 Phase II participants; Phase I provided targets) where participants could spend part of their own endowment to reduce the earnings of peers who had previously completed a real-effort task with or without LLM support. On average, participants destroyed 36% of the earnings of those who relied exclusively on the model, with punishment increasing monotonically with actual LLM use. Disclosure about LLM use created a credibility gap: self-reported null use was punished more harshly than actual null use, suggesting that declarations of "no use" are treated with suspicion. Conversely, at high levels of use, actual reliance on the model was punished more strongly than self-reported reliance. Taken together, these findings provide the first behavioral evidence that the efficiency gains of LLMs come at the cost of social sanctions.

</details>


### [55] [Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention](https://arxiv.org/abs/2601.09805)
*Nguyen Minh Phuong,Dang Huu Tien,Naoya Inoue*

Main category: cs.AI

TL;DR: 本文提出了一种非交互式的端到端逻辑推理框架，通过在少样本提示中引入结构信息激活与逻辑运算符对齐的注意力头，并在此基础上设计了推理时的注意力干预方法AAI，有效提升了大语言模型在多种逻辑推理任务上的性能，且计算开销极低。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的逻辑推理方法多依赖复杂的交互式框架或外部资源（如符号求解器），前者带来额外开销，后者限制了可扩展性。因此，亟需一种无需外部组件、能内生于模型本身的高效推理机制。

Method: 作者提出Attention-Aware Intervention（AAI）方法：首先在少样本提示中嵌入结构信息以激活与逻辑推理算子对齐的特定注意力头；然后在推理阶段对这些被识别出的注意力头进行注意力分数重加权，从而引导模型利用先验知识进行推理。

Result: 大量实验表明，AAI方法在多种逻辑推理基准和不同模型架构上均显著提升了推理性能，同时仅带来可忽略不计的额外计算开销。

Conclusion: 该工作证明了通过在提示中引入结构信息并结合注意力干预，可以在不依赖外部工具的情况下有效增强大语言模型的逻辑推理能力，为构建高效、可分析且可扩展的推理系统提供了新思路。

Abstract: Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While interactive approaches introduce additional overhead, hybrid approaches depend on external components, which limit their scalability. A non-interactive, end-to-end framework enables reasoning to emerge within the model itself -- improving generalization while preserving analyzability without any external resources. In this work, we introduce a non-interactive, end-to-end framework for reasoning tasks. We show that introducing structural information into the few-shot prompt activates a subset of attention heads that patterns aligned with logical reasoning operators. Building on this insight, we propose Attention-Aware Intervention (AAI), an inference-time intervention method that reweights attention scores across selected heads identified by their logical patterns. AAI offers an efficient way to steer the model's reasoning toward leveraging prior knowledge through attention modulation. Extensive experiments show that AAI enhances logical reasoning performance across diverse benchmarks and model architectures, while incurring negligible additional computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.

</details>


### [56] [Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models](https://arxiv.org/abs/2601.09855)
*Michael R. Metel,Yufei Cui,Boxing Chen,Prasanna Parthasarathi*

Main category: cs.AI

TL;DR: 本文提出了一种名为Min-Seek的新型序列测试时缩放方法，通过仅在KV缓存中保留一个额外诱导思维的KV对，并采用无位置嵌入的自定义KV缓存机制，显著提升大推理模型在多种任务上的准确率，同时保持稳定性、避免精度下降，并实现线性计算复杂度和超越模型最大上下文长度的持续推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的序列测试时缩放方法虽能通过延长模型推理过程提升准确率，但存在推理过长导致准确率下降和模型不稳定的问题，且需对推理长度进行精细调优。因此，亟需一种既能提升准确率又具备稳定性和效率的新方法。

Method: 提出Min-Seek方法：在推理过程中仅将一个额外诱导思维的KV对保留在KV缓存中；设计一种不存储位置嵌入的自定义KV缓存，在每次生成新思维前动态连续编码位置信息。

Result: Min-Seek在广泛诱导思维长度范围内显著提升模型准确率，稳定了序列缩放的性能，无需推理长度微调；同时具备高效性，可在温和条件下实现线性计算复杂度，并支持超越模型最大上下文长度的推理。

Conclusion: Min-Seek是一种高效、稳定且无需训练的序列测试时缩放方法，有效解决了现有方法在长推理过程中准确率下降和不稳定性问题，同时突破了上下文长度限制，具有良好的可扩展性和实用性。

Abstract: Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reasoning is further extended, it has also been shown to result in accuracy degradation and model instability. This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling, and removing the need for reasoning length fine-tuning. Beyond improving model accuracy over a variety of reasoning tasks, our method is inherently efficient, as only the KV pairs of one additional induced thought are kept in the KV cache during reasoning. With a custom KV cache which stores keys without position embeddings, by dynamically encoding them contiguously before each new generated thought, our method can continue to reason well beyond a model's maximum context length, and under mild conditions has linear computational complexity.

</details>


### [57] [Epistemology gives a Future to Complementarity in Human-AI Interactions](https://arxiv.org/abs/2601.09871)
*Andrea Ferrario,Alessandro Facchini,Juan M. Durán*

Main category: cs.AI

TL;DR: 本文通过认识论视角重新阐释人机互补性，将其定位为可靠认知过程的证据，而非仅作为预测准确性的相对指标，从而提升其在实际人机协作中的理论价值与可操作性。


<details>
  <summary>Details</summary>
Motivation: 人机互补性概念虽广受关注，但缺乏明确的理论基础，仅被用作事后预测准确性的指标，且忽视了人机交互中的其他重要目标及性能增益的成本效益问题，导致实证研究中难以实现。

Method: 作者借助认识论，特别是计算可靠主义（computational reliabilism），将互补性置于“证成性AI”（justificatory AI）的框架下进行重构，将其视为人机协作是否构成可靠认知过程的证据之一。

Result: 该方法表明，互补性与其他可靠性指标共同评估人机团队是否符合特定任务的认知标准与社会技术实践，从而为受AI决策影响的相关方提供实践推理依据。

Conclusion: 互补性的真正价值不在于衡量预测准确性，而在于帮助校准决策，使其与日益影响日常生活的AI支持过程的可靠性相一致。

Abstract: Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offering a more practical alternative to the contested construct of 'trust in AI.' Yet complementarity faces key theoretical challenges: it lacks precise theoretical anchoring, it is formalized just as a post hoc indicator of relative predictive accuracy, it remains silent about other desiderata of human-AI interactions and it abstracts away from the magnitude-cost profile of its performance gain. As a result, complementarity is difficult to obtain in empirical settings. In this work, we leverage epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, we argue that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a given predictive task. Together with other reliability indicators assessing the alignment of the human-AI team with the epistemic standards and socio-technical practices, complementarity contributes to the degree of reliability of human-AI teams when generating predictions. This supports the practical reasoning of those affected by these outputs -- patients, managers, regulators, and others. In summary, our approach suggests that the role and value of complementarity lies not in providing a relative measure of predictive accuracy, but in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.

</details>


### [58] [Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL](https://arxiv.org/abs/2601.09883)
*Xinxing Ren,Quagmire Zang,Caelum Forder,Suman Deb,Ahsen Tahir,Roman J. Georgio,Peter Carroll,Zekun Guo*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息流协调的多智能体新范式（CORAL），通过自然语言实现智能体间动态通信与任务协调，无需预定义工作流，在GAIA基准上显著优于现有基于规则的工作流方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统大多依赖人工预定义的工作流和状态规则，难以覆盖复杂现实任务的所有可能状态，且需要大量人工干预。为克服这些局限，作者提出一种无需预设流程、能动态协调智能体的新范式。

Method: 引入一个专用的信息流协调器，持续监控任务进展，并通过Agent-to-Agent（A2A）通信工具包以自然语言动态协调其他智能体，摒弃了传统预定义工作流的设计。

Result: 在GAIA通用基准测试中，该方法在pass@1设置下达到63.64%的准确率，比基线系统OWL（55.15%）高出8.49个百分点，且在相近的token消耗下表现出更强的边缘案例处理能力和任务监控灵活性。

Conclusion: 所提出的CORAL范式有效突破了传统规则驱动多智能体系统的局限，展示了通过自然语言动态协调智能体在复杂任务中的优越性与可行性。

Abstract: Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which suffer from two fundamental limitations: they require substantial manual effort to anticipate and encode possible task states, and they cannot exhaustively cover the state space of complex real-world tasks. To address these issues, we propose an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, in which a dedicated information flow orchestrator continuously monitors task progress and dynamically coordinates other agents through the A2A toolkit using natural language, without relying on predefined workflows. We evaluate our approach on the general-purpose benchmark GAIA, using the representative workflow-based MAS OWL as the baseline while controlling for agent roles and underlying models. Under the pass@1 setting, our method achieves 63.64% accuracy, outperforming OWL's 55.15% by 8.49 percentage points with comparable token consumption. Further case-level analysis shows that our paradigm enables more flexible task monitoring and more robust handling of edge cases. Our implementation is publicly available at: https://github.com/Coral-Protocol/Beyond-Rule-Based-Workflows

</details>


### [59] [Generative AI collective behavior needs an interactionist paradigm](https://arxiv.org/abs/2601.10567)
*Laura Ferrarotti,Gian Maria Campedelli,Roberto Dessì,Andrea Baronchelli,Giovanni Iacca,Kathleen M. Carley,Alex Pentland,Joel Z. Leibo,James Evans,Bruno Lepri*

Main category: cs.AI

TL;DR: 本文主张理解基于大语言模型（LLM）的智能体集体行为至关重要，需建立一种交互主义范式，整合新的理论、方法和跨学科对话，以系统研究先验知识、内嵌价值观与社会情境如何共同塑造多智能体生成式AI系统中的涌现现象。


<details>
  <summary>Details</summary>
Motivation: 大语言模型具备预训练知识、隐含社会先验及上下文学习能力，其独特性质使得传统分析框架不足以解释其在多智能体系统中的集体行为，因此亟需新的研究范式。

Method: 提出一种交互主义研究范式，强调结合替代性的理论基础、方法论和分析工具，并倡导在理论、方法和跨学科对话三个维度推进研究。

Result: 明确了四个关键研究方向，为LLM驱动的智能体集体系统的开发与部署提供指导框架。

Conclusion: 为有效理解和引导LLM集体行为所带来的社会风险与机遇，必须发展融合先验知识、价值观与社会互动的新研究路径。

Abstract: In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.

</details>


### [60] [Continuum Memory Architectures for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.09913)
*Joe Logan*

Main category: cs.AI

TL;DR: 本文提出了一种名为“连续记忆架构”（CMA）的新范式，以克服传统检索增强生成（RAG）在长期记忆管理上的局限性，通过持久存储、选择性保留、关联路由、时间链和抽象整合等机制，使大语言模型具备持续演化的记忆能力。


<details>
  <summary>Details</summary>
Motivation: RAG 将记忆视为无状态的查找表，无法支持信息的累积、更新或消歧，限制了大语言模型在长期交互任务中的表现。因此，需要一种能维护和更新内部状态的记忆架构。

Method: 作者定义了连续记忆架构（CMA），其核心机制包括持久存储、选择性保留、关联路由、时间链以及向高阶抽象的整合，并通过行为实验验证其优势，而非聚焦具体实现细节。

Result: 在知识更新、时间关联、关联回忆和上下文消歧等任务中，CMA 显著优于传统 RAG，表明其是构建长期智能体所必需的架构原语。

Conclusion: CMA 为大语言模型提供了必要的记忆演化能力，是实现长期智能体的关键架构，但仍面临延迟、漂移和可解释性等挑战。

Abstract: Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal continuity is absent. We define the \textit{Continuum Memory Architecture} (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. Rather than disclosing implementation specifics, we specify the architectural requirements CMA imposes and show consistent behavioral advantages on tasks that expose RAG's structural inability to accumulate, mutate, or disambiguate memory. The empirical probes (knowledge updates, temporal association, associative recall, contextual disambiguation) demonstrate that CMA is a necessary architectural primitive for long-horizon agents while highlighting open challenges around latency, drift, and interpretability.

</details>


### [61] [CaMeLs Can Use Computers Too: System-level Security for Computer Use Agents](https://arxiv.org/abs/2601.09923)
*Hanna Foerster,Robert Mullins,Tom Blanchard,Nicolas Papernot,Kristina Nikolić,Florian Tramèr,Ilia Shumailov,Cheng Zhang,Yiren Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种名为“单次规划”（Single-Shot Planning）的新架构，用于提升计算机使用智能体（CUAs）对提示注入攻击的防御能力。该方法通过在接触任何潜在恶意内容前，由可信规划器生成包含条件分支的完整执行图，实现控制流完整性保障，并在保持可用性的同时显著增强安全性。


<details>
  <summary>Details</summary>
Motivation: 当前计算机使用智能体（CUAs）因需持续观察UI状态以决定下一步操作，难以应用已知最有效的安全防御机制——架构隔离（即严格分离可信任务规划与不可信环境观测），使其易受提示注入攻击，可能导致凭证泄露或经济损失。

Method: 作者提出“单次规划”方法：利用UI工作流结构上的可预测性，在未接触任何潜在恶意UI内容前，由可信规划器一次性生成包含条件分支的完整执行图；同时识别并防御新型“分支引导”（Branch Steering）攻击。

Result: 在OSWorld基准上评估表明，该方法在防止指令注入攻击的同时，保留了前沿模型最高57%的性能，并使小型开源模型性能提升最多19%。

Conclusion: 严格的架构隔离与实用性可在CUAs中兼得；通过单次规划和对分支引导攻击的额外防护，可实现对提示注入攻击的可证明安全防御。

Abstract: AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) -- systems that automate tasks by viewing screens and executing actions -- presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.

</details>


### [62] [Hallucination Detection and Mitigation in Large Language Models](https://arxiv.org/abs/2601.09929)
*Ahmad Pesaranghader,Erin Li*

Main category: cs.AI

TL;DR: 本文提出了一种面向高风险领域（如金融和法律）的幻觉管理框架，通过识别模型、数据和上下文三类幻觉根源，结合多维度检测与分层缓解策略，构建闭环反馈机制以持续提升大语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）和大推理模型（LRMs）在金融、法律等高风险领域具有变革潜力，但其易产生事实错误或无依据内容（即“幻觉”），严重威胁系统可靠性，亟需系统性解决方案。

Method: 提出一个基于根本原因识别的持续改进型幻觉管理框架，将幻觉来源分为模型、数据和上下文三类，并整合不确定性估计、推理一致性等多维检测方法，以及知识锚定、置信度校准等分层缓解策略，通过三层架构形成闭环反馈。

Result: 在金融数据抽取案例中验证了该框架的有效性，展示了模型层、上下文层和数据层如何协同工作，实现生成式AI系统可靠性的渐进式提升。

Conclusion: 该框架为在受监管环境中构建可信的生成式AI系统提供了一种系统化、可扩展的方法，有助于缓解幻觉问题并提升实际部署的可靠性。

Abstract: Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). We demonstrate its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.

</details>


### [63] [Chinese Labor Law Large Language Model Benchmark](https://arxiv.org/abs/2601.09972)
*Zixun Lan,Maochun Xu,Yifan Ren,Rui Wu,Jianghui Zhou,Xueyang Cheng,Jianan Ding Ding,Xinheng Wang,Mingmin Chi,Fei Ma*

Main category: cs.AI

TL;DR: 本文提出了专用于中国劳动法的法律大语言模型LabourLawLLM，并构建了涵盖多项任务的基准数据集LabourLawBench，实验表明该模型在多个指标上优于通用及现有法律领域模型。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型（如GPT-4）在需要精确法律知识、复杂推理和上下文敏感性的法律子领域（如劳动法）中表现不佳，因此有必要开发专门针对特定法律领域的模型以提升性能与实用性。

Method: 构建专门针对中国劳动法的大语言模型LabourLawLLM，并设计包含法律条文引用、知识问答、案例分类、赔偿计算、命名实体识别和案例分析等任务的综合评测基准LabourLawBench；评估采用客观指标（如ROUGE-L、准确率、F1、soft-F1）与基于GPT-4的主观评分相结合的方式。

Result: LabourLawLLM在各类劳动法任务中均优于通用模型和其他法律专用模型，验证了其在专业法律任务中的优越性。

Conclusion: 本研究不仅提升了劳动法领域AI应用的准确性与可靠性，还为其他法律子领域构建专业化大语言模型提供了可扩展的方法。

Abstract: Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark covering diverse labor-law tasks, including legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework combines objective metrics (e.g., ROUGE-L, accuracy, F1, and soft-F1) with subjective assessment based on GPT-4 scoring. Experiments show that LabourLawLLM consistently outperforms general-purpose and existing legal-specific LLMs across task categories. Beyond labor law, our methodology provides a scalable approach for building specialized LLMs in other legal subfields, improving accuracy, reliability, and societal value of legal AI applications.

</details>


### [64] [Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL](https://arxiv.org/abs/2601.10011)
*Zerui Yang,Weichuan Wang,Yanwei Xu,Linqi Song,Yudai Matsuda,Wei Han,Bo Bai*

Main category: cs.AI

TL;DR: Memo-SQL 是一种无需训练的 NL2SQL 框架，通过结构化分解和基于历史经验的自修正机制，在显著降低计算资源消耗的同时，实现了当前开放、零微调方法中的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有 NL2SQL 系统存在两大问题：仅使用正确示例进行上下文学习，忽略了错误-修正对中的有用信息；测试时缩放方法分解问题方式随意，导致生成的 SQL 候选高度相似，且在准确率与效率之间存在严重权衡。

Method: 提出 Memo-SQL 框架，包含两个核心设计：（1）采用实体级、层次化和原子序列三种明确的结构化分解策略以促进推理多样性；（2）构建动态记忆库，存储成功查询与历史错误-修正对，并在推理时通过检索增强提示引入相关示例，无需微调或外部 API。

Result: 在 BIRD 数据集上达到 68.5% 的执行准确率，成为当前开放、零微调方法中的新 SOTA，同时所用资源比以往测试时缩放方法减少十倍以上。

Conclusion: Memo-SQL 有效解决了 NL2SQL 中准确率与效率难以兼顾的问题，证明了结构化推理与经验驱动的自修正机制在无需训练条件下的强大潜力。

Abstract: Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive computation, while fast variants compromise quality. We present Memo-SQL, a training-free framework that addresses these issues through two simple ideas: structured decomposition and experience-aware self-correction. Instead of leaving decomposition to chance, we apply three clear strategies, entity-wise, hierarchical, and atomic sequential, to encourage diverse reasoning. For correction, we build a dynamic memory of both successful queries and historical error-fix pairs, and use retrieval-augmented prompting to bring relevant examples into context at inference time, no fine-tuning or external APIs required. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10 times fewer resources than prior TTS approaches.

</details>


### [65] [PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization](https://arxiv.org/abs/2601.10029)
*Tingyue Pan,Jie Ouyang,Mingyue Cheng,Qingchuan Li,Zirui Liu,Mingfan Pan,Shuo Yu,Qi Liu*

Main category: cs.AI

TL;DR: 本文提出PaperScout，一种将学术论文搜索建模为序贯决策过程的自主智能体，并引入新算法PSPO以解决多轮智能体任务中强化学习的粒度不匹配问题，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有学术论文搜索方法依赖固定工作流，难以处理复杂、条件性的查询；同时，传统强化学习在多轮智能体任务中存在粒度不匹配问题，导致信用分配噪声大。

Method: 提出PaperScout智能体框架，动态决定何时及如何调用搜索与扩展工具；并设计Proximal Sequence Policy Optimization（PSPO）算法，实现面向序列级交互的策略优化。

Result: 在合成和真实世界基准上的实验表明，PaperScout在召回率和相关性方面显著优于基于工作流和强化学习的强基线方法。

Conclusion: 将论文搜索重构为序贯决策任务，并结合序列级策略优化方法，能有效提升学术搜索系统的性能与适应性。

Abstract: Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such agents presents a fundamental challenge: standard reinforcement learning methods, typically designed for single-turn tasks, suffer from a granularity mismatch when applied to multi-turn agentic tasks, where token-level optimization diverges from the granularity of sequence-level interactions, leading to noisy credit assignment. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.

</details>


### [66] [FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data](https://arxiv.org/abs/2601.10031)
*Jianheng Tang,Shilong Tao,Zhe Feng,Haonan Sun,Menglu Wang,Zhanxing Zhu,Yunhuai Liu*

Main category: cs.AI

TL;DR: 本文提出FilDeep，一种基于多保真度数据的深度学习框架，用于解决弹塑性固体大变形问题中数据数量与精度之间的权衡难题，并在拉伸弯曲问题中实现优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在处理弹塑性固体大变形问题时存在局限性，而现有深度学习方法依赖高质量、大量数据，但此类数据在大变形问题中难以获取，导致数据数量与精度之间存在矛盾。

Method: 提出FilDeep框架，结合低保真度（数量多、精度低）和高保真度（数量少、精度高）数据进行联合训练，并设计了注意力机制增强的跨保真度模块，以捕捉多保真度数据间的长程物理相互作用。

Result: 大量实验表明，FilDeep在大变形问题中始终达到最先进的性能，并可高效部署于制造场景。

Conclusion: FilDeep是首个将多保真度深度学习应用于弹塑性固体大变形问题的框架，有效缓解了数据数量与精度之间的矛盾，具有良好的实际应用前景。

Abstract: The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.

</details>


### [67] [State of AI: An Empirical 100 Trillion Token Study with OpenRouter](https://arxiv.org/abs/2601.10088)
*Malika Aubakirova,Alex Atallah,Chris Clark,Justin Summerville,Anjney Midha*

Main category: cs.AI

TL;DR: 本文基于OpenRouter平台分析了超过100万亿token的真实大语言模型（LLM）使用数据，揭示了开放权重模型的广泛采用、创意角色扮演和编程辅助的流行，以及智能体推理的兴起，并发现早期用户具有显著更高的留存率（“玻璃鞋效应”），强调真实世界中LLM使用行为的复杂性。


<details>
  <summary>Details</summary>
Motivation: 随着2024年12月首个广泛采用的推理模型o1发布，大语言模型从单次生成转向多步推理，但对其实际使用情况的实证理解仍滞后。作者旨在填补这一空白，通过大规模真实交互数据分析LLM在实践中的使用模式。

Method: 利用OpenRouter平台收集并分析涵盖多种任务、地域和时间段的超过100万亿token的真实LLM交互数据，进行实证研究和用户留存分析。

Result: 研究发现：1）开放权重模型被大量采用；2）创意角色扮演和编程辅助远比预期更受欢迎；3）智能体推理正在兴起；4）早期用户群体展现出显著更高的长期留存率（“玻璃鞋效应”）。

Conclusion: 真实世界中开发者和终端用户对LLM的使用是复杂且多面的，模型构建者、AI开发者和基础设施提供商应基于数据驱动的使用理解来优化LLM系统的设计与部署。

Abstract: The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged behind. In this work, we leverage the OpenRouter platform, which is an AI inference provider across a wide variety of LLMs, to analyze over 100 trillion tokens of real-world LLM interactions across tasks, geographies, and time. In our empirical study, we observe substantial adoption of open-weight models, the outsized popularity of creative roleplay (beyond just the productivity tasks many assume dominate) and coding assistance categories, plus the rise of agentic inference. Furthermore, our retention analysis identifies foundational cohorts: early users whose engagement persists far longer than later cohorts. We term this phenomenon the Cinderella "Glass Slipper" effect. These findings underscore that the way developers and end-users engage with LLMs "in the wild" is complex and multifaceted. We discuss implications for model builders, AI developers, and infrastructure providers, and outline how a data-driven understanding of usage can inform better design and deployment of LLM systems.

</details>


### [68] [MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning](https://arxiv.org/abs/2601.10101)
*Ke Chen,Jiandian Zeng,Zihao Peng,Guo Li,Guangxue Zhang,Tian Wang*

Main category: cs.AI

TL;DR: 本文提出MatrixCoT，一种基于矩阵规划的结构化思维链框架，通过规范化自然语言表达、引入显式引用字段和矩阵化步骤关系，在不依赖外部求解器的情况下提升大语言模型在符号逻辑推理任务中的鲁棒性、可解释性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有思维链（CoT）方法在处理依赖符号表达和严格演绎规则的逻辑推理任务时表现不足；神经符号方法虽能保证形式正确性，但对外部求解器格式敏感，易因模型输出微小扰动而失败；纯LLM驱动方法则缺乏结构化表示和过程级纠错机制。

Method: 提出MatrixCoT框架：1）对自然语言表达进行规范化与类型标注；2）添加显式引用字段；3）采用基于矩阵的规划方法以保留推理步骤间的全局关系；4）引入反馈驱动的重规划机制，在语义等价约束下检测缺陷、重写并压缩依赖矩阵，生成更可信的答案。

Result: 在五个逻辑推理基准和五种大语言模型上的实验表明，MatrixCoT在不使用外部求解器的前提下，显著提升了模型在复杂符号推理任务中的鲁棒性和可解释性，同时保持了具有竞争力的性能。

Conclusion: MatrixCoT通过结构化的矩阵规划与反馈重规划机制，有效增强了大语言模型的逻辑推理能力，为符号密集型任务提供了一种稳定、可验证且无需外部工具的解决方案。

Abstract: As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions, attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan becomes a verifiable artifact, making execution more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both robustness and interpretability when tackling complex symbolic reasoning tasks, while maintaining competitive performance.

</details>


### [69] [Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs](https://arxiv.org/abs/2601.10114)
*Cheng Feng,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.AI

TL;DR: 本文提出了一种新的理论见解：若学生模型在“学生偏好子域”（SFS）上的优势足以抵消其在“教师偏好子域”（TFS）上的劣势，则其可在特定领域任务上超越教师模型。基于此，作者提出了“调度检查点蒸馏”（SCD）和“样本级自适应加权”（AW）机制，在多个语言和任务上显著优于现有蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因规模庞大难以部署于特定领域任务，而传统知识蒸馏常因师生模型能力差距导致性能不佳。因此，亟需探索学生模型何时以及如何在特定任务上匹配甚至超越其教师模型。

Method: 提出调度检查点蒸馏（SCD），通过在监督微调过程中模拟教师模型的收敛路径以减少TFS上的劣势；同时引入样本级自适应加权（AW）机制，保留学生在SFS上的优势。

Result: 在多种语言的问答、命名实体识别和文本分类等任务上，所提方法一致优于现有蒸馏方法，使学生模型性能达到甚至超过微调后的教师模型。

Conclusion: 通过理论分析与方法设计，证明了学生模型在特定条件下可超越教师模型，并验证了所提SCD与AW机制的有效性。

Abstract: Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher's convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks--including QA, NER, and text classification in multiple languages--show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.

</details>


### [70] [Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction](https://arxiv.org/abs/2601.10132)
*Yanan Cao,Farnaz Fallahi,Murali Mohana Krishna Dandu,Lalitesh Morishetti,Kai Zhao,Luyi Ma,Sinduja Subramaniam,Jianpeng Xu,Evren Korpeoglu,Kaushiki Nag,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 本文系统研究了大语言模型（LLMs）在预测用户重复行为（如复购）时间间隔方面的能力，发现尽管LLMs优于简单统计基线，但始终不如专用机器学习模型，且过多上下文反而会降低其性能。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能从结构化行为数据中推断时间规律，特别是在预测用户重复行为的时间间隔方面的能力尚未充分研究。

Method: 在零样本设置下，使用一个简单的复购场景，对当前最先进的大语言模型进行基准测试，并与统计模型和机器学习模型进行比较，同时考察不同层次上下文信息对其预测性能的影响。

Result: 1）LLMs虽优于轻量级统计基线，但始终逊于专用机器学习模型；2）适度上下文可提升LLMs准确性，但增加更多用户级细节反而降低性能。

Conclusion: 当前大语言模型在结构化时间推理任务中存在根本性局限，未来应设计结合统计精度与语言灵活性的上下文感知混合模型。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that "more context leads to better reasoning". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.

</details>


### [71] [History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis](https://arxiv.org/abs/2601.10143)
*Haochong Xia,Yao Long Teng,Regan Tan,Molei Qin,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 本文提出了一种面向金融市场的漂移感知数据流系统，通过将自适应控制机制融入数据生成与管理流程，提升模型在非平稳市场环境下的鲁棒性和风险调整后收益。


<details>
  <summary>Details</summary>
Motivation: 金融市场中存在概念漂移和分布非平稳性，导致基于静态历史数据训练的模型泛化能力差，难以在真实交易环境中稳定表现，因此需要一种能随市场动态演化的自适应数据生成方法。

Method: 构建一个可微分的漂移感知数据流系统，包含参数化的数据操作模块（如单资产变换、多资产混合、数据筛选）和基于梯度的双层优化自适应调度器，统一实现数据增强、课程学习与工作流管理。

Result: 在预测与强化学习交易任务上的大量实验表明，该框架显著提升了模型鲁棒性与风险调整后收益，并支持数据溯源回放与持续质量监控。

Conclusion: 该系统为金融数据提供了一种通用的自适应数据管理范式，实现了学习驱动的工作流自动化，有效缓解了训练与实际性能之间的差距。

Abstract: In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra "History Is Not Enough" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.

</details>


### [72] [DecisionLLM: Large Language Models for Long Sequence Decision Exploration](https://arxiv.org/abs/2601.10148)
*Xiaowei Lv,Zhilin Zhang,Yijun Li,Yusen Huo,Siyuan Ju,Xuyan Li,Chunxiang Hong,Tianyu Wang,Yongcai Wang,Peng Sun,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出DecisionLLM，将轨迹视为独立模态并与自然语言任务描述对齐，使大语言模型（LLM）能用于离线长序列决策任务，在多个基准上优于传统Decision Transformer。


<details>
  <summary>Details</summary>
Motivation: 探索基于Transformer的大语言模型（LLM）是否能在长时程序列决策任务中超越现有方法，尤其是解决其无法原生理解连续数值的问题。

Method: 将轨迹数据视为一种独立模态，通过与自然语言任务描述对齐，构建名为DecisionLLM的自回归决策框架，并研究模型规模、数据量和数据质量对性能的影响。

Result: 在Maze2D umaze-v1和AuctionNet等离线实验中，DecisionLLM-3B分别比传统Decision Transformer高出69.4和0.085，展现出优越性能。

Conclusion: DecisionLLM有效克服了LLM处理连续值的局限，在离线长序列决策任务中表现优异，为在线竞价等应用提供了新方向。

Abstract: Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whether LLMs, which share the same Transformer foundation, but operate at a much larger scale, can unlock new levels of performance in long-horizon sequential decision-making problem. This work investigates the application of LLMs to offline decision making tasks. A fundamental challenge in this domain is the LLMs' inherent inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order when values are represented as text strings. To address this, we propose treating trajectories as a distinct modality. By learning to align trajectory data with natural language task descriptions, our model can autoregressively predict future decisions within a cohesive framework we term DecisionLLM. We establish a set of scaling laws governing this paradigm, demonstrating that performance hinges on three factors: model scale, data volume, and data quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance. Specifically, DecisionLLM-3B outperforms the traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding.

</details>


### [73] [MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging](https://arxiv.org/abs/2601.10154)
*Leonard Nürnberg,Dennis Bontempi,Suraj Pai,Curtis Lisle,Steve Pieper,Ron Kikinis,Sil van de Leemput,Rahul Soni,Gowtham Murugesan,Cosmin Ciausu,Miriam Groeneveld,Felix J. Dorfner,Jue Jiang,Aneesh Rangnekar,Harini Veeraraghavan,Joeran S. Bosma,Keno Bressem,Raymond Mak,Andrey Fedorov,Hugo JWL Aerts*

Main category: cs.AI

TL;DR: MHub.ai 是一个开源、基于容器的平台，旨在通过标准化 AI 模型的访问和执行，提升医学影像 AI 研究的可访问性与可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像 AI 研究受限于模型实现多样、文档不一致及可复现性差等问题，亟需统一标准以促进临床转化。

Method: 开发 MHub.ai 平台，将同行评审论文中的 AI 模型打包为标准化容器，支持 DICOM 等格式直接处理、统一接口调用和结构化元数据嵌入，并提供公开参考数据用于验证。

Result: 平台集成了多种先进分割、预测和特征提取模型，成功应用于肺部分割模型的对比评估，并公开了分割结果、评估指标及交互式仪表板以支持复现和扩展分析。

Conclusion: MHub.ai 通过简化模型部署与标准化输出，显著降低了医学影像 AI 模型的使用门槛，促进了模型间的公平比较与临床转化。

Abstract: Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation.

</details>


### [74] [MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning](https://arxiv.org/abs/2601.10157)
*Yusong Wang,Jialun Shen,Zhihao Wu,Yicheng Xu,Shiyin Tan,Mingkun Xu,Changshuo Wang,Zixing Song,Prayag Tiwari*

Main category: cs.AI

TL;DR: MMPG is a multi-perspective graph neural network framework for protein representation learning that constructs protein graphs from physical, chemical, and geometric views and adaptively fuses them using a Mixture of Experts (MoE) module to capture both perspective-specific and cross-perspective interaction features, achieving state-of-the-art performance on multiple downstream tasks.


<details>
  <summary>Details</summary>
Motivation: Existing GNN-based protein representation learning methods use single-perspective graph construction, which captures only partial residue interaction properties and leads to incomplete protein representations.

Method: MMPG constructs protein graphs from physical, chemical, and geometric perspectives and employs a Mixture of Experts (MoE) module to dynamically route and fuse these perspectives, enabling the learning of both perspective-specific features and cross-perspective synergies.

Result: MMPG produces enhanced protein representations and achieves superior performance on four downstream protein-related tasks, with quantitative evidence showing MoE effectively models interactions at multiple levels—from individual perspectives to global consensus.

Conclusion: By integrating multi-perspective graph construction and adaptive fusion via MoE, MMPG overcomes the limitations of single-view approaches and significantly improves protein representation learning.

Abstract: Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.

</details>


### [75] [CtD: Composition through Decomposition in Emergent Communication](https://arxiv.org/abs/2601.10169)
*Boaz Carmeli,Ron Meir,Yonatan Belinkov*

Main category: cs.AI

TL;DR: 本文提出“通过分解实现组合”（Composition through Decomposition）方法，使神经智能体在无需额外训练的情况下，能零样本泛化地描述未见过的图像。


<details>
  <summary>Details</summary>
Motivation: 探索人工神经智能体如何像人类一样，通过组合已知概念来系统性地理解和描述新图像，从而实现组合性泛化。

Method: 该方法包含两个阶段：首先在多目标协调游戏中学习将图像分解为基本概念并构建码本（Decompose）；然后利用该码本将基本概念组合成复杂短语以描述新图像（Compose）。

Result: 实验表明，智能体在“Compose”阶段能够实现零样本的组合性泛化，成功描述训练中未见过的图像。

Conclusion: 通过分解与再组合的两阶段训练策略，人工神经智能体可有效获得并利用组合性泛化能力，甚至在无额外训练的情况下实现对新图像的描述。

Abstract: Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed "Composition through Decomposition", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game. Subsequently, in the 'Compose' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases. Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training.

</details>


### [76] [How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series](https://arxiv.org/abs/2601.10191)
*Mathieu Cherpitel,Janne Luijten,Thomas Bäck,Camiel Verhamme,Martijn Tannemaat,Anna Kononova*

Main category: cs.AI

TL;DR: 本文提出了一种系统评估针式肌电图（nEMG）信号下采样过程中信息损失的工作流程，结合波形失真度量与分类性能分析，发现形状感知型下采样算法在保留诊断信息的同时显著降低计算负担，适用于近实时分析。


<details>
  <summary>Details</summary>
Motivation: 高且异构的采样率使基于特征的机器学习模型在处理nEMG信号时面临巨大计算挑战，尤其在近实时分析场景中；而下采样虽可缓解此问题，但其对诊断信息和分类性能的影响尚不明确。

Method: 提出一个综合工作流程，结合基于形状的失真度量、特征空间分析及现有特征驱动的机器学习模型的分类结果，系统评估不同下采样算法和参数对波形完整性和预测性能的影响，并在三类神经肌肉疾病分类任务中进行实验验证。

Result: 实验表明，形状感知型下采样算法优于传统降采样方法，能更好地保留信号峰值结构和整体形态；所提工作流程可有效识别在大幅降低计算负载的同时保留诊断信息的下采样配置。

Conclusion: 该研究为nEMG信号近实时分析中的下采样策略选择提供了实用指导，并提出了一个可推广至其他高频时间序列应用的通用工作流程，以在数据压缩与模型性能之间取得平衡。

Abstract: Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals' high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.

</details>


### [77] [GFM4GA: Graph Foundation Model for Group Anomaly Detection](https://arxiv.org/abs/2601.10193)
*Jiujiu Chen,Weijun Zeng,Shaofeng Hu,Sihong Xie,Hui Xiong*

Main category: cs.AI

TL;DR: 本文提出GFM4GA，一种面向群组异常检测的图基础模型，通过双层级对比学习预训练和少样本微调策略，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型（GFMs）虽在个体异常检测中表现良好，但难以直接推广至群组异常检测，因为群组异常需整体识别，而其中个体可能看似正常。

Method: GFM4GA采用基于特征估计与群组提取的双层级对比学习进行预训练；在下游任务中，通过参数受限、按群组异常比例加权的少样本设置进行微调，并利用已标记异常邻居确定的群组上下文增强对未见群组异常的适应能力。

Result: 实验表明，GFM4GA在AUROC和AUPRC上分别平均提升2.85%和2.55%，优于现有群组异常检测器及用于个体异常的GFMs。

Conclusion: GFM4GA有效解决了群组异常检测中的泛化难题，为图基础模型在复杂异常模式识别中的应用提供了新思路。

Abstract: Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.

</details>


### [78] [Topo-RAG: Topology-aware retrieval for hybrid text-table documents](https://arxiv.org/abs/2601.10215)
*Alex Dantart,Marco Kóvacs-Navarro*

Main category: cs.AI

TL;DR: Topo-RAG 是一种新型 RAG 框架，通过区分处理文本叙述与表格结构，在混合查询任务中显著优于传统线性化方法。


<details>
  <summary>Details</summary>
Motivation: 当前 RAG 系统将复杂的企业文档（包含文本和表格）简单线性化为纯文本，无法有效保留表格的空间结构信息，导致检索效果受限。

Method: 提出 Topo-RAG 双路径架构：使用传统稠密检索器处理叙述性文本，同时引入 Cell-Aware Late Interaction 机制专门处理表格数据，以保留其拓扑结构。

Result: 在模拟企业场景的 SEC-25 数据集上，Topo-RAG 在混合查询的 nDCG@10 指标上比标准线性化方法提升 18.4%。

Conclusion: 信息具有内在“形状”，RAG 系统应尊重不同类型数据的拓扑特性，而非统一视为纯文本；Topo-RAG 为此提供了有效解决方案。

Abstract: In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. We convert rich, multidimensional tables into simple Markdown-style text strings, hoping that an embedding model will capture the geometry of a spreadsheet in a single vector. But it has already been shown that this is mathematically insufficient.
  This work presents Topo-RAG, a framework that challenges the assumption that "everything is text". We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It's not just about searching better; it's about understanding the shape of information.

</details>


### [79] [TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks](https://arxiv.org/abs/2601.10245)
*Vansh Kapoor,Aman Gupta,Hao Chen,Anurag Beniwal,Jing Huang,Aviral Kumar*

Main category: cs.AI

TL;DR: TRIM是一种针对多步推理任务的新型路由方法，通过在步骤级别将关键步骤路由到大模型、常规步骤交由小模型处理，显著提升推理效率与成本效益。


<details>
  <summary>Details</summary>
Motivation: 多步推理任务（如数学问题求解）易因单一步骤错误导致整体失败，而现有大语言模型路由方法将整个查询分配给单一模型，无法区分各步骤的重要性。

Method: TRIM在步骤级别进行路由决策，利用过程奖励模型识别可能出错的关键步骤，并基于步骤不确定性与预算约束，将这些步骤交由更强的大模型处理，其余步骤由小模型完成。提出了从简单阈值策略到考虑长期准确率-成本权衡的多种路由策略。

Result: 在MATH-500上，最简单的阈值策略即可实现比先前方法高5倍的成本效率；更高级策略在使用80%更少昂贵模型token的情况下达到与强模型相当的性能。在AIME等更难基准上，TRIM最高实现6倍成本效率提升，且方法在不同数学推理任务中具有良好的泛化能力。

Conclusion: TRIM通过在关键推理步骤上精准调用大模型，有效防止错误传播，在大幅降低计算成本的同时保持高性能，表明步骤级难度是推理任务中的基本特征。

Abstract: Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\unicode{x2013}$those likely to derail the solution$\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.

</details>


### [80] [NoReGeo: Non-Reasoning Geometry Benchmark](https://arxiv.org/abs/2601.10254)
*Irina Abdullaeva,Anton Vasiliuk,Elizaveta Goncharova,Temurbek Rahmatullaev,Zagorulko Ivan,Maxim Kurkin,Andrey Kuznetsov*

Main category: cs.AI

TL;DR: NoReGeo 是一个新基准，用于评估大语言模型（LLMs）在不依赖推理或代数计算的情况下对几何的内在理解能力。实验表明，即便是最先进的模型（如 GPT-4）在此任务上的准确率最高仅达 65%，且微调无法显著提升几何理解能力，说明需专门训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有几何评估基准主要关注基于推理和代数方法的解题能力，难以衡量 LLMs 是否具备对空间关系和几何属性的原生理解。因此，作者提出 NoReGeo，旨在填补这一评估空白。

Method: 构建包含 2500 个简单几何问题的 NoReGeo 基准，涵盖 25 个类别，所有问题均可仅通过原生几何理解解答（假设已知对象位置）。在多个前沿 LLM 上进行评估，并开展消融实验分析微调对几何理解的影响。

Result: 最先进模型在 NoReGeo 的二分类任务中最高准确率为 65%；消融实验表明，仅靠微调无法有效提升几何理解能力。

Conclusion: 当前 LLM 在原生几何认知方面存在明显不足，未来需从训练初期引入专门方法以提升其几何理解能力。

Abstract: We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.

</details>


### [81] [Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning](https://arxiv.org/abs/2601.10306)
*Xin Guan,Zijian Li,Shen Huang,Pengjun Xie,Jingren Zhou,Jiuxin Cao*

Main category: cs.AI

TL;DR: 本文提出EAPO（Evidence-Augmented Policy Optimization）方法，通过引入基于证据的密集过程奖励和自适应奖励-策略协同进化机制，显著提升大语言模型在长上下文推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在长上下文推理中受限于稀疏的结果奖励，无法有效惩罚无依据的“幸运猜测”，导致关键的证据检索过程缺乏监督。

Method: 提出Evidence-Augmented Reasoning范式，并设计EAPO算法：利用Group-Relative Evidence Reward提供密集的过程监督，并通过Adaptive Reward-Policy Co-Evolution机制迭代优化奖励模型，以维持训练过程中监督的准确性。

Result: 在八个基准测试中，EAPO显著优于当前最先进的基线方法，有效提升了长上下文推理能力。

Conclusion: EAPO通过显式优化证据质量并动态改进奖励模型，成功解决了长上下文推理中证据检索缺乏监督的问题，为强化学习在复杂推理任务中的应用提供了有效路径。

Abstract: While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded "lucky guesses," leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.

</details>


### [82] [C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing](https://arxiv.org/abs/2601.10342)
*Cheng Lin Cheng,Ting Chuan Lin,Chai Kai Chang*

Main category: cs.AI

TL;DR: 本文提出C-GRASP方法，通过结合个体化基线与RAG增强推理流程，解决大语言模型在心率变异性（HRV）分析中的生理幻觉问题，提升情绪分类准确性和临床推理一致性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在HRV解读中存在生理幻觉问题，如呼吸性窦性心律不齐（RSA）干扰、非线性指标对短数据不稳定，以及忽视个体基线而依赖群体常模，限制了其在临床情感计算中的可靠性。

Method: 提出C-GRASP框架，包含八个可追溯的推理步骤，核心是Z分数优先级层级，强调个体基线变化而非群体统计；并引入自动化的RSA感知防护机制，防止频域指标污染；结合高阶推理模型（如MedGemma3-thinking）进行情绪分类。

Result: 在DREAMER数据集414次试验中，C-GRASP在四类情绪分类任务中达到37.3%准确率，临床推理一致性（CRC）得分为69.6%；消融实验证明Delta Z-score模块有效缓解了LLM的“群体偏见”。

Conclusion: C-GRASP将情感计算从黑箱分类转变为透明、基于证据的临床决策支持系统，为AI在生物医学工程中的安全应用提供新路径。

Abstract: Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the "population bias" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.

</details>


### [83] [LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries](https://arxiv.org/abs/2601.10398)
*Xuancheng Ren,Shijing Hu,Zhihui Lu,Jiangqi Huang,Qiang Duan*

Main category: cs.AI

TL;DR: 本文提出LatentRefusal，一种基于大语言模型中间隐藏状态预测查询可回答性的轻量级拒绝机制，有效提升text-to-SQL系统在面对不可回答或模糊查询时的安全性与准确性。


<details>
  <summary>Details</summary>
Motivation: 在基于大语言模型的text-to-SQL系统中，不可回答或未充分指定的用户查询可能导致生成错误但可执行的SQL程序，带来误导性结果或安全风险；现有拒绝策略存在脆弱性或高开销问题。

Method: 将安全拒绝形式化为可回答性门控问题，提出LatentRefusal方法，利用Tri-Residual Gated Encoder从LLM中间隐藏激活中提取稀疏、局部的问句-模式不匹配信号，以判断查询是否可回答。

Result: 在四个基准上，LatentRefusal将平均F1分数提升至88.5%，且仅增加约2毫秒的探针开销，实验证明其高效、可附加且有效。

Conclusion: LatentRefusal为text-to-SQL系统提供了一个轻量、高效且可解释的安全拒绝机制，显著提升了对不可回答查询的识别能力与系统安全性。

Abstract: In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead.

</details>


### [84] [ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics](https://arxiv.org/abs/2601.10406)
*Weiping Fu,Bifan Wei,Jingyi Hao,Yushun Zhang,Jian Zhang,Jiaxin Wang,Bo Li,Yu He,Lingling Zhang,Jun Liu*

Main category: cs.AI

TL;DR: 本文提出ErrEval，一种面向错误感知的自动问答生成（QG）评估框架，通过显式错误诊断提升评估质量。


<details>
  <summary>Details</summary>
Motivation: 现有QG评估方法（包括基于大语言模型的评估器）多采用黑箱整体评估范式，缺乏对事实幻觉、答案不匹配等关键缺陷的显式建模，导致评估结果高估问题质量。

Method: ErrEval将评估重构为两阶段流程：首先由轻量级、即插即用的错误识别器检测并分类结构、语言和内容层面的常见错误；随后将这些诊断信号作为显式证据，引导LLM评估器进行更细粒度、有依据的评分。

Result: 在三个基准上的实验表明，ErrEval能有效提升与人类判断的一致性，并显著缓解对低质量问题的高估现象。

Conclusion: 引入显式错误诊断机制可显著改进QG评估的准确性和可靠性，ErrEval为此提供了一个灵活有效的解决方案。

Abstract: Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.

</details>


### [85] [LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies](https://arxiv.org/abs/2601.10413)
*Haiyue Yuan,Nikolay Matyunin,Ali Raza,Shujun Li*

Main category: cs.AI

TL;DR: 本文提出LADFA框架，结合大语言模型（LLM）与检索增强生成（RAG），从隐私政策中自动提取个人数据流并构建数据流图，以支持大规模分析。


<details>
  <summary>Details</summary>
Motivation: 隐私政策通常因语言复杂、长度冗长且各组织间实践不一致而难以理解，亟需自动化方法进行高效分析。

Method: 开发了端到端的LADFA框架，包含预处理器、基于LLM的处理器和数据流后处理器，结合RAG与定制知识库，从非结构化隐私政策文本中提取并分析个人数据流。

Result: 通过汽车行业10份隐私政策的案例研究，验证了LADFA在提取准确性和分析有效性方面的表现，并展示了其灵活性和可扩展性。

Conclusion: LADFA为隐私政策中的个人数据流分析提供了一种高效、准确且可定制的自动化解决方案，具有应用于其他文本分析任务的潜力。

Abstract: Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.

</details>


### [86] [LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models](https://arxiv.org/abs/2601.10416)
*Tiesunlong Shen,Rui Mao,Jin Wang,Heming Sun,Jian Zhang,Xuejie Zhang,Erik Cambria*

Main category: cs.AI

TL;DR: 本文提出LLMdoctor，一种基于“患者-医生”范式的高效测试时对齐框架，通过细粒度的token级奖励信号和token级流引导偏好优化（TFPO），在不微调大模型的前提下实现优于现有测试时对齐方法甚至超越全参数微调（如DPO）的性能，同时保留生成多样性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型对齐方法计算成本高、灵活性差；现有测试时对齐方法依赖失真的轨迹级信号或低效采样，限制性能且损害生成多样性。

Method: 提出LLMdoctor框架，利用冻结的大模型作为“患者”，小型专用模型作为“医生”；从患者模型行为变化中提取token级偏好信号，并通过token级流引导偏好优化（TFPO）训练医生模型，实现逐token对齐并保持生成多样性。

Result: 实验表明LLMdoctor显著优于现有测试时对齐方法，性能甚至超过DPO等全参数微调方法。

Conclusion: LLMdoctor通过token级信号与流一致性优化，实现了高效、高性能且多样化的测试时对齐，为大模型对齐提供了一种新范式。

Abstract: Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.

</details>


### [87] [NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models](https://arxiv.org/abs/2601.10457)
*Ziming Dai,Dabiao Ma,Jinle Tong,Mengyuan Han,Jian Yang,Haojun Fei*

Main category: cs.AI

TL;DR: NSR-Boost 是一种面向工业场景的神经符号残差提升框架，通过非侵入式方式修复遗留模型在“困难区域”的预测失败问题，在多个公开和私有数据集上表现优于 SOTA 方法，并成功部署于金融风控系统。


<details>
  <summary>Details</summary>
Motivation: 在高并发生产环境中，升级基于 GBDT 的遗留模型面临高昂的重训练成本和系统性风险，亟需一种低成本、安全的模型演进方案。

Method: NSR-Boost 将遗留模型视为冻结模型，通过三阶段流程进行修复：1）利用残差识别困难区域；2）借助大语言模型生成可解释的符号专家代码，并用贝叶斯优化微调参数；3）通过轻量级聚合器动态融合专家与原模型输出。

Result: 在六个公开数据集和一个私有数据集上显著优于现有 SOTA 方法，并在真实线上金融风控场景中实现显著性能提升，有效捕捉传统模型遗漏的长尾风险。

Conclusion: NSR-Boost 提供了一种安全、低成本的工业模型演进范式，兼具高性能与可解释性，适用于高并发生产环境中的模型升级。

Abstract: Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being "non-intrusive". It treats the legacy model as a frozen model and performs targeted repairs on "hard regions" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.

</details>


### [88] [ChartComplete: A Taxonomy-based Inclusive Chart Dataset](https://arxiv.org/abs/2601.10462)
*Ahmad Mustapha,Charbel Toumieh,Mariette Awad*

Main category: cs.AI

TL;DR: 本文提出了一个名为ChartComplete的新数据集，涵盖30种图表类型，旨在弥补现有基准数据集在图表类型覆盖上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有用于评估多模态大语言模型（MLLMs）图表理解能力的基准数据集仅限于少量图表类型，限制了模型的全面评估。

Method: 基于可视化领域的图表分类体系，构建了一个包含30种不同图表类型的图像数据集ChartComplete，该数据集仅提供分类后的图表图像，不包含学习信号。

Result: 成功构建并发布了ChartComplete数据集，为研究社区提供了一个更全面的图表理解基准资源。

Conclusion: ChartComplete数据集填补了现有图表理解基准在图表类型多样性方面的空白，为未来MLLMs的评估和开发提供了基础。

Abstract: With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.

</details>


### [89] [Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge](https://arxiv.org/abs/2601.10485)
*Runhao Zhao,Weixin Zeng,Wentao Zhang,Chong Chen,Zhengpin Li,Xiang Zhao,Lei Chen*

Main category: cs.AI

TL;DR: 该论文提出领域知识图谱融合（DKGF）任务，通过从通用知识图谱中引入相关事实来增强领域知识图谱，并提出ExeFuse方法，以“事实即程序”的范式统一解决领域相关性模糊与知识粒度不一致两大挑战。


<details>
  <summary>Details</summary>
Motivation: 领域知识图谱（DKG）通常覆盖不足，而通用知识图谱（GKG）虽覆盖面广但包含大量无关信息。如何有效利用GKG中的相关信息来增强DKG，同时应对领域相关性模糊和知识粒度不一致的问题，是本文的研究动机。

Method: 作者提出ExeFuse方法，采用“事实即程序”（Fact-as-Program）范式：将GKG中的每个事实视为潜在语义程序，将抽象关系映射为感知粒度的操作符，并通过在目标DKG上执行程序来验证其领域相关性，从而在一个统一的概率框架中联合处理相关性和粒度对齐问题。

Result: 构建了两个基准数据集DKGF(W-I)和DKGF(Y-I)，涵盖21种评估配置；大量实验验证了DKGF任务的重要性以及ExeFuse方法的有效性，并提供了首个标准化的DKGF测试平台。

Conclusion: 本文成功定义并实现了领域知识图谱融合任务，提出的ExeFuse方法在解决相关性与粒度对齐方面表现优异，为后续研究提供了基准和方法论支持。

Abstract: Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF.

</details>


### [90] [Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection](https://arxiv.org/abs/2601.10524)
*Frank Bobe,Gregory D. Vetaw,Chase Pavlick,Darshan Bryner,Matthew Cook,Jose Salas-Vernis*

Main category: cs.AI

TL;DR: 本文通过多层诊断框架研究了不同大语言模型（Llama 3.1 8B、Gemma 2 9B 和 Mistral）在钓鱼检测任务中的泛化失败问题，发现模型泛化能力高度依赖于架构与数据多样性的协同作用，并揭示了各模型在不同训练设置下的表现差异。


<details>
  <summary>Details</summary>
Motivation: 当前对微调大语言模型（LLMs）为何在特定任务上表现优异但泛化能力脆弱的理解仍不充分，亟需系统性方法诊断其失败原因。

Method: 作者在高风险钓鱼检测任务上微调三种主流LLM（Llama 3.1 8B、Gemma 2 9B 和 Mistral），并结合SHAP分析与机制可解释性技术，构建跨架构的多层诊断框架以探究泛化失败的根本原因。

Result: 研究发现：(1) Gemma 2 9B 在风格多样的“通才”数据集上达到>91% F1，展现架构与数据多样性协同效应；(2) Llama 3.1 8B 在窄域数据上表现良好，但无法有效整合多样数据，导致性能显著下降；(3) Mistral 模型在多种训练范式下均表现出稳定且强健的泛化能力。

Conclusion: 可靠的AI系统需深入验证模型架构、数据和训练策略三者之间的相互作用，本文提出的诊断方法为理解与改进LLM泛化能力提供了具体路径。

Abstract: The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.

</details>


### [91] [A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5](https://arxiv.org/abs/2601.10527)
*Xingjun Ma,Yixu Wang,Hengyuan Xu,Yutao Wu,Yifan Ding,Yunhan Zhao,Zilong Wang,Jiabin Hua,Ming Wen,Jianan Liu,Ranjie Duan,Yifeng Gao,Yingshui Tan,Yunhao Chen,Hui Xue,Xin Wang,Wei Cheng,Jingjing Chen,Zuxuan Wu,Bo Li,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 该报告对7个前沿大模型在语言、视觉-语言和图像生成任务中进行了统一的安全性评估，发现模型安全性高度异质，且在对抗性测试下普遍表现脆弱，强调需采用多维度、标准化的安全评估体系。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）和多模态大语言模型（MLLM）在能力上快速进步，但其安全性是否同步提升尚不明确，部分原因在于现有评估方法碎片化，局限于单一模态或威胁模型。

Method: 采用统一协议对7个前沿模型（GPT-5.2、Gemini 3 Pro、Qwen3-VL、Doubao 1.8、Grok 4.1 Fast、Nano Banana Pro、Seedream 4.5）进行综合安全评估，涵盖基准测试、对抗性测试、多语言测试和合规性测试，并整合为安全排行榜与模型安全画像。

Result: GPT-5.2在各项评估中表现稳定均衡；其他模型在基准安全性、对抗对齐、多语言泛化和合规性之间存在明显权衡；所有模型在对抗性评估下性能显著下降；文生图模型在受监管视觉风险类别中对齐较好，但在对抗或语义模糊提示下仍显脆弱。

Conclusion: 前沿模型的安全性本质上是多维的，受模态、语言和评估方式影响，亟需标准化、多维度的安全评估以准确衡量现实风险并指导负责任的模型开发与部署。

Abstract: The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment.

</details>


### [92] [Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing](https://arxiv.org/abs/2601.10543)
*Yinzhi Zhao,Ming Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.AI

TL;DR: 本文提出一种在大语言模型解码过程中利用其内部潜在安全信号进行早期不安全内容检测的新方法，有效提升对越狱攻击的防御能力，同时保持低误拒率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型经过安全对齐，但其安全性仍易受越狱攻击影响，现有防御机制（如解码约束和事后检测）难以兼顾鲁棒性和模型效用。

Method: 通过分析模型解码过程，发现即使被成功越狱，模型内部仍存在潜在的安全相关信号；据此提出一种显式激发并利用这些信号以在生成过程中早期识别不安全内容的方法。

Result: 在多种越狱攻击场景下，该方法显著提升了模型安全性，同时在良性输入上保持较低的过度拒绝率，并维持良好的响应质量。

Conclusion: 在解码过程中激活模型内在的安全意识是一种有前景且可与现有方法互补的越狱防御方向。

Abstract: Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.

</details>


### [93] [From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA](https://arxiv.org/abs/2601.10581)
*Kimia Abedini,Farzad Shami,Gianmaria Silvello*

Main category: cs.AI

TL;DR: 本文提出GenomAgent，一种多智能体框架，用于提升基因组问答任务的性能，相比现有方法GeneGPT平均提升12%，且具有更强的通用性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在基因组问答任务中受限于对特定数据库的访问能力，而现有系统如GeneGPT依赖固定API，适应性差，难以应对复杂的基因组查询需求。

Method: 作者复现了GeneGPT，并在此基础上提出GenomAgent，一个由多个专用智能体协同工作的多智能体框架，用于处理复杂的基因组学问题。

Result: 在GeneTuring基准的九项任务上，GenomAgent平均性能比GeneGPT高出12%，展现出更优的问答能力。

Conclusion: GenomAgent不仅在基因组问答任务中表现优异，其灵活架构还可推广至其他需要专家知识提取的科学领域。

Abstract: Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.

</details>


### [94] [Multi-Property Synthesis](https://arxiv.org/abs/2601.10651)
*Christoph Weinhuber,Yannik Schnitzer,Alessandro Abate,David Parker,Giuseppe De Giacomo,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: 本文提出了一种针对LTLf合成中多属性不可同时满足问题的高效符号化算法，通过一次不动点计算即可确定各状态可实现的最大目标集，并利用布尔目标变量与单调性紧凑表示指数级目标组合，显著优于基于枚举的基线方法。


<details>
  <summary>Details</summary>
Motivation: 在LTLf合成中，多个属性可能无法同时满足，传统方法需枚举属性子集，效率低下。因此需要一种更高效的方法来处理多属性合成问题。

Method: 提出一种完全符号化的算法，在一次不动点计算中构建产品博弈状态与可实现目标集之间的关系，引入布尔目标变量并利用单调性以紧凑方式表示大量目标组合。

Result: 该方法在性能上显著优于基于枚举的基线方法，速度提升最高达两个数量级。

Conclusion: 所提方法能高效处理LTLf多属性合成中的不可满足性问题，通过紧凑表示和符号计算大幅提升合成效率。

Abstract: We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.

</details>


### [95] [Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models](https://arxiv.org/abs/2601.10679)
*Zirui Ren,Ziming Liu*

Main category: cs.AI

TL;DR: 本文对分层推理模型（HRM）进行了机制性研究，揭示其在简单任务中失败、推理步骤中存在“顿悟”现象以及多重不动点等问题，表明HRM更像在“猜测”而非真正“推理”。基于此，作者提出三种增强策略，并构建Augmented HRM，在Sudoku-Extreme上将准确率从54.5%提升至96.9%。


<details>
  <summary>Details</summary>
Motivation: 理解HRM在推理任务中表现优异背后的原因及其潜在失效模式，揭示其实际推理机制是否为真正的逻辑推理。

Method: 通过机制性分析发现HRM的三个关键行为特征，并据此提出三种提升其性能的策略：数据增强、输入扰动和模型自举。

Result: 结合所提方法构建的Augmented HRM在Sudoku-Extreme数据集上将准确率显著提升至96.9%，同时揭示了HRM本质上更接近“猜测”而非系统性推理。

Conclusion: HRM的推理过程具有“猜测”特性，通过扩展猜测的质量与数量可显著提升其性能；该研究为理解推理模型的工作机制提供了新视角。

Abstract: Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) "Grokking" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM "guesses" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be "guessing" instead of "reasoning". Leveraging this "guessing" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models "reason".

</details>


### [96] [Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems](https://arxiv.org/abs/2601.10681)
*Amir Khurshid,Abhishek Sehgal*

Main category: cs.AI

TL;DR: 本文提出了一种结构感知且多样性受限的上下文“气泡”构建框架，用于替代传统的top-k检索方法，在有限token预算下生成更紧凑、信息更丰富且可引用的上下文。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法通过top-k检索选择段落，导致文档结构中的信息图碎片化、内容重复、过度检索以及对查询的二阶、三阶侧面覆盖不足。

Method: 该方法利用文档固有结构，组织多粒度文本片段（如章节、行），并结合任务条件的结构先验指导检索；从高相关性锚点出发，通过平衡查询相关性、边际覆盖率和冗余惩罚，在严格token限制下构建上下文“气泡”，同时确保多样性和可审计性。

Result: 在企业文档上的实验表明，该方法显著减少冗余上下文，更好地覆盖次要查询侧面，并在有限上下文窗口内提升回答质量和引用忠实度；消融实验证明结构先验和多样性约束均不可或缺。

Conclusion: 所提出的上下文气泡构建框架有效克服了传统RAG的局限性，通过结构感知与多样性约束，在有限资源下实现了更高效、可审计且高质量的上下文构建。

Abstract: Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.

</details>


### [97] [The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load](https://arxiv.org/abs/2601.10696)
*Han Jiang,Yao Xiao,Rachel Hurley,Shichao Liu*

Main category: cs.AI

TL;DR: 本研究发现生成式AI（GenAI）在建筑概念设计任务中对新手设计师的设计表现有显著提升作用，但会降低使用者的一般创造性自我效能感；认知负荷在不同条件下无显著差异，但特定提示策略可有效减轻认知负荷。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI如何影响建筑概念设计中的表现、创造性自我效能感和认知负荷，特别是在不同专业背景和经验水平的用户中是否存在差异。

Method: 36名来自建筑与工程及其他专业的学生参与两阶段设计任务：第一阶段独立完成，第二阶段分别使用生成式AI或在线建筑项目库（对照组）。专家评估设计成果，参与者自评自我效能感和认知负荷。采用双重差分法及子群分析进行数据检验。

Result: 整体上GenAI未带来显著性能优势，但在新手设计师子群中显著提升设计表现；使用GenAI的学生创造性自我效能感下降；认知负荷无显著组间差异，但迭代生成与视觉反馈类提示与认知负荷降低相关。

Conclusion: GenAI的效果取决于用户的先验专业知识和提示交互策略，在支持新手设计的同时可能削弱其创造性自信，需谨慎引导使用方式。

Abstract: Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [98] [Adaptive Orchestration: Scalable Self-Evolving Multi-Agent Systems](https://arxiv.org/abs/2601.09742)
*Sathish Sampath,Anuradha Baskaran*

Main category: cs.MA

TL;DR: 本文提出了一种名为“自演化礼宾系统”的新架构，通过动态混合专家（DMoE）方法，在运行时根据对话内容动态调用专用子智能体，以解决大语言模型在通用性与专业性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为自主智能体部署时面临“通用-专用困境”：单一智能体因工具过多导致上下文污染和注意力衰减，而静态多智能体系统则带来高延迟与资源开销。

Method: 采用动态混合专家（DMoE）架构，包括异步“元认知引擎”检测能力缺口、基于LRU策略的资源回收机制，以及“外科式历史剪枝”以减少拒绝偏见，并在运行时动态加载专用子智能体。

Result: 实验表明，该架构在保持高任务成功率的同时，显著降低了token消耗，优于静态多智能体系统。

Conclusion: 所提出的自演化礼宾系统有效平衡了通用性与专业性，在提升效率与稳定性方面具有显著优势。

Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous agents, they face a critical scalability bottleneck known as the "Generalization-Specialization Dilemma." Monolithic agents equipped with extensive toolkits suffer from context pollution and attention decay, leading to hallucinations. Conversely, static multi-agent swarms introduce significant latency and resource overhead. This paper introduces a Self-Evolving Concierge System, a novel architecture utilizing a Dynamic Mixture of Experts (DMoE) approach. Unlike recent self-improving agents that rewrite their own codebase, our system preserves stability by dynamically restructuring its runtime environment: "hiring" specialized sub-agents based on real-time conversation analysis. We introduce an asynchronous "Meta-Cognition Engine" that detects capability gaps, a Least Recently Used (LRU) eviction policy for resource constraints, and a novel "Surgical History Pruning" mechanism to mitigate refusal bias. Experimental results demonstrate that this architecture maintains high task success rates while minimizing token consumption compared to static agent swarms.

</details>


### [99] [Multi-Agent Cooperative Learning for Robust Vision-Language Alignment under OOD Concepts](https://arxiv.org/abs/2601.09746)
*Philip Xu,Isabel Wagner,Eerke Boiten*

Main category: cs.MA

TL;DR: 本文提出了一种多智能体协同学习（MACL）框架，通过四个核心智能体协作缓解视觉-语言模型在处理分布外概念时的跨模态对齐崩溃问题，在少样本和零样本设置下均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言模型在面对分布外（OOD）概念时出现的跨模态对齐崩溃问题，尤其是由于模态不平衡导致的性能下降。

Method: 引入包含图像、文本、命名和协调四个智能体的多智能体协同学习框架，通过结构化消息传递、多智能体特征空间命名学习、上下文交换增强的少样本学习算法以及自适应动态平衡机制来调节智能体间的贡献。

Result: 在VISTA-Beyond数据集上的实验表明，MACL在少样本和零样本场景中均显著优于基线方法，在多个视觉领域中实现了1-5%的精度提升。

Conclusion: 所提出的MACL框架有效缓解了跨模态对齐崩溃问题，提升了模型在分布外概念上的泛化能力，为多模态学习提供了新的协同建模范式。

Abstract: This paper introduces a novel Multi-Agent Cooperative Learning (MACL) framework to address cross-modal alignment collapse in vision-language models when handling out-of-distribution (OOD) concepts. Four core agents, including image, text, name, and coordination agents, collaboratively mitigate modality imbalance through structured message passing. The proposed framework enables multi-agent feature space name learning, incorporates a context exchange enhanced few-shot learning algorithm, and adopts an adaptive dynamic balancing mechanism to regulate inter-agent contributions. Experiments on the VISTA-Beyond dataset demonstrate that MACL significantly improves performance in both few-shot and zero-shot settings, achieving 1-5% precision gains across diverse visual domains.

</details>


### [100] [When Personas Override Payoffs: Role Identity Bias in Multi-Agent LLM Decision-Making](https://arxiv.org/abs/2601.10102)
*Viswonathan Manoranjan,Snehalkumar `Neil' S. Gaikwad*

Main category: cs.MA

TL;DR: 该研究发现，在多智能体系统中，角色身份（personas）和收益可见性显著影响大语言模型的战略推理能力；去除角色身份并提供明确收益信息可使Qwen模型高效达成纳什均衡，而角色身份会引导模型偏向社会偏好结果，忽略收益最优解；不同模型对这些设计选择的敏感性存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 理解多智能体系统中设计选择（如角色身份和收益可见性）如何影响大语言模型的战略推理能力，特别是在复杂环境决策任务中，系统是作为追求收益最优化的战略推理者，还是作为优先对齐角色身份的身份驱动行为者。

Method: 在包含四个智能体的复杂环境决策博弈中，对四种大语言模型（Qwen-7B、Qwen-32B、Llama-8B、Mistral-7B）进行系统实验，通过是否提供角色身份和明确收益信息的不同组合，以纳什均衡达成率作为战略推理能力的诊断指标。

Result: 1）去除角色身份并提供明确收益信息时，Qwen模型能高效达成纳什均衡；2）角色身份会系统性地将均衡选择偏向“绿色转型”等社会偏好结果，即使“公地悲剧”是收益最优解也无法达成均衡；3）收益信息的效果完全依赖于角色身份是否存在；4）Qwen模型对设计选择高度敏感，而Llama和Mistral表现僵化。

Conclusion: 在多智能体系统中，表征设计选择（如角色身份和收益可见性）是实质性的治理决策，决定了系统是作为战略推理者还是身份驱动行为者，这对现实世界部署具有重要影响。

Abstract: Large language models are increasingly deployed in multi-agent systems for strategic tasks, yet how design choices such as role-based personas and payoff visibility affect reasoning remains poorly understood. We investigate whether multi-agent systems function as strategic reasoners capable of payoff optimization or as identity-driven actors that prioritize role alignment over explicit incentives. Using Nash equilibrium achievement as a diagnostic for strategic reasoning, we conduct systematic experiments across four LLM architectures (Qwen-7B, Qwen-32B, Llama-8B, Mistral-7B) in complex environmental decision-making games involving four agents. We show that role identity bias fundamentally alters strategic reasoning even when payoff-optimal equilibria exist and complete payoff information is available. Removing personas and providing explicit payoffs enables Qwen models to achieve high Nash equilibrium rates, indicating that both conditions are necessary for strategic reasoning. In contrast, personas systematically bias equilibrium selection toward socially preferred outcomes: with personas present, all of the achieved equilibria correspond to Green Transition, while models entirely fail to reach equilibrium when Tragedy of the Commons is payoff-optimal. The effect of explicit payoffs depends entirely on persona presence, revealing strong interactions between representational design choices. We also observe clear model-dependent patterns. Qwen architectures are highly sensitive to both personas and payoff visibility, whereas Llama and Mistral exhibit rigid reasoning behavior across conditions. These findings demonstrate that representational choices are substantive governance decisions that determine whether multi-agent systems act as strategic reasoners or identity-driven actors, with important implications for real-world deployment.

</details>


### [101] [TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems](https://arxiv.org/abs/2601.10120)
*Rui Sun,Jie Ding,Chenghua Gong,Tianjun Gu,Yihang Jiang,Juyuan Zhang,Liming Pan,Linyuan Lü*

Main category: cs.MA

TL;DR: TopoDIM 是一种用于大语言模型多智能体系统的单次通信拓扑生成框架，通过多样化的交互模式实现去中心化、高效且高性能的通信。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖时空交互范式，在多轮对话中产生高延迟和计算开销；受评估与辩论机制可提升多智能体问题解决能力的启发，作者提出新框架以克服上述限制。

Method: 提出 TopoDIM 框架，支持去中心化执行，使智能体能自主构建异构通信拓扑，无需迭代协调，实现多样化的交互模式。

Result: 实验表明，TopoDIM 相比最先进方法减少 46.41% 的总 token 消耗，并平均提升 1.50% 的任务性能，同时在异构智能体通信组织上表现出强适应性。

Conclusion: TopoDIM 有效提升了多智能体系统在通信效率与任务性能方面的表现，为去中心化、异构智能体协作提供了可行方案。

Abstract: Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes. Designed for decentralized execution to enhance adaptability and privacy, TopoDIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TopoDIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. Moreover, the framework exhibits strong adaptability in organizing communication among heterogeneous agents. Code is available at: https://anonymous.4open.science/r/TopoDIM-8D35/

</details>


### [102] [Fairness Driven Multi-Agent Path Finding Problem](https://arxiv.org/abs/2601.10123)
*Aditi Anand,Dildar Ali,Suman Banerjee*

Main category: cs.MA

TL;DR: 本文研究了多智能体路径规划（MAPF）问题，在考虑公平性的前提下，分别针对非理性智能体提出启发式解法，以及针对理性智能体设计了一个满足激励相容、个体理性且具有占优策略的机制。


<details>
  <summary>Details</summary>
Motivation: MAPF 问题在机器人路径规划和无人机空域分配等现实场景中广泛存在，但其计算复杂度高；此外，当智能体具有理性行为时，可能虚报私有信息，因此需要在公平性框架下设计有效机制。

Method: 对非理性智能体采用启发式算法求解；对理性智能体则设计一个机制，并证明其具备占优策略、激励相容性和个体理性。

Result: 通过多种求解方法验证了所提方法在效率与有效性方面的优势。

Conclusion: 本文在公平性视角下为 MAPF 问题提供了兼顾非理性与理性智能体的解决方案，兼具理论保证与实际可行性。

Abstract: The Multi-Agent Path Finding (MAPF) problem aims at finding non-conflicting paths for multiple agents from their respective sources to destinations. This problem arises in multiple real-life situations, including robot motion planning and airspace assignment for unmanned aerial vehicle movement. The problem is computationally expensive, and adding to it, the agents are rational and can misreport their private information. In this paper, we study both variants of the problem under the realm of fairness. For the non-rational agents, we propose a heuristic solution for this problem. Considering the agents are rational, we develop a mechanism and demonstrate that it is a dominant strategy, incentive compatible, and individually rational. We employ various solution methodologies to highlight the effectiveness and efficiency of the proposed solution approaches.

</details>


### [103] [Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems](https://arxiv.org/abs/2601.10560)
*Xi Shi,Mengxin Zheng,Qian Lou*

Main category: cs.MA

TL;DR: 本文提出了一种名为LAMaS的延迟感知多智能体系统框架，通过在并行执行下显式优化关键执行路径，显著降低推理延迟，同时保持或提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有大多数多智能体系统方法主要优化任务性能和推理成本，通常假设顺序执行，在并行执行场景下难以有效控制延迟，限制了其在时间敏感应用中的可扩展性和实用性。

Method: 提出LAMaS框架，采用基于学习的编排策略，在并行执行环境下对多智能体系统进行显式的延迟监督，通过构建低延迟的执行拓扑图来优化关键路径。

Result: 在多个基准测试中，相比当前最先进的多智能体架构搜索方法，LAMaS将关键路径长度减少了38%–46%，同时维持甚至提升了任务性能。

Conclusion: 显式优化并行执行下的延迟对于设计高效多智能体系统至关重要，LAMaS为此提供了一种有效解决方案。

Abstract: Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS

</details>


### [104] [Procedural Fairness in Multi-Agent Bandits](https://arxiv.org/abs/2601.10600)
*Joshua Caiata,Carter Blair,Kate Larson*

Main category: cs.MA

TL;DR: 该论文提出了一种新的公平性目标——程序公平性，强调在多智能体多臂老虎机（MA-MAB）问题中赋予所有智能体平等的决策权，而非仅优化结果（如福利最大化或效用均衡）。研究表明，基于结果的公平性会牺牲个体的发言权和代表性，而采用程序公平策略对结果公平性的影响很小。作者论证了不同公平理念本质上代表互不相容的价值取向，主张应更重视程序合法性，并提供了实现程序公平的框架。


<details>
  <summary>Details</summary>
Motivation: 现有MA-MAB中的公平性研究主要关注结果层面（如福利、不平等、效用平衡），但心理学、经济学和罗尔斯理论表明，公平也关乎过程与决策参与权。因此，有必要引入一种兼顾决策平等与结果比例性的新公平范式。

Method: 提出“程序公平”这一新目标，其核心是确保所有智能体拥有平等的决策权力，并满足比例性结果要求；通过理论分析与实证比较，评估程序公平与传统结果导向公平（如平等主义、功利主义）之间的权衡。

Result: 实证结果显示，以结果为导向的公平策略显著牺牲了智能体的平等发言权和代表性，而采用程序公平策略对结果公平性（如平等性和功利性）的损失极小；此外，不同公平理念所优先的价值存在根本性冲突。

Conclusion: 公平性需依赖明确的规范性选择，程序合法性应作为关键公平目标受到更多关注；本文为此提供了可操作的程序公平实现框架。

Abstract: In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice.

</details>
