<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 81]
- [cs.CG](#cs.CG) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Complex Mathematical Expression Recognition: Benchmark, Large-Scale Dataset and Strong Baseline](https://arxiv.org/abs/2512.13731)
*Weikang Bai,Yongkun Du,Yuchen Su,Yazhen Xie,Zhineng Chen*

Main category: cs.CV

TL;DR: 本文提出了CMER-Bench基准、大规模复杂数学表达式数据集MER-17M和CMER-3M，以及一种新的结构化数学语言表示方法和专用模型CMERNet，在复杂数学表达式识别任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前数学表达式识别（MER）在处理包含大量符号和多行结构的复杂表达式时性能显著下降，主要原因是现有公开训练数据集中简单样本占主导，缺乏对复杂表达式的覆盖。

Method: 构建了包含三个难度级别的CMER-Bench基准；发布了强调复杂表达式的MER-17M和CMER-3M数据集；提出了一种新的表达式分词器和结构化数学语言表示；在此基础上设计了基于编码器-解码器架构的专用模型CMERNet，并在CMER-3M上进行训练。

Result: 实验表明，仅含1.25亿参数的CMERNet在CMER-Bench上显著优于现有的MER模型和通用多模态大语言模型（MLLMs），尤其在复杂表达式识别方面表现突出。

Conclusion: 通过构建更全面的评估基准、发布聚焦复杂表达式的大规模数据集，并引入能显式建模表达式层次与空间结构的新表示方法和专用模型，可有效提升复杂数学表达式识别的准确性和鲁棒性。

Abstract: Mathematical Expression Recognition (MER) has made significant progress in recognizing simple expressions, but the robust recognition of complex mathematical expressions with many tokens and multiple lines remains a formidable challenge. In this paper, we first introduce CMER-Bench, a carefully constructed benchmark that categorizes expressions into three difficulty levels: easy, moderate, and complex. Leveraging CMER-Bench, we conduct a comprehensive evaluation of existing MER models and general-purpose multimodal large language models (MLLMs). The results reveal that while current methods perform well on easy and moderate expressions, their performance degrades significantly when handling complex mathematical expressions, mainly because existing public training datasets are primarily composed of simple samples. In response, we propose MER-17M and CMER-3M that are large-scale datasets emphasizing the recognition of complex mathematical expressions. The datasets provide rich and diverse samples to support the development of accurate and robust complex MER models. Furthermore, to address the challenges posed by the complicated spatial layout of complex expressions, we introduce a novel expression tokenizer, and a new representation called Structured Mathematical Language, which explicitly models the hierarchical and spatial structure of expressions beyond LaTeX format. Based on these, we propose a specialized model named CMERNet, built upon an encoder-decoder architecture and trained on CMER-3M. Experimental results show that CMERNet, with only 125 million parameters, significantly outperforms existing MER models and MLLMs on CMER-Bench.

</details>


### [2] [Human-AI Collaboration Mechanism Study on AIGC Assisted Image Production for Special Coverage](https://arxiv.org/abs/2512.13739)
*Yajie Yang,Yuqing Zhao,Xiaochao Xi,Yinan Zhu*

Main category: cs.CV

TL;DR: 本文探讨了人工智能生成内容（AIGC）在新闻特稿图像制作中的可控性问题，通过两个实验分析现有工具的语义对齐缺陷，并提出一种结合高精度分割、语义对齐与风格调控的人机协同模块化流程，以提升新闻图像的真实性、文化准确性与公众适宜性。


<details>
  <summary>Details</summary>
Motivation: AIGC在新闻图像生产中引发关于虚假信息、真实性、语义保真度和可解释性的争议；现有工具多为“黑箱”，难以兼顾内容准确性与语义一致性，带来伦理、社会技术与信任挑战。

Method: 开展两项实验：(1) 跨平台适应性测试，使用标准化提示评估三个场景下不同AIGC平台的表现；(2) 构建人机协同模块化流程，整合SAM/GroundingDINO进行分割、BrushNet实现语义对齐、Style-LoRA/Prompt-to-Prompt调节风格，并通过CLIP评分、NSFW/OCR/YOLO过滤及可验证凭证保障编辑忠实度。

Result: 实验1揭示训练语料偏差和平台过滤机制导致语义对齐、文化特异性与视觉真实感存在显著差异；实验2所提流程有效保障语义表达的可追溯性与编辑控制力，并提出Character Identity Stability (CIS)、Cultural Expression Accuracy (CEA) 和 User-Public Appropriateness (U-PA) 三项评估指标。

Conclusion: 为应对AIGC在新闻特稿中的可信度挑战，应建立人机协作机制，通过模块化、可追溯、可验证的技术路径提升图像生产的可控性，并采用CIS、CEA与U-PA作为关键评估维度。

Abstract: Artificial Intelligence Generated Content (AIGC) assisting image production triggers controversy in journalism while attracting attention from media agencies. Key issues involve misinformation, authenticity, semantic fidelity, and interpretability. Most AIGC tools are opaque "black boxes," hindering the dual demands of content accuracy and semantic alignment and creating ethical, sociotechnical, and trust dilemmas. This paper explores pathways for controllable image production in journalism's special coverage and conducts two experiments with projects from China's media agency: (1) Experiment 1 tests cross-platform adaptability via standardized prompts across three scenes, revealing disparities in semantic alignment, cultural specificity, and visual realism driven by training-corpus bias and platform-level filtering. (2) Experiment 2 builds a human-in-the-loop modular pipeline combining high-precision segmentation (SAM, GroundingDINO), semantic alignment (BrushNet), and style regulating (Style-LoRA, Prompt-to-Prompt), ensuring editorial fidelity through CLIP-based semantic scoring, NSFW/OCR/YOLO filtering, and verifiable content credentials. Traceable deployment preserves semantic representation. Consequently, we propose a human-AI collaboration mechanism for AIGC assisted image production in special coverage and recommend evaluating Character Identity Stability (CIS), Cultural Expression Accuracy (CEA), and User-Public Appropriateness (U-PA).

</details>


### [3] [DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models](https://arxiv.org/abs/2512.13742)
*Md. Najib Hasan,Imran Ahmad,Sourav Basak Shuvo,Md. Mahadi Hasan Ankon,Sunanda Das,Nazmul Siddique,Hui Wang*

Main category: cs.CV

TL;DR: 本文提出一个结合深度学习图像分类与大语言模型（LLM）临床推理的框架，用于提升胃肠道疾病诊断的可解释性。新提出的MobileCoAtNet模型在八类胃部疾病上表现优异，其分类结果驱动多个LLM生成临床解释，并通过两个专家验证的基准评估解释质量。研究发现，尽管强分类能力可提升解释质量，但当前LLM在医学高风险场景中仍不可靠，且对提示敏感、稳定性不足。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类器虽能有效检测胃肠道疾病，但缺乏可解释性；而大语言模型虽能生成临床文本，却在视觉推理方面存在不足，难以提供稳定、准确的临床解释。因此，亟需弥合模型“所见”与临床医生期望的推理之间的差距。

Method: 提出一个新框架，将基于MobileCoAtNet的深度学习图像分类器与多个大语言模型结合：首先利用MobileCoAtNet对内窥镜图像进行高精度分类，然后以其输出驱动LLM生成结构化临床推理。同时构建两个涵盖病因、症状、治疗、生活方式和随访的专家验证基准，用于评估32个LLM的解释质量。

Result: MobileCoAtNet在八类胃部疾病分类任务中取得高准确率；强分类性能提升了LLM生成解释的质量，但所有LLM均未达到人类水平的稳定性，且对提示变化敏感，解释内容易变。

Conclusion: 结合深度学习与大语言模型可生成有用的临床叙述，但当前LLM在高风险医疗决策中仍不可靠。该框架有助于揭示LLM的局限性，并为构建更安全的医学推理系统提供路径。

Abstract: Medical image classifiers detect gastrointestinal diseases well, but they do not explain their decisions. Large language models can generate clinical text, yet they struggle with visual reasoning and often produce unstable or incorrect explanations. This leaves a gap between what a model sees and the type of reasoning a clinician expects. We introduce a framework that links image classification with structured clinical reasoning. A new hybrid model, MobileCoAtNet, is designed for endoscopic images and achieves high accuracy across eight stomach-related classes. Its outputs are then used to drive reasoning by several LLMs. To judge this reasoning, we build two expert-verified benchmarks covering causes, symptoms, treatment, lifestyle, and follow-up care. Thirty-two LLMs are evaluated against these gold standards. Strong classification improves the quality of their explanations, but none of the models reach human-level stability. Even the best LLMs change their reasoning when prompts vary. Our study shows that combining DL with LLMs can produce useful clinical narratives, but current LLMs remain unreliable for high-stakes medical decisions. The framework provides a clearer view of their limits and a path for building safer reasoning systems. The complete source code and datasets used in this study are available at https://github.com/souravbasakshuvo/DL3M.

</details>


### [4] [HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis](https://arxiv.org/abs/2512.14352)
*Kaizhe Zhang,Yijie Zhou,Weizhan Zhang,Caixia Yan,Haipeng Du,yugui xie,Yu-Hui Wen,Yong-Jin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Hybrid Gaussian Splatting (HGS) 的高效动态新视角合成方法，通过静态-动态区域解耦和径向基函数建模，在大幅压缩模型体积的同时实现高质量实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的动态新视角合成方法因模型复杂度过高、参数冗余严重，导致模型体积庞大、渲染速度慢，难以满足资源受限设备上的实时应用需求。

Method: 提出 Hybrid Gaussian Splatting（HGS）框架，核心是静态-动态分解（SDD）策略：对动态区域使用时间相关的径向基函数（RBF）建模以捕捉时序变化和突变；对静态区域共享时间不变参数以减少冗余。同时采用两阶段训练策略提升静态-动态边界的时间一致性。

Result: 模型体积最多减少98%，在单张RTX 3090上实现4K分辨率最高125 FPS的实时渲染，在RTX 3050上达160 FPS，并已集成至VR系统；在高频细节和场景突变方面视觉保真度优于现有方法，整体渲染质量与SOTA相当。

Conclusion: HGS通过显式建模与参数解耦，在显著降低模型复杂度的同时保持甚至提升了动态新视角合成的渲染质量和效率，为资源受限设备上的沉浸式应用提供了可行方案。

Abstract: Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.

</details>


### [5] [Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making](https://arxiv.org/abs/2512.13747)
*Siyuan Dai,Lunxiao Li,Kun Zhao,Eardi Lila,Paul K. Crane,Heng Huang,Dongkuan Xu,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 当前多模态大语言模型（MLLMs）在生物医学领域的视觉-语言任务中表现不佳，尤其在阿尔茨海默病三阶段分类和胸部X光片多标签诊断任务中，纯文本推理优于多模态输入。研究提出三种改进策略，并指出MLLMs缺乏具身视觉理解。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在通用视觉-语言任务中展现出强大的零样本能力，但在医学决策任务中表现欠佳，尤其是在视觉差异细微或标签复杂的场景下，亟需探究其局限性并提出改进方法。

Method: 作者构建两个具有挑战性的医学数据集（阿尔茨海默病三阶段分类和MIMIC-CXR胸片14类诊断），系统评估MLLM在纯文本、纯视觉及多模态设置下的表现，并尝试三种缓解策略：带推理注释的上下文学习、先生成图像描述再进行纯文本推理、以及对视觉编码器进行少样本微调。

Result: 实验发现，在医学决策任务中，纯文本推理始终优于包含视觉信息的设置，多模态输入甚至常比仅用文本更差；所提出的三种策略在一定程度上缓解了该问题。

Conclusion: 当前MLLM在医学领域缺乏扎实的视觉理解能力，未来应加强视觉与语义的对齐，提升多模态医疗决策的可靠性。

Abstract: With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.

</details>


### [6] [STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning](https://arxiv.org/abs/2512.13752)
*Jie Qin,Jiancheng Huang,Limeng Qiao,Lin Ma*

Main category: cs.CV

TL;DR: STAR提出了一种堆叠自回归方案，通过分阶段处理理解、生成和编辑任务，在不干扰已有能力的前提下提升多模态大语言模型的生成性能，并在多个基准上达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在统一理解和生成目标方面面临优化冲突与性能权衡的挑战，亟需一种既能增强生成能力又不损害理解能力的方法。

Method: STAR将多模态学习分解为理解、生成和编辑三个阶段，冻结基础自回归模型参数，并逐层堆叠同构自回归模块以避免任务间干扰；同时引入高容量VQ提升图像表征粒度，并采用隐式推理机制改善复杂条件下的生成质量。

Result: STAR在GenEval（0.91）、DPG-Bench（87.44）和ImgEdit（4.34）等基准上取得当前最优性能。

Conclusion: STAR有效实现了统一的多模态学习，在保持理解能力的同时显著提升了生成与编辑性能。

Abstract: Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.

</details>


### [7] [Time-aware UNet and super-resolution deep residual networks for spatial downscaling](https://arxiv.org/abs/2512.13753)
*Mika Sipilä,Sabrina Maggio,Sandra De Iaco,Klaus Nordhausen,Monica Palma,Sara Taskinen*

Main category: cs.CV

TL;DR: 本文提出在SRDRN和UNet两种深度学习模型中引入轻量级时间模块，通过正弦或径向基函数编码观测时间，提升对流层臭氧卫星数据的空间降尺度性能。


<details>
  <summary>Details</summary>
Motivation: 卫星大气污染物数据空间分辨率较低，限制了其在局地环境分析与决策中的应用，因此需要有效的空间降尺度方法。

Method: 在SRDRN和UNet模型中加入轻量级时间模块，利用正弦或RBF编码将观测时间信息融合进空间特征表示中，实现时间感知的臭氧降尺度。

Result: 在意大利臭氧降尺度案例中，所提时间感知模型在仅小幅增加计算复杂度的情况下，显著提升了降尺度性能和收敛速度。

Conclusion: 引入时间信息有助于提升深度学习模型在大气污染物空间降尺度任务中的表现，是一种高效且有效的改进策略。

Abstract: Satellite data of atmospheric pollutants are often available only at coarse spatial resolution, limiting their applicability in local-scale environmental analysis and decision-making. Spatial downscaling methods aim to transform the coarse satellite data into high-resolution fields. In this work, two widely used deep learning architectures, the super-resolution deep residual network (SRDRN) and the encoder-decoder-based UNet, are considered for spatial downscaling of tropospheric ozone. Both methods are extended with a lightweight temporal module, which encodes observation time using either sinusoidal or radial basis function (RBF) encoding, and fuses the temporal features with the spatial representations in the networks. The proposed time-aware extensions are evaluated against their baseline counterparts in a case study on ozone downscaling over Italy. The results suggest that, while only slightly increasing computational complexity, the temporal modules significantly improve downscaling performance and convergence speed.

</details>


### [8] [Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries](https://arxiv.org/abs/2512.13796)
*Victor Rong,Jan Held,Victor Chu,Daniel Rebain,Marc Van Droogenbroeck,Kiriakos N. Kutulakos,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 该论文提出了一种超越点渲染的新表示方法，通过将几何与外观解耦，在显著减少图元数量和内存占用的同时，保持与3D高斯泼溅相当的感知质量，并实现更快的渲染速度。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅虽在新视角合成中表现优异，但需数百万图元才能建模高纹理场景，即使场景几何结构简单，也导致资源消耗大；因此需要一种更紧凑高效的表示方法。

Method: 使用surfels表示几何，并结合全局神经场与每个图元的颜色来表示外观；神经场为每个像素纹理固定数量的图元，以控制计算开销。

Result: 在室外场景中使用9.7倍更少的图元和5.5倍更少的内存，在室内场景中使用31倍更少的图元和3.7倍更少的内存，同时渲染速度是现有纹理图元方法的两倍，并提升了视觉质量。

Conclusion: 所提方法在大幅降低资源消耗的同时，保持甚至超越了现有方法的渲染质量和效率，验证了解耦几何与外观表示的有效性。

Abstract: Though Gaussian splatting has achieved impressive results in novel view synthesis, it requires millions of primitives to model highly textured scenes, even when the geometry of the scene is simple. We propose a representation that goes beyond point-based rendering and decouples geometry and appearance in order to achieve a compact representation. We use surfels for geometry and a combination of a global neural field and per-primitive colours for appearance. The neural field textures a fixed number of primitives for each pixel, ensuring that the added compute is low. Our representation matches the perceptual quality of 3D Gaussian splatting while using $9.7\times$ fewer primitives and $5.5\times$ less memory on outdoor scenes and using $31\times$ fewer primitives and $3.7\times$ less memory on indoor scenes. Our representation also renders twice as fast as existing textured primitives while improving upon their visual quality.

</details>


### [9] [MoLingo: Motion-Language Alignment for Text-to-Motion Generation](https://arxiv.org/abs/2512.13840)
*Yannan He,Garvita Tiwari,Xiaohan Zhang,Pankaj Bora,Tolga Birdal,Jan Eric Lenssen,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: MoLingo 是一种新型文本到动作生成模型，通过在语义对齐的连续潜在空间中进行去噪扩散，并结合交叉注意力文本条件机制，实现了当前最优的人体动作生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法在潜在空间扩散策略和文本条件注入方式上存在局限，影响生成动作的真实性和与文本描述的一致性。本文旨在探索如何构建更适合扩散的语义对齐潜在空间，并优化文本条件注入方式以提升生成质量。

Method: 提出一种语义对齐的动作编码器，利用帧级文本标签训练，使语义相近的动作潜在表示更接近；同时采用多令牌交叉注意力机制替代单令牌条件注入，并结合自回归生成策略在连续潜在空间中进行扩散。

Result: MoLingo 在标准评估指标和用户研究中均达到新的最先进水平，显著提升了动作的真实感和文本-动作对齐度。

Conclusion: 通过语义对齐的潜在空间、自回归生成和交叉注意力文本条件机制，MoLingo 有效提升了文本到人体动作生成的质量，为后续研究和应用提供了有力工具。

Abstract: We introduce MoLingo, a text-to-motion (T2M) model that generates realistic, lifelike human motion by denoising in a continuous latent space. Recent works perform latent space diffusion, either on the whole latent at once or auto-regressively over multiple latents. In this paper, we study how to make diffusion on continuous motion latents work best. We focus on two questions: (1) how to build a semantically aligned latent space so diffusion becomes more effective, and (2) how to best inject text conditioning so the motion follows the description closely. We propose a semantic-aligned motion encoder trained with frame-level text labels so that latents with similar text meaning stay close, which makes the latent space more diffusion-friendly. We also compare single-token conditioning with a multi-token cross-attention scheme and find that cross-attention gives better motion realism and text-motion alignment. With semantically aligned latents, auto-regressive generation, and cross-attention text conditioning, our model sets a new state of the art in human motion generation on standard metrics and in a user study. We will release our code and models for further research and downstream usage.

</details>


### [10] [Coarse-to-Fine Hierarchical Alignment for UAV-based Human Detection using Diffusion Models](https://arxiv.org/abs/2512.13869)
*Wenda Li,Meng Wu,Sungmin Eum,Heesung Kwon,Qing Qu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CFHA的三阶段扩散框架，用于将合成数据转化为适用于无人机（UAV）场景下的人体检测任务，通过全局风格迁移、局部细节增强和幻觉实例过滤，有效缩小合成域与真实域之间的差距，在多个Sim2Real基准上显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 无人机人体检测面临标注数据稀缺及目标分布动态变化的问题，虽可借助合成数据缓解标注成本，但合成图像与真实图像之间存在显著域偏移，限制了模型在真实场景中的泛化能力。

Method: 提出Coarse-to-Fine Hierarchical Alignment（CFHA）框架，包含三个模块：（1）全局风格迁移：利用扩散模型将合成图像的颜色、光照和纹理对齐到真实图像风格；（2）局部细化：使用超分辨率扩散模型增强小目标（如人体）的细节，保持形状和边界；（3）幻觉去除：过滤视觉属性不符真实分布的人体实例。

Result: 在公开的UAV Sim2Real检测基准上，CFHA显著优于未转换的基线方法，在Semantic-Drone数据集上mAP50提升高达14.1；消融实验验证了各模块的互补性和分层对齐的有效性。

Conclusion: CFHA通过分层对齐策略有效弥合了合成与真实图像间的域差距，在保留原始标注的同时显著提升了UAV场景下的人体检测性能，为Sim2Real迁移提供了实用且高效的解决方案。

Abstract: Training object detectors demands extensive, task-specific annotations, yet this requirement becomes impractical in UAV-based human detection due to constantly shifting target distributions and the scarcity of labeled images. As a remedy, synthetic simulators are adopted to generate annotated data, with a low annotation cost. However, the domain gap between synthetic and real images hinders the model from being effectively applied to the target domain. Accordingly, we introduce Coarse-to-Fine Hierarchical Alignment (CFHA), a three-stage diffusion-based framework designed to transform synthetic data for UAV-based human detection, narrowing the domain gap while preserving the original synthetic labels. CFHA explicitly decouples global style and local content domain discrepancies and bridges those gaps using three modules: (1) Global Style Transfer -- a diffusion model aligns color, illumination, and texture statistics of synthetic images to the realistic style, using only a small real reference set; (2) Local Refinement -- a super-resolution diffusion model is used to facilitate fine-grained and photorealistic details for the small objects, such as human instances, preserving shape and boundary integrity; (3) Hallucination Removal -- a module that filters out human instances whose visual attributes do not align with real-world data to make the human appearance closer to the target distribution. Extensive experiments on public UAV Sim2Real detection benchmarks demonstrate that our methods significantly improve the detection accuracy compared to the non-transformed baselines. Specifically, our method achieves up to $+14.1$ improvement of mAP50 on Semantic-Drone benchmark. Ablation studies confirm the complementary roles of the global and local stages and highlight the importance of hierarchical alignment. The code is released at \href{https://github.com/liwd190019/CFHA}{this url}.

</details>


### [11] [SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning](https://arxiv.org/abs/2512.13874)
*Jitesh Jain,Jialuo Li,Zixian Ma,Jieyu Zhang,Chris Dongjoo Kim,Sangho Lee,Rohun Tripathi,Tanmay Gupta,Christopher Clark,Humphrey Shi*

Main category: cs.CV

TL;DR: 本文提出SAGE系统，通过多轮推理机制实现对任意时长视频的高效理解，并引入合成数据生成流程与强化学习后训练策略，显著提升了长视频推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视频推理模型通常以单轮方式处理大量帧，资源消耗大且缺乏人类般的灵活推理能力，难以适应不同长度视频的任务需求。

Method: 提出SAGE智能体系统，包含核心协调器SAGE-MM；利用Gemini-2.5-Flash构建合成数据生成流水线用于训练SAGE-MM；并设计强化学习后训练方案以增强其任意时长推理能力。

Result: 在开放域视频推理任务上最高提升6.1%，在超过10分钟的长视频上提升达8.2%；同时构建了平均时长超700秒的评测基准SAGE-Bench。

Conclusion: 所提出的SAGE系统、数据生成方法和强化学习训练策略有效提升了模型在任意时长视频上的推理能力，尤其在长视频场景中表现突出。

Abstract: As humans, we are natural any-horizon reasoners, i.e., we can decide whether to iteratively skim long videos or watch short ones in full when necessary for a given task. With this in mind, one would expect video reasoning models to reason flexibly across different durations. However, SOTA models are still trained to predict answers in a single turn while processing a large number of frames, akin to watching an entire long video, requiring significant resources. This raises the question: Is it possible to develop performant any-horizon video reasoning systems? Inspired by human behavior, we first propose SAGE, an agent system that performs multi-turn reasoning on long videos while handling simpler problems in a single turn. Secondly, we introduce an easy synthetic data generation pipeline using Gemini-2.5-Flash to train the orchestrator, SAGE-MM, which lies at the core of SAGE. We further propose an effective RL post-training recipe essential for instilling any-horizon reasoning ability in SAGE-MM. Thirdly, we curate SAGE-Bench with an average duration of greater than 700 seconds for evaluating video reasoning ability in real-world entertainment use cases. Lastly, we empirically validate the effectiveness of our system, data, and RL recipe, observing notable improvements of up to 6.1% on open-ended video reasoning tasks, as well as an impressive 8.2% improvement on videos longer than 10 minutes.

</details>


### [12] [Route-DETR: Pairwise Query Routing in Transformers for Object Detection](https://arxiv.org/abs/2512.13876)
*Ye Zhang,Qi Chen,Wenyou Huang,Rui Liu,Zhengjian Kang*

Main category: cs.CV

TL;DR: Route-DETR improves DETR by introducing adaptive pairwise routing in decoder self-attention to reduce query redundancy, achieving better performance without extra inference cost.


<details>
  <summary>Details</summary>
Motivation: DETR suffers from inefficient query competition where multiple queries converge to similar positions, causing redundant computations and suboptimal detection performance.

Method: Route-DETR introduces dual routing mechanisms—suppressor routes to reduce attention between competing queries and delegator routes to promote exploration of distinct regions—using inter-query similarity, confidence, and geometry. These are implemented via learnable low-rank attention biases and trained with a dual-branch strategy that adds no overhead at inference.

Result: Experiments on COCO and Cityscapes show consistent gains across DETR variants: +1.7% mAP over DINO with ResNet-50 and 57.6% mAP with Swin-L, outperforming previous state-of-the-art models.

Conclusion: Route-DETR effectively mitigates query redundancy in DETR through adaptive routing, significantly boosting detection accuracy while maintaining inference efficiency.

Abstract: Detection Transformer (DETR) offers an end-to-end solution for object detection by eliminating hand-crafted components like non-maximum suppression. However, DETR suffers from inefficient query competition where multiple queries converge to similar positions, leading to redundant computations. We present Route-DETR, which addresses these issues through adaptive pairwise routing in decoder self-attention layers. Our key insight is distinguishing between competing queries (targeting the same object) versus complementary queries (targeting different objects) using inter-query similarity, confidence scores, and geometry. We introduce dual routing mechanisms: suppressor routes that modulate attention between competing queries to reduce duplication, and delegator routes that encourage exploration of different regions. These are implemented via learnable low-rank attention biases enabling asymmetric query interactions. A dual-branch training strategy incorporates routing biases only during training while preserving standard attention for inference, ensuring no additional computational cost. Experiments on COCO and Cityscapes demonstrate consistent improvements across multiple DETR baselines, achieving +1.7% mAP gain over DINO on ResNet-50 and reaching 57.6% mAP on Swin-L, surpassing prior state-of-the-art models.

</details>


### [13] [KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI](https://arxiv.org/abs/2512.13902)
*Anning Tian,Byunghyun Ko,Kaichen Qu,Mengyuan Liu,Jeongkyu Lee*

Main category: cs.CV

TL;DR: 提出了一种名为KLO-Net的高效前列腺MRI分割模型，结合动态K近邻注意力机制与CSP编码器，在保证分割精度的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 前列腺MRI分割在临床工作站上的实时部署常受限于计算负载和内存占用，且由于解剖结构变异大，深度学习方法面临挑战。因此，亟需一种兼顾效率与准确性的解决方案。

Method: 提出KLO-Net模型，包含动态K近邻注意力机制（可自适应确定每个空间位置的注意力连接数）和Cross Stage Partial（CSP）编码器以降低计算与内存开销。

Result: 在PROMISE12和PROSTATEx两个公开数据集上的实验表明，该模型在计算效率和分割质量方面均优于现有方法。

Conclusion: KLO-Net有效平衡了前列腺MRI分割任务中的效率与准确性，具备良好的临床部署潜力。

Abstract: Real-time deployment of prostate MRI segmentation on clinical workstations is often bottlenecked by computational load and memory footprint. Deep learning-based prostate gland segmentation approaches remain challenging due to anatomical variability. To bridge this efficiency gap while still maintaining reliable segmentation accuracy, we propose KLO-Net, a dynamic K-Nearest Neighbor attention U-Net with Cross Stage Partial, i.e., CSP, encoder for efficient prostate gland segmentation from MRI scan. Unlike the regular K-NN attention mechanism, the proposed dynamic K-NN attention mechanism allows the model to adaptively determine the number of attention connections for each spatial location within a slice. In addition, CSP blocks address the computational load to reduce memory consumption. To evaluate the model's performance, comprehensive experiments and ablation studies are conducted on two public datasets, i.e., PROMISE12 and PROSTATEx, to validate the proposed architecture. The detailed comparative analysis demonstrates the model's advantage in computational efficiency and segmentation quality.

</details>


### [14] [From Unlearning to UNBRANDING: A Benchmark for Trademark-Safe Text-to-Image Generation](https://arxiv.org/abs/2512.13953)
*Dawid Malarz,Artur Kasymov,Filip Manjak,Maciej Zięba,Przemysław Spurek*

Main category: cs.CV

TL;DR: 本文提出“去品牌化”（unbranding）新任务，旨在细粒度地移除图像中的商标及隐含的品牌结构特征（如汽车格栅、可乐瓶形状），同时保持语义一致性，并构建了首个相关基准数据集和基于视觉语言模型（VLM）的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型容易未经授权复现品牌内容，而当前方法仅关注通用概念（如风格、名人），无法处理多维度的品牌识别问题，包括显式商标和隐含的结构性品牌特征（即“商业外观”，trade dress）。

Method: 提出“去品牌化”任务，构建包含品牌标识与结构特征的基准数据集，并设计基于视觉语言模型（VLM）的问答式评估指标，以同时检测显式logo和隐式整体品牌特征。

Result: 实验表明，随着模型保真度提升（如SDXL、FLUX相比早期Stable Diffusion），生成品牌标识的倾向更强；所提VLM评估指标验证了“去品牌化”是一个独特且具有现实意义的问题。

Conclusion: “去品牌化”需专门技术应对，本文通过新任务定义、数据集和评估指标为该方向奠定基础，凸显了在高保真生成模型时代保护品牌知识产权的紧迫性。

Abstract: The rapid progress of text-to-image diffusion models raises significant concerns regarding the unauthorized reproduction of trademarked content. While prior work targets general concepts (e.g., styles, celebrities), it fails to address specific brand identifiers. Crucially, we note that brand recognition is multi-dimensional, extending beyond explicit logos to encompass distinctive structural features (e.g., a car's front grille). To tackle this, we introduce unbranding, a novel task for the fine-grained removal of both trademarks and subtle structural brand features, while preserving semantic coherence. To facilitate research, we construct a comprehensive benchmark dataset. Recognizing that existing brand detectors are limited to logos and fail to capture abstract trade dress (e.g., the shape of a Coca-Cola bottle), we introduce a novel evaluation metric based on Vision Language Models (VLMs). This VLM-based metric uses a question-answering framework to probe images for both explicit logos and implicit, holistic brand characteristics. Furthermore, we observe that as model fidelity increases, with newer systems (SDXL, FLUX) synthesizing brand identifiers more readily than older models (Stable Diffusion), the urgency of the unbranding challenge is starkly highlighted. Our results, validated by our VLM metric, confirm unbranding is a distinct, practically relevant problem requiring specialized techniques. Project Page: https://gmum.github.io/UNBRANDING/.

</details>


### [15] [FocalComm: Hard Instance-Aware Multi-Agent Perception](https://arxiv.org/abs/2512.13982)
*Dereje Shenkut,Vijayakumar Bhagavatula*

Main category: cs.CV

TL;DR: FocalComm 是一种新型多智能体协同感知框架，通过交换针对困难实例（如行人）的特征，在真实世界数据集上显著提升了行人等小型关键目标的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知方法主要优化车辆检测指标，对行人等小型但安全关键的目标检测效果不佳，且采用全特征交换，未聚焦于有助于减少漏检的显著特征。

Method: 提出 FocalComm 框架，包含两个核心设计：(1) 可学习的渐进式困难实例挖掘（HIM）模块，用于提取各智能体的困难实例导向特征；(2) 基于查询的特征级融合技术，在协作过程中动态加权这些特征。

Result: 在 V2X-Real 和 DAIR-V2X 两个真实数据集上，FocalComm 在车端和路侧协同设置下均优于当前最先进的方法，并在 V2X-Real 上显著提升了行人检测性能。

Conclusion: FocalComm 通过聚焦困难实例特征的交换与融合，有效提升了协同感知系统对安全关键目标（如行人）的检测能力，具有实际应用价值。

Abstract: Multi-agent collaborative perception (CP) is a promising paradigm for improving autonomous driving safety, particularly for vulnerable road users like pedestrians, via robust 3D perception. However, existing CP approaches often optimize for vehicle detection performance metrics, underperforming on smaller, safety-critical objects such as pedestrians, where detection failures can be catastrophic. Furthermore, previous CP methods rely on full feature exchange rather than communicating only salient features that help reduce false negatives. To this end, we present FocalComm, a novel collaborative perception framework that focuses on exchanging hard-instance-oriented features among connected collaborative agents. FocalComm consists of two key novel designs: (1) a learnable progressive hard instance mining (HIM) module to extract hard instance-oriented features per agent, and (2) a query-based feature-level (intermediate) fusion technique that dynamically weights these identified features during collaboration. We show that FocalComm outperforms state-of-the-art collaborative perception methods on two challenging real-world datasets (V2X-Real and DAIR-V2X) across both vehicle-centric and infrastructure-centric collaborative setups. FocalComm also shows a strong performance gain in pedestrian detection in V2X-Real.

</details>


### [16] [Repurposing 2D Diffusion Models for 3D Shape Completion](https://arxiv.org/abs/2512.13991)
*Yao He,Youngjoong Kwon,Tiange Xiang,Wenxiao Cai,Ehsan Adeli*

Main category: cs.CV

TL;DR: 本文提出了一种将2D扩散模型用于不完整点云的3D形状补全的新框架，通过引入名为Shape Atlas的紧凑2D几何表示，有效弥合了3D输入与2D潜在空间之间的模态鸿沟，并在有限3D数据下实现了高质量、细节保留的形状补全。


<details>
  <summary>Details</summary>
Motivation: 由于高质量3D数据集稀缺以及3D输入与2D潜在空间之间存在模态差异，3D扩散模型的发展滞后于2D扩散模型。为解决这些问题，作者希望利用预训练2D扩散模型的强大生成能力进行3D形状补全。

Method: 提出Shape Atlas——一种3D几何的紧凑2D表示方法，使预训练2D扩散模型能直接用于3D形状补全任务，并对齐条件输入与输出空间的模态，从而提升条件建模效果。

Result: 在PCN和ShapeNet-55数据集上验证了方法的有效性，生成的补全结果具有高质量和良好的细节保留能力，并成功应用于从补全点云生成艺术家级网格模型。

Conclusion: 所提出的统一2D表示框架有效克服了3D扩散模型的数据和模态限制，显著提升了3D形状补全的质量和实用性。

Abstract: We present a framework that adapts 2D diffusion models for 3D shape completion from incomplete point clouds. While text-to-image diffusion models have achieved remarkable success with abundant 2D data, 3D diffusion models lag due to the scarcity of high-quality 3D datasets and a persistent modality gap between 3D inputs and 2D latent spaces. To overcome these limitations, we introduce the Shape Atlas, a compact 2D representation of 3D geometry that (1) enables full utilization of the generative power of pretrained 2D diffusion models, and (2) aligns the modalities between the conditional input and output spaces, allowing more effective conditioning. This unified 2D formulation facilitates learning from limited 3D data and produces high-quality, detail-preserving shape completions. We validate the effectiveness of our results on the PCN and ShapeNet-55 datasets. Additionally, we show the downstream application of creating artist-created meshes from our completed point clouds, further demonstrating the practicality of our method.

</details>


### [17] [Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models](https://arxiv.org/abs/2512.14008)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: Sparse-LaViDa 是一种新型建模框架，通过在每一步推理中动态裁剪冗余的掩码标记，并引入专用寄存器标记来保持生成质量，从而将 MDM 的采样速度提升最高达 2 倍。


<details>
  <summary>Details</summary>
Motivation: Masked Discrete Diffusion Models（MDMs）在多模态任务中表现优异，但其推理速度受限于每一步采样中对大量冗余掩码标记的重复处理。

Method: 提出 Sparse-LaViDa 框架，在推理过程中动态截断不必要的掩码标记；引入专用寄存器标记以紧凑表示被截断的标记；设计专用注意力掩码以保证训练与推理过程的一致性。

Result: 基于 LaViDa-O 模型，Sparse-LaViDa 在文本到图像生成、图像编辑和数学推理等任务上实现最高 2 倍的加速，同时保持生成质量。

Conclusion: Sparse-LaViDa 有效提升了 MDM 的推理效率，为实际应用中的高效多模态生成提供了可行方案。

Abstract: Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

</details>


### [18] [KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding](https://arxiv.org/abs/2512.14017)
*Zongyao Li,Kengo Ishida,Satoshi Yamazaki,Xiaotong Ji,Jianquan Liu*

Main category: cs.CV

TL;DR: 提出了KFS-Bench，首个用于长视频问答中关键帧采样的基准，包含多场景标注，可直接评估采样策略；研究发现采样精度、场景覆盖与采样平衡是影响问答性能的关键因素，并据此设计了新的采样质量指标和一种基于问题-视频相关性的自适应平衡采样方法，在关键帧采样和问答任务上均取得更优表现。


<details>
  <summary>Details</summary>
Motivation: 现有工作仅通过问答准确率间接评估关键帧采样质量，缺乏对采样策略本身的直接、鲁棒评价手段。

Method: 构建包含多场景标注的KFS-Bench基准，开展全面的关键帧采样方法研究，并提出一种结合问题-视频相关性、在采样多样性与问题-帧相似性之间取得平衡的自适应采样方法。

Result: 发现采样精度、场景覆盖和采样平衡是影响问答性能的关键因素；所提新采样质量指标与问答准确率高度相关；新采样方法在关键帧采样质量和问答性能上均优于现有方法。

Conclusion: KFS-Bench为关键帧采样提供了直接评估手段，揭示了影响长视频问答性能的关键采样因素，并通过新指标和新方法验证了平衡采样的有效性，推动了高效长视频理解的发展。

Abstract: We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.

</details>


### [19] [Deep Learning Perspective of Scene Understanding in Autonomous Robots](https://arxiv.org/abs/2512.14020)
*Afia Maham,Dur E Nayab Tashfa*

Main category: cs.CV

TL;DR: 本文综述了深度学习在自主机器人场景理解中的应用，涵盖目标检测、语义与实例分割、深度估计、三维重建和视觉SLAM等方向，并探讨其如何克服传统几何模型的局限性，提升实时深度感知与语义推理能力，从而增强机器人在动态非结构化环境中的决策与交互能力。


<details>
  <summary>Details</summary>
Motivation: 传统几何模型在复杂、动态和非结构化环境中存在局限，难以应对遮挡、无纹理表面等问题，限制了机器人对环境的准确感知与理解。

Method: 综述深度学习在机器人场景理解中的多种关键技术，包括目标检测、语义与实例分割、深度估计、3D重建和视觉SLAM，并分析其集成应用效果。

Result: 深度学习方法显著提升了机器人在实时深度感知、语义理解和环境建模方面的能力，使其在复杂环境中更有效地进行导航、决策与交互。

Conclusion: 尽管深度学习推动了机器人场景理解的发展，但仍存在挑战，需进一步研究以实现更鲁棒、高效和可泛化的学习型感知系统。

Abstract: This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.

</details>


### [20] [Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers](https://arxiv.org/abs/2512.14026)
*Yibing Fu,Yunpeng Zhao,Zhitao Zeng,Cheng Chen,Yueming Jin*

Main category: cs.CV

TL;DR: 本文提出了一种名为CITab的新型自监督学习框架，通过引入语义感知的表格建模机制和原型引导的混合线性层（P-MoLin），实现了跨数据集的多模态医学图像与表格数据的有效融合，在阿尔茨海默病诊断任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在处理异构表格数据时存在建模机制僵化的问题，导致模型难以在不同数据队列间迁移共享的医学知识，限制了多模态表示学习的泛化能力与可扩展性。

Method: CITab框架从语义感知角度设计表格建模机制，将列标题作为语义线索，并引入原型引导的混合线性层（P-MoLin）模块以增强对表格数据异质性的处理能力，从而支持跨表格的多模态特征表示学习。

Result: 在包含4,461名受试者的三个公开阿尔茨海默病数据集上的实验表明，CITab在诊断任务中性能优于当前最先进的方法。

Conclusion: CITab有效解决了跨队列表格数据建模难题，为可扩展、高效的多模态医学自监督学习提供了新路径。

Abstract: Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

</details>


### [21] [Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding](https://arxiv.org/abs/2512.14028)
*Jiaheng Li,Qiyu Dai,Lihan Li,Praneeth Chakravarthula,He Sun,Baoquan Chen,Wenzheng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的单次结构光三维成像解码框架，通过在特征空间中进行匹配并结合几何先验与单目深度先验，在仅使用合成数据训练的情况下，在真实室内环境中显著优于传统像素域方法及商用系统。


<details>
  <summary>Details</summary>
Motivation: 传统结构光方法依赖像素域匹配，在遮挡、精细结构和非朗伯表面等复杂场景下鲁棒性有限，因此需要更鲁棒的解码机制。

Method: 提出一种学习型结构光解码框架：1）从投影图案和红外图像中提取神经特征，在特征空间构建代价体以实现鲁棒匹配；2）引入基于大规模单目深度模型的深度优化模块；3）构建物理真实的结构光渲染管线，生成近百万合成数据用于训练。

Result: 该方法在仅使用合成数据训练的情况下，能泛化到真实室内环境，无需重训练即可处理多种图案类型，并在精度和细节恢复上优于商用结构光系统和被动式RGB立体深度估计方法。

Conclusion: 所提方法通过特征空间匹配与深度优化，显著提升了结构光系统在复杂场景下的鲁棒性和重建质量，验证了合成数据训练在真实应用中的有效性。

Abstract: We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.

</details>


### [22] [ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization](https://arxiv.org/abs/2512.14039)
*Meng Wei,Cheng Zhang,Jianmin Zheng,Hamid Rezatofighi,Jianfei Cai*

Main category: cs.CV

TL;DR: 该论文提出ASAP Textured Gaussians方法，通过自适应采样和误差驱动的各向异性参数化策略，在减少纹理参数数量的同时显著提升3D高斯泼溅的渲染质量与内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有带纹理参数化的3D高斯泼溅方法存在内存效率低的问题，主要源于在规范空间中定义纹理导致采样效率低下，以及对所有高斯统一分配纹理参数造成过度参数化。

Method: 提出两种策略：（1）基于高斯密度分布的自适应采样；（2）根据渲染误差进行误差驱动的各向异性纹理参数分配。

Result: 所提方法在使用更少纹理参数的情况下实现了高质量渲染，显著改善了质量与效率之间的权衡。

Conclusion: 通过针对性优化纹理采样与分配策略，ASAP Textured Gaussians有效缓解了现有方法的内存效率瓶颈，提升了3D高斯泼溅在外观建模和下游任务中的实用性。

Abstract: Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.

</details>


### [23] [ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning](https://arxiv.org/abs/2512.14040)
*Boran Wang,Xinming Wang,Yi Chen,Xiang Li,Jian Xu,Jing Yuan,Chenglin Liu*

Main category: cs.CV

TL;DR: 本文提出ChartAgent，一种基于工具集成推理（TIR）的图表理解框架，通过模块化工具库和可追溯的证据包，在缺乏显式文本标注的情况下显著提升图表理解的鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在图表理解任务中严重依赖显式文本标注，当关键数字缺失时性能显著下降，缺乏对复杂图表进行系统、透明解析的能力。

Method: 受人类认知启发，ChartAgent将图表分析分解为一系列可观测、可重放的步骤，利用包含关键元素检测、实例分割、OCR等十余种工具的模块化工具库，动态协调工具执行，并将中间结果标准化为结构化的“证据包”以支持最终推理。

Result: 实验表明，ChartAgent在稀疏标注或无关键数值标注的场景下显著优于现有方法，提升了图表理解的鲁棒性和可靠性。

Conclusion: ChartAgent通过工具集成推理和结构化证据机制，为构建可信、可扩展且可验证的图表理解系统提供了有效路径。

Abstract: With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.

</details>


### [24] [OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving](https://arxiv.org/abs/2512.14044)
*Zhenguo Zhang,Haohan Zhen,Yishen Wang,Le Xu,Tianchen Deng,Xuefeng Chen,Qu Chen,Bo Zhang,Wuxiong Huang*

Main category: cs.CV

TL;DR: 本文提出OmniDrive-R1，一种端到端的视觉语言模型框架，通过交错多模态思维链（iMCoT）和基于强化学习的视觉定位机制，显著提升了自动驾驶场景中的推理准确性和答案正确率，同时无需密集标注。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等安全关键领域部署视觉语言模型（VLMs）面临可靠性问题，尤其是对象幻觉。现有方法因感知与推理阶段解耦及依赖昂贵密集标注而效果受限。

Method: 提出OmniDrive-R1框架，采用交错多模态思维链（iMCoT）统一感知与推理，并引入基于强化学习的视觉定位能力，通过两阶段强化学习训练和Clip-GRPO算法实现无标注的过程奖励，确保视觉聚焦与文本推理的跨模态一致性。

Result: 在DriveLMM-o1数据集上，OmniDrive-R1将整体推理得分从51.77%提升至80.35%，最终答案准确率从37.81%提升至73.62%。

Conclusion: OmniDrive-R1有效解决了VLM在自动驾驶中因未接地推理导致的可靠性问题，通过端到端联合优化和无标注强化学习机制，在减少对密集标签依赖的同时显著提升了性能。

Abstract: The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and "zoom in" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.

</details>


### [25] [SELECT: Detecting Label Errors in Real-world Scene Text Data](https://arxiv.org/abs/2512.14050)
*Wenjun Liu,Qian Wu,Yifeng Hu,Yuke Li*

Main category: cs.CV

TL;DR: SELECT 是一种利用多模态训练检测现实场景文本数据集中标签错误的新方法，结合图像-文本编码器和字符级分词器，并引入 SSLC（基于相似性的序列标签污染）策略模拟真实标签错误，有效提升标签纠错能力和场景文本识别（STR）准确率。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的场景文本数据集常存在标签错误，包括可变长度序列标签、标签序列错位和字符级错误等问题，现有方法难以有效处理这些挑战。

Method: 提出 SELECT 方法，结合图像-文本编码器与字符级分词器进行多模态训练；并设计 SSLC 策略，在训练中通过考虑字符视觉相似性有意引入标签错误，以模拟真实错误场景。

Result: SELECT 在检测标签错误方面优于现有方法，并在真实场景文本数据集上提升了 STR 的准确率，验证了其实际应用价值。

Conclusion: SELECT 是首个能有效处理可变长度标签并在真实场景文本数据集中成功检测标签错误的方法，具有良好的实用性和性能优势。

Abstract: We introduce SELECT (Scene tExt Label Errors deteCTion), a novel approach that leverages multi-modal training to detect label errors in real-world scene text datasets. Utilizing an image-text encoder and a character-level tokenizer, SELECT addresses the issues of variable-length sequence labels, label sequence misalignment, and character-level errors, outperforming existing methods in accuracy and practical utility. In addition, we introduce Similarity-based Sequence Label Corruption (SSLC), a process that intentionally introduces errors into the training labels to mimic real-world error scenarios during training. SSLC not only can cause a change in the sequence length but also takes into account the visual similarity between characters during corruption. Our method is the first to detect label errors in real-world scene text datasets successfully accounting for variable-length labels. Experimental results demonstrate the effectiveness of SELECT in detecting label errors and improving STR accuracy on real-world text datasets, showcasing its practical utility.

</details>


### [26] [HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices](https://arxiv.org/abs/2512.14052)
*HyperAI Team,Yuchen Liu,Kaiyang Han,Zhiqiang Xia,Yuhang Dong,Chen Song,Kangyu Tang,Jiaming Xu,Xiushi Feng,WenXuan Yu,Li Peng,Mingyang Wang,Kai Wang,Changpeng Yang,Yang Li,Haoyu Lu,Hao Wang,Bingna Xu,Guangyao Liu,Long Huang,Kaibin Guo,Jinyang Wu,Dan Wu,Hongzhen Wang,Peng Zhou,Shuai Nie,Shande Wang,Runyu Shi,Ying Huang*

Main category: cs.CV

TL;DR: 本文提出了HyperVL，一种面向端侧部署的高效多模态大语言模型，通过图像分块、视觉分辨率压缩器（VRC）和双一致性学习（DCL）技术，在保持高性能的同时显著降低延迟与功耗。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型计算和内存开销大，难以在端侧设备部署；而小型模型中的标准ViT编码器在处理高分辨率图像时仍存在延迟高、内存消耗大的问题。

Method: HyperVL采用图像分块策略控制峰值内存，并引入两项新技术：(1) 视觉分辨率压缩器（VRC），自适应预测最优编码分辨率以减少冗余计算；(2) 双一致性学习（DCL），在统一框架下对齐多尺度ViT编码器，支持在共享LLM下动态切换视觉分支。

Result: 实验表明，HyperVL在多个基准上达到同规模模型的最先进性能，并在真实移动设备上显著降低延迟和功耗。

Conclusion: HyperVL有效解决了端侧多模态推理中的效率瓶颈，兼具高性能与实用性，适合实际部署。

Abstract: Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.

</details>


### [27] [FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling](https://arxiv.org/abs/2512.14056)
*Kim Sung-Bin,Joohyun Chang,David Harwath,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 本文提出将说话人脸编辑与生成统一为“语音条件下面部运动填充”任务，并提出了基于扩散Transformer的模型FacEDiT，通过自监督学习实现局部编辑（如替换、插入、删除）与整体生成，同时引入新数据集FacEDiTBench和评估指标。


<details>
  <summary>Details</summary>
Motivation: 传统上，说话人脸编辑与生成被视为两个独立任务。作者认为二者可统一为一个更通用的语音条件下面部运动填充问题，从而实现更灵活、一致且高质量的人脸动画合成与编辑。

Method: 提出FacEDiT模型，一种基于流匹配训练的语音条件扩散Transformer；借鉴掩码自编码器思想，利用周围面部动作和语音信息重建被掩码区域；引入偏置注意力机制和时间平滑约束以提升边界连续性和唇音同步效果。

Result: 实验表明FacEDiT在编辑和生成任务中均表现优异：能生成准确对齐语音的面部动作，保持身份一致性，并实现与未编辑区域的平滑过渡；同时在新提出的FacEDiTBench基准上验证了方法的有效性。

Conclusion: 语音条件下面部运动填充是一个有效的统一框架，能够自然涵盖说话人脸编辑与生成两大任务；所提FacEDiT模型在多个方面优于现有方法，并为未来研究提供了新的基准和评估标准。

Abstract: Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.

</details>


### [28] [Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning](https://arxiv.org/abs/2512.14058)
*Zulin Zhuang,Yu Bian*

Main category: cs.CV

TL;DR: 本文提出一种基于多模态深度学习的实时室内工作面照度预测方法，利用侧窗区域图像特征而非室内像素，在动态占用环境中实现高精度预测。


<details>
  <summary>Details</summary>
Motivation: 现有室内日光预测研究多针对静态场景，难以适用于人员动态变化的实际建筑环境；同时，准确的实时照度预测对实现高效日光联动控制（DLCs）以节能至关重要。

Method: 提出一种多模态深度学习框架，仅从侧窗区域提取图像的时间-空间特征，以非侵入式图像实时预测室内工作面照度分布。

Result: 在广州实测房间采集17,344个样本进行训练与验证，模型在同一分布测试集上R² > 0.98、RMSE < 0.14，在未见日期测试集上R² > 0.82、RMSE < 0.17，表现出高精度和良好时间泛化能力。

Conclusion: 所提方法在动态占用的室内环境中仍能准确预测照度，为日光联动控制系统提供可靠支持，具有实际应用潜力。

Abstract: Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.

</details>


### [29] [GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants](https://arxiv.org/abs/2512.14087)
*Yang Yang,Risa Shinoda,Hiroaki Santo,Fumio Okura*

Main category: cs.CV

TL;DR: 该论文提出GaussianPlant，一种基于3D高斯泼溅（3DGS）的分层表示方法，通过结构基元（StPs）和外观基元（ApPs）联合重建植物的外观与内部结构，实现高保真外观渲染和准确结构提取。


<details>
  <summary>Details</summary>
Motivation: 标准3D高斯泼溅虽能高质量重建场景外观，但缺乏对植物内在结构（如枝干与叶片的拓扑关系）的显式建模，限制了其在植物表型分析等任务中的应用。

Method: 引入结构基元（StPs）以圆柱体和圆盘分别建模枝干与叶片，并通过自组织方式优化其属性；外观基元（ApPs）绑定到StPs上，使用3D高斯表示外观。两者通过多视角图像的重渲染损失及ApP到StP的梯度流联合优化。

Result: 实验表明，GaussianPlant能同时实现高保真外观重建和精确结构重建，支持枝干结构与叶片实例的提取。

Conclusion: GaussianPlant有效解耦并联合优化了植物的外观与结构表示，拓展了3DGS在需要结构信息的植物表型等任务中的适用性。

Abstract: We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.

</details>


### [30] [Quality-Aware Framework for Video-Derived Respiratory Signals](https://arxiv.org/abs/2512.14093)
*Nhi Nguyen,Constantino Álvarez Casado,Le Nguyen,Manuel Lage Cañellas,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 本文提出一种质量感知的视频呼吸率估计框架，通过融合多种信号源并动态评估其可靠性，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的呼吸率估计方法因信号质量不一致而不可靠，亟需一种能动态评估和融合多源信号的可靠框架。

Method: 从面部rPPG、上半身运动和深度学习管道中提取10种信号，采用Welch、MUSIC、FFT和峰值检测四种频谱估计算法分析，并利用片段级质量指标训练机器学习模型以预测准确性或选择最可靠信号，实现自适应信号融合与质量过滤。

Result: 在OMuSense-23、COHFACE和MAHNOB-HCI三个公开数据集上的实验表明，该框架在多数情况下优于单一方法，性能提升依赖于数据集特性。

Conclusion: 质量驱动的预测建模有望实现可扩展且泛化能力强的视频呼吸监测解决方案。

Abstract: Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.

</details>


### [31] [AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation](https://arxiv.org/abs/2512.14095)
*Sisi Dai,Kai Xu*

Main category: cs.CV

TL;DR: 本文提出AnchorHOI框架，通过结合视频扩散模型与锚点引导的先验蒸馏策略，在无需大规模4D人-物交互（HOI）数据集的情况下，实现高质量、多样化的零样本4D HOI生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督学习的文本驱动4D人-物交互生成方法受限于大规模4D HOI数据集的稀缺；而现有零样本方法在生成过程中未能充分提取交互线索，难以适应多样场景。

Method: 提出AnchorHOI框架，融合图像与视频扩散模型的混合先验，并设计基于锚点的先验蒸馏策略：利用锚点NeRF表达交互结构，锚点关键点合成真实动作，分两步引导4D HOI生成。

Result: 大量实验表明，AnchorHOI在生成多样性与泛化能力方面优于现有方法。

Conclusion: AnchorHOI有效解决了零样本4D人-物交互生成中交互线索不足和高维优化困难的问题，显著提升了生成质量与适用性。

Abstract: Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.

</details>


### [32] [OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration](https://arxiv.org/abs/2512.14096)
*Ruitong Sun,Tianze Yang,Wei Niu,Jin Sun*

Main category: cs.CV

TL;DR: OUSAC 是一种用于加速扩散模型（特别是 DiT）的框架，通过优化可变引导尺度调度和自适应缓存机制，在大幅减少计算开销的同时提升生成质量。


<details>
  <summary>Details</summary>
Motivation: Classifier-Free Guidance (CFG) 虽能提升生成质量，但因需同时进行条件与无条件前向传播而使计算成本翻倍。现有加速方法难以在使用可变引导尺度时维持高效缓存，限制了进一步优化。

Method: 提出 OUSAC 框架：第一阶段利用进化算法联合优化跳过哪些时间步及对应的引导尺度；第二阶段引入自适应秩分配策略，针对不同 Transformer 块动态调整缓存校准强度，以应对可变引导带来的去噪偏差。

Result: 在多个主流模型上显著优于现有加速方法：DiT-XL/2 上节省 53% 计算量并提升 15% 质量；PixArt-alpha 上节省 60% 并提升 16.1%；FLUX 上实现 5 倍加速且 CLIP Score 更优。

Conclusion: OUSAC 通过联合优化引导调度与自适应缓存机制，有效解决了可变引导尺度下扩散模型加速难题，在保持甚至提升生成质量的同时大幅降低计算成本。

Abstract: Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.

</details>


### [33] [ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models](https://arxiv.org/abs/2512.14099)
*Ruishu Zhu,Zhihao Huang,Jiacheng Sun,Ping Luo,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: ViewMask-1-to-3 是一种基于离散扩散模型的新方法，通过将多视角图像生成建模为离散序列预测问题，在无需复杂3D几何约束的情况下实现了优异的跨视角一致性，并在多个指标上取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖3D感知架构或专用扩散模型，需大量多视角训练数据和复杂的几何先验，难以兼顾生成质量和实现简洁性。

Method: 将多视角图像生成转化为离散序列建模任务，利用MAGVIT-v2对各视角进行视觉token化，并通过文本引导下的掩码token预测与迭代去掩码机制，结合自注意力实现多视角一致生成。

Result: 在GSO和3D-FUTURE数据集上，ViewMask-1-to-3在PSNR、SSIM和LPIPS指标上平均排名第一，同时保持架构简洁。

Conclusion: 离散扩散模型可作为多视角图像生成的有效且简化的替代方案，无需复杂3D约束即可实现高质量、一致性的多视角合成。

Abstract: Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.

</details>


### [34] [Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries](https://arxiv.org/abs/2512.14102)
*Emanuele Mezzi,Gertjan Burghouts,Maarten Kruithof*

Main category: cs.CV

TL;DR: 本文提出RUNE方法，结合大语言模型与神经符号AI，通过将文本查询转化为一阶逻辑表达式并对检测到的遥感图像实体进行显式推理，以提升遥感图文检索的性能、鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感大视觉语言模型（RS-LVLMs）在复杂空间关系处理和可解释性方面存在不足，限制了其在现实场景中的应用。

Method: RUNE利用大语言模型将文本查询翻译为一阶逻辑（FOL）表达式，并通过神经符号推理模块对图像中检测到的实体进行显式逻辑推理；同时引入逻辑分解策略以提升可扩展性，并仅用基础模型生成FOL而非端到端检索。

Result: 在基于DOTA数据集构建的新评测基准上，RUNE在复杂查询和图像不确定性条件下均优于现有RS-LVLM方法，并通过RRQC和RRIU两个新指标验证其鲁棒性；案例研究展示了其在洪灾后遥感图像检索中的实际潜力。

Conclusion: RUNE通过显式逻辑推理显著提升了遥感图文检索的性能、可解释性与鲁棒性，为现实世界遥感应用提供了有效解决方案。

Abstract: Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.

</details>


### [35] [Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach](https://arxiv.org/abs/2512.14113)
*Ashish Mishra,Gyanaranjan Nayak,Tarun Kumar,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练和数据的CLIP模型“遗忘”框架，支持三种遗忘模式：全局遗忘、领域特定遗忘和选择性领域完全遗忘，通过多模态零空间有效移除特定类别信息而不影响其他任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中常需在不重新训练或额外数据的情况下，从预训练模型（如CLIP）中移除特定对象类别的知识，同时不影响其在其他任务上的表现。

Method: 利用CLIP联合嵌入空间中的文本提示与合成视觉原型，构建多模态零空间，实现无需训练和数据的三类遗忘机制。

Result: 该方法高效地移除了目标类别信息，在保留模型其余知识的同时，克服了现有基于重训练方法的局限性。

Conclusion: 所提框架为可控模型遗忘提供了一种灵活且计算高效的解决方案，适用于多种实际应用场景。

Abstract: Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or "unlearning") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.

</details>


### [36] [Consistent Instance Field for Dynamic Scene Understanding](https://arxiv.org/abs/2512.14126)
*Junyi Wu,Van Nguyen Nguyen,Benjamin Planche,Jiachen Tao,Changchang Sun,Zhongpai Gao,Zhenghao Zhao,Anwesa Choudhuri,Gengyu Zhang,Meng Zheng,Feiran Wang,Terrence Chen,Yan Yan,Ziyan Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“一致实例场”（Consistent Instance Field）的新方法，通过基于可变形3D高斯的连续概率时空表示，实现动态场景中对象身份的一致建模，在新视角全景分割和开放词汇4D查询任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖离散跟踪或视角相关特征，难以在动态场景中保持对象身份的一致性；本文旨在通过解耦可见性与持久对象身份，构建更鲁棒的时空语义表示。

Method: 提出一种基于可变形3D高斯的实例嵌入表示，通过可微光栅化从RGB图像和实例掩码中联合学习辐射度与语义信息，并引入高斯身份校准与重采样机制，以增强语义活跃区域的一致性。

Result: 在HyperNeRF和Neu3D数据集上的实验表明，该方法在新视角全景分割和开放词汇4D查询任务上显著优于当前最先进的方法。

Conclusion: 所提出的一致实例场能够有效建模动态场景中的持久对象身份，为4D场景理解提供了新的连续概率表示框架，并在多个任务上展现出优越性能。

Abstract: We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.

</details>


### [37] [Erasing CLIP Memories: Non-Destructive, Data-Free Zero-Shot class Unlearning in CLIP Models](https://arxiv.org/abs/2512.14137)
*Ashish Mishra,Tarun Kumar,Gyanaranjan Nayak,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 提出了一种无需重训练的闭式选择性遗忘方法，通过零空间投影消除多模态模型（如CLIP）中目标类别的信息。


<details>
  <summary>Details</summary>
Motivation: 传统遗忘方法依赖迭代微调和大量数据整理，计算成本高且不够精准；本文旨在实现高效、精确地从预训练多模态模型中移除特定类别信息，以应对模型去污染与隐私保护的挑战。

Method: 利用零空间投影，在CLIP等预训练多模态模型的最终投影层中，通过计算目标文本嵌入张成子空间的正交基并投影这些方向，从而削弱图像特征与目标类别的对齐，无需重训练或遗忘集图像。

Result: 实验表明，该方法显著降低目标类别的零样本性能，同时保留模型整体多模态知识；部分投影可在完全遗忘与保留有用信息之间取得平衡。

Conclusion: 所提方法在计算效率和遗忘精度上优于传统技术，为多模态模型的选择性遗忘提供了一种有效且实用的解决方案。

Abstract: We introduce a novel, closed-form approach for selective unlearning in multimodal models, specifically targeting pretrained models such as CLIP. Our method leverages nullspace projection to erase the target class information embedded in the final projection layer, without requiring any retraining or the use of images from the forget set. By computing an orthonormal basis for the subspace spanned by target text embeddings and projecting these directions, we dramatically reduce the alignment between image features and undesired classes. Unlike traditional unlearning techniques that rely on iterative fine-tuning and extensive data curation, our approach is both computationally efficient and surgically precise. This leads to a pronounced drop in zero-shot performance for the target classes while preserving the overall multimodal knowledge of the model. Our experiments demonstrate that even a partial projection can balance between complete unlearning and retaining useful information, addressing key challenges in model decontamination and privacy preservation.

</details>


### [38] [SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing](https://arxiv.org/abs/2512.14140)
*Han Zou,Yan Zhang,Ruiqi Yu,Cong Xie,Jie Huang,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: 本文提出了SketchAssist，一个结合指令引导全局编辑与线条引导局部重绘的交互式草图绘制助手，通过新颖的数据生成流程和统一的编辑框架，在保持风格与结构的同时实现高质量草图编辑。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑系统难以在支持高层语义修改和精确局部重绘的同时，保留线稿稀疏且对风格敏感的结构。

Method: 作者构建了一个可控的数据生成流程，包括从无属性草图构建属性添加序列、跨序列采样形成多步编辑链、以及使用风格保留的属性移除模型扩展风格覆盖。在此基础上，提出统一的草图编辑框架，复用DiT编辑器结构，将RGB通道用于编码输入，并在LoRA层中引入任务引导的混合专家模块，根据文本和视觉线索路由以提升语义控制力、结构保真度和风格保留能力。

Result: 实验表明，SketchAssist在指令遵循、结构保真和风格保留方面优于当前基线方法，在两类任务上均达到SOTA性能。

Conclusion: SketchAssist结合所提出的高质量数据集，为草图创作与修改提供了一个实用且可控的交互式辅助工具。

Abstract: Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.

</details>


### [39] [TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models](https://arxiv.org/abs/2512.14141)
*Hanning Chen,Keyu Man,Kevin Zhu,Chenguang Zhu,Haonan Li,Tongbo Luo,Xizhou Feng,Wei Sun,Sreen Tallam,Mohsen Imani,Partha Kanuparthy*

Main category: cs.CV

TL;DR: 本文提出了首个用于评估和提升机器学习模型在PyTorch执行轨迹中检测性能反模式能力的基准数据集，并设计了一种轻量级模型与大语言模型（LLM）结合的迭代方法，显著优于现有无监督和规则方法。


<details>
  <summary>Details</summary>
Motivation: 当前在机器学习模型训练和推理中识别性能反模式通常需要系统、模型和内核开发等多领域专家知识，而大多数计算机视觉研究人员缺乏大型科技公司所拥有的专业ML基础设施支持；尤其在长执行轨迹中定位问题片段既耗时又难以自动化，包括LLM在内的现有模型在此任务上表现有限。

Method: 作者构建了一个包含600多个来自多种计算机视觉任务（分类、检测、分割、生成）和硬件平台的PyTorch执行轨迹的数据集；并提出一种两阶段迭代方法：先由轻量级ML模型检测存在反模式的轨迹片段，再由LLM进行细粒度分类与反馈。

Result: 实验表明，该方法在检测反模式区域方面显著优于无监督聚类和基于规则的统计技术，同时有效缓解了LLM上下文长度限制和推理效率低的问题。

Conclusion: 该工作为ML性能反模式检测提供了可复现的基准和高效实用的方法，有助于降低非专业用户优化模型性能的门槛。

Abstract: Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.

</details>


### [40] [CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World](https://arxiv.org/abs/2512.14158)
*Shuxin Zhao,Bo Lang,Nan Xiao,Yilang Zhang*

Main category: cs.CV

TL;DR: 本文提出CIS-BA，一种基于对象间连续交互模式的新型后门攻击方法，通过构建“空间触发器”实现多触发-多目标攻击，在保持高攻击成功率的同时具备强鲁棒性并能规避现有防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测后门攻击方法依赖单一触发器与单一目标的映射及脆弱的像素级线索，能力与鲁棒性受限，难以适用于真实复杂场景。

Method: 提出CIS-BA攻击范式，将触发器设计从静态对象特征转向对象间的连续交互模式；设计CIS-Frame框架，通过交互分析构建空间触发器，将其形式化为类别-几何约束用于样本投毒，并在检测器训练中嵌入后门。

Result: 在MS-COCO和真实视频上的实验表明，CIS-BA在复杂环境中攻击成功率超过97%，在动态多触发条件下有效性仍超95%，并成功规避三种先进防御方法。

Conclusion: CIS-BA拓展了交互密集型场景下后门攻击的研究边界，为目标检测系统的安全性提供了新视角。

Abstract: Object detection models deployed in real-world applications such as autonomous driving face serious threats from backdoor attacks. Despite their practical effectiveness,existing methods are inherently limited in both capability and robustness due to their dependence on single-trigger-single-object mappings and fragile pixel-level cues. We propose CIS-BA, a novel backdoor attack paradigm that redefines trigger design by shifting from static object features to continuous inter-object interaction patterns that describe how objects co-occur and interact in a scene. By modeling these patterns as a continuous interaction space, CIS-BA introduces space triggers that, for the first time, enable a multi-trigger-multi-object attack mechanism while achieving robustness through invariant geometric relations. To implement this paradigm, we design CIS-Frame, which constructs space triggers via interaction analysis, formalizes them as class-geometry constraints for sample poisoning, and embeds the backdoor during detector training. CIS-Frame supports both single-object attacks (object misclassification and disappearance) and multi-object simultaneous attacks, enabling complex and coordinated effects across diverse interaction states. Experiments on MS-COCO and real-world videos show that CIS-BA achieves over 97% attack success under complex environments and maintains over 95% effectiveness under dynamic multi-trigger conditions, while evading three state-of-the-art defenses. In summary, CIS-BA extends the landscape of backdoor attacks in interaction-intensive scenarios and provides new insights into the security of object detection systems.

</details>


### [41] [FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation](https://arxiv.org/abs/2512.14162)
*Qingyuan Cai,Linxin Zhang,Xuecai Hu,Saihui Hou,Yongzhen Huang*

Main category: cs.CV

TL;DR: 本文提出了Fast3DHPE框架，用于统一单目3D人体姿态估计方法的训练与评估，并在此框架下引入了基于解耦扩散模型的新方法FastDDHPose，在多个数据集上实现了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体姿态估计方法通常在不一致的框架下训练和评估，缺乏公平比较的基础，且训练效率较低。

Method: 提出Fast3DHPE模块化框架以标准化训练和评估流程；在该框架内设计FastDDHPose方法，利用扩散模型分别建模骨骼长度与方向，并引入运动学层次时空去噪器以聚焦关节层次结构。

Result: 在Human3.6M和MPI-INF-3DHP数据集上的实验表明，Fast3DHPE显著提升训练效率并支持公平比较，FastDDHPose在框架内达到SOTA性能，具备良好的泛化能力和野外场景鲁棒性。

Conclusion: Fast3DHPE为3D人体姿态估计提供了高效、统一的开发与评估平台，所提出的FastDDHPose方法有效提升了性能与鲁棒性。

Abstract: Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

</details>


### [42] [Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes](https://arxiv.org/abs/2512.14177)
*Joseph Hoche,Andrei Bursuc,David Brellmann,Gilles Louppe,Pavel Izmailov,Angela Yao,Gianni Franchi*

Main category: cs.CV

TL;DR: 本文提出了一种名为语义高斯过程不确定性（SGPU）的新方法，通过分析答案嵌入的几何结构来估计大型视觉语言模型的语义不确定性，避免了传统聚类方法的脆弱性，并在多个数据集和模型上实现了最先进的校准与判别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于外部模型聚类的语义不确定性估计方法对措辞变化敏感，容易错误地合并或分离语义相近的答案，导致不确定性估计不可靠。

Method: SGPU将生成的答案映射到稠密语义空间，计算其嵌入的Gram矩阵，并通过特征谱总结语义结构；该谱表示被输入高斯过程分类器，以学习语义一致性模式与预测不确定性的映射关系，适用于黑盒和白盒场景。

Result: 在涵盖VQA、图像分类和文本问答的8个数据集上，对6个大语言模型和大型视觉语言模型的实验表明，SGPU在ECE、AUROC和AUARC指标上均达到SOTA水平，并展现出跨模型和跨模态的泛化能力。

Conclusion: SGPU通过谱表示有效捕捉语义不确定性的一般模式，提供了一种鲁棒且通用的不确定性估计框架，优于依赖聚类的现有方法。

Abstract: Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.

</details>


### [43] [Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere](https://arxiv.org/abs/2512.14180)
*Francesco Di Sario,Daniel Rebain,Dor Verbin,Marco Grangetto,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: 本文提出了一种名为球面Voronoi（Spherical Voronoi, SV）的新方法，用于3D高斯点阵（3D Gaussian Splatting）中的外观建模，以克服球谐函数（SH）在高频信号、吉布斯振铃效应和镜面反射建模方面的局限性。SV通过将方向域划分为可学习的平滑区域，提供了一种直观且稳定的视相关外观参数化方式，在漫反射和镜面反射建模上均取得优异效果，且优化更简单高效。


<details>
  <summary>Details</summary>
Motivation: 球谐函数（SH）在辐射场方法（如3D高斯点阵）中广泛用于外观建模，但其难以处理高频信号、存在吉布斯振铃伪影，并无法有效捕捉镜面反射，影响真实感渲染效果。尽管已有替代方案（如球面高斯），但通常带来更高的优化复杂度。因此，亟需一种既能克服SH缺陷又保持优化效率的外观表示方法。

Method: 作者提出球面Voronoi（SV）作为统一的外观表示框架。该方法将方向域划分为具有可学习边界和平滑过渡的区域，用于建模视相关外观。对于漫反射部分，SV提供简洁而有效的参数化；对于镜面反射，则将SV用作可学习的反射探针，以反射方向为输入，借鉴经典图形学原理进行建模。

Result: 实验表明，SV在合成和真实数据集上均达到当前最优（state-of-the-art）的渲染效果。在漫反射建模方面，其性能与现有方法相当但优化更简单；在镜面反射建模方面显著优于SH，有效提升了渲染的真实感。

Conclusion: 球面Voronoi（SV）是一种原则性强、高效且通用的外观建模方法，适用于显式3D表示（如3D高斯点阵），能有效克服球谐函数的固有缺陷，在保持优化简洁性的同时显著提升渲染质量。

Abstract: Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.

</details>


### [44] [Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity](https://arxiv.org/abs/2512.14196)
*Cassandra Krause,Mattias P. Heinrich,Ron Keuth*

Main category: cs.CV

TL;DR: 本文提出一种通过自动为骨折边界框分配AO编码来提取骨折形态的方法，将全局多标签任务转化为局部多类任务，在公开数据集上平均F1分数提升7.89%，但依赖于精确的骨折检测器。


<details>
  <summary>Details</summary>
Motivation: 儿童在成长过程中骨折发生率高（15%–45%），而骨折形态是诊断的关键特征之一，因此需要准确、自动化的骨折形态识别方法以辅助临床诊断。

Method: 通过自动为骨折边界框分配全局AO编码，将原本的全局多标签分类任务转化为局部多类分类任务，并利用公开数据集进行训练与评估。

Result: 该方法在理想条件下使平均F1分数提升了7.89%，但在使用不完美的骨折检测器时性能显著下降。

Conclusion: 所提方法在骨折形态自动识别方面具有潜力，但其实际部署受限于骨折检测的准确性，未来需提升对检测误差的鲁棒性。

Abstract: Between $15\,\%$ and $45\,\%$ of children experience a fracture during their growth years, making accurate diagnosis essential. Fracture morphology, alongside location and fragment angle, is a key diagnostic feature. In this work, we propose a method to extract fracture morphology by assigning automatically global AO codes to corresponding fracture bounding boxes. This approach enables the use of public datasets and reformulates the global multilabel task into a local multiclass one, improving the average F1 score by $7.89\,\%$. However, performance declines when using imperfect fracture detectors, highlighting challenges for real-world deployment. Our code is available on GitHub.

</details>


### [45] [Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination](https://arxiv.org/abs/2512.14200)
*Zhuoxiao Li,Wenzong Ma,Taoyu Wu,Jinjing Zhu,Zhenchao Q,Shuai Zhang,Jing Ou,Yinrui Ren,Weiqing Qi,Guobin Shen,Hui Xiong,Wufan Zhao*

Main category: cs.CV

TL;DR: 本文提出了SkyLume，一个大规模真实世界无人机数据集，用于研究光照鲁棒的3D重建。该数据集包含10个城区在一天中三个不同时段采集的超过10万张高分辨率图像，并配有LiDAR扫描和精确3D真值，同时引入新指标TCC评估逆渲染中的光照-材质解耦性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和3D Gaussian Splatting的大规模无人机3D重建方法在处理多时段采集数据时，因光照不一致导致颜色伪影、几何失真和外观不一致；而缺乏系统性记录同一区域在不同光照条件下变化的无人机数据集，使得该问题尚未充分研究。

Method: 构建SkyLume数据集：(1) 在10个城区采集超过10万张高分辨率无人机图像（四个倾斜视角和正射），每个区域在一天三个时段拍摄以分离光照变化；(2) 提供每场景LiDAR扫描与精确3D真值，用于评估深度、表面法线及重建质量；(3) 提出时间一致性系数（TCC）作为衡量跨时段反照率稳定性的新指标，评估光照与材质解耦的鲁棒性。

Result: 成功构建了首个专为光照鲁棒3D重建设计的大规模真实世界无人机数据集SkyLume，支持对几何、外观及逆渲染任务在不同光照条件下的精确评估，并通过TCC指标有效衡量材质与光照解耦效果。

Conclusion: SkyLume填补了现有无人机数据集中缺乏系统性多光照条件记录的空白，为大规模逆渲染、几何重建与新视角合成的研究和实际评估提供了重要基础资源。

Abstract: Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.

</details>


### [46] [DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos](https://arxiv.org/abs/2512.14217)
*Yang Bai,Liudi Yang,George Eskandar,Fengyi Shen,Mohammad Altillawi,Ziyuan Liu,Gitta Kutyniok*

Main category: cs.CV

TL;DR: DRAW2ACT is a depth-aware, trajectory-conditioned video generation framework that improves controllability and consistency for robotic manipulation by jointly generating aligned RGB and depth videos and using them to train a multimodal policy for joint angle regression.


<details>
  <summary>Details</summary>
Motivation: Existing trajectory-conditioned video generation methods for robotic manipulation are limited by reliance on 2D trajectories or single-modality conditioning, which hampers their ability to produce controllable and spatio-temporally consistent demonstrations.

Method: DRAW2ACT extracts multiple orthogonal representations (depth, semantics, shape, motion) from input trajectories and injects them into a diffusion model. It jointly generates spatially aligned RGB and depth videos using cross-modality attention and depth supervision, then trains a multimodal policy conditioned on these videos to predict robot joint angles.

Result: Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks demonstrate that DRAW2ACT achieves higher visual fidelity, better spatio-temporal consistency, and improved robotic manipulation success rates compared to existing baselines.

Conclusion: DRAW2ACT effectively addresses the limitations of prior methods by integrating depth awareness and multimodal conditioning, leading to more reliable and high-quality robotic video generation and control.

Abstract: Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.

</details>


### [47] [History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation](https://arxiv.org/abs/2512.14222)
*Xichen Ding,Jianzhe Gao,Cong Pan,Wenguan Wang,Jie Qin*

Main category: cs.CV

TL;DR: 本文提出了一种历史增强的两阶段Transformer（HETT）框架，用于提升无人机在城市环境中根据语言指令进行视觉-语言导航的能力，通过粗到细的导航策略结合全局推理与局部理解，并引入历史网格图增强场景感知，在优化后的CityNav数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有无人机视觉-语言导航方法多采用单一粒度框架，难以同时兼顾全局环境推理与局部场景理解，限制了导航性能。

Method: 提出History-Enhanced Two-Stage Transformer（HETT）框架：第一阶段融合空间地标与历史上下文预测粗粒度目标位置，第二阶段通过细粒度视觉分析细化动作；同时设计历史网格图以动态聚合视觉特征形成结构化空间记忆，并对CityNav数据集标注进行人工优化。

Result: 在优化后的CityNav数据集上，HETT显著优于现有方法，消融实验验证了各组件的有效性。

Conclusion: 所提出的HETT框架有效结合了全局与局部信息，提升了无人机在复杂城市环境中的视觉-语言导航能力，为未来AVLN研究提供了新思路。

Abstract: Aerial Vision-and-Language Navigation (AVLN) requires Unmanned Aerial Vehicle (UAV) agents to localize targets in large-scale urban environments based on linguistic instructions. While successful navigation demands both global environmental reasoning and local scene comprehension, existing UAV agents typically adopt mono-granularity frameworks that struggle to balance these two aspects. To address this limitation, this work proposes a History-Enhanced Two-Stage Transformer (HETT) framework, which integrates the two aspects through a coarse-to-fine navigation pipeline. Specifically, HETT first predicts coarse-grained target positions by fusing spatial landmarks and historical context, then refines actions via fine-grained visual analysis. In addition, a historical grid map is designed to dynamically aggregate visual features into a structured spatial memory, enhancing comprehensive scene awareness. Additionally, the CityNav dataset annotations are manually refined to enhance data quality. Experiments on the refined CityNav dataset show that HETT delivers significant performance gains, while extensive ablation studies further verify the effectiveness of each component.

</details>


### [48] [Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity](https://arxiv.org/abs/2512.14320)
*Shuai Dong,Jie Zhang,Guoying Zhao,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的图像免疫方法SIFM，通过扰动扩散模型中间特征来防止文本引导的恶意图像编辑，并引入新指标ISR评估免疫效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像免疫评估指标仅关注输出图像与参考图像的视觉差异，忽略了破坏编辑语义对齐这一核心目标，无法准确衡量免疫有效性。

Method: 提出Synergistic Intermediate Feature Manipulation (SIFM)方法，通过两个协同目标扰动扩散模型中间特征：(1) 最大化与原始编辑轨迹的特征差异以破坏语义对齐；(2) 最小化特征范数以引入感知退化。同时提出Immunization Success Rate (ISR)指标，利用多模态大语言模型评估语义失败或感知退化的比例。

Result: 大量实验表明，所提出的SIFM方法在防御基于扩散模型的恶意图像编辑方面达到了当前最优性能。

Conclusion: 图像免疫的成功应定义为编辑结果在语义上与提示不匹配或出现显著感知退化，SIFM方法结合ISR评估指标能有效实现并衡量这一目标。

Abstract: Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.

</details>


### [49] [OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving](https://arxiv.org/abs/2512.14225)
*Tao Tang,Enhui Ma,xia zhou,Letian Wang,Tianyi Yan,Xueyang Zhang,Kun Zhan,Peng Jia,XianPeng Lang,Jia-Wang Bian,Kaicheng Yu,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出OminiGen，一种在统一框架下生成对齐的多模态传感器数据的方法，通过共享鸟瞰图（BEV）空间和新颖的UAE重建方法，结合Diffusion Transformer与ControlNet，实现可控、一致且灵活的多模态数据生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型主要聚焦于单模态数据生成，在多模态传感器数据生成中存在效率低下和模态间不一致的问题；同时，获取多样性和极端场景的真实世界数据成本高昂。

Method: OminiGen利用共享的鸟瞰图（BEV）空间统一多模态特征，设计了通用的多模态重建方法UAE，通过体渲染联合解码LiDAR和多视角相机数据，并引入带ControlNet分支的Diffusion Transformer以实现可控生成。

Result: 实验表明，OminiGen在多模态一致性、传感器灵活调整和统一生成性能方面表现优异。

Conclusion: OminiGen有效解决了多模态传感器数据生成中的对齐与效率问题，为自动驾驶数据合成提供了高效、可控的新方案。

Abstract: Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

</details>


### [50] [Dual Attention Guided Defense Against Malicious Edits](https://arxiv.org/abs/2512.14333)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 提出了一种名为DANP的新型免疫方法，通过在多个时间步上同时干扰扩散模型的交叉注意力机制和噪声预测过程，有效防御恶意文本引导的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型虽能通过文本提示实现图像编辑，但也带来被滥用于生成欺骗性或有害内容的伦理风险；现有防御方法（如添加不可感知扰动）在面对恶意篡改时效果有限。

Method: 提出Dual Attention-Guided Noise Perturbation（DANP）方法，在多个时间步上操作：利用动态阈值生成掩码区分文本相关与无关区域，降低相关区域注意力、提升无关区域注意力以误导编辑方向；同时最大化注入噪声与模型预测噪声之间的差异，干扰生成过程。

Result: 大量实验表明，DANP在抵御恶意编辑方面表现出色，达到了当前最优（state-of-the-art）的防御性能。

Conclusion: 通过同时攻击注意力机制和噪声预测两个关键环节，DANP能有效保护图像免受恶意文本引导编辑的侵害，为扩散模型的安全应用提供了新思路。

Abstract: Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.

</details>


### [51] [Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients](https://arxiv.org/abs/2512.14232)
*Rawan Alyahya,Asrar Alruwayqi,Atheer Alqarni,Asma Alkhaldi,Metab Alkubeyyer,Xin Gao,Mona Alshahrani*

Main category: cs.CV

TL;DR: 本研究提出一种基于多视角MRI图像和深度学习的非侵入性方法，用于检测胶质母细胞瘤（GBM）患者MGMT启动子甲基化状态，避免了复杂的3D模型，并引入新的肿瘤切片提取技术，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前确认MGMT启动子甲基化依赖于侵入性脑肿瘤组织活检，亟需开发非侵入性的替代方法以支持精准医疗。

Method: 利用MRI扫描和深度学习模型，提出一种多视角方法，综合考虑MRI各视角之间的空间关系；同时引入一种新的肿瘤切片提取技术，并构建可复现的模型流程。

Result: 所提方法在多个评估指标上优于现有技术，有效识别MGMT甲基化状态，且避免了3D深度学习模型带来的高参数量、收敛慢和内存需求大等问题。

Conclusion: 该研究展示了基于影像组学和深度学习的非侵入性方法在检测MGMT启动子甲基化方面的潜力，有助于推动GBM精准治疗的发展。

Abstract: The presence of MGMT promoter methylation significantly affects how well chemotherapy works for patients with Glioblastoma Multiforme (GBM). Currently, confirmation of MGMT promoter methylation relies on invasive brain tumor tissue biopsies. In this study, we explore radiogenomics techniques, a promising approach in precision medicine, to identify genetic markers from medical images. Using MRI scans and deep learning models, we propose a new multi-view approach that considers spatial relationships between MRI views to detect MGMT methylation status. Importantly, our method extracts information from all three views without using a complicated 3D deep learning model, avoiding issues associated with high parameter count, slow convergence, and substantial memory demands. We also introduce a new technique for tumor slice extraction and show its superiority over existing methods based on multiple evaluation metrics. By comparing our approach to state-of-the-art models, we demonstrate the efficacy of our method. Furthermore, we share a reproducible pipeline of published models, encouraging transparency and the development of robust diagnostic tools. Our study highlights the potential of non-invasive methods for identifying MGMT promoter methylation and contributes to advancing precision medicine in GBM treatment.

</details>


### [52] [Towards Transferable Defense Against Malicious Image Edits](https://arxiv.org/abs/2512.14341)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为TDAE的双模态防御框架，通过图像-文本协同优化提升图像对恶意编辑的免疫力，在跨模型评估中表现出优越的迁移性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于不可感知扰动的防御方法在跨模型评估中迁移性有限，难以有效抵御不同扩散模型下的恶意图像编辑。

Method: 提出TDAE框架，包含两个核心机制：1）视觉层面的FlatGrad Defense Mechanism（FDM），通过梯度正则化引导扰动朝向平坦极小值以增强鲁棒性；2）文本层面的Dynamic Prompt Defense（DPD），通过动态优化文本嵌入并迭代更新图像，提升跨模型免疫能力。

Result: 实验表明，TDAE在同模型和跨模型设置下均显著优于现有方法，在抵御恶意编辑任务中达到SOTA性能。

Conclusion: TDAE通过联合优化图像扰动与文本提示，有效提升了防御机制的泛化能力和跨模型迁移性，为扩散模型图像编辑安全提供了新思路。

Abstract: Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.

</details>


### [53] [4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation](https://arxiv.org/abs/2512.14235)
*Jimmie Kwok,Holger Caesar,Andras Palffy*

Main category: cs.CV

TL;DR: 提出了一种名为4D-RaDiff的新框架，通过在潜在空间中对稀疏的4D雷达点云进行扩散生成，以合成高质量雷达数据用于目标检测训练，显著提升检测性能并减少对真实标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 由于标注的雷达数据稀缺，限制了基于雷达的感知系统的发展，因此需要一种有效的方法来生成可用于训练和评估的4D雷达点云数据。

Method: 设计了一种针对雷达点云稀疏性和独特性的扩散生成方法，在潜在点云表示上进行扩散，并通过对象级或场景级条件控制生成过程；该方法可将无标签边界框转化为高质量雷达标注，并将LiDAR点云转换为逼真的雷达场景。

Result: 实验表明，使用4D-RaDiff生成的合成雷达数据作为数据增强手段，能持续提升目标检测性能；此外，仅用10%的真实标注数据配合合成数据预训练即可达到与全量真实数据相当的性能。

Conclusion: 所提出的4D-RaDiff框架有效缓解了雷达标注数据不足的问题，为雷达感知系统的训练和评估提供了高效、实用的数据生成方案。

Abstract: Automotive radar has shown promising developments in environment perception due to its cost-effectiveness and robustness in adverse weather conditions. However, the limited availability of annotated radar data poses a significant challenge for advancing radar-based perception systems. To address this limitation, we propose a novel framework to generate 4D radar point clouds for training and evaluating object detectors. Unlike image-based diffusion, our method is designed to consider the sparsity and unique characteristics of radar point clouds by applying diffusion to a latent point cloud representation. Within this latent space, generation is controlled via conditioning at either the object or scene level. The proposed 4D-RaDiff converts unlabeled bounding boxes into high-quality radar annotations and transforms existing LiDAR point cloud data into realistic radar scenes. Experiments demonstrate that incorporating synthetic radar data of 4D-RaDiff as data augmentation method during training consistently improves object detection performance compared to training on real data only. In addition, pre-training on our synthetic data reduces the amount of required annotated radar data by up to 90% while achieving comparable object detection performance.

</details>


### [54] [DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning](https://arxiv.org/abs/2512.14420)
*Nakamasa Inoue,Kanoko Goto,Masanari Oi,Martyna Gruszka,Mahiro Ukai,Takumi Hirose,Yusuke Sekikawa*

Main category: cs.CV

TL;DR: 提出了一种无需微调的方法DISCODE，通过测试时自适应策略提升图像描述评估在跨领域场景下的鲁棒性，并构建了新基准MCEval进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLMs）在图像描述评估中面对领域迁移时表现不稳定，难以与人类判断保持一致。

Method: 提出Distribution-Aware Score Decoder（DISCODE），利用高斯先验分布设计Adaptive Test-Time（ATT）损失，在测试时通过解析解优化评分；同时构建涵盖六个领域的Multi-domain Caption Evaluation（MCEval）基准。

Result: DISCODE在MCEval及四个现有基准上作为无参考评估指标达到最先进性能。

Conclusion: DISCODE有效提升了跨领域图像描述评估的鲁棒性和与人类判断的一致性，且无需微调。

Abstract: Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.

</details>


### [55] [Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding](https://arxiv.org/abs/2512.14236)
*Nando Metzger,Prune Truong,Goutam Bhat,Konrad Schindler,Federico Tombari*

Main category: cs.CV

TL;DR: Elastic3D 是一种基于条件潜在扩散模型的端到端单目转立体视频方法，无需显式深度估计和图像扭曲，通过新颖的引导式VAE解码器生成高质量、视差一致的立体视频，并支持用户在推理时通过单一参数调节立体效果强度。


<details>
  <summary>Details</summary>
Motivation: 随着对沉浸式3D内容需求的增长，亟需自动化地将普通单目视频转换为立体视频。现有方法常因显式深度估计和图像扭曲而引入伪影，且缺乏对立体效果强度的有效控制。

Method: 提出 Elastic3D 方法，基于（条件）潜在扩散模型，采用新颖的引导式VAE解码器，在不依赖显式深度图和图像扭曲的情况下直接生成立体视频，并引入一个标量参数用于在推理阶段控制视差范围。

Result: 在三个真实世界立体视频数据集上的实验表明，Elastic3D 在质量和可控性方面优于传统基于扭曲的方法和近期无扭曲基线方法。

Conclusion: Elastic3D 实现了高质量、可控且可靠的单目到立体视频转换，为该领域树立了新标准。

Abstract: The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.

</details>


### [56] [TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels](https://arxiv.org/abs/2512.14477)
*Andreas Sjölander,Valeria Belloni,Robel Fekadu,Andrea Nascetti*

Main category: cs.CV

TL;DR: 本文发布了一个新的公开隧道缺陷图像数据集，涵盖三种衬砌类型及典型病害（裂缝、析出物和渗水），旨在支持多种深度学习方法并提升模型在不同隧道类型间的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统隧道检测依赖人工，耗时、主观且昂贵；尽管移动测绘与深度学习技术提供了自动化检测的可能，但缺乏适用于隧道场景的高质量标注数据集限制了其应用。

Method: 构建并发布一个包含三种不同类型隧道衬砌、标注了典型缺陷（裂缝、析出、渗水）的图像数据集，支持监督、半监督和无监督深度学习方法。

Result: 该数据集具有丰富的纹理和施工工艺多样性，可用于训练和评估缺陷检测与分割模型，并研究其跨隧道类型的泛化与迁移能力。

Conclusion: 该数据集填补了隧道自动化检测领域专用数据的空白，有助于推动基于深度学习的智能隧道检测技术发展，从而实现更安全高效的基础设施运维。

Abstract: Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.

</details>


### [57] [Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs](https://arxiv.org/abs/2512.14257)
*Wentao Wan,Kaiyu Wu,Qingyang Ma,Nan Kang,Yunjie Chen,Liang Lin,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出EVPG方法，通过构建有向概率图将非可微的视觉编程（VP）执行过程转化为可微的概率推理过程，从而实现利用最终标签对整个VP框架进行端到端梯度优化，在多个复杂视觉推理任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编程（VP）方法主要关注提升大语言模型生成的视觉程序质量，却忽略了对VP调用的预训练子模型的优化；由于缺乏子任务标签且VP本身不可微，难以利用最终任务标签进行端到端梯度优化。

Method: 提出EVPG方法，依据VP执行过程中变量间的依赖关系构建有向概率图，将不可微的VP执行过程重构为该图上的可微精确概率推理过程，从而支持基于最终标签的端到端梯度优化。

Result: 在GQA、NLVRv2和Open Images三个经典复杂视觉推理任务上进行了广泛实验，结果表明EVPG显著提升了VP的性能。

Conclusion: EVPG有效解决了VP框架中因不可微性和缺乏子任务标签导致的优化难题，通过概率图建模实现了端到端监督学习，显著增强了视觉编程在复杂视觉推理任务中的表现。

Abstract: Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.

</details>


### [58] [CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning](https://arxiv.org/abs/2512.14540)
*Andreas Lolos,Theofilos Christodoulou,Aris L. Moustakas,Stergios Christodoulidis,Maria Vakalopoulou*

Main category: cs.CV

TL;DR: 本文提出CAPRMIL，一种受神经PDE求解器启发的新型MIL框架，通过在聚合前生成富含全局上下文信息的patch嵌入，在保持性能的同时大幅降低计算开销和参数量。


<details>
  <summary>Details</summary>
Motivation: 在计算病理学中，由于全切片图像（WSI）尺寸巨大且像素级标注稀缺，多实例学习（MIL）通常依赖复杂的注意力机制进行slide-level建模。作者旨在简化MIL聚合过程，将相关性学习的复杂性从聚合器中移除，转而通过增强实例表示来提升性能。

Method: CAPRMIL利用冻结的patch编码器提取特征，将其投影为少量全局上下文/形态感知token，并通过多头自注意力注入全局上下文，其计算复杂度相对于bag size呈线性增长；随后配合简单的Mean MIL聚合器完成分类。

Result: CAPRMIL在多个公开病理数据集上达到SOTA水平，同时相比现有MIL方法减少48%-92.8%的可训练参数，推理FLOPs降低52%-99%，并在GPU内存效率和训练时间方面表现优异。

Conclusion: 在聚合前学习富含上下文信息的实例表示是一种高效且可扩展的替代方案，能够取代复杂的池化机制用于全切片分析。

Abstract: In computational pathology, weak supervision has become the standard for deep learning due to the gigapixel scale of WSIs and the scarcity of pixel-level annotations, with Multiple Instance Learning (MIL) established as the principal framework for slide-level model training. In this paper, we introduce a novel setting for MIL methods, inspired by proceedings in Neural Partial Differential Equation (PDE) Solvers. Instead of relying on complex attention-based aggregation, we propose an efficient, aggregator-agnostic framework that removes the complexity of correlation learning from the MIL aggregator. CAPRMIL produces rich context-aware patch embeddings that promote effective correlation learning on downstream tasks. By projecting patch features -- extracted using a frozen patch encoder -- into a small set of global context/morphology-aware tokens and utilizing multi-head self-attention, CAPRMIL injects global context with linear computational complexity with respect to the bag size. Paired with a simple Mean MIL aggregator, CAPRMIL matches state-of-the-art slide-level performance across multiple public pathology benchmarks, while reducing the total number of trainable parameters by 48%-92.8% versus SOTA MILs, lowering FLOPs during inference by 52%-99%, and ranking among the best models on GPU memory efficiency and training time. Our results indicate that learning rich, context-aware instance representations before aggregation is an effective and scalable alternative to complex pooling for whole-slide analysis. Our code is available at https://github.com/mandlos/CAPRMIL

</details>


### [59] [DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance](https://arxiv.org/abs/2512.14266)
*Shreedhar Govil,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: 本文提出了DriverGaze360——一个包含约100万帧360度全景视角下标注了驾驶员注视点的大规模数据集，并设计了DriverGaze360-Net模型，通过联合学习注意力图和语义分割，在全景驾驶图像上实现了最先进的驾驶员注意力预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员注意力预测方法受限于狭窄的前向视野和有限的驾驶场景多样性，难以捕捉包括变道、转弯及与行人或骑行者等周边物体交互时的完整空间上下文信息。

Method: 构建了包含19名驾驶员、约100万帧360度全景注视标注的DriverGaze360数据集；提出DriverGaze360-Net模型，通过引入辅助语义分割头，联合学习注意力图与被关注物体，提升在宽视场全景输入下的空间感知与注意力预测能力。

Result: 在多个指标上，DriverGaze360-Net在全景驾驶图像上的注意力预测性能达到当前最优水平。

Conclusion: DriverGaze360数据集和DriverGaze360-Net方法有效提升了对驾驶员在复杂全景驾驶场景中注意力行为的建模能力，为可解释自动驾驶系统和人机混合交通研究提供了重要支持。

Abstract: Predicting driver attention is a critical problem for developing explainable autonomous driving systems and understanding driver behavior in mixed human-autonomous vehicle traffic scenarios. Although significant progress has been made through large-scale driver attention datasets and deep learning architectures, existing works are constrained by narrow frontal field-of-view and limited driving diversity. Consequently, they fail to capture the full spatial context of driving environments, especially during lane changes, turns, and interactions involving peripheral objects such as pedestrians or cyclists. In this paper, we introduce DriverGaze360, a large-scale 360$^\circ$ field of view driver attention dataset, containing $\sim$1 million gaze-labeled frames collected from 19 human drivers, enabling comprehensive omnidirectional modeling of driver gaze behavior. Moreover, our panoramic attention prediction approach, DriverGaze360-Net, jointly learns attention maps and attended objects by employing an auxiliary semantic segmentation head. This improves spatial awareness and attention prediction across wide panoramic inputs. Extensive experiments demonstrate that DriverGaze360-Net achieves state-of-the-art attention prediction performance on multiple metrics on panoramic driving images. Dataset and method available at https://av.dfki.de/drivergaze360.

</details>


### [60] [CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer](https://arxiv.org/abs/2512.14560)
*Xianwei Cao,Dou Quan,Shuang Wang,Ning Huyan,Wei Wang,Yunan Li,Licheng Jiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为CLNet的新型特征优化框架，通过显式建模跨视图图像间的空间对应关系，显著提升了图像检索型跨视角地理定位的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨视角地理定位任务中主要依赖全局表征学习或隐式特征对齐，难以捕捉对精确定位至关重要的显式空间对应关系。

Method: 提出CLNet框架，包含三个可学习模块：神经对应图（NCM）用于通过潜在对应场对跨视角特征进行空间对齐；非线性嵌入转换器（NEC）利用MLP实现跨视角特征重映射；全局特征重校准（GFR）模块则根据学习到的空间线索对特征通道进行重加权。

Result: 在CVUSA、CVACT、VIGOR和University-1652四个公开数据集上的实验表明，CLNet取得了当前最优的性能，并具有更好的可解释性和泛化能力。

Conclusion: CLNet通过显式建模语义与几何差异之间的对应关系，在跨视角地理定位任务中实现了更准确、更具解释性的匹配效果，为该领域提供了有效的新思路。

Abstract: Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.

</details>


### [61] [Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in](https://arxiv.org/abs/2512.14273)
*Xiaoqian Shen,Min-Hung Chen,Yu-Chiang Frank Wang,Mohamed Elhoseiny,Ryo Hachiuma*

Main category: cs.CV

TL;DR: Zoom-Zero 是一种用于提升视频问答中时序定位准确性的粗到精框架，通过引入 zoom-in 准确性奖励和 token 选择性信用分配机制，在多个基准上显著提升了时序定位与答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于 GRPO 的方法在 grounded video question answering（GVQA）任务中难以准确将答案与时序视频证据对齐，导致时序错位和幻觉问题。

Method: 提出 Zoom-Zero 框架：首先粗略定位与问题相关的视频片段，再对最显著帧进行细粒度视觉验证；引入 zoom-in 准确性奖励以验证时序定位的保真度，并采用 token-selective credit assignment 将奖励分配给负责时序定位或答案生成的 token。

Result: 在 NExT-GQA 和 ReXTime 上分别提升时序定位准确率 5.2% 和 4.6%，平均答案准确率提升 2.4%；在长视频理解任务上平均提升 6.4%。

Conclusion: Zoom-Zero 有效缓解了 LVLMs 在 GVQA 中的时序感知不足问题，显著提升了定位与回答性能，尤其适用于长视频场景。

Abstract: Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\% on NExT-GQA and 4.6\% on ReXTime, while also enhancing average answer accuracy by 2.4\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\% on long-video benchmarks.

</details>


### [62] [FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos](https://arxiv.org/abs/2512.14601)
*Zhaolun Li,Jichang Li,Yinqi Cai,Junye Chen,Xiaonan Luo,Guanbin Li,Rushi Lan*

Main category: cs.CV

TL;DR: FakeRadar 是一种基于大模型的深度伪造视频检测框架，通过引入伪造异常样本探测和异常引导的三重训练机制，显著提升了在跨域场景下对未知伪造技术的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法依赖特定伪造线索，在面对新型或未知伪造技术时泛化能力差，难以适应真实世界中不断演化的伪造手段。

Method: 利用大规模预训练模型（如 CLIP）进行特征空间探测，提出 Forgery Outlier Probing 机制，通过动态子簇建模与条件异常生成合成边界附近的异常样本；并设计 Outlier-Guided Tri-Training 策略，结合异常驱动的对比学习与条件交叉熵损失优化检测器。

Result: 在多个深度伪造视频基准数据集上，特别是在跨域评估中，FakeRadar 显著优于现有方法，有效应对了多种新兴伪造技术。

Conclusion: FakeRadar 通过主动建模未知伪造分布并引入异常引导训练策略，有效提升了深度伪造检测模型在真实复杂场景中的跨域泛化能力。

Abstract: In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.

</details>


### [63] [A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images](https://arxiv.org/abs/2512.14640)
*Rao Muhammad Umer,Daniel Sens,Jonathan Noll,Christian Matek,Lukas Wolfseher,Rainer Spang,Ralf Huss,Johannes Raffler,Sarah Reinke,Wolfram Klapper,Katja Steiger,Kristina Schwamborn,Carsten Marr*

Main category: cs.CV

TL;DR: 本文提出了首个涵盖四种常见淋巴瘤亚型及健康对照组织的多中心淋巴瘤基准数据集，并系统评估了五种公开病理基础模型与两种多实例学习聚合方法在不同放大倍数下的性能。结果显示，在分布内测试集中，模型多分类平衡准确率超过80%，40x分辨率已足够；但在分布外测试集中性能显著下降至约60%，凸显泛化挑战。


<details>
  <summary>Details</summary>
Motivation: 当前淋巴瘤诊断依赖多种昂贵且耗时的技术手段，而基于常规HE染色切片的深度学习方法有望辅助病理医生，但缺乏针对多中心数据的全面淋巴瘤亚型分类基准。

Method: 构建首个覆盖四种常见淋巴瘤亚型和健康对照的多中心基准数据集，系统评估五种公开病理基础模型（H-optimus-1、H0-mini、Virchow2、UNI2、Titan）结合注意力机制（AB-MIL）与Transformer（TransMIL）两种多实例学习聚合器在10x、20x、40x三种放大倍数下的表现，并分析模型在分布内与分布外测试集上的泛化能力。

Result: 在分布内测试集中，所有模型在各放大倍数下均取得超过80%的多分类平衡准确率，40x分辨率已足够，更高分辨率或跨分辨率聚合未带来性能提升；但在分布外测试集中，性能大幅下降至约60%，表明存在显著泛化问题。

Conclusion: 尽管现有基础模型在多中心分布内数据上表现良好，但其泛化能力仍有限，未来需更大规模、涵盖更多罕见亚型的多中心研究。作者提供了自动化基准测试流程以促进后续研究。

Abstract: Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.

</details>


### [64] [SS4D: Native 4D Generative Model via Structured Spacetime Latents](https://arxiv.org/abs/2512.14284)
*Zhibing Li,Mengchen Zhang,Tong Wu,Jing Tan,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: SS4D 是一种原生的 4D 生成模型，可直接从单目视频合成动态 3D 对象，通过结构化的时空隐变量实现高保真度、时间一致性和结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于 3D 或视频生成模型优化构建 4D 表示，难以兼顾时间一致性与结构完整性；同时 4D 训练数据稀缺，限制了模型性能。

Method: SS4D 直接在 4D 数据上训练生成器，采用结构化时空隐变量：(1) 基于预训练的单图到 3D 模型保持空间一致性；(2) 引入专用时间层跨帧推理以增强时间一致性；(3) 利用因子化 4D 卷积和时间下采样模块压缩时间轴上的隐变量序列，提升长视频训练与推理效率；并设计鲁棒训练策略应对遮挡问题。

Result: 该方法在生成动态 3D 对象时实现了高保真度、良好的时间连贯性与结构一致性，并能高效处理长视频序列。

Conclusion: SS4D 通过直接建模 4D 数据和结构化时空表示，在单目视频驱动的动态 3D 生成任务中取得了显著效果，为未来 4D 生成模型提供了新思路。

Abstract: We present SS4D, a native 4D generative model that synthesizes dynamic 3D objects directly from monocular video. Unlike prior approaches that construct 4D representations by optimizing over 3D or video generative models, we train a generator directly on 4D data, achieving high fidelity, temporal coherence, and structural consistency. At the core of our method is a compressed set of structured spacetime latents. Specifically, (1) To address the scarcity of 4D training data, we build on a pre-trained single-image-to-3D model, preserving strong spatial consistency. (2) Temporal consistency is enforced by introducing dedicated temporal layers that reason across frames. (3) To support efficient training and inference over long video sequences, we compress the latent sequence along the temporal axis using factorized 4D convolutions and temporal downsampling blocks. In addition, we employ a carefully designed training strategy to enhance robustness against occlusion

</details>


### [65] [Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure](https://arxiv.org/abs/2512.14336)
*Jooyeol Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出了一种通过语义结构恢复来提升视觉语言模型（VLM）对SVG动画生成能力的新框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理SVG动画时难以识别应协同运动的图形元素，因为SVG常被拆分为缺乏语义关联的低级形状，导致动画不连贯。

Method: 通过聚合多个弱部件预测结果，从噪声预测中稳定推断出语义结构，并将SVG重新组织为语义组，以支持更一致的动画生成。

Result: 实验表明，该方法在SVG动画生成方面相比现有方法有显著提升，增强了VLM与矢量图形之间的可解释交互。

Conclusion: 语义结构的恢复是实现鲁棒SVG动画的关键步骤，能有效提升视觉语言模型在矢量图形动画任务中的表现。

Abstract: Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.

</details>


### [66] [EcoScapes: LLM-Powered Advice for Crafting Sustainable Cities](https://arxiv.org/abs/2512.14373)
*Martin Röhn,Nora Gourmelon,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出了一种结合专用大语言模型（LLMs）、卫星图像分析和知识库的多层系统，以帮助资源有限的小城市整合多源数据，制定有效的气候适应策略。


<details>
  <summary>Details</summary>
Motivation: 小城市在气候适应方面面临人员资源有限和难以整合多源海量数据的挑战，亟需有效工具支持其可持续发展甚至生存。

Method: 构建一个多层系统，融合专用大语言模型、卫星影像分析与知识库，辅助进行综合性的气候适应分析。

Result: 该系统能够有效整合多源数据，为小城市提供可行的气候适应策略支持。

Conclusion: 所提出的多层系统为资源受限的小城市提供了实用且可扩展的气候适应解决方案，有助于提升其应对气候变化的能力。

Abstract: Climate adaptation is vital for the sustainability and sometimes the mere survival of our urban areas. However, small cities often struggle with limited personnel resources and integrating vast amounts of data from multiple sources for a comprehensive analysis. To overcome these challenges, this paper proposes a multi-layered system combining specialized LLMs, satellite imagery analysis and a knowledge base to aid in developing effective climate adaptation strategies. The corresponding code can be found at https://github.com/Photon-GitHub/EcoScapes.

</details>


### [67] [Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos](https://arxiv.org/abs/2512.14406)
*Le Jiang,Shaotong Zhu,Yedi Luo,Shayda Moezzi,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: ExpanDyNeRF is a monocular dynamic NeRF method that improves novel view synthesis under large viewpoint shifts by using Gaussian splatting priors and pseudo-ground-truth generation, validated on a new synthetic dataset SynDM and real-world scenes.


<details>
  <summary>Details</summary>
Motivation: Existing dynamic NeRF methods struggle with rendering stability and realism when there are significant deviations in viewing angles.

Method: ExpanDyNeRF integrates Gaussian splatting priors and a pseudo-ground-truth generation strategy to optimize density and color features for improved reconstruction from extreme viewpoints; it is evaluated using the newly introduced SynDM dataset.

Result: Experiments on SynDM and real-world datasets show that ExpanDyNeRF achieves superior rendering fidelity compared to current dynamic NeRF approaches under large-angle rotations.

Conclusion: ExpanDyNeRF effectively addresses the challenge of unstable renderings in dynamic NeRF under extreme viewpoint changes, offering a robust solution supported by both synthetic and real-world evaluations.

Abstract: In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

</details>


### [68] [LCMem: A Universal Model for Robust Image Memorization Detection](https://arxiv.org/abs/2512.14421)
*Mischa Dombrowski,Felix Nützel,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本文提出了一种名为LCMem的新方法，将记忆检测视为重识别与复制检测的统一问题，通过两阶段训练策略在多个数据集上显著提升了跨域记忆检测的性能，为生成图像模型的隐私审计提供了更可靠、可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前生成图像模型虽能生成逼真图像，但其在隐私保护数据共享方面的潜力尚不明确，主要障碍在于缺乏可靠的记忆检测机制、定量评估不足以及现有隐私审计方法跨域泛化能力差。

Method: 作者将记忆检测视为重识别与复制检测的统一问题，提出了Latent Contrastive Memorization Network（LCMem），采用两阶段训练策略：先学习身份一致性，再引入对增强鲁棒的复制检测，并在六个基准数据集上进行联合评估。

Result: LCMem在重识别任务上最多提升16个百分点，在复制检测任务上最多提升30个百分点，显著优于现有隐私过滤方法，在跨域记忆检测方面表现出更强的可靠性与可扩展性。

Conclusion: LCMem为跨域隐私审计设立了新标准，能够实现更可靠、可扩展的记忆检测，揭示了现有隐私保护机制的局限性，并强调了开发更强保护机制的必要性。

Abstract: Recent advances in generative image modeling have achieved visual realism sufficient to deceive human experts, yet their potential for privacy preserving data sharing remains insufficiently understood. A central obstacle is the absence of reliable memorization detection mechanisms, limited quantitative evaluation, and poor generalization of existing privacy auditing methods across domains. To address this, we propose to view memorization detection as a unified problem at the intersection of re-identification and copy detection, whose complementary goals cover both identity consistency and augmentation-robust duplication, and introduce Latent Contrastive Memorization Network (LCMem), a cross-domain model evaluated jointly on both tasks. LCMem achieves this through a two-stage training strategy that first learns identity consistency before incorporating augmentation-robust copy detection. Across six benchmark datasets, LCMem achieves improvements of up to 16 percentage points on re-identification and 30 percentage points on copy detection, enabling substantially more reliable memorization detection at scale. Our results show that existing privacy filters provide limited performance and robustness, highlighting the need for stronger protection mechanisms. We show that LCMem sets a new standard for cross-domain privacy auditing, offering reliable and scalable memorization detection. Code and model is publicly available at https://github.com/MischaD/LCMem.

</details>


### [69] [The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy](https://arxiv.org/abs/2512.14423)
*Zhuo Chen,Fanyue Wei,Runze Xu,Jingjing Li,Lixin Duan,Angela Yao,Wen Li*

Main category: cs.CV

TL;DR: 本文提出SynPS方法，通过协同利用位置嵌入和语义信息，有效解决非刚性图像编辑中的注意力坍塌问题，从而在保持图像保真度的同时实现更准确的复杂编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于大扩散模型的免训练图像编辑方法在处理复杂的非刚性编辑（如姿态或形状变化）时仍面临挑战，主要原因是现有注意力共享机制中存在“注意力坍塌”现象，即位置嵌入或语义特征主导视觉内容检索，导致过度编辑或编辑不足。

Method: 作者提出SynPS方法，首先设计一种编辑度量来量化每个去噪步骤所需的编辑强度，然后构建一个注意力协同机制，根据该度量动态调节位置嵌入的影响，以在语义修改与保真度之间取得平衡。

Result: 在公开及新构建的基准数据集上的大量实验表明，SynPS在非刚性图像编辑任务中具有优越的性能和更高的编辑忠实度。

Conclusion: 通过自适应融合位置和语义线索，SynPS能有效避免过度编辑和编辑不足，显著提升复杂非刚性图像编辑的质量和可靠性。

Abstract: Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.

</details>


### [70] [Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging](https://arxiv.org/abs/2512.14435)
*Chang Cai,Hao Jiang,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于得分的涡轮消息传递（STMP）算法，用于压缩图像恢复，通过结合得分生成模型与消息传递框架，在性能和复杂度之间取得更优平衡，并进一步提出了适用于量化测量的Q-STMP变体。


<details>
  <summary>Details</summary>
Motivation: 传统插件式（PnP）方法依赖通用或手工设计的先验，难以准确刻画自然图像的复杂统计结构，导致在高度欠定条件下重建效果不佳；而基于得分的生成模型虽能精确建模图像分布，但直接用于后验采样计算开销过大。

Method: 利用得分生成模型与经验贝叶斯去噪之间的联系，构建一个集成得分MMSE去噪器的消息传递框架（STMP），并针对量化测量场景引入逐元素MMSE去量化模块，形成Q-STMP；同时推导其渐近性能的状态演化（SE）方程。

Result: 在FFHQ数据集上的实验表明，STMP相比现有基线方法在性能-复杂度权衡上显著更优，Q-STMP在1比特量化下仍保持鲁棒性，且两者通常在10次迭代内收敛。

Conclusion: 所提出的STMP和Q-STMP算法有效融合了得分生成先验的表达能力和消息传递的快速收敛特性，为压缩成像提供了一种高效且高精度的解决方案。

Abstract: Message-passing algorithms have been adapted for compressive imaging by incorporating various off-the-shelf image denoisers. However, these denoisers rely largely on generic or hand-crafted priors and often fall short in accurately capturing the complex statistical structure of natural images. As a result, traditional plug-and-play (PnP) methods often lead to suboptimal reconstruction, especially in highly underdetermined regimes. Recently, score-based generative models have emerged as a powerful framework for accurately characterizing sophisticated image distribution. Yet, their direct use for posterior sampling typically incurs prohibitive computational complexity. In this paper, by exploiting the close connection between score-based generative modeling and empirical Bayes denoising, we devise a message-passing framework that integrates a score-based minimum mean-squared error (MMSE) denoiser for compressive image recovery. The resulting algorithm, named score-based turbo message passing (STMP), combines the fast convergence of message passing with the expressive power of score-based generative priors. For practical systems with quantized measurements, we further propose quantized STMP (Q-STMP), which augments STMP with a component-wise MMSE dequantization module. We demonstrate that the asymptotic performance of STMP and Q-STMP can be accurately predicted by a set of state-evolution (SE) equations. Experiments on the FFHQ dataset demonstrate that STMP strikes a significantly better performance-complexity tradeoff compared with competing baselines, and that Q-STMP remains robust even under 1-bit quantization. Remarkably, both STMP and Q-STMP typically converge within 10 iterations.

</details>


### [71] [S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation](https://arxiv.org/abs/2512.14440)
*Leon Sick,Lukas Hoyer,Dominik Engel,Pedro Hermosilla,Timo Ropinski*

Main category: cs.CV

TL;DR: 本文提出了一种仅使用真实视频数据进行训练的无监督视频实例分割模型，通过利用深度运动先验识别高质量关键掩码，并采用稀疏到稠密蒸馏方法与时间DropLoss策略，实现了优于当前最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频实例分割方法依赖于从ImageNet等以对象为中心的图像数据集生成的合成视频，但这种通过人工平移和缩放图像实例掩码的方式无法准确建模真实视频中的运动（如透视变化、部分或多个实例的移动、摄像机运动等）。

Method: 从单帧无监督实例分割掩码出发，利用深度运动先验识别视频中高质量的关键掩码（keymasks），将其作为稀疏伪标签，通过提出的“稀疏到稠密蒸馏”（Sparse-To-Dense Distillation）方法结合Temporal DropLoss进行训练，实现隐式掩码传播，最终在完整稠密标签集上训练得到最终模型。

Result: 该方法在多个基准测试中超越了当前最先进的无监督视频实例分割方法。

Conclusion: 仅使用真实视频数据并结合运动先验与稀疏到稠密蒸馏策略，能够有效提升无监督视频实例分割的性能，克服合成数据建模运动不真实的问题。

Abstract: In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.

</details>


### [72] [A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning](https://arxiv.org/abs/2512.14442)
*Zixin Zhang,Kanghao Chen,Hanqing Wang,Hongfei Zhang,Harold Haodong Chen,Chenfei Liao,Litao Guo,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出A4-Agent，一种无需训练的智能体框架，将可供性预测解耦为三阶段流程，利用预训练基础模型在零样本设置下显著优于现有监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型将高层推理与低层定位耦合在单一管道中，依赖标注数据训练，导致在新物体和未见环境中泛化能力差。

Method: 提出A4-Agent框架，在测试时协调三种专用基础模型：Dreamer（生成模型可视化交互方式）、Thinker（大视觉语言模型判断交互部位）、Spotter（视觉基础模型精确定位交互区域），无需任务特定微调。

Result: 在多个基准上显著超越当前最先进的监督方法，并在真实世界场景中展现出强大的泛化能力。

Conclusion: 通过解耦推理与定位并整合预训练模型的优势，A4-Agent在零样本条件下实现了更优的可供性预测性能和更强的泛化能力。

Abstract: Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\textbf{Dreamer}$ that employs generative models to visualize $\textit{how}$ an interaction would look; (2) a $\textbf{Thinker}$ that utilizes large vision-language models to decide $\textit{what}$ object part to interact with; and (3) a $\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.

</details>


### [73] [SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition](https://arxiv.org/abs/2512.14489)
*Alessia Micieli,Giovanni Maria Farinella,Francesco Ragusa*

Main category: cs.CV

TL;DR: 本文提出了SignIT，一个用于意大利手语（LIS）识别的新数据集，包含644个视频（共3.33小时），涵盖94个手语类别，并提供了2D关键点标注；作者在此数据集上对多个前沿模型进行了基准测试，揭示了现有方法在该任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对意大利手语（LIS）的大规模、结构化数据集，限制了手语识别技术的发展。为推动该领域研究，作者构建并公开了一个带有详细标注和关键点信息的LIS数据集。

Method: 构建包含644个视频的SignIT数据集，涵盖94个手语类别及5个宏观类别；人工标注视频内容，并提取与手部、面部和身体相关的2D关键点；在该数据集上采用多种前沿模型进行手语识别基准测试，评估RGB帧、2D关键点和时序信息对模型性能的影响。

Result: 实验结果表明，现有先进模型在SignIT这一具有挑战性的意大利手语数据集上表现有限，突显了当前方法在复杂手语识别任务中的不足。

Conclusion: SignIT数据集为意大利手语识别研究提供了宝贵资源，基准测试揭示了现有模型的局限性，为未来研究指明了方向；作者已公开发布该数据集及其标注。

Abstract: In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.

</details>


### [74] [Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency](https://arxiv.org/abs/2512.14499)
*Jia Guo,Jiawei Du,Shengzhu Yang,Shuai Lu,Wenquan Cheng,Kaiwen Zhang,Yihua Sun,Chuhong Yang,Weihang Zhang,Fang Chen,Yilan Wu,Lie Ju,Guochen Ning,Longfei Ma,Huiping Yao,Jinyuan Wang,Peilun Shi,Yukun Zhou,Jie Xu,Pearse A. Keane,Hanruo Liu,Hongen Liao,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: ReVision 是一个从大规模真实世界远程医疗数据中学习的视网膜基础模型，无需任务特定训练即可在多种眼科任务中实现高效、高精度的零样本诊断，并显著提升医生诊断准确性，适用于资源有限环境。


<details>
  <summary>Details</summary>
Motivation: 现有视网膜基础模型依赖于缺乏真实临床背景的研究数据集，且需大量任务特定优化，限制了其在低资源环境中的部署效率。

Method: 利用中国162家医疗机构十年积累的485,980张彩色眼底照片及其对应诊断报告，构建名为 ReVision 的视网膜基础模型，通过自然对齐的学习方式提取临床原生智能。

Result: ReVision 在12个公开基准和3个独立临床队列上分别达到平均 AUROC 0.946 和 0.952；微调时所需参数和标注样本数量远少于现有方法；在前瞻性读者研究中，辅助医生诊断准确率提升14.8%。

Conclusion: 从真实临床档案中可直接提取临床原生智能，无需额外标注即可构建适用于多种低资源场景的医学 AI 系统。

Abstract: Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.

</details>


### [75] [DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors](https://arxiv.org/abs/2512.14536)
*Yiheng Huang,Junhong Chen,Anqi Ning,Zhanhong Liang,Nick Michiels,Luc Claesen,Wenyin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为DASP的自监督框架，通过引入时空先验信息来提升夜间单目深度估计的性能，在多个数据集上达到了当前最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有自监督单目深度估计方法在白天表现良好，但在夜间因光照不足和动态物体导致的低可见度、纹理缺失及模糊区域等问题而性能显著下降。

Method: DASP框架包含一个对抗分支和一个自监督分支。对抗分支通过四个专门设计的时空先验学习模块（SPLB）提取白天的时空先验：其中空间-时间学习模块（STLM）利用正交差分提取时序运动变化，轴向空间学习模块（ASLM）结合局部非对称卷积与全局轴向注意力捕获多尺度结构信息；自监督分支则引入3D一致性投影损失，将目标帧与源帧双向投影至共享3D空间，并以二者投影结果的3D差异作为优化目标。

Result: 在Oxford RobotCar和nuScenes数据集上的大量实验表明，该方法在夜间深度估计任务中达到SOTA性能，消融实验也验证了各组件的有效性。

Conclusion: 所提出的DASP框架有效利用时空先验信息，显著提升了夜间场景下单目深度估计的准确性与鲁棒性。

Abstract: Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.

</details>


### [76] [TAT: Task-Adaptive Transformer for All-in-One Medical Image Restoration](https://arxiv.org/abs/2512.14550)
*Zhiwen Yang,Jiaju Zhang,Yang Yi,Jian Liang,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种任务自适应Transformer（TAT）框架，用于解决医学图像恢复中多任务联合训练时的任务干扰与任务不平衡问题，在PET合成、CT去噪和MRI超分辨率任务上达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像恢复（MedIR）中的All-in-One模型需同时处理多种不同模态和退化类型的任务，但任务间存在梯度冲突（任务干扰）和学习难度差异（任务不平衡），影响模型性能。

Method: 提出任务自适应Transformer（TAT），包含两项创新：1）任务自适应权重生成策略，为不同任务生成专属参数以消除共享参数上的梯度冲突；2）任务自适应损失平衡策略，根据各任务的学习难度动态调整损失权重。

Result: 在PET合成、CT去噪和MRI超分辨率三项医学图像恢复任务中，无论是在独立任务还是All-in-One设置下，TAT均取得当前最优性能。

Conclusion: 所提出的TAT有效缓解了多任务医学图像恢复中的任务干扰与不平衡问题，显著提升了模型在多种任务上的综合表现。

Abstract: Medical image restoration (MedIR) aims to recover high-quality medical images from their low-quality counterparts. Recent advancements in MedIR have focused on All-in-One models capable of simultaneously addressing multiple different MedIR tasks. However, due to significant differences in both modality and degradation types, using a shared model for these diverse tasks requires careful consideration of two critical inter-task relationships: task interference, which occurs when conflicting gradient update directions arise across tasks on the same parameter, and task imbalance, which refers to uneven optimization caused by varying learning difficulties inherent to each task. To address these challenges, we propose a task-adaptive Transformer (TAT), a novel framework that dynamically adapts to different tasks through two key innovations. First, a task-adaptive weight generation strategy is introduced to mitigate task interference by generating task-specific weight parameters for each task, thereby eliminating potential gradient conflicts on shared weight parameters. Second, a task-adaptive loss balancing strategy is introduced to dynamically adjust loss weights based on task-specific learning difficulties, preventing task domination or undertraining. Extensive experiments demonstrate that our proposed TAT achieves state-of-the-art performance in three MedIR tasks--PET synthesis, CT denoising, and MRI super-resolution--both in task-specific and All-in-One settings. Code is available at https://github.com/Yaziwel/TAT.

</details>


### [77] [TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios](https://arxiv.org/abs/2512.14595)
*Mengyu Li,Xingcheng Zhou,Guang Chen,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 本文针对智能交通系统中传统帧相机在弱光和高速运动场景下的局限性，提出利用事件相机的优势，并构建了首个面向事件相机的车辆与行人检测与跟踪数据集，同时建立了基于该数据集的检测-跟踪基准方法，取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 帧相机在弱光和高速运动条件下表现不佳，而事件相机具有低延迟、高动态范围和高时间分辨率等优势；然而，目前针对事件相机在智能交通系统中的研究较少，存在研究空白。

Method: 构建了一个专用于事件相机的智能交通系统试点数据集，涵盖车辆与行人检测与跟踪任务，并在此基础上建立了一个基于专用特征提取器的“检测后跟踪”（tracking-by-detection）基准方法。

Result: 所提出的基准方法在该数据集上实现了优异的多目标跟踪性能。

Conclusion: 事件相机在智能交通系统中具有巨大潜力，本文通过构建新数据集和基准方法为后续研究奠定了基础。

Abstract: In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.

</details>


### [78] [WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling](https://arxiv.org/abs/2512.14614)
*Wenqiang Sun,Haiyu Zhang,Haoyuan Wang,Junta Wu,Zehan Wang,Zhenwei Wang,Yunhong Wang,Jun Zhang,Tengfei Wang,Chunchao Guo*

Main category: cs.CV

TL;DR: WorldPlay 是一种流式视频扩散模型，通过三项关键技术实现实时交互式世界建模，并在保持长期几何一致性的同时突破了现有方法在速度与内存之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实时交互式世界建模中面临速度与内存之间的权衡，难以同时实现高效推理和长期几何一致性。

Method: WorldPlay 引入三项核心技术：1）Dual Action Representation 用于响应用户输入实现稳健动作控制；2）Reconstituted Context Memory 通过从历史帧重建上下文并利用时间重帧保留关键几何信息；3）Context Forcing 是一种面向记忆感知模型的新型蒸馏方法，通过对齐教师与学生模型的记忆上下文，防止误差累积并支持实时生成。

Result: WorldPlay 能以 24 FPS 实时生成 720p 长时程流式视频，在一致性和泛化能力方面优于现有方法，并在多种场景中表现良好。

Conclusion: WorldPlay 成功解决了实时交互式世界建模中的速度-内存权衡问题，实现了高一致性、高效率和强泛化能力的视频生成。

Abstract: This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.

</details>


### [79] [Distill Video Datasets into Images](https://arxiv.org/abs/2512.14621)
*Zhenghao Zhao,Haoxuan Wang,Kai Wang,Yuzhang Shang,Yuan Hong,Yan Yan*

Main category: cs.CV

TL;DR: 本文提出了一种名为单帧视频集蒸馏（SFVD）的新方法，通过将视频蒸馏为每类高度信息丰富的单帧，并结合可微插值与真实视频采样，在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频数据集蒸馏面临因时间维度引入大量可学习参数而导致优化困难和收敛缓慢的问题，限制了其性能表现。

Method: 提出SFVD框架：将视频蒸馏为每类最具判别性的单帧；利用可微插值将这些帧转换为视频序列并与原始数据匹配；仅更新帧本身以提升优化效率；并通过通道重塑层在匹配过程中融合采样的真实视频以引入时序信息。

Result: 在多个基准（如MiniUCF）上的实验表明，SFVD相比先前方法性能显著提升，最高提升达5.3%。

Conclusion: SFVD有效解决了视频数据集蒸馏中的优化难题，通过单帧蒸馏与真实视频融合策略，实现了更高效、更准确的视频数据压缩与模型训练。

Abstract: Dataset distillation aims to synthesize compact yet informative datasets that allow models trained on them to achieve performance comparable to training on the full dataset. While this approach has shown promising results for image data, extending dataset distillation methods to video data has proven challenging and often leads to suboptimal performance. In this work, we first identify the core challenge in video set distillation as the substantial increase in learnable parameters introduced by the temporal dimension of video, which complicates optimization and hinders convergence. To address this issue, we observe that a single frame is often sufficient to capture the discriminative semantics of a video. Leveraging this insight, we propose Single-Frame Video set Distillation (SFVD), a framework that distills videos into highly informative frames for each class. Using differentiable interpolation, these frames are transformed into video sequences and matched with the original dataset, while updates are restricted to the frames themselves for improved optimization efficiency. To further incorporate temporal information, the distilled frames are combined with sampled real videos from real videos during the matching process through a channel reshaping layer. Extensive experiments on multiple benchmarks demonstrate that SFVD substantially outperforms prior methods, achieving improvements of up to 5.3% on MiniUCF, thereby offering a more effective solution.

</details>


### [80] [AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation](https://arxiv.org/abs/2512.14639)
*Fei Wu,Marcel Dreier,Nora Gourmelon,Sebastian Wind,Jianlin Zhang,Thorsten Seehaus,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出AMD-HookNet++，一种结合CNN与Transformer的混合模型，用于合成孔径雷达图像中的冰川分割和崩解锋面描绘，通过增强空间-通道注意力模块和像素级对比深度监督，在CaFFe数据集上取得当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有纯CNN方法（如AMD-HookNet）因卷积操作的局部性和平移不变性，难以捕捉长距离依赖关系，限制了冰川崩解锋面分割的精度和平滑度；而纯Transformer方法又易产生锯齿状边缘。因此，需设计兼顾全局上下文与局部细节的混合架构以提升冰川监测效果。

Method: 提出AMD-HookNet++，包含基于Transformer的上下文分支（捕获长程依赖）和基于CNN的目标分支（保留局部细节）；引入增强的空间-通道注意力模块以动态调整双分支间的特征交互；并采用像素到像素对比深度监督，将像素级度量学习融入分割任务。

Result: 在CaFFe冰川分割基准数据集上，模型达到IoU 78.2%、HD95 1,318米、MDE 367米，性能优于现有方法，并生成更平滑的崩解锋面边界，有效缓解纯Transformer方法的锯齿问题。

Conclusion: AMD-HookNet++通过融合CNN与Transformer优势，显著提升了冰川分割与崩解锋面描绘的精度与平滑性，为冰川动态监测提供了高效可靠的解决方案。

Abstract: The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.

</details>


### [81] [ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking](https://arxiv.org/abs/2512.14654)
*Lihong Wang,Liangqi Li,Weiwei Feng,Jiamin Wu,Changtao Miao,Tieru Wu,Rui Ma,Bo Zhang,Zhe Li*

Main category: cs.CV

TL;DR: 本文提出ViRC框架，通过引入Reason Chunking机制将多模态数学推理分解为连续的关键推理单元（CRUs），并构建CRUX数据集和渐进式训练策略，显著提升多模态大语言模型在数学任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在多模态数学任务中仅依赖静态图像进行文本推理，忽略了人类在推理过程中动态获取视觉信息并分步验证中间命题的认知策略；受认知科学中Miller定律启发，作者旨在模拟人类专家的问题解决模式。

Method: 提出ViRC框架，包含Reason Chunking机制，将多模态思维链划分为连续的关键推理单元（CRUs）；构建CRUX数据集，使用三种视觉工具和四种推理模式为每个数学问题标注多路径CRUs；采用渐进式训练策略（Instructional SFT、Practice SFT、Strategic RL）增强模型的Reason Chunking能力。

Result: 所提出的ViRC-7B模型在多个数学基准上平均比基线模型提升18.8%。

Conclusion: 通过模拟人类分步推理与动态视觉交互的认知机制，ViRC框架有效提升了多模态大语言模型在复杂数学任务中的结构化推理能力。

Abstract: CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [82] [Fast computation of the first discrete homology group](https://arxiv.org/abs/2512.13929)
*Jacob Ender,Chris Kapulkin*

Main category: cs.CG

TL;DR: 提出了一种计算图的一阶离散同调群的新算法，在随机图数据集上表现优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现有算法在计算图的一阶离散同调群时效率较低，亟需更高效的解决方案。

Method: 设计并实现了一种新算法用于计算图的一阶离散同调群。

Result: 在多个随机图数据集上的实验表明，该算法显著优于其他已知算法。

Conclusion: 所提出的新算法在计算图的一阶离散同调群方面具有明显性能优势，具备实际应用潜力。

Abstract: We present a new algorithm for computing the first discrete homology group of a graph. By testing the algorithm on different data sets of random graphs, we find that it significantly outperforms other known algorithms.

</details>


### [83] [Polygon Containment and Translational Min-Hausdorff-Distance between Segment Sets are 3SUM-Hard](https://arxiv.org/abs/2512.14184)
*Gill Barequet,Sariel Har-Peled*

Main category: cs.CG

TL;DR: 该论文证明了若干几何判定问题（如多边形包含性问题和最小化Hausdorff距离的平移问题）属于3SUM-Hard问题，表明它们在计算上可能至少需要Ω(n²)时间。


<details>
  <summary>Details</summary>
Motivation: 研究几何变换下多边形包含性问题以及Hausdorff距离优化问题的计算复杂性，以理解其是否属于广泛认为难以突破二次时间下界的3SUM类问题。

Method: 通过将3SUM问题归约到所研究的几何决策问题（包括仅平移、仅旋转或任意刚体运动下的多边形包含性问题，以及线段集间最小Hausdorff距离的平移问题），证明这些问题为3SUM-Hard。

Result: 证明了三种多边形包含性变体问题和一个Hausdorff距离最小化问题均为3SUM-Hard。

Conclusion: 这些几何问题在当前假设下无法在显著优于O(n²)的时间内求解，揭示了其内在计算难度与3SUM猜想的紧密联系。

Abstract: The 3SUM problem represents a class of problems conjectured to require $Ω(n^2)$ time to solve, where $n$ is the size of the input. Given two polygons $P$ and $Q$ in the plane, we show that some variants of the decision problem, whether there exists a transformation of $P$ that makes it contained in $Q$, are 3SUM-Hard. In the first variant $P$ and $Q$ are any simple polygons and the allowed transformations are translations only; in the second and third variants both polygons are convex and we allow either rotations only or any rigid motion. We also show that finding the translation in the plane that minimizes the Hausdorff distance between two segment sets is 3SUM-Hard.

</details>


### [84] [Solving the Heilbronn Triangle Problem using Global Optimization Methods](https://arxiv.org/abs/2512.14505)
*Amirhossein Monji,Amirali Modir,Burak Kocuk*

Main category: cs.CG

TL;DR: 本文研究了Heilbronn三角形问题，提出了三种可由全局优化求解器直接求解的二次约束规划模型，并通过边界收紧与对称性破缺等增强技术，在秒级时间内复现了n≤8的已知最优解，并首次在一天内为n=9的情形计算出带认证的最优值。


<details>
  <summary>Details</summary>
Motivation: Heilbronn三角形问题的标准maximin建模高度非线性且非凸，难以求解，因此需要更有效的数学规划方法。

Method: 提出两种混合整数二次约束规划（MIQCP）和一种二次约束规划（QCP）模型，并结合边界收紧、对称性破缺及问题结构特有增强策略进行求解。

Result: 模型在秒级内复现n=8及以下的最优解；对n=9，在一天内获得带认证的最优值，显著优于此前31天的计算记录。

Conclusion: 所提优化模型与增强技术能高效求解Heilbronn三角形问题，大幅缩短计算时间并为未证明情形提供数值认证最优解。

Abstract: We study the Heilbronn triangle problem, which involves placing n points in the unit square such that the minimum area of any triangle formed by these points is maximized. A straightforward maximin formulation of this problem is highly non-linear and non-convex due to the existence of bilinear terms and absolute value equations. We propose two mixed-integer quadratically constrained programming (MIQCP) and one QCP formulation, which can be readily solved by any global optimization solver. We develop several formulation enhancements in the form of bound tightening and symmetry breaking inequalities that are prevalent in the global optimization literature in addition to other enhancements that exploit the problem structure. With the help of these enhancements, our models reproduce proven optimal values for instances up to n = 8 points with certified optimality in the order of seconds. In the case of n = 9 points, for which no analytical proof is known, we establish a certified optimal value by a computational effort of one day. This is a significant improvement over the previous benchmark established in 31 days of computations by Chen et al. (2017).

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [85] [Multi-Agent Collaborative Framework for Intelligent IT Operations: An AOI System with Context-Aware Compression and Dynamic Task Scheduling](https://arxiv.org/abs/2512.13956)
*Zishan Bai,Enze Ge,Junfeng Hao*

Main category: cs.MA

TL;DR: 本文提出AOI（AI-Oriented Operations）框架，通过多智能体协作与基于大语言模型的上下文压缩机制，有效缓解云原生环境中因信息过载导致的运维瓶颈，在保留关键信息的同时显著提升任务成功率并缩短故障修复时间。


<details>
  <summary>Details</summary>
Motivation: 云原生架构的复杂性和动态性导致运维数据爆炸式增长，传统系统难以高效处理信息、协调任务并保持上下文连续性，亟需一种新型智能运维范式。

Method: 提出AOI多智能体协同框架，包含三个专用智能体和一个基于LLM的上下文压缩器；采用动态任务调度策略和三层记忆架构（工作层、情景层、语义层）以优化上下文管理。

Result: 在合成与真实基准测试中，AOI实现72.4%的上下文压缩率，保留92.8%的关键信息，任务成功率达94.2%，相比最优基线将平均修复时间（MTTR）缩短34.4%。

Conclusion: AOI为下一代IT基础设施提供了一种可扩展、自适应且上下文感知的自主运维新范式，显著减少人工干预需求。

Abstract: The proliferation of cloud-native architectures, characterized by microservices and dynamic orchestration, has rendered modern IT infrastructures exceedingly complex and volatile. This complexity generates overwhelming volumes of operational data, leading to critical bottlenecks in conventional systems: inefficient information processing, poor task coordination, and loss of contextual continuity during fault diagnosis and remediation. To address these challenges, we propose AOI (AI-Oriented Operations), a novel multi-agent collaborative framework that integrates three specialized agents with an LLM-based Context Compressor. Its core innovations include: (1) a dynamic task scheduling strategy that adaptively prioritizes operations based on real-time system states, and (2) a three-layer memory architecture comprising Working, Episodic, and Semantic layers that optimizes context retention and retrieval. Extensive experiments on both synthetic and real-world benchmarks demonstrate that AOI effectively mitigates information overload, achieving a 72.4% context compression ratio while preserving 92.8% of critical information and significantly enhances operational efficiency, attaining a 94.2% task success rate and reducing the Mean Time to Repair (MTTR) by 34.4% compared to the best baseline. This work presents a paradigm shift towards scalable, adaptive, and context-aware autonomous operations, enabling robust management of next-generation IT infrastructures with minimal human intervention.

</details>


### [86] [Multi-Agent Medical Decision Consensus Matrix System: An Intelligent Collaborative Framework for Oncology MDT Consultations](https://arxiv.org/abs/2512.14321)
*Xudong Han,Xianglun Gao,Xiaoyi Qu,Zhenyu Yu*

Main category: cs.MA

TL;DR: 本文提出了一种多智能体医疗决策共识矩阵系统，通过七类专科大语言模型智能体模拟多学科团队（MDT）会诊，并结合Kendall一致性系数与强化学习方法，实现可量化、可追溯的高质量临床决策。


<details>
  <summary>Details</summary>
Motivation: 当前癌症诊疗中的MDT会诊缺乏对共识程度的量化机制和决策过程的可追溯性，亟需一种结构化、可解释且高效的智能辅助决策框架。

Method: 构建包含七类专科角色（如肿瘤科医生、放射科医生、护士等）的多智能体系统，引入基于Kendall's W的一致性矩阵评估共识水平，并融合Q-Learning、PPO和DQN等强化学习算法优化推荐质量与共识效率；所有输出强制引用临床指南和文献，遵循GRADE原则确保可追溯性。

Result: 在五个医学基准测试中平均准确率达87.5%（优于最强基线83.8%），共识达成率为89.3%，平均Kendall's W为0.823，专家对临床适用性评分为8.9/10。

Conclusion: 该系统通过结构化共识度量、角色专业化多智能体协作和基于证据的可解释性，显著提升了临床决策的质量与效率，为医疗AI提供了新范式。

Abstract: Multidisciplinary team (MDT) consultations are the gold standard for cancer care decision-making, yet current practice lacks structured mechanisms for quantifying consensus and ensuring decision traceability. We introduce a Multi-Agent Medical Decision Consensus Matrix System that deploys seven specialized large language model agents, including an oncologist, a radiologist, a nurse, a psychologist, a patient advocate, a nutritionist and a rehabilitation therapist, to simulate realistic MDT workflows. The framework incorporates a mathematically grounded consensus matrix that uses Kendall's coefficient of concordance to objectively assess agreement. To further enhance treatment recommendation quality and consensus efficiency, the system integrates reinforcement learning methods, including Q-Learning, PPO and DQN. Evaluation across five medical benchmarks (MedQA, PubMedQA, DDXPlus, MedBullets and SymCat) shows substantial gains over existing approaches, achieving an average accuracy of 87.5% compared with 83.8% for the strongest baseline, a consensus achievement rate of 89.3% and a mean Kendall's W of 0.823. Expert reviewers rated the clinical appropriateness of system outputs at 8.9/10. The system guarantees full evidence traceability through mandatory citations of clinical guidelines and peer-reviewed literature, following GRADE principles. This work advances medical AI by providing structured consensus measurement, role-specialized multi-agent collaboration and evidence-based explainability to improve the quality and efficiency of clinical decision-making.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [87] [LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms](https://arxiv.org/abs/2512.13713)
*Ali Parsaee,Yashar Talebirad,Csongor Szepesvári,Vishwajeet Ohal,Eden Redman*

Main category: cs.AI

TL;DR: 本文提出了LoopBench基准，用于评估大语言模型（LLM）在分布式系统中对称性破缺和元认知推理的能力，通过着色奇数环图任务发现高级推理模型能有效避免死锁。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型作为自主智能体在分布式系统中的协调能力尚不清楚，缺乏专门的评估基准来研究其在无通信条件下的协同与推理表现。

Method: 构建LoopBench基准，聚焦于使用有限颜色对奇数环图（如C₃、C₅、C₁₁）进行着色的任务，引入策略传递机制作为一致记忆，并测试不同LLM在此任务中的表现。

Result: 标准LLM和经典启发式方法在任务中表现不佳，而高级推理模型（如O3）能够设计出有效策略以跳出无限循环并完成任务。

Conclusion: LoopBench为研究基于语言推理的分布式算法和集体智能提供了一个有效测试平台，揭示了先进LLM在分布式协调中的潜力。

Abstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.

</details>


### [88] [Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records](https://arxiv.org/abs/2512.13700)
*Mitchell A. Klusty,Elizabeth C. Solie,Caroline N. Leach,W. Vaiden Logan,Lynnet E. Richey,John C. Gensel,David P. Szczykutowicz,Bryan C. McLellan,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 本文提出了一种基于本地部署大语言模型（LLM）的安全、模块化框架，用于从临床笔记中自动提取结构化特征，显著减少人工图表审查的负担并提高数据一致性。


<details>
  <summary>Details</summary>
Motivation: 人工图表审查在临床研究中耗时且资源密集，需专家从非结构化的电子健康记录（EHR）中提取复杂信息，亟需自动化解决方案以提升效率和一致性。

Method: 该框架在符合HIPAA规范的机构计算基础设施上本地部署大语言模型，结合检索增强生成（RAG）与结构化响应方法，并封装为可广泛部署和扩展的容器化系统。

Result: 在评估中，该框架在多个医学特征提取任务上表现出高准确性，与专家标注数据集相比不仅性能优异，还发现了人工审查中遗漏的若干标注错误。

Conclusion: 该框架展示了大语言模型在自动化临床数据提取中的潜力，能有效减轻人工图表审查负担、提升数据捕获一致性，从而加速临床研究进程。

Abstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.

</details>


### [89] [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)
*Mayank Singh,Vikas Yadav,Shiva Krishna Reddy Malay,Shravan Nayak,Sai Rajeswar,Sathwik Tejaswi Madhusudhan,Eduardo Blanco*

Main category: cs.AI

TL;DR: 本文提出了一种结构化的多智能体系统自动搜索框架，通过一组简单且可组合的组件进行探索，在多数基准测试中优于基于大语言模型的自由形式搜索方法，并具备成本更低、逻辑更简洁和系统更可解释等优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的多智能体系统自动搜索方法依赖于代码空间中的自由形式生成，缺乏结构化，导致成本高、可解释性差。因此，作者希望设计一种更结构化、高效且可解释的替代方案。

Method: 提出一个结构化搜索框架，利用一组固定的、简单且可组合的组件在相同的代码空间中探索多智能体系统，而非依赖LLM在候选生成阶段的生成灵活性。

Result: 在数学和问答两个领域的五个基准测试中，该方法在其中四个上优于先前基于LLM的方法；同时实现了更低的搜索成本和更高的系统模块化与可解释性。

Conclusion: 结构化的组件化搜索策略在多智能体系统自动生成任务中不仅性能优越，而且更具成本效益和可解释性，为未来智能体AI研究提供了新方向。

Abstract: Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.

</details>


### [90] [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)
*Zheng Xing,Junting Chen*

Main category: cs.AI

TL;DR: 本文提出了一种无需位置标签的盲无线电地图构建框架，利用MIMO-OFDM信道测量数据推断用户轨迹，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统无线电地图构建方法依赖大量带位置标签的数据，成本高且在许多实际场景中难以实现，因此需要一种无需位置标签的替代方案。

Method: 基于非直视（NLOS）环境下信道状态信息（CSI）的空间连续性，构建与物理距离成比例的CSI距离度量；针对泊松分布接入点部署下的直线轨迹，证明定位误差的克拉美-罗下界（CRLB）可渐近趋于零；在此基础上，开发了一个空间正则化的贝叶斯推断框架，联合估计信道特征、区分LOS/NLOS条件并恢复用户轨迹。

Result: 在射线追踪数据集上的实验表明，该方法平均定位误差为0.68米，波束图重建误差为3.3%。

Conclusion: 所提出的盲无线电地图构建方法在无需位置标签的情况下，能够有效恢复用户轨迹并准确重建无线电地图，具有良好的实用性和性能。

Abstract: Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio map construction framework that infers user trajectories from indoor multiple-input multiple-output (MIMO)-Orthogonal Frequency-Division Multiplexing (OFDM) channel measurements without relying on location labels. It first proves that channel state information (CSI) under non-line-of-sight (NLOS) exhibits spatial continuity under a quasi-specular environmental model, allowing the derivation of a CSI-distance metric that is proportional to the corresponding physical distance. For rectilinear trajectories in Poisson-distributed access point (AP) deployments, it is shown that the Cramer-Rao Lower Bound (CRLB) of localization error vanishes asymptotically, even under poor angular resolution. Building on these theoretical results, a spatially regularized Bayesian inference framework is developed that jointly estimates channel features, distinguishes line-of-sight (LOS)/NLOS conditions and recovers user trajectories. Experiments on a ray-tracing dataset demonstrate an average localization error of 0.68 m and a beam map reconstruction error of 3.3%, validating the effectiveness of the proposed blind mapping method.

</details>


### [91] [Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents](https://arxiv.org/abs/2512.13704)
*Doohee You,Sundeep Paul*

Main category: cs.AI

TL;DR: Adjudicator 是一个结合知识图谱与多智能体大语言模型的系统，用于自动识别和修正训练数据中的标签噪声，在 AlleNoise 基准测试中 F1 分数达 0.99，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 高风险工业场景中，标签噪声会严重损害机器学习系统的性能与可信度，亟需一种可部署、高精度且可解释的自动化数据清洗方案。

Method: 构建动态知识图谱（KG）以整合样本上下文信息，并以此驱动“智能体委员会”——一种新型多智能体大语言模型架构，通过专用智能体对标签有效性进行辩论与投票；同时引入基于 KG 的覆盖逻辑以精准识别结构性错误。

Result: 在 AlleNoise 基准的 1,000 项平衡子集上，Adjudicator 达到 0.99 的 F1 分数，远超单一大语言模型（0.48）和无 KG 的多智能体系统（0.59），并实现对复杂结构性错误的完全召回。

Conclusion: Adjudicator 展示了一种鲁棒、可解释且高精度的自动化数据验证系统，为在严格监管的工业环境中生成黄金数据集提供了有效可行的方案。

Abstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a "Council of Agents," a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.

</details>


### [92] [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)
*Gangesh Pathak,Prasanna Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种基于人工智能的标注流程，通过人机协同的方式识别并修复大语言模型（LLM）输出中的不稳定性问题，以提升其在高度监管行业中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在高度监管行业中因不稳定、推理不一致、幻觉和性能波动等问题难以安全应用，而现有稳定化方法（如RLHF和监督微调）依赖大量人工标注，成本高且难以持续扩展。

Method: 采用人机协同的AI标注管道，结合自动化弱监督模型与基于置信度的标注，并辅以目标人工验证；引入语义一致性、事实正确性和逻辑连贯性三类稳定性专用标注，通过反馈循环持续校准模型。

Result: 该方法能有效识别和修正LLM输出中的不稳定性模式，在保障反馈信息可靠性与道德合规的同时，提升模型的鲁棒性。

Conclusion: 所提出的AI驱动标注框架为解决LLM在关键领域中的可靠性问题提供了可扩展、可持续的新路径，有望推动其在高要求场景中的安全部署。

Abstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).

</details>


### [93] [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)
*Yitong Luo,Ziang Chen,Hou Hei Lam,Jiayu zhan,Junqi Wang,Zhenliang Zhang,Xue Feng*

Main category: cs.AI

TL;DR: 该论文提出了一种以人类价值观驱动的个性化决策方法，通过ValuePilot框架（包含数据集生成工具包DGT和决策模块DMM）实现AI在新场景中依据个体价值偏好做出更符合人类选择的决策，并在实验中优于多个主流大语言模型。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在现实世界中的广泛应用，仅依赖任务完成或群体对齐已不足以满足个性化需求。现有方法缺乏对个体稳定、可迁移价值偏好的建模，导致AI在新情境下难以做出恰当且可解释的决策。

Method: 作者提出了ValuePilot框架，包含两个阶段：1）利用人与大语言模型协作构建多样化、带有价值标注的情境数据集（DGT）；2）训练决策模块（DMM）根据个体价值偏好评估行动，在不同情境下生成个性化决策。

Result: 在未见过的情境中，DMM在与人类行动选择的一致性上优于GPT-5、Claude-Sonnet-4、Gemini-2-flash和Llama-3.1-70b等强基线模型，验证了价值驱动方法的有效性和泛化能力。

Conclusion: 以人类价值观为驱动的个性化决策是一种可行且可扩展的技术路径，有助于构建更具解释性和适应性的个性化AI智能体。

Abstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals that support consistent and generalizable behavior across contexts. Compared to task-oriented paradigms driven by external rewards and incentives, value-driven decision-making enhances interpretability and enables agents to act appropriately even in novel scenarios. We introduce ValuePilot, a two-phase framework consisting of a dataset generation toolkit (DGT) and a decision-making module (DMM). DGT constructs diverse, value-annotated scenarios from a human-LLM collaborative pipeline. DMM learns to evaluate actions based on personal value preferences, enabling context-sensitive, individualized decisions. When evaluated on previously unseen scenarios, DMM outperforms strong LLM baselines, including GPT-5, Claude-Sonnet-4, Gemini-2-flash, and Llama-3.1-70b, in aligning with human action choices. Our results demonstrate that value-driven decision-making is an effective and extensible engineering pathway toward building interpretable, personalized AI agents.

</details>


### [94] [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)
*Steve Nwaiwu,Nipat Jongsawat,Anucha Tungkasthan*

Main category: cs.AI

TL;DR: 本文首次系统评估了量化（如INT8和NF4）对大语言模型在Pearl因果阶梯三个层级（关联、干预、反事实）上因果推理能力的影响，发现四比特量化下因果推理整体稳健，其中干预推理最敏感，而现有反事实基准难以揭示量化带来的深层脆弱性；引入因果图增强可部分缓解干预推理的性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向边缘和资源受限环境部署，低精度量化模型（如INT8、NF4）日益普及，但量化对正式因果推理能力的影响尚不清楚，尤其在Pearl因果阶梯的三个层级上缺乏系统研究。

Method: 作者构建了一个包含3000个样本的分层CLadder基准，并在Llama 3 8B模型上评估不同量化方案（INT8、NF4）在因果阶梯各层级的表现；同时在CRASS常识反事实基准上测试，并引入基于真实因果图的图检索增强生成（Graph RAG）方法以提升干预推理准确性。

Result: 量化对Llama 3 8B的整体因果推理准确率影响微小（NF4总体下降不到1%）；干预查询（第二级）对精度损失最敏感，反事实推理（第三级）相对稳定但存在特定类型（如对撞偏误、后门调整）的异质性弱点；CRASS基准未能揭示量化引起的推理漂移；图增强使NF4在干预任务上准确率提升1.7%。

Conclusion: 因果推理在四比特量化下表现出意外的鲁棒性，图结构增强可选择性强化干预推理，而当前反事实基准缺乏揭示深层因果脆弱性的能力；该研究为部署高效且结构支持的因果AI系统提供了实证基础与实践指导。

Abstract: Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.

</details>


### [95] [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)
*TK Lee*

Main category: cs.AI

TL;DR: 该论文提出了一种定性案例研究方法，用于审计大语言模型在长对话中因政策敏感性而表现出的选择性行为，并引入“习得性无能”（Learned Incapacity, LI）作为描述此类行为的新概念。


<details>
  <summary>Details</summary>
Motivation: 标准量化基准难以捕捉大语言模型在长期交互中的行为模式，尤其在涉及政策或提供商敏感领域时可能出现选择性拒绝。作者旨在通过定性方法揭示这种行为不对称性，并探讨其潜在影响。

Method: 通过单次86轮对话的案例研究，识别并分类模型在不同领域的响应模式：正常表现（NP）、功能性拒绝（FR）和元叙事（MN），并分析这些模式之间的关联，特别是MN与FR在敏感语境中的共现。

Result: 研究发现模型在非敏感领域表现正常，但在政策敏感领域反复出现功能性拒绝，且元叙事常伴随拒绝出现；提出“习得性无能”作为描述该现象的行为术语。

Conclusion: 该研究提供了一个基于可观测行为的交互级审计框架，并建议将“习得性无能”作为理解对齐副作用的新视角，值得在更多用户和模型中进一步验证。

Abstract: Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.

</details>


### [96] [Mathematics and Coding are Universal AI Benchmarks](https://arxiv.org/abs/2512.13764)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 该论文研究数学与编程在AI智能体心理测量测试空间中的特殊作用，提出“数学纤维”概念，并证明由数学定理证明和编程任务生成的测试子空间在评估度量下是稠密的。编程具有表达上的普适性，而数学则在谱性质上具有优势，二者共同构成评估的“通用坐标”，并为高级AI智能体的递归自我改进提供自然起点。


<details>
  <summary>Details</summary>
Motivation: 探索数学与编程在AI智能体能力评估中的基础性角色，理解其是否以及如何构成通用且有效的评估基准，并揭示其在AI自我改进机制中的潜在作用。

Method: 基于AAI框架与GVU动力学，定义“数学纤维”，结合形式化证明内核（如Lean、Coq），分析GVU流在此纤维上的谱稳定性；并通过一致紧性和Lipschitz AAI泛函条件，证明相关测试子空间的稠密性。

Result: 证明了由数学定理证明和编程任务生成的测试子空间在心理测量电池模空间中是稠密的；编程本身具有表达普适性，而纯数学不具备，但数学在谱稳定性方面具有独特优势。

Conclusion: 数学与编程共同提供了AI评估的“通用坐标”，其中形式化数学是高级AI智能体实现递归自我改进的自然起点。

Abstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.

</details>


### [97] [Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems](https://arxiv.org/abs/2512.13771)
*Javier Marín*

Main category: cs.AI

TL;DR: 本文提出语义锚定指数（SGI），通过衡量生成回答在嵌入空间中相对于问题和检索上下文的角距离比值，有效识别RAG系统中的幻觉现象。研究发现幻觉回答倾向于靠近问题而非上下文（“语义惰性”），SGI在高问题-上下文角分离度、长回答和短问题场景下表现尤佳，并可作为概率估计指标，但仅反映主题相关性而非事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在产生幻觉时缺乏有效的几何判据，作者旨在探索幻觉在嵌入空间中的几何特征，并构建一个理论扎实、计算高效的指标以识别需验证的回答。

Method: 提出语义锚定指数（SGI），定义为单位超球面上回答到问题与到上下文的角距离之比；基于球面三角不等式推导SGI判别能力与问题-上下文角分离度的关系，并在HaluEval和TruthfulQA数据集上进行实验验证，涵盖多种嵌入模型及子群分析。

Result: 在HaluEval上，SGI展现出大效应量（Cohen's d=0.92–1.28），跨模型相关性高（r=0.85）；效应量随问题-上下文角分离度增加而单调上升（d从0.61增至1.27，AUC从0.72升至0.83）；在长回答（d=2.05）和短问题（d=1.22）上表现突出，ECE=0.10表明其可作概率估计；但在TruthfulQA上AUC=0.478，说明SGI衡量的是主题参与度而非事实准确性。

Conclusion: SGI是一种理论支撑充分、计算高效的指标，能有效识别RAG系统中需要人工验证的幻觉回答，适用于实际部署，但其反映的是语义贴近性而非事实真值。

Abstract: When retrieval-augmented generation (RAG) systems hallucinate, what geometric trace does this leave in embedding space? We introduce the Semantic Grounding Index (SGI), defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere $\mathbb{S}^{d-1}$.Our central finding is \emph{semantic laziness}: hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. On HaluEval ($n$=5,000), we observe large effect sizes (Cohen's $d$ ranging from 0.92 to 1.28) across five embedding models with mean cross-model correlation $r$=0.85. Crucially, we derive from the spherical triangle inequality that SGI's discriminative power should increase with question-context angular separation $θ(q,c)$-a theoretical prediction confirmed empirically: effect size rises monotonically from $d$=0.61 -low $θ(q,c)$, to $d$=1.27 -high $θ(q,c)$, with AUC improving from 0.72 to 0.83. Subgroup analysis reveals that SGI excels on long responses ($d$=2.05) and short questions ($d$=1.22), while remaining robust across context lengths. Calibration analysis yields ECE=0.10, indicating SGI scores can serve as probability estimates, not merely rankings. A critical negative result on TruthfulQA (AUC=0.478) establishes that angular geometry measures topical engagement rather than factual accuracy. SGI provides computationally efficient, theoretically grounded infrastructure for identifying responses that warrant verification in production RAG deployments.

</details>


### [98] [MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2512.13955)
*Sindhuja Madabushi,Dawood Wasif,Jin-Hee Cho*

Main category: cs.AI

TL;DR: 本文提出MURIM，一种多维声誉激励机制，通过综合考虑客户端的可靠性、隐私保护、资源能力和公平性，在联邦学习中实现更公平的激励分配并提升系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临客户端激励不足、隐私泄露风险和资源受限等挑战，亟需一种能有效评估客户端可靠性并据此公平分配激励的机制，以防止恶意或不可靠客户端获取不当奖励，同时保障全局模型性能。

Method: 提出MURIM机制，结合客户端贡献度、延迟和声誉进行激励分配，并引入可靠性验证模块，综合考量客户端的可靠性、隐私、资源容量与公平性。

Result: 在MNIST、FMNIST和ADULT Income数据集上的实验表明，MURIM相比现有方法在公平性指标上提升最多18%，隐私攻击成功率降低5-9%，对投毒和噪声梯度攻击的鲁棒性提升高达85%。

Conclusion: MURIM能有效缓解联邦学习中的对抗威胁，促进公平可信的参与行为，并在异构和动态环境下保持模型稳定收敛。

Abstract: Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.

</details>


### [99] [Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms](https://arxiv.org/abs/2512.13978)
*Yang Cao,Yubin Chen,Xuyang Guo,Zhao Song,Song Yue,Jiahao Zhang,Jiale Zhao*

Main category: cs.AI

TL;DR: 本文对四个前沿大语言模型（GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking 和 Grok-4）在《随机算法》经典教材上的数学证明生成能力进行了系统评估，发现顶尖模型准确率约66%，但其他模型表现明显落后，表明当前模型虽具备研究生水平的辅助能力，但在严谨数学推导上仍存在可靠性差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学推理和科学发现中展现出潜力，但仍缺乏对其在标准研究生级数学理论任务上的严格评估。因此，有必要通过经典教材构建基准，以衡量其基础推理能力。

Method: 作者要求四个前沿大语言模型针对 Motwani 与 Raghavan 的《随机算法》教材中的引理和习题生成正式的 LaTeX 证明，并从准确性、简洁性、幻觉率和逻辑结构等方面进行定量与定性分析。

Result: 顶尖模型（Gemini 和 Claude）在证明任务中达到约66%的准确率，显示出对概率方法和形式逻辑的良好掌握；而其他模型准确率仅约40%，一致性较差。定性分析揭示了各模型在证明质量上的显著差异。

Conclusion: 当前前沿大语言模型已具备支持研究生数学教学和形式化任务的能力，但在严谨数学推导方面的可靠性仍有较大差异，需谨慎使用。

Abstract: The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${ó}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].
  We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.

</details>


### [100] [ReflCtrl: Controlling LLM Reflection via Representation Engineering](https://arxiv.org/abs/2512.13979)
*Ge Yan,Chung-En Sun,Tsui-Wei,Weng*

Main category: cs.AI

TL;DR: 本文提出ReflCtrl框架，通过表示工程识别大语言模型推理中的反思步骤，并在潜在空间中提取控制反思行为的方向，从而实现对反思频率的调控，在保持性能的同时最多可节省33.6%的推理token。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）结合思维链（CoT）推理虽表现优异，但其自我反思机制会增加推理成本。作者旨在研究如何有效控制反思行为以降低开销。

Method: 通过表示工程将模型推理过程分步，识别出对应反思的步骤，并在潜在空间中提取一个控制反思行为的方向，据此提出一种逐步调控反思频率的方法（ReflCtrl）。

Result: 实验表明：(1) 在许多情况下反思是冗余的，尤其在更强的模型中，最多可节省33.6%的推理token而不影响性能；(2) 模型的反思行为与其内部不确定性信号高度相关。

Conclusion: 大语言模型的自我反思行为可通过潜在空间中的特定方向进行调控，且该行为与模型内部不确定性密切相关，为高效推理提供了新思路。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) reasoning have achieved strong performance across diverse tasks, including mathematics, coding, and general reasoning. A distinctive ability of these reasoning models is self-reflection: the ability to review and revise previous reasoning steps. While self-reflection enhances reasoning performance, it also increases inference cost. In this work, we study self-reflection through the lens of representation engineering. We segment the model's reasoning into steps, identify the steps corresponding to reflection, and extract a reflection direction in the latent space that governs this behavior. Using this direction, we propose a stepwise steering method that can control reflection frequency. We call our framework ReflCtrl. Our experiments show that (1) in many cases reflections are redundant, especially in stronger models (in our experiments, we can save up to 33.6 percent of reasoning tokens while preserving performance), and (2) the model's reflection behavior is highly correlated with an internal uncertainty signal, implying self-reflection may be controlled by the model's uncertainty.

</details>


### [101] [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)
*Can Jin,Hongwu Peng,Mingcan Xiang,Qixin Zhang,Xiangchi Yuan,Amit Hasan,Ohiremen Dibua,Yifan Gong,Yan Kang,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: 本文提出 DTop-p MoE，一种可控制稀疏度的动态 Top-p 路由机制，通过 PI 控制器动态调整概率阈值，并引入动态路由归一化，使各层能学习不同的专家选择模式，在保持计算可控的同时优于 Top-k 与固定阈值 Top-p 方法。


<details>
  <summary>Details</summary>
Motivation: 标准 Top-k 路由对所有 token 强加统一稀疏模式，忽略 token 难度差异；而现有 Top-p 路由使用固定全局概率阈值，导致计算成本不可控且对超参敏感。

Method: 提出 DTop-p MoE：1）利用比例-积分（PI）控制器动态调节概率阈值，使激活专家稀疏度逼近目标值；2）设计动态路由归一化机制，对各层路由 logits 进行自适应调整，支持在全局阈值下实现层间差异化专家选择。

Result: 在大语言模型和扩散 Transformer 上的实验表明，DTop-p 在性能上一致优于 Top-k 和固定阈值 Top-p 基线，能精确控制激活专家数量，并在 token 和层之间自适应分配计算资源；同时在专家粒度、容量、模型规模和数据规模上展现出良好扩展性。

Conclusion: DTop-p MoE 提供了一种鲁棒、可扩展且计算可控的稀疏 MoE 路由方案，适用于大规模 MoE 预训练。

Abstract: Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.

</details>


### [102] [MobileWorldBench: Towards Semantic World Modeling For Mobile Agents](https://arxiv.org/abs/2512.14014)
*Shufan Li,Konstantinos Kallidromitis,Akash Gokul,Yusuke Kato,Kazuki Kozuka,Aditya Grover*

Main category: cs.AI

TL;DR: 本文提出了一种基于自然语言描述状态转移的语义世界模型方法，用于移动GUI智能体，并发布了MobileWorldBench基准和包含140万样本的MobileWorld数据集，实验证明该方法能有效提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于像素空间的世界模型在GUI环境中难以准确预测未来状态中的复杂视觉元素，限制了其在移动GUI智能体中的应用。

Method: 构建MobileWorldBench评估基准和MobileWorld大规模数据集，训练视觉语言模型（VLM）作为语义世界模型，并将其集成到移动智能体的规划框架中。

Result: 所提出的方法显著提升了VLM作为世界模型的能力，并在实际任务中提高了移动GUI智能体的任务成功率。

Conclusion: 使用自然语言描述状态转移的语义世界模型是一种有效替代传统像素级预测的方法，能够切实提升移动GUI智能体的性能。

Abstract: World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld

</details>


### [103] [Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation](https://arxiv.org/abs/2512.14048)
*Shen Li,Li Huang,Shaoxiong Zhan,Weifeng Sun,Tao Yin,Zhongxin Liu,Meng Yan*

Main category: cs.AI

TL;DR: 本文提出RoutingGen，一种难度感知的动态提示框架，通过在简单任务上使用少样本提示、复杂任务上使用新设计的意图链式思维（ICoT）策略，提升代码生成性能并降低46.37%的平均token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示方法在代码生成中存在两个问题：一是对简单任务过度推理，二是缺乏对算法意图（如核心逻辑与效率）的抽象建模，导致模型关注表层结构而忽略全局目标。

Method: 提出RoutingGen框架，根据任务难度动态选择提示策略：简单任务采用少样本提示，复杂任务采用新提出的Intention Chain-of-Thought（ICoT），显式引导模型捕捉任务意图（如算法逻辑和时间复杂度）。

Result: 在三个模型和六个标准代码生成基准上，RoutingGen在多数设置中达到SOTA性能，平均减少46.37%的token使用；ICoT在困难任务上优于六种现有提示方法。

Conclusion: RoutingGen通过难度感知的动态路由机制有效平衡了推理深度与效率，在提升代码生成质量的同时显著降低计算开销，验证了结构化推理应按需启用的认知经济原则。

Abstract: Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.

</details>


### [104] [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)
*Mengzhang Cai,Xin Gao,Yu Li,Honglin Lin,Zheng Liu,Zhuoshi Pan,Qizhi Pei,Xiaoran Shang,Mengyuan Sun,Zinan Tang,Xiaoyang Wang,Zhanping Zhong,Yun Zhu,Dahua Lin,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 本文提出了OpenDataArena（ODA），一个用于系统评估大语言模型后训练数据内在价值的开放平台，包含统一训练-评估流程、多维数据评分框架、交互式数据谱系探索器和开源工具包，旨在推动数据为中心的人工智能研究。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽经过严格评测，但其训练数据组成不透明、来源不明且缺乏系统性评估，阻碍了可复现性并模糊了数据特性与模型行为之间的因果关系。

Method: 构建OpenDataArena平台，整合四大核心组件：(i) 统一的训练-评估流水线；(ii) 多维度数据质量评分框架；(iii) 交互式数据谱系可视化工具；(iv) 开源训练、评估与评分工具包，并在120多个数据集、22个基准和600多次训练实验中进行验证。

Result: 实验揭示了数据复杂性与任务性能之间的权衡关系，通过谱系追踪识别出流行基准中的冗余，并绘制了不同数据集间的谱系关联。

Conclusion: ODA通过开放所有结果、工具和配置，推动从试错式数据筛选向数据为中心的AI科学转变，为研究数据混合规律和基础模型的数据构成策略奠定基础。

Abstract: The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.

</details>


### [105] [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)
*Junjie Ma,Jinlong Li*

Main category: cs.AI

TL;DR: RADAR is a novel speculative sampling method that uses reinforcement learning to dynamically generate draft trees, improving inference speed of large language models by 3.17x–4.82x.


<details>
  <summary>Details</summary>
Motivation: Speculative sampling improves LLM inference efficiency, but its fixed number of draft model calls is inflexible and can lead to redundant computation.

Method: RADAR formulates draft tree generation as a Markov Decision Process and uses offline reinforcement learning to train a model that dynamically decides when to call the draft model.

Result: Experiments on three LLMs and four tasks show RADAR achieves 3.17x–4.82x speedup over standard auto-regressive decoding.

Conclusion: RADAR effectively accelerates LLM inference by dynamically optimizing draft token generation through reinforcement learning, outperforming existing speculative sampling approaches.

Abstract: Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.

</details>


### [106] [Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis](https://arxiv.org/abs/2512.14157)
*Yankai Jiang,Yujie Zhang,Peng Zhang,Yichen Li,Jintai Chen,Xiaoming Shi,Shihui Zhen*

Main category: cs.AI

TL;DR: 本文提出Ophiuchus，一种工具增强的多模态大语言模型框架，通过三阶段训练策略提升医学图像细粒度区域的动态聚焦与推理能力，在多个医学基准任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于推理的医学多模态大语言模型（MLLMs）虽能生成逐步文本推理链，但在需要动态、迭代关注图像细粒度区域以实现精准定位和诊断的复杂任务中仍表现不足。

Method: Ophiuchus框架使MLLM能够判断何时需要额外视觉证据、确定在医学图像中何处探查与定位，并将相关子图像内容无缝融入多模态思维链。其核心为三阶段训练策略：冷启动训练（集成工具的推理数据）、自省微调（强化反思并复核工具输出）以及基于智能体的工具强化学习（优化任务奖励，模拟专家诊断行为）。

Result: 在包括VQA、检测和基于推理的分割在内的多种医学基准测试中，Ophiuchus持续优于当前最先进的开源和闭源方法。

Conclusion: Ophiuchus为构建能通过工具集成推理“用图像思考”的医学AI智能体提供了可行路径，相关数据集、代码和模型将公开发布。

Abstract: Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely "think with images" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.

</details>


### [107] [Georeferencing complex relative locality descriptions with large language models](https://arxiv.org/abs/2512.14228)
*Aneesha Fernando,Surangika Ranathunga,Kristin Stock,Raj Prasanna,Christopher B. Jones*

Main category: cs.AI

TL;DR: 本文探讨了利用大语言模型（LLM）自动对生物多样性标本记录中复杂的相对位置描述进行地理编码的方法，通过有效的提示设计和QLoRA微调，在多个数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统地理解析方法依赖地名辞典或地理指示词，难以准确处理包含相对空间关系的复杂位置描述，尤其在缺乏GPS坐标的生物标本记录中。为支持生物多样性研究，亟需高效、自动化的高精度地理编码方案。

Method: 作者首先识别有效的提示模式，然后使用量化低秩适配（QLoRA）技术在多地区、多语言的生物多样性数据集上对大语言模型进行微调，以实现对复杂位置描述的自动地理编码。

Result: 该方法在固定训练数据量下，平均65%的记录地理编码误差在10公里以内；在纽约州数据集上表现最佳，85%的记录在10公里内，67%在1公里内。模型对长而复杂的描述表现出色。

Conclusion: 大语言模型在处理复杂、叙述性位置描述方面具有显著潜力，可有效提升生物多样性领域地理编码的自动化水平与准确性。

Abstract: Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.

</details>


### [108] [Gödel's Poetry](https://arxiv.org/abs/2512.14252)
*Kelly J. Davis*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体架构与递归分解策略的新型Lean4形式化定理证明方法，显著提升了在miniF2F基准上的通过率，并开源了相关工具。


<details>
  <summary>Details</summary>
Motivation: 形式化自动定理证明是人工智能领域长期存在的挑战，现有方法在处理复杂定理时仍存在局限性。

Method: 采用专门针对Lean4训练的语言模型，结合多智能体架构协调自动形式化、证明生成与递归分解；通过扩展Kimina Lean Server以支持AST解析，实现对困难定理的自动化递归分解。

Result: 在miniF2F数据集上，不使用分解时达到90.4%的通过率，引入递归分解后性能显著提升。

Conclusion: 所提方法有效提升了形式化定理证明的自动化水平和成功率，且系统已开源，便于社区进一步拓展和适配不同语言模型。

Abstract: Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.

</details>


### [109] [Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting](https://arxiv.org/abs/2512.14288)
*Georgios Bouchouras,Dimitrios Doumanas,Andreas Soularidis,Konstantinos Kotis,George A. Vouros*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLM）在帕金森病监测与预警本体构建中的应用，比较了One Shot、Chain of Thought、X-HCOME和SimX-HCOME+四种方法，发现纯LLM生成的本体不够全面，而结合人类专家的混合方法（尤其是SimX-HCOME+）能显著提升本体的完整性与准确性。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能独立构建完整的本体，若不能，则评估人机协作在提升本体工程效果方面的潜力，特别是在帕金森病这一复杂医学领域。

Method: 采用四种方法进行本体构建：One Shot（OS）提示、思维链（CoT）提示、X-HCOME（人机混合方法）以及SimX-HCOME+（强调持续人工监督与迭代优化的混合方法），并通过对比分析其生成本体的完整性与准确性。

Result: LLM可自主生成初步本体，但需大量人工修正；X-HCOME显著提升本体质量，接近专家水平；SimX-HCOME+通过持续人机协作进一步提高了本体的全面性与精确性。

Conclusion: 大语言模型尚不足以独立完成高质量本体构建，但在人类专家协作下，尤其通过持续迭代的人机混合方法，可有效推动复杂领域本体工程的发展，未来可探索专用GPT模型用于本体构建。

Abstract: This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.
  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.
  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.
  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.
  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.

</details>


### [110] [Massive Editing for Large Language Models Based on Dynamic Weight Generation](https://arxiv.org/abs/2512.14395)
*Wentao Wan,Qiqing Lao,Zhiwei Xie,Hefeng Wu,Runnan Lin,Liang Lin,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于动态权重生成的大规模知识编辑方法 MeG，通过在大语言模型特定层附加一个动态权重神经元，并利用扩散模型根据输入查询生成该神经元的权重，从而以较低成本实现大规模、高可靠性、通用性和局部性的知识编辑。


<details>
  <summary>Details</summary>
Motivation: 当前在大语言模型上进行大规模知识编辑时，难以同时保证编辑的可靠性（Reliability）、通用性（Generality）和局部性（Locality），因此需要一种新方法来有效解决这一挑战。

Method: 提出 MeG 方法，在大语言模型的特定层附加一个动态权重神经元，并使用扩散模型根据输入的知识编辑查询条件生成该神经元的权重，从而实现单神经元支持的大规模知识编辑。

Result: 实验表明，MeG 在 Reliability、Generality 和 Locality 三项指标上均显著优于现有方法，尤其在 Locality 指标的绝对值上有明显提升。

Conclusion: MeG 方法能有效实现低成本、高性能的大规模知识编辑，尤其在保持编辑局部性方面具有突出优势，为大语言模型的知识更新提供了一种高效可行的新路径。

Abstract: Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.

</details>


### [111] [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)
*Jia Hu,Junqi Li,Weimeng Lin,Peng Jia,Yuxiong Ji,Jintao Lai*

Main category: cs.AI

TL;DR: 本文提出PortAgent，一种基于大语言模型（LLM）的车辆调度智能体，通过虚拟专家团队（VET）实现自动化、低数据依赖、快速部署的码头车辆调度系统迁移，显著提升其跨码头可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有车辆调度系统（VDS）在自动化集装箱码头（ACT）中难以广泛商业化，主要受限于对港口操作专家的高度依赖、对终端特定数据的高需求以及耗时的手动部署流程，导致其跨码头可迁移性差。

Method: 提出PortAgent，利用大语言模型构建虚拟专家团队（VET），包含知识检索器、建模器、编码器和调试器四个虚拟专家，通过少样本示例学习和检索增强生成（RAG）机制获取领域知识，并建立自动化的VDS设计工作流，引入受LLM Reflexion启发的自纠错循环。

Result: PortAgent实现了无需专家参与、低数据需求和快速部署的VDS迁移流程，有效解决了现有系统在可迁移性方面的三大瓶颈。

Conclusion: 借助大语言模型的能力，PortAgent为自动化集装箱码头提供了一种高效、可迁移的车辆调度解决方案，有望推动VDS的广泛应用与商业化。

Abstract: Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created

</details>


### [112] [Seismology modeling agent: A smart assistant for geophysical researchers](https://arxiv.org/abs/2512.14429)
*Yukun Ren,Siwei Yu,Kai Chen,Jianwei Ma*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的智能交互式工作流，通过引入首个面向SPECFEM地震波模拟软件的Model Context Protocol（MCP）服务器套件，将传统依赖复杂手动操作的工作流转变为意图驱动的对话式交互，显著降低使用门槛并提升可复现性。


<details>
  <summary>Details</summary>
Motivation: 传统SPECFEM地震波模拟软件存在学习曲线陡峭、依赖繁琐的手动文件编辑和命令行操作等问题，限制了其易用性和普及性。为解决这一问题，作者希望借助大语言模型实现更智能、交互性更强的工作流。

Method: 开发了支持SPECFEM 2D、3D Cartesian和3D Globe版本的MCP服务器套件，将整个模拟流程分解为一系列可由智能体执行的工具模块，涵盖参数生成、网格划分、求解器运行到可视化等环节，并支持全自动或人机协同模式。

Result: 通过多个案例验证，该工作流在自主和交互模式下均能无缝运行，获得与标准基线一致的高保真结果，显著减少了低层次操作负担。

Conclusion: 本研究首次将MCP技术应用于计算地震学，有效降低了SPECFEM的使用门槛，增强了科研可复现性，为推动计算地球物理学迈向AI辅助与自动化研究提供了新路径。

Abstract: To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.

</details>


### [113] [Context-Picker: Dynamic context selection using multi-stage reinforcement learning](https://arxiv.org/abs/2512.14465)
*Siyuan Zhu,Chengdong Xu,Kaiqiang Ke,Chao Yu*

Main category: cs.AI

TL;DR: 本文提出Context-Picker，一种面向长上下文问答的推理感知框架，通过两阶段强化学习从检索结果中选择最小充分证据子集，显著提升答案准确性并减少冗余。


<details>
  <summary>Details</summary>
Motivation: 在长上下文问答中，传统方法难以确定最优上下文数量：过少会遗漏关键信息，过多则引入噪声，尤其对只需少量证据的事实型问题影响显著。

Method: Context-Picker将上下文选择视为决策过程，采用两阶段强化学习策略：先以召回为导向覆盖推理链，再以精度为导向剔除冗余；并通过Leave-One-Out离线蒸馏生成“最小充分集”作为密集奖励信号。

Result: 在五个长上下文和多跳问答基准上，Context-Picker优于强RAG基线，在相同或更短上下文长度下取得更高答案准确率；消融实验证明其各组件均有效。

Conclusion: 通过将上下文选择从相似性排序转为最小充分子集选择，并结合推理感知的两阶段优化与奖励设计，Context-Picker有效解决了长上下文问答中的噪声与冗余问题。

Abstract: In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

</details>


### [114] [Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling](https://arxiv.org/abs/2512.14474)
*Annu Rana,Gaurav Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种名为Model-First Reasoning（MFR）的新范式，通过让大语言模型首先显式构建问题模型（包括实体、状态变量、动作和约束），再生成解决方案，在多个规划任务中显著减少了约束违反并提升了方案质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂多步规划任务中常出现高比例的约束违反和不一致解，现有方法如Chain-of-Thought和ReAct缺乏显式的问题表示，导致规划能力受限。

Method: 受经典AI规划启发，提出两阶段的Model-First Reasoning（MFR）方法：第一阶段由LLM构建显式问题模型，第二阶段基于该模型生成解决方案。

Result: 在医疗排班、路径规划、资源分配、逻辑谜题和过程合成等多个领域，MFR相比Chain-of-Thought和ReAct显著降低了约束违反率并提高了方案质量；消融实验表明显式建模阶段对性能提升至关重要。

Conclusion: LLM在规划任务中的失败主要源于表征缺陷而非推理能力不足，显式建模是构建鲁棒且可解释AI智能体的关键组成部分。

Abstract: Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

</details>


### [115] [Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence](https://arxiv.org/abs/2512.14527)
*Shreyas Subramanian,Bala Krishnamoorthy,Pranav Murthy*

Main category: cs.AI

TL;DR: 本文提出了一种名为 GreedyLR 的新型学习率调度器，它根据当前损失自适应调整学习率，在多个 NLP、CV 和大语言模型任务中表现优于现有调度器，并具备理论收敛性保证和良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管优化器研究取得了显著进展，但大多数工作仍使用如余弦或指数衰减等通用学习率调度策略。作者旨在探索一种更高效、自适应的学习率调度方法以提升训练效果。

Method: 提出 GreedyLR 调度器，该方法在训练过程中基于当前损失动态调整学习率；同时提供理论分析，包括收敛性证明和最优缩放因子 F 的推导。

Result: 在涵盖 NLP、CV 和参数规模高达 7B 的 LLM 任务上的实验表明，GreedyLR 在准确率、训练速度和收敛性方面优于多种先进调度器，并在含噪环境中表现出良好鲁棒性。

Conclusion: GreedyLR 是一种易于实现、计算高效且性能优越的学习率调度器，可作为训练过程中的默认选择。

Abstract: Despite significant advances in optimizers for training, most research works use common scheduler choices like Cosine or exponential decay. In this paper, we study \emph{GreedyLR}, a novel scheduler that adaptively adjusts the learning rate during training based on the current loss. To validate the effectiveness of our proposed scheduler, we conduct experiments on several NLP, CV, and LLM tasks with up to $7B$ parameters, including both fine-tuning and pre-training experiments. The results show that our approach outperforms several state-of-the-art schedulers in terms of accuracy, speed, and convergence. We also provide a theoretical analysis of the GreedyLR algorithm, including a proof of convergence and derivation of the optimal scaling factor $F$ that maximizes the convergence rate, along with experiments to show robustness of the algorithm to realistic noisy landscapes. Our scheduler is easy to implement, computationally efficient, and could be considered a good default scheduler for training.

</details>


### [116] [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)
*Zitian Gao,Lynx Chen,Yihao Xiao,He Xing,Ran Tao,Haoming Luo,Joey Zhou,Bryan Dai*

Main category: cs.AI

TL;DR: 本文发现通用Transformer（UT）在ARC-AGI等推理任务中的性能提升主要源于其递归归纳偏置和强非线性组件，而非复杂架构设计，并据此提出增强版模型URM，在ARC-AGI上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 探究通用Transformer（UT）在复杂推理任务中性能提升的真正来源，以澄清是否来自架构设计或其内在特性。

Method: 系统分析UT变体，识别关键性能因素，并在此基础上引入短卷积与截断反向传播，构建Universal Reasoning Model（URM）。

Result: URM在ARC-AGI 1上达到53.8% pass@1，在ARC-AGI 2上达到16.0% pass@1，均为当前最优结果。

Conclusion: UT的推理能力主要源于其递归归纳偏置和非线性能力，基于此设计的URM显著提升了复杂推理任务的性能。

Abstract: Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

</details>
