<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 87]
- [cs.AI](#cs.AI) [Total: 56]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy](https://arxiv.org/abs/2602.04994)
*Zhuosen Bao,Xia Du,Zheng Lin,Jizhe Zhou,Zihan Fang,Jiening Wu,Yuxin Zhang,Zhe Chen,Chi-man Pun,Wei Ni,Jun Luo*

Main category: cs.CV

TL;DR: 本文提出SIDeR框架，通过语义解耦在保护人脸图像视觉隐私的同时保留机器可识别的身份信息，并支持授权还原。


<details>
  <summary>Details</summary>
Motivation: 随着人脸识别广泛应用于在线银行和身份验证等服务，如何在图像存储与传输过程中有效将身份信息与视觉表征解耦，成为隐私保护的关键挑战。

Method: SIDeR将人脸图像分解为身份特征向量和语义外观组件，利用扩散模型潜在空间中的语义引导重组生成视觉匿名但身份一致的对抗人脸，并引入动量驱动的无限制扰动优化和语义-视觉平衡因子以合成多样且自然的样本；同时支持通过密码授权还原原始图像。

Result: 在CelebA-HQ和FFHQ数据集上的实验表明，SIDeR在黑盒场景下攻击成功率达99%，并在基于PSNR的还原质量上比基线方法提升41.28%。

Conclusion: SIDeR有效实现了人脸图像的隐私保护与身份一致性之间的平衡，兼具高匿名性、高自然度和可逆恢复能力。

Abstract: With the deep integration of facial recognition into online banking, identity verification, and other networked services, achieving effective decoupling of identity information from visual representations during image storage and transmission has become a critical challenge for privacy protection. To address this issue, we propose SIDeR, a Semantic decoupling-driven framework for unrestricted face privacy protection. SIDeR decomposes a facial image into a machine-recognizable identity feature vector and a visually perceptible semantic appearance component. By leveraging semantic-guided recomposition in the latent space of a diffusion model, it generates visually anonymous adversarial faces while maintaining machine-level identity consistency. The framework incorporates momentum-driven unrestricted perturbation optimization and a semantic-visual balancing factor to synthesize multiple visually diverse, highly natural adversarial samples. Furthermore, for authorized access, the protected image can be restored to its original form when the correct password is provided. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that SIDeR achieves a 99% attack success rate in black-box scenarios and outperforms baseline methods by 41.28% in PSNR-based restoration quality.

</details>


### [2] [Food Portion Estimation: From Pixels to Calories](https://arxiv.org/abs/2602.05078)
*Gautham Vinod,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文综述了基于图像的膳食评估中用于精确估算食物份量的各种策略，重点解决从二维图像估计三维食物尺寸的挑战。


<details>
  <summary>Details</summary>
Motivation: 基于图像的膳食评估在慢性病和肥胖防控中具有重要作用，但其关键瓶颈在于难以从2D图像准确估计食物的3D体积，因此需要系统梳理现有解决方案。

Method: 文章回顾并分析了多种应对该问题的方法，包括使用深度图、多视角输入、模板匹配等辅助手段，以及利用深度学习结合单目图像或融合辅助信息进行份量预测的技术。

Result: 展示了不同策略在提升食物份量估计准确性方面的有效性，并指出深度学习方法在整合图像与辅助输入方面具有显著潜力。

Conclusion: 综合多种技术手段，尤其是深度学习与辅助信息融合的方法，是提高图像膳食评估精度的关键方向。

Abstract: Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.

</details>


### [3] [Visual concept ranking uncovers medical shortcuts used by large multimodal models](https://arxiv.org/abs/2602.05096)
*Joseph D. Janizek,Sonnet Xu,Junayd Lateef,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 本文提出了一种名为视觉概念排序（VCR）的方法，用于识别大型多模态模型（LMMs）在医疗任务中依赖的关键视觉概念，并揭示其在不同人群子组间性能差异的问题。


<details>
  <summary>Details</summary>
Motivation: 在医疗等安全关键领域，确保机器学习模型的可靠性至关重要。现有方法难以有效揭示模型在处理医学图像时的行为缺陷，特别是在不同人口统计学群体中的表现差异，因此需要一种可解释且可验证的审计方法。

Method: 作者提出视觉概念排序（VCR）方法，通过分析LMM在处理皮肤病变、胸部X光和自然图像等任务时所依赖的视觉概念，生成关于模型决策依据的假设，并通过人工干预进行验证。

Result: 研究发现，LMM在使用示例提示时，在不同人口统计学子组之间存在显著且意外的性能差距；VCR方法成功识别出模型所依赖的视觉特征，并通过人工干预验证了这些假设。

Conclusion: VCR为理解和审计LMM在医疗任务中的行为提供了一种有效工具，有助于揭示模型偏见和不可靠性，从而提升其在安全关键场景中的可信度。

Abstract: Ensuring the reliability of machine learning models in safety-critical domains such as healthcare requires auditing methods that can uncover model shortcomings. We introduce a method for identifying important visual concepts within large multimodal models (LMMs) and use it to investigate the behaviors these models exhibit when prompted with medical tasks. We primarily focus on the task of classifying malignant skin lesions from clinical dermatology images, with supplemental experiments including both chest radiographs and natural images. After showing how LMMs display unexpected gaps in performance between different demographic subgroups when prompted with demonstrating examples, we apply our method, Visual Concept Ranking (VCR), to these models and prompts. VCR generates hypotheses related to different visual feature dependencies, which we are then able to validate with manual interventions.

</details>


### [4] [ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation](https://arxiv.org/abs/2602.05132)
*Jia Li,Wenjie Zhao,Shijian Deng,Bolin Lai,Yuheng Wu,RUijia Chen,Jon E. Froehlich,Yuhang Zhao,Yapeng Tian*

Main category: cs.CV

TL;DR: 本文提出ARGaze，一种基于自回归机制的在线第一人称视线估计方法，通过结合当前视觉特征和近期视线历史，在多个基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 第一人称（自我中心）视线估计缺乏明确的头部或眼部信号，需依赖手-物交互等间接线索；同时，人在目标导向活动中视线具有强时间连续性，可作为预测先验。

Method: ARGaze将视线估计建模为序列预测任务，使用Transformer解码器在每个时间步融合当前视觉特征与固定长度的“视线上下文窗口”（近期视线估计结果），实现因果约束下的流式推理。

Result: 在多个自我中心视线估计基准上实现了在线评估下的最先进性能，消融实验验证了引入有限长度视线历史的自回归建模对鲁棒预测至关重要。

Conclusion: 利用视线的时间连续性并以自回归方式建模，能有效提升在线第一人称视线估计的准确性，该方法具备实际部署潜力。

Abstract: Online egocentric gaze estimation predicts where a camera wearer is looking from first-person video using only past and current frames, a task essential for augmented reality and assistive technologies. Unlike third-person gaze estimation, this setting lacks explicit head or eye signals, requiring models to infer current visual attention from sparse, indirect cues such as hand-object interactions and salient scene content. We observe that gaze exhibits strong temporal continuity during goal-directed activities: knowing where a person looked recently provides a powerful prior for predicting where they look next. Inspired by vision-conditioned autoregressive decoding in vision-language models, we propose ARGaze, which reformulates gaze estimation as sequential prediction: at each timestep, a transformer decoder predicts current gaze by conditioning on (i) current visual features and (ii) a fixed-length Gaze Context Window of recent gaze target estimates. This design enforces causality and enables bounded-resource streaming inference. We achieve state-of-the-art performance across multiple egocentric benchmarks under online evaluation, with extensive ablations validating that autoregressive modeling with bounded gaze history is critical for robust prediction. We will release our source code and pre-trained models.

</details>


### [5] [AirGlove: Exploring Egocentric 3D Hand Tracking and Appearance Generalization for Sensing Gloves](https://arxiv.org/abs/2602.05159)
*Wenhui Cui,Ziyi Kou,Chuan Qin,Ergys Ristani,Li Guan*

Main category: cs.CV

TL;DR: 本文首次系统评估了基于视觉的手部追踪模型在佩戴传感手套场景下的表现，发现现有裸手模型因外观差异导致性能显著下降，并提出AirGlove方法，在有限数据下有效泛化至新手套设计。


<details>
  <summary>Details</summary>
Motivation: 传感手套在遥操作和机器人策略学习中至关重要，但基于传感器的追踪方法受限于信号质量和校准精度；而当前基于视觉的方法虽在裸手上表现优异，但在不同外观的传感手套上效果尚未充分探索。

Method: 对现有视觉手部追踪模型在佩戴手套条件下进行零样本和微调设置下的系统评估，并提出AirGlove方法，利用已有手套数据学习可泛化的手套表征，以适应新类型手套。

Result: 实验表明，现有裸手模型在传感手套上性能大幅下降；AirGlove在多种传感手套上显著优于对比方法，能有效将手姿模型泛化至新手套设计。

Conclusion: 针对传感手套的视觉手部追踪需专门处理外观差异问题，AirGlove通过表征泛化策略，在数据有限情况下实现了对手套手姿的高效准确追踪。

Abstract: Sensing gloves have become important tools for teleoperation and robotic policy learning as they are able to provide rich signals like speed, acceleration and tactile feedback. A common approach to track gloved hands is to directly use the sensor signals (e.g., angular velocity, gravity orientation) to estimate 3D hand poses. However, sensor-based tracking can be restrictive in practice as the accuracy is often impacted by sensor signal and calibration quality. Recent advances in vision-based approaches have achieved strong performance on human hands via large-scale pre-training, but their performance on gloved hands with distinct visual appearances remains underexplored. In this work, we present the first systematic evaluation of vision-based hand tracking models on gloved hands under both zero-shot and fine-tuning setups. Our analysis shows that existing bare-hand models suffer from substantial performance degradation on sensing gloves due to large appearance gap between bare-hand and glove designs. We therefore propose AirGlove, which leverages existing gloves to generalize the learned glove representations towards new gloves with limited data. Experiments with multiple sensing gloves show that AirGlove effectively generalizes the hand pose models to new glove designs and achieves a significant performance boost over the compared schemes.

</details>


### [6] [LOBSTgER-enhance: an underwater image enhancement pipeline](https://arxiv.org/abs/2602.05163)
*Andreas Mentzelopoulos,Keith Ellenbogen*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的图像到图像转换方法，用于修复水下摄影中的对比度降低、模糊和颜色失真等问题，在小规模高质量数据集上训练后表现出良好的感知一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 水下摄影存在固有挑战，如对比度降低、空间模糊和波长相关的颜色失真，严重影响海洋生物影像的鲜艳度，摄影师常需繁重的后期处理来校正这些问题。

Method: 构建一个合成退化流程以模拟水下图像退化，并利用基于扩散的生成模型学习逆转这些退化效果；在Keith Ellenbogen提供的约2.5k张高质量水下意识摄影图像上从头训练一个约1100万参数的模型。

Result: 该方法在生成512x768分辨率图像时实现了高感知一致性与强泛化能力。

Conclusion: 所提出的扩散模型驱动的图像修复方法能有效应对水下摄影退化问题，在有限数据条件下仍可取得高质量修复效果。

Abstract: Underwater photography presents significant inherent challenges including reduced contrast, spatial blur, and wavelength-dependent color distortions. These effects can obscure the vibrancy of marine life and awareness photographers in particular are often challenged with heavy post-processing pipelines to correct for these distortions.
  We develop an image-to-image pipeline that learns to reverse underwater degradations by introducing a synthetic corruption pipeline and learning to reverse its effects with diffusion-based generation. Training and evaluation are performed on a small high-quality dataset of awareness photography images by Keith Ellenbogen. The proposed methodology achieves high perceptual consistency and strong generalization in synthesizing 512x768 images using a model of ~11M parameters after training from scratch on ~2.5k images.

</details>


### [7] [ShapePuri: Shape Guided and Appearance Generalized Adversarial Purification](https://arxiv.org/abs/2602.05175)
*Zhe Li,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本文提出Shape Guided Purification（ShapePuri），一种新型对抗防御框架，通过结合形状编码模块（SEM）和全局外观去偏模块（GAD），在保持高准确率的同时显著提升模型鲁棒性，在AutoAttack基准上首次突破80%的鲁棒准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的净化方法在对抗防御中存在计算成本高和信息丢失的问题，因此需要一种更高效且能保留结构信息的防御机制。

Method: ShapePuri包含两个核心组件：1）形状编码模块（SEM），利用符号距离函数（SDF）提供密集几何引导；2）全局外观去偏模块（GAD），通过随机变换缓解外观偏差。该方法无需额外辅助模块或增加推理计算开销。

Result: 在AutoAttack协议下，ShapePuri达到84.06%的干净准确率和81.64%的鲁棒准确率，是首个在该基准上鲁棒准确率超过80%的防御框架。

Conclusion: ShapePuri通过将模型表示与稳定的结构不变量对齐，实现了一种可扩展、高效的对抗防御方法，在不牺牲预测稳定性的情况下显著提升了鲁棒性。

Abstract: Deep neural networks demonstrate impressive performance in visual recognition, but they remain vulnerable to adversarial attacks that is imperceptible to the human. Although existing defense strategies such as adversarial training and purification have achieved progress, diffusion-based purification often involves high computational costs and information loss. To address these challenges, we introduce Shape Guided Purification (ShapePuri), a novel defense framework enhances robustness by aligning model representations with stable structural invariants. ShapePuri integrates two components: a Shape Encoding Module (SEM) that provides dense geometric guidance through Signed Distance Functions (SDF), and a Global Appearance Debiasing (GAD) module that mitigates appearance bias via stochastic transformations. In our experiments, ShapePuri achieves $84.06\%$ clean accuracy and $81.64\%$ robust accuracy under the AutoAttack protocol, representing the first defense framework to surpass the $80\%$ threshold on this benchmark. Our approach provides a scalable and efficient adversarial defense that preserves prediction stability during inference without requiring auxiliary modules or additional computational cost.

</details>


### [8] [PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction](https://arxiv.org/abs/2602.05190)
*Ju Shen,Chen Chen,Tam V. Nguyen,Vijayan K. Asari*

Main category: cs.CV

TL;DR: PoseGaussian 是一种结合人体姿态引导的高斯点阵化框架，用于高质量人体新视角合成，在保持实时渲染（100 FPS）的同时，在多个数据集上达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态人体场景中难以处理关节运动和严重自遮挡问题，且姿态信息通常仅作为条件或用于图像扭曲，未能充分融入几何与时间建模。

Method: 将人体姿态作为结构先验融合进颜色编码器以优化深度估计，并通过专用姿态编码器处理姿态作为时间线索以增强帧间一致性；整体构建为端到端可微分训练的高斯点阵化流程。

Result: 在 ZJU-MoCap、THuman2.0 和内部数据集上验证，取得 PSNR 30.86、SSIM 0.979、LPIPS 0.028 的指标，实现 SOTA 的感知质量和结构精度，并支持 100 FPS 实时渲染。

Conclusion: PoseGaussian 通过将姿态信号嵌入几何与时间建模阶段，有效提升了动态人体新视角合成的鲁棒性、泛化能力与效率。

Abstract: We propose PoseGaussian, a pose-guided Gaussian Splatting framework for high-fidelity human novel view synthesis. Human body pose serves a dual purpose in our design: as a structural prior, it is fused with a color encoder to refine depth estimation; as a temporal cue, it is processed by a dedicated pose encoder to enhance temporal consistency across frames. These components are integrated into a fully differentiable, end-to-end trainable pipeline. Unlike prior works that use pose only as a condition or for warping, PoseGaussian embeds pose signals into both geometric and temporal stages to improve robustness and generalization. It is specifically designed to address challenges inherent in dynamic human scenes, such as articulated motion and severe self-occlusion. Notably, our framework achieves real-time rendering at 100 FPS, maintaining the efficiency of standard Gaussian Splatting pipelines. We validate our approach on ZJU-MoCap, THuman2.0, and in-house datasets, demonstrating state-of-the-art performance in perceptual quality and structural accuracy (PSNR 30.86, SSIM 0.979, LPIPS 0.028).

</details>


### [9] [GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling](https://arxiv.org/abs/2602.05202)
*Shivanshu Shekhar,Uttaran Bhattacharya,Raghavendra Addanki,Mehrab Tanjim,Somdeb Sarkhel,Tong Zhang*

Main category: cs.CV

TL;DR: 本文提出一种新方法，将视频生成模型转化为具有时间感知能力的奖励模型，通过对比学习和合成负样本训练，在仅使用少量人工标注的情况下实现优于现有基于视觉语言模型（VLM）方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型（VLM）的奖励建模方法难以捕捉视频中细微的时间动态，限制了视频生成模型与人类偏好的对齐效果。

Method: 将先进的视频生成模型重新构建为基于能量的模型（EBM），通过对比目标训练其区分高质量与低质量视频的能力；设计三种可控的潜在空间扰动（时间切片、特征交换、帧打乱）生成具有挑战性的合成负样本，以促使模型学习有意义的时空特征。

Result: \modelname 在 GenAI-Bench 和 MonteBench 上达到当前最优性能，仅使用 3 万条人工标注，比现有 VLM 方法少 6 至 65 倍。

Conclusion: 将视频生成模型用作奖励模型是一种高效且数据经济的方法，能有效建模时间动态并准确评估视频质量，显著减少对大规模人工标注的依赖。

Abstract: Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\times$ to $65\times$ fewer than existing VLM-based approaches.

</details>


### [10] [Dual-Representation Image Compression at Ultra-Low Bitrates via Explicit Semantics and Implicit Textures](https://arxiv.org/abs/2602.05213)
*Chuqin Zhou,Xiaoyue Ling,Yunuo Chen,Jincheng Dai,Guo Lu,Wenjun Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的统一框架，通过结合显式高层语义与隐式细节表示，在超低码率下实现感知质量与语义保真度的平衡，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经编解码器在超低码率下性能下降，而基于生成模型的压缩方法在语义保真度与感知真实感之间存在权衡：显式方法保留结构但缺乏细节，隐式方法生成逼真细节但易出现语义偏移。

Method: 将扩散模型以显式高层语义为条件，并利用反向信道编码隐式传递细粒度细节；同时引入可插拔编码器，通过调节隐式信息灵活控制失真-感知权衡。

Result: 在Kodak、DIV2K和CLIC2020数据集上，DISTS BD-Rate分别比DiffC提升29.92%、19.33%和20.89%，达到最先进的率-感知性能。

Conclusion: 所提框架有效融合显式与隐式表示，在不需额外训练的情况下显著提升超低码率图像压缩的感知质量和语义一致性。

Abstract: While recent neural codecs achieve strong performance at low bitrates when optimized for perceptual quality, their effectiveness deteriorates significantly under ultra-low bitrate conditions. To mitigate this, generative compression methods leveraging semantic priors from pretrained models have emerged as a promising paradigm. However, existing approaches are fundamentally constrained by a tradeoff between semantic faithfulness and perceptual realism. Methods based on explicit representations preserve content structure but often lack fine-grained textures, whereas implicit methods can synthesize visually plausible details at the cost of semantic drift. In this work, we propose a unified framework that bridges this gap by coherently integrating explicit and implicit representations in a training-free manner. Specifically, We condition a diffusion model on explicit high-level semantics while employing reverse-channel coding to implicitly convey fine-grained details. Moreover, we introduce a plug-in encoder that enables flexible control of the distortion-perception tradeoff by modulating the implicit information. Extensive experiments demonstrate that the proposed framework achieves state-of-the-art rate-perception performance, outperforming existing methods and surpassing DiffC by 29.92%, 19.33%, and 20.89% in DISTS BD-Rate on the Kodak, DIV2K, and CLIC2020 datasets, respectively.

</details>


### [11] [E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching](https://arxiv.org/abs/2602.05215)
*Jiahao Nie,Wenbin An,Gongjie Zhang,Yicheng Xu,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为E.M.Ground的新型视频大语言模型，用于提升时间视频定位（TVG）任务的性能，通过引入事件整体感知机制、Savitzky-Golay平滑和多粒度帧特征聚合，在多个基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在时间视频定位任务中通常依赖两个独立标记匹配起止帧，忽视了事件语义的连续性和完整性，导致定位模糊。

Method: E.M.Ground引入三项关键技术：(i) 一个特殊<event>标记，聚合查询事件所有帧的信息以保持语义连续性；(ii) 使用Savitzky-Golay平滑降低时间戳间标记-帧相似度的噪声；(iii) 多粒度帧特征聚合，增强匹配可靠性和时间理解能力。

Result: 在多个基准数据集上的实验表明，E.M.Ground显著优于当前最先进的视频大语言模型。

Conclusion: 通过整体事件感知与多粒度特征融合，E.M.Ground有效提升了时间视频定位的准确性和鲁棒性。

Abstract: Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.

</details>


### [12] [Cross-Domain Few-Shot Segmentation via Multi-view Progressive Adaptation](https://arxiv.org/abs/2602.05217)
*Jiahao Nie,Guanqiao Fu,Wenbin An,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: 本文提出多视角渐进适应（MPA）方法，通过数据和策略两个层面的渐进式增强与学习，显著提升跨域少样本分割性能，超越现有方法7.0%。


<details>
  <summary>Details</summary>
Motivation: 现有跨域少样本分割方法在目标域样本数量和多样性有限的情况下性能受限，且源域训练模型在目标域初始能力弱、域间差距大，阻碍了有效适应。

Method: 提出多视角渐进适应（MPA）：（i）数据层面采用混合渐进增强，通过累积强增强生成多样复杂视图；（ii）策略层面设计双链多视角预测，通过串行与并行学习路径在强监督下充分利用复杂视图，并强制跨视图预测一致性。

Result: 大量实验表明，MPA在跨域少样本分割任务中显著优于当前最先进方法，性能提升达+7.0%。

Conclusion: 通过从数据和策略两方面协同实现渐进式适应，MPA能有效提升模型在目标域的少样本分割能力，实现鲁棒且准确的跨域迁移。

Abstract: Cross-Domain Few-Shot Segmentation aims to segment categories in data-scarce domains conditioned on a few exemplars. Typical methods first establish few-shot capability in a large-scale source domain and then adapt it to target domains. However, due to the limited quantity and diversity of target samples, existing methods still exhibit constrained performance. Moreover, the source-trained model's initially weak few-shot capability in target domains, coupled with substantial domain gaps, severely hinders the effective utilization of target samples and further impedes adaptation. To this end, we propose Multi-view Progressive Adaptation, which progressively adapts few-shot capability to target domains from both data and strategy perspectives. (i) From the data perspective, we introduce Hybrid Progressive Augmentation, which progressively generates more diverse and complex views through cumulative strong augmentations, thereby creating increasingly challenging learning scenarios. (ii) From the strategy perspective, we design Dual-chain Multi-view Prediction, which fully leverages these progressively complex views through sequential and parallel learning paths under extensive supervision. By jointly enforcing prediction consistency across diverse and complex views, MPA achieves both robust and accurate adaptation to target domains. Extensive experiments demonstrate that MPA effectively adapts few-shot capability to target domains, outperforming state-of-the-art methods by a large margin (+7.0%).

</details>


### [13] [Boosting SAM for Cross-Domain Few-Shot Segmentation via Conditional Point Sparsification](https://arxiv.org/abs/2602.05218)
*Jiahao Nie,Yun Xing,Wenbin An,Qingsong Zhao,Jiawei Shao,Yap-Peng Tan,Alex C. Kot,Shijian Lu,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为条件点稀疏化（CPS）的无训练方法，用于提升Segment Anything Model（SAM）在跨域少样本分割（CD-FSS）任务中的性能，通过参考图像中的真实掩码自适应地稀疏匹配点，从而改善分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的少样本分割方法在跨域场景（如医学或卫星图像）中表现不佳，主要由于域偏移破坏了SAM学习到的点-图像交互，且密集匹配点在这些情况下效果差。

Method: 提出Conditional Point Sparsification（CPS），一种无需训练的方法，利用参考图像中的真实掩码对密集匹配点进行自适应稀疏化，以更有效地引导SAM在跨域图像上的交互。

Result: 在多个跨域少样本分割数据集上，CPS显著优于现有的无训练SAM方法。

Conclusion: 点密度在跨域少样本分割中起关键作用，通过条件稀疏化策略可有效提升SAM在该任务中的泛化能力与分割准确性。

Abstract: Motivated by the success of the Segment Anything Model (SAM) in promptable segmentation, recent studies leverage SAM to develop training-free solutions for few-shot segmentation, which aims to predict object masks in the target image based on a few reference exemplars. These SAM-based methods typically rely on point matching between reference and target images and use the matched dense points as prompts for mask prediction. However, we observe that dense points perform poorly in Cross-Domain Few-Shot Segmentation (CD-FSS), where target images are from medical or satellite domains. We attribute this issue to large domain shifts that disrupt the point-image interactions learned by SAM, and find that point density plays a crucial role under such conditions. To address this challenge, we propose Conditional Point Sparsification (CPS), a training-free approach that adaptively guides SAM interactions for cross-domain images based on reference exemplars. Leveraging ground-truth masks, the reference images provide reliable guidance for adaptively sparsifying dense matched points, enabling more accurate segmentation results. Extensive experiments demonstrate that CPS outperforms existing training-free SAM-based methods across diverse CD-FSS datasets.

</details>


### [14] [PatchFlow: Leveraging a Flow-Based Model with Patch Features](https://arxiv.org/abs/2602.05238)
*Boxiang Zhang,Baijian Yang,Xiaoming Wang,Corey Vian*

Main category: cs.CV

TL;DR: 本文提出一种结合局部邻域感知图像块特征、归一化流模型和适配器模块的无监督异常检测方法，显著提升压铸件表面缺陷检测的准确率。


<details>
  <summary>Details</summary>
Motivation: 压铸件表面缺陷影响产品质量，传统检测方法效率低；现有基于计算机视觉的自动检测方法在工业图像上泛化能力有限，需提升精度与效率。

Method: 融合局部邻域感知的图像块特征与归一化流模型，并引入适配器模块，弥合通用预训练特征提取器与工业产品图像之间的差距，实现无需异常样本的无监督异常检测。

Result: 在MVTec AD数据集上图像级AUROC达99.28%，错误率降低20%；在VisA数据集上AUROC达96.48%，错误率降低28.2%；在自建压铸数据集上准确率达95.77%。

Conclusion: 所提方法有效提升了压铸件表面缺陷的自动检测性能，展示了计算机视觉与深度学习在工业质检中的应用潜力。

Abstract: Die casting plays a crucial role across various industries due to its ability to craft intricate shapes with high precision and smooth surfaces. However, surface defects remain a major issue that impedes die casting quality control. Recently, computer vision techniques have been explored to automate and improve defect detection. In this work, we combine local neighbor-aware patch features with a normalizing flow model and bridge the gap between the generic pretrained feature extractor and industrial product images by introducing an adapter module to increase the efficiency and accuracy of automated anomaly detection. Compared to state-of-the-art methods, our approach reduces the error rate by 20\% on the MVTec AD dataset, achieving an image-level AUROC of 99.28\%. Our approach has also enhanced performance on the VisA dataset , achieving an image-level AUROC of 96.48\%. Compared to the state-of-the-art models, this represents a 28.2\% reduction in error. Additionally, experiments on a proprietary die casting dataset yield an accuracy of 95.77\% for anomaly detection, without requiring any anomalous samples for training. Our method illustrates the potential of leveraging computer vision and deep learning techniques to advance inspection capabilities for the die casting industry

</details>


### [15] [Active Label Cleaning for Reliable Detection of Electron Dense Deposits in Transmission Electron Microscopy Images](https://arxiv.org/abs/2602.05250)
*Jieyun Tan,Shuo Liu,Guibin Zhang,Ziqi Li,Jian Geng,Lei Zhang,Lei Cao*

Main category: cs.CV

TL;DR: 提出一种主动标签清洗方法，通过主动学习选择最有价值的噪声样本进行专家重标注，在显著降低标注成本的同时大幅提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在肾小球疾病中自动检测电子致密沉积物（EDD）面临高质量标注数据稀缺的问题；众包虽可降低成本，但引入标签噪声，影响模型性能。

Method: 设计一个标签选择模块，利用众包标签与模型预测之间的差异，进行样本选择和实例级噪声分级，并通过主动学习策略引导专家对关键噪声样本进行重标注，构建高精度清洗模型。

Result: 在私有数据集上达到67.18% AP₅₀，比直接使用噪声标签训练提升18.83%，达到全专家标注性能的95.79%，同时减少73.30%的标注成本。

Conclusion: 该方法为在专家资源有限的情况下开发可靠医疗AI提供了一种实用且经济高效的解决方案。

Abstract: Automated detection of electron dense deposits (EDD) in glomerular disease is hindered by the scarcity of high-quality labeled data. While crowdsourcing reduces annotation cost, it introduces label noise. We propose an active label cleaning method to efficiently denoise crowdsourced datasets. Our approach uses active learning to select the most valuable noisy samples for expert re-annotation, building high-accuracy cleaning models. A Label Selection Module leverages discrepancies between crowdsourced labels and model predictions for both sample selection and instance-level noise grading. Experiments show our method achieves 67.18% AP\textsubscript{50} on a private dataset, an 18.83% improvement over training on noisy labels. This performance reaches 95.79% of that with full expert annotation while reducing annotation cost by 73.30%. The method provides a practical, cost-effective solution for developing reliable medical AI with limited expert resources.

</details>


### [16] [Magic-MM-Embedding: Towards Visual-Token-Efficient Universal Multimodal Embedding with MLLMs](https://arxiv.org/abs/2602.05275)
*Qi Li,Yanzhe Zhao,Yongxin Zhou,Yameng Wang,Yandong Yang,Yuanjia Zhou,Jue Wang,Zuojian Wang,Jinxiang Liu*

Main category: cs.CV

TL;DR: 本文提出Magic-MM-Embedding，一种高效且性能领先的通用多模态嵌入模型，通过视觉token压缩和多阶段渐进训练策略，在降低计算开销的同时显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在通用多模态检索中表现优异，但因处理大量视觉token导致计算成本高，限制了实际应用。因此，亟需兼顾效率与性能的解决方案。

Method: 方法包括两个核心部分：(1) 引入视觉token压缩的高效MLLM架构，以减少推理延迟和内存占用；(2) 多阶段渐进训练策略，包括继续预训练恢复多模态能力、大规模对比预训练与难负样本挖掘增强判别力，以及由MLLM作为裁判指导的任务感知微调。

Result: 实验表明，Magic-MM-Embedding在通用多模态嵌入任务中大幅超越现有方法，同时具有更高的推理效率。

Conclusion: Magic-MM-Embedding通过架构优化与训练策略协同设计，成功实现了高效且高性能的多模态嵌入，为MLLM在实际检索场景中的部署提供了可行路径。

Abstract: Multimodal Large Language Models (MLLMs) have shown immense promise in universal multimodal retrieval, which aims to find relevant items of various modalities for a given query. But their practical application is often hindered by the substantial computational cost incurred from processing a large number of tokens from visual inputs. In this paper, we propose Magic-MM-Embedding, a series of novel models that achieve both high efficiency and state-of-the-art performance in universal multimodal embedding. Our approach is built on two synergistic pillars: (1) a highly efficient MLLM architecture incorporating visual token compression to drastically reduce inference latency and memory footprint, and (2) a multi-stage progressive training strategy designed to not only recover but significantly boost performance. This coarse-to-fine training paradigm begins with extensive continue pretraining to restore multimodal understanding and generation capabilities, progresses to large-scale contrastive pretraining and hard negative mining to enhance discriminative power, and culminates in a task-aware fine-tuning stage guided by an MLLM-as-a-Judge for precise data curation. Comprehensive experiments show that our model outperforms existing methods by a large margin while being more inference-efficient.

</details>


### [17] [Fast-SAM3D: 3Dfy Anything in Images but Faster](https://arxiv.org/abs/2602.05293)
*Weilun Feng,Mingqiang Wu,Zhiliang Chen,Chuanguang Yang,Haotong Qin,Yuqi Li,Xiaokun Liu,Guoxin Fan,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出Fast-SAM3D，一种无需训练的加速框架，通过感知SAM3D三维重建流程中的多层次异质性，实现最高2.67倍的端到端加速，几乎不损失重建质量。


<details>
  <summary>Details</summary>
Motivation: SAM3D虽能实现开放世界复杂场景的可扩展3D重建，但其推理延迟过高，限制了实际部署。现有通用加速策略在此任务中表现脆弱，原因在于忽略了该流程内在的多层次异质性。

Method: 提出Fast-SAM3D框架，包含三个异质性感知机制：(1) 模态感知步缓存，解耦结构演化与布局更新；(2) 联合时空Token剪枝，聚焦高熵区域进行细化；(3) 频谱感知Token聚合，自适应调整解码分辨率。

Result: 实验表明，Fast-SAM3D在单视图3D生成任务中实现了最高2.67倍的端到端加速，同时保持了几乎可忽略的保真度损失。

Conclusion: Fast-SAM3D通过显式建模SAM3D推理过程中的多层次异质性，为高效单视图3D生成建立了新的效率-质量帕累托前沿。

Abstract: SAM3D enables scalable, open-world 3D reconstruction from complex scenes, yet its deployment is hindered by prohibitive inference latency. In this work, we conduct the \textbf{first systematic investigation} into its inference dynamics, revealing that generic acceleration strategies are brittle in this context. We demonstrate that these failures stem from neglecting the pipeline's inherent multi-level \textbf{heterogeneity}: the kinematic distinctiveness between shape and layout, the intrinsic sparsity of texture refinement, and the spectral variance across geometries. To address this, we present \textbf{Fast-SAM3D}, a training-free framework that dynamically aligns computation with instantaneous generation complexity. Our approach integrates three heterogeneity-aware mechanisms: (1) \textit{Modality-Aware Step Caching} to decouple structural evolution from sensitive layout updates; (2) \textit{Joint Spatiotemporal Token Carving} to concentrate refinement on high-entropy regions; and (3) \textit{Spectral-Aware Token Aggregation} to adapt decoding resolution. Extensive experiments demonstrate that Fast-SAM3D delivers up to \textbf{2.67$\times$} end-to-end speedup with negligible fidelity loss, establishing a new Pareto frontier for efficient single-view 3D generation. Our code is released in https://github.com/wlfeng0509/Fast-SAM3D.

</details>


### [18] [FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion](https://arxiv.org/abs/2602.05305)
*Zhuokun Chen,Jianfei Cai,Bohan Zhuang*

Main category: cs.CV

TL;DR: 本文提出FlashBlock方法，通过缓存块外注意力输出，减少长上下文扩散模型中的注意力计算和KV缓存访问，在不影响生成质量的前提下显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 在长上下文场景中，块扩散（block diffusion）仍因重复计算不断增长的KV缓存而带来显著开销。作者发现块内跨步注意力存在冗余：块外token的注意力输出在扩散步间基本稳定，而块内变化较大。

Method: 提出FlashBlock机制，复用稳定的块外注意力输出，避免重复计算；该方法不修改扩散过程，且可与稀疏注意力正交结合，作为互补的残差复用策略。

Result: 在扩散语言模型和视频生成任务上，FlashBlock实现最高1.44倍的token吞吐量提升和1.6倍的注意力计算时间减少，对生成质量影响可忽略。

Conclusion: FlashBlock有效利用块扩散中跨步注意力的稳定性，显著提升长序列生成效率，为高效扩散模型提供了实用且兼容性强的优化方案。

Abstract: Generating long-form content, such as minute-long videos and extended texts, is increasingly important for modern generative models. Block diffusion improves inference efficiency via KV caching and block-wise causal inference and has been widely adopted in diffusion language models and video generation. However, in long-context settings, block diffusion still incurs substantial overhead from repeatedly computing attention over a growing KV cache. We identify an underexplored property of block diffusion: cross-step redundancy of attention within a block. Our analysis shows that attention outputs from tokens outside the current block remain largely stable across diffusion steps, while block-internal attention varies significantly. Based on this observation, we propose FlashBlock, a cached block-external attention mechanism that reuses stable attention output, reducing attention computation and KV cache access without modifying the diffusion process. Moreover, FlashBlock is orthogonal to sparse attention and can be combined as a complementary residual reuse strategy, substantially improving model accuracy under aggressive sparsification. Experiments on diffusion language models and video generation demonstrate up to 1.44$\times$ higher token throughput and up to 1.6$\times$ reduction in attention time, with negligible impact on generation quality. Project page: https://caesarhhh.github.io/FlashBlock/.

</details>


### [19] [Consistency-Preserving Concept Erasure via Unsafe-Safe Pairing and Directional Fisher-weighted Adaptation](https://arxiv.org/abs/2602.05339)
*Yongwoo Kim,Sungmin Cha,Hyunsoo Kim,Jaewon Lee,Donghyun Kim*

Main category: cs.CV

TL;DR: 本文提出PAIR框架，通过利用不安全-安全样本对，在擦除有害概念的同时保持生成图像的结构与语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法仅移除不安全内容，缺乏对安全替代方案的引导，导致生成结果在结构和语义上与原始内容不一致。

Method: 提出PAIRed Erasing（PAIR）框架，包含两个核心组件：(1) 配对语义重对齐（Paired Semantic Realignment），利用不安全-安全样本对将目标概念映射到语义对齐的安全锚点；(2) 用于DoRA的Fisher加权初始化，基于样本对初始化低秩适配矩阵，以抑制不安全概念并促进安全内容生成。

Result: 实验表明，该方法在有效擦除目标概念的同时，显著优于现有最先进方法，在结构完整性、语义一致性和生成质量方面表现优异。

Conclusion: PAIR通过将概念擦除重构为语义重对齐任务，实现了细粒度、一致性保留的概念擦除，为文本到图像扩散模型的安全可控生成提供了有效解决方案。

Abstract: With the increasing versatility of text-to-image diffusion models, the ability to selectively erase undesirable concepts (e.g., harmful content) has become indispensable. However, existing concept erasure approaches primarily focus on removing unsafe concepts without providing guidance toward corresponding safe alternatives, which often leads to failure in preserving the structural and semantic consistency between the original and erased generations. In this paper, we propose a novel framework, PAIRed Erasing (PAIR), which reframes concept erasure from simple removal to consistency-preserving semantic realignment using unsafe-safe pairs. We first generate safe counterparts from unsafe inputs while preserving structural and semantic fidelity, forming paired unsafe-safe multimodal data. Leveraging these pairs, we introduce two key components: (1) Paired Semantic Realignment, a guided objective that uses unsafe-safe pairs to explicitly map target concepts to semantically aligned safe anchors; and (2) Fisher-weighted Initialization for DoRA, which initializes parameter-efficient low-rank adaptation matrices using unsafe-safe pairs, encouraging the generation of safe alternatives while selectively suppressing unsafe concepts. Together, these components enable fine-grained erasure that removes only the targeted concepts while maintaining overall semantic consistency. Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving effective concept erasure while preserving structural integrity, semantic coherence, and generation quality.

</details>


### [20] [Learning with Adaptive Prototype Manifolds for Out-of-Distribution Detection](https://arxiv.org/abs/2602.05349)
*Ningkang Peng,JiuTao Zhou,Yuhao Zhang,Xiaoqian Peng,Qianfeng Yu,Linjing Qian,Tingyu Lu,Yi Chen,Yanhui Gu*

Main category: cs.CV

TL;DR: 本文提出APEX框架，通过自适应原型流形（APM）和后验感知OOD评分（PAOS）机制，解决现有基于原型的OOD检测方法中存在的静态同质性假设和学习-推理脱节问题，在CIFAR-100等基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的OOD检测方法受限于两个根本缺陷：静态同质性假设（所有类别使用固定表示资源）和学习-推理脱节（推理时忽略原型质量信息），限制了模型性能。

Method: 提出APEX框架，包含两个核心创新：(1) 自适应原型流形（APM），基于最小描述长度（MDL）原则为每个类别自动确定最优原型复杂度 $K_c^*$；(2) 后验感知OOD评分（PAOS），通过量化原型内聚性和分离性来弥合学习与推理之间的差距。

Result: 在CIFAR-100等标准基准上的实验表明，APEX显著优于现有方法，达到了新的最先进（SOTA）性能。

Conclusion: 通过解决原型表示中的静态同质性和学习-推理脱节问题，APEX有效提升了OOD检测的准确性和鲁棒性，为安全部署机器学习模型提供了新思路。

Abstract: Out-of-distribution (OOD) detection is a critical task for the safe deployment of machine learning models in the real world. Existing prototype-based representation learning methods have demonstrated exceptional performance. Specifically, we identify two fundamental flaws that universally constrain these methods: the Static Homogeneity Assumption (fixed representational resources for all classes) and the Learning-Inference Disconnect (discarding rich prototype quality knowledge at inference). These flaws fundamentally limit the model's capacity and performance. To address these issues, we propose APEX (Adaptive Prototype for eXtensive OOD Detection), a novel OOD detection framework designed via a Two-Stage Repair process to optimize the learned feature manifold. APEX introduces two key innovations to address these respective flaws: (1) an Adaptive Prototype Manifold (APM), which leverages the Minimum Description Length (MDL) principle to automatically determine the optimal prototype complexity $K_c^*$ for each class, thereby fundamentally resolving prototype collision; and (2) a Posterior-Aware OOD Scoring (PAOS) mechanism, which quantifies prototype quality (cohesion and separation) to bridge the learning-inference disconnect. Comprehensive experiments on benchmarks such as CIFAR-100 validate the superiority of our method, where APEX achieves new state-of-the-art performance.

</details>


### [21] [Multimodal Latent Reasoning via Hierarchical Visual Cues Injection](https://arxiv.org/abs/2602.05359)
*Yiming Zhang,Qiangyu Yan,Borui Jiang,Kai Han*

Main category: cs.CV

TL;DR: 本文提出HIVE框架，通过在潜空间中注入分层视觉线索，实现多模态大语言模型的“慢思考”式推理，提升对复杂场景的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs依赖端到端生成或以语言为中心的思维链（CoT），存在效率低、冗长和易产生幻觉的问题，缺乏在潜空间中融合多模态信号进行稳健推理的能力。

Method: 提出HIVE框架，递归扩展Transformer块，在模型潜表示中注入从全局场景到细粒度区域的分层视觉线索，构建内部迭代推理循环，实现无需显式文本理由的潜空间多步推理。

Result: 实验表明，在测试时引入视觉知识可有效提升性能，且整合分层信息显著增强了模型对复杂场景的理解能力。

Conclusion: 通过在潜空间中进行分层视觉引导的迭代推理，HIVE实现了更稳健、高效且具感知基础的多模态推理机制。

Abstract: The advancement of multimodal large language models (MLLMs) has enabled impressive perception capabilities. However, their reasoning process often remains a "fast thinking" paradigm, reliant on end-to-end generation or explicit, language-centric chains of thought (CoT), which can be inefficient, verbose, and prone to hallucination. This work posits that robust reasoning should evolve within a latent space, integrating multimodal signals seamlessly. We propose multimodal latent reasoning via HIerarchical Visual cuEs injection (\emph{HIVE}), a novel framework that instills deliberate, "slow thinking" without depending on superficial textual rationales. Our method recursively extends transformer blocks, creating an internal loop for iterative reasoning refinement. Crucially, it injectively grounds this process with hierarchical visual cues from global scene context to fine-grained regional details directly into the model's latent representations. This enables the model to perform grounded, multi-step inference entirely in the aligned latent space. Extensive evaluations demonstrate that test-time scaling is effective when incorporating vision knowledge, and that integrating hierarchical information significantly enhances the model's understanding of complex scenes.

</details>


### [22] [Breaking Semantic Hegemony: Decoupling Principal and Residual Subspaces for Generalized OOD Detection](https://arxiv.org/abs/2602.05360)
*Ningkang Peng,Xiaoqian Peng,Yuhao Zhang,Qianfeng Yu,Feng Xing,Peirong Ma,Xichen Yang,Yi Chen,Tingyu Lu,Yanhui Gu*

Main category: cs.CV

TL;DR: 本文揭示了当前SOTA OOD检测方法中存在的“简单性悖论”：模型对语义细微的OOD样本敏感，却对结构差异大但语义简单的样本或高频传感器噪声表现盲区。作者提出训练无关的D-KNN框架，通过几何解耦和双空间校准机制，显著提升OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于特征的后处理OOD检测方法在面对结构差异明显但语义简单的样本或高频噪声时表现不佳（即“几何盲区”），作者旨在揭示其根源并提出有效解决方案。

Method: 提出D-KNN方法，一种无需训练、即插即用的几何解耦框架。该方法利用正交分解将语义成分与结构残差显式分离，并引入双空间校准机制以增强模型对弱残差信号的敏感性。

Result: 在CIFAR和ImageNet基准上达到新的SOTA性能。解决“简单性悖论”时，FPR95从31.3%降至2.3%；在高斯噪声等传感器故障场景下，AUROC从79.7%提升至94.9%。

Conclusion: “语义霸权”是导致几何盲区的根本原因，D-KNN通过几何解耦有效打破该现象，显著提升OOD检测能力，尤其在结构差异和高频噪声场景下效果突出。

Abstract: While feature-based post-hoc methods have made significant strides in Out-of-Distribution (OOD) detection, we uncover a counter-intuitive Simplicity Paradox in existing state-of-the-art (SOTA) models: these models exhibit keen sensitivity in distinguishing semantically subtle OOD samples but suffer from severe Geometric Blindness when confronting structurally distinct yet semantically simple samples or high-frequency sensor noise. We attribute this phenomenon to Semantic Hegemony within the deep feature space and reveal its mathematical essence through the lens of Neural Collapse. Theoretical analysis demonstrates that the spectral concentration bias, induced by the high variance of the principal subspace, numerically masks the structural distribution shift signals that should be significant in the residual subspace. To address this issue, we propose D-KNN, a training-free, plug-and-play geometric decoupling framework. This method utilizes orthogonal decomposition to explicitly separate semantic components from structural residuals and introduces a dual-space calibration mechanism to reactivate the model's sensitivity to weak residual signals. Extensive experiments demonstrate that D-KNN effectively breaks Semantic Hegemony, establishing new SOTA performance on both CIFAR and ImageNet benchmarks. Notably, in resolving the Simplicity Paradox, it reduces the FPR95 from 31.3% to 2.3%; when addressing sensor failures such as Gaussian noise, it boosts the detection performance (AUROC) from a baseline of 79.7% to 94.9%.

</details>


### [23] [Imagine a City: CityGenAgent for Procedural 3D City Generation](https://arxiv.org/abs/2602.05362)
*Zishan Liu,Zecong Tang,RuoCheng Wu,Xinzhe Zheng,Jingyu Hu,Ka-Hei Hui,Haoran Xie,Bo Dai,Zhengzhe Liu*

Main category: cs.CV

TL;DR: 本文提出CityGenAgent，一种基于自然语言的分层程序化生成框架，用于高质量3D城市的自动生成与编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高保真资产生成、可控性和可编辑性方面存在不足，难以满足自动驾驶、虚拟现实等应用对高质量交互式3D城市的需求。

Method: 将城市生成分解为Block Program和Building Program两个可解释组件，采用两阶段学习策略：先通过监督微调（SFT）训练BlockGen和BuildingGen生成符合结构约束的程序，再通过强化学习（RL）引入空间对齐奖励和视觉一致性奖励，提升空间推理能力和图文一致性。

Result: 实验表明，CityGenAgent在语义对齐、视觉质量和可控性方面优于现有方法，并支持基于自然语言的城市编辑与操控。

Conclusion: CityGenAgent为可扩展、高质量、可交互的3D城市生成提供了坚实基础。

Abstract: The automated generation of interactive 3D cities is a critical challenge with broad applications in autonomous driving, virtual reality, and embodied intelligence. While recent advances in generative models and procedural techniques have improved the realism of city generation, existing methods often struggle with high-fidelity asset creation, controllability, and manipulation. In this work, we introduce CityGenAgent, a natural language-driven framework for hierarchical procedural generation of high-quality 3D cities. Our approach decomposes city generation into two interpretable components, Block Program and Building Program. To ensure structural correctness and semantic alignment, we adopt a two-stage learning strategy: (1) Supervised Fine-Tuning (SFT). We train BlockGen and BuildingGen to generate valid programs that adhere to schema constraints, including non-self-intersecting polygons and complete fields; (2) Reinforcement Learning (RL). We design Spatial Alignment Reward to enhance spatial reasoning ability and Visual Consistency Reward to bridge the gap between textual descriptions and the visual modality. Benefiting from the programs and the models' generalization, CityGenAgent supports natural language editing and manipulation. Comprehensive evaluations demonstrate superior semantic alignment, visual quality, and controllability compared to existing methods, establishing a robust foundation for scalable 3D city generation.

</details>


### [24] [SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback](https://arxiv.org/abs/2602.05380)
*Xiaoxuan He,Siming Fu,Wanli Li,Zhiyuan Li,Dacheng Yin,Kang Rong,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: SAIL 是一种仅需少量人工反馈即可实现扩散模型与人类偏好对齐的新方法，无需额外奖励模型，通过模型自迭代学习显著减少对大规模偏好数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 在缺乏奖励模型且大规模偏好数据收集成本高昂的情况下，如何仅用极少量人工反馈有效对齐扩散模型与人类偏好。

Method: 提出 SAIL 框架，利用初始少量人工标注的偏好对，让扩散模型在闭环中自我生成样本、自我标注偏好，并通过引入排序偏好混合策略防止灾难性遗忘，实现持续自优化。

Result: SAIL 在多个基准上优于当前最先进方法，仅使用现有方法 6% 的偏好数据即可取得更优性能。

Conclusion: 扩散模型具备强大的自提升能力，通过合理引导可替代大规模人工标注和外部奖励模型，实现高效偏好对齐。

Abstract: Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \textbf{SAIL} (\textbf{S}elf-\textbf{A}mplified \textbf{I}terative \textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.

</details>


### [25] [VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs](https://arxiv.org/abs/2602.05382)
*Tina Khezresmaeilzadeh,Jike Zhong,Konstantinos Psounis*

Main category: cs.CV

TL;DR: 本文提出了VRIQ基准，用于评估视觉语言模型（VLMs）的非语言推理能力，发现其在抽象推理任务中表现接近随机，主要受限于感知能力而非推理本身。


<details>
  <summary>Details</summary>
Motivation: 探究当前视觉语言模型是否能可靠地进行非语言视觉推理，并识别其失败的根本原因。

Method: 构建VRIQ基准，包含抽象谜题和自然图像两类推理任务；引入诊断探针分析感知与推理各自对失败的贡献，并进一步细分为形状、数量、位置、3D/深度等感知类别。

Result: VLMs在抽象任务上准确率仅约28%，自然图像任务为45%；工具增强仅带来有限提升；约56%失败源于感知问题，43%源于感知与推理共同问题，仅1%纯属推理问题。

Conclusion: 当前VLMs在抽象视觉推理方面仍不可靠，主要瓶颈在于感知能力，该研究为改进多模态系统的视觉推理提供了细粒度诊断基础。

Abstract: Recent progress in Vision Language Models (VLMs) has raised the question of whether they can reliably perform nonverbal reasoning. To this end, we introduce VRIQ (Visual Reasoning IQ), a novel benchmark designed to assess and analyze the visual reasoning ability of VLMs. We evaluate models on two sets of tasks: abstract puzzle-style and natural-image reasoning tasks. We find that on abstract puzzles, performance remains near random with an average accuracy of around 28%, while natural tasks yield better but still weak results with 45% accuracy. We also find that tool-augmented reasoning demonstrates only modest improvements. To uncover the source of this weakness, we introduce diagnostic probes targeting perception and reasoning. Our analysis demonstrates that around 56% of failures arise from perception alone, 43% from both perception and reasoning, and only a mere 1% from reasoning alone. This motivates us to design fine-grained diagnostic probe questions targeting specific perception categories (e.g., shape, count, position, 3D/depth), revealing that certain categories cause more failures than others. Our benchmark and analysis establish that current VLMs, even with visual reasoning tools, remain unreliable abstract reasoners, mostly due to perception limitations, and offer a principled basis for improving visual reasoning in multimodal systems.

</details>


### [26] [Dolphin-v2: Universal Document Parsing via Scalable Anchor Prompting](https://arxiv.org/abs/2602.05384)
*Hao Feng,Wei Shi,Ke Zhang,Xiang Fei,Lei Liao,Dingkang Yang,Yongkun Du,Xuecheng Wu,Jingqun Tang,Yang Liu,Hong Chen,Can Huang*

Main category: cs.CV

TL;DR: Dolphin-v2 是一种新型两阶段文档图像解析模型，通过联合文档类型分类与布局分析，并采用针对数字原生和拍摄文档的差异化解析策略，显著提升了对扭曲或拍摄文档的处理能力及细粒度元素识别精度。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析方法依赖于轴对齐边界框进行布局检测，难以有效处理扭曲或拍摄的文档；同时领域内模型碎片化严重，限制了系统的可扩展性和用户使用体验。

Method: Dolphin-v2 在第一阶段联合执行文档类型分类（数字原生 vs 拍摄）与布局分析，对数字原生文档进行细粒度元素检测与阅读顺序预测；第二阶段对拍摄文档采用整体页面级解析以应对几何失真，对数字原生文档则基于布局锚点进行并行元素级解析。此外引入代码块识别、语义属性提取等增强功能。

Result: 在 DocPTBench、OmniDocBench 和自建 RealDoc-160 基准上评估显示，Dolphin-v2 在 OmniDocBench 上整体提升 +14.78 分，在拍摄文档上错误率降低 91%，同时保持高效推理。

Conclusion: Dolphin-v2 通过统一框架有效解决了现有文档解析模型在处理多样化文档类型时的局限性，尤其在拍摄文档鲁棒性和细粒度内容提取方面取得显著进展。

Abstract: Document parsing has garnered widespread attention as vision-language models (VLMs) advance OCR capabilities. However, the field remains fragmented across dozens of specialized models with varying strengths, forcing users to navigate complex model selection and limiting system scalability. Moreover, existing two-stage approaches depend on axis-aligned bounding boxes for layout detection, failing to handle distorted or photographed documents effectively. To this end, we present Dolphin-v2, a two-stage document image parsing model that substantially improves upon the original Dolphin. In the first stage, Dolphin-v2 jointly performs document type classification (digital-born versus photographed) alongside layout analysis. For digital-born documents, it conducts finer-grained element detection with reading order prediction. In the second stage, we employ a hybrid parsing strategy: photographed documents are parsed holistically as complete pages to handle geometric distortions, while digital-born documents undergo element-wise parallel parsing guided by the detected layout anchors, enabling efficient content extraction. Compared with the original Dolphin, Dolphin-v2 introduces several crucial enhancements: (1) robust parsing of photographed documents via holistic page-level understanding, (2) finer-grained element detection (21 categories) with semantic attribute extraction such as author information and document metadata, and (3) code block recognition with indentation preservation, which existing systems typically lack. Comprehensive evaluations are conducted on DocPTBench, OmniDocBench, and our self-constructed RealDoc-160 benchmark. The results demonstrate substantial improvements: +14.78 points overall on the challenging OmniDocBench and 91% error reduction on photographed documents, while maintaining efficient inference through parallel processing.

</details>


### [27] [Parallel Swin Transformer-Enhanced 3D MRI-to-CT Synthesis for MRI-Only Radiotherapy Planning](https://arxiv.org/abs/2602.05387)
*Zolnamar Dorjsembe,Hung-Yi Chen,Furen Xiao,Hsing-Kuo Pao*

Main category: cs.CV

TL;DR: 本文提出一种基于并行Swin Transformer增强的Med2Transformer三维架构，用于从MRI生成高质量合成CT，以支持仅MRI的放疗计划。


<details>
  <summary>Details</summary>
Motivation: MRI缺乏电子密度信息，无法直接用于剂量计算，当前放疗需结合MRI与CT，带来配准不确定性和流程复杂性；因此需要可靠地从MRI生成合成CT。

Method: 采用3D架构，结合卷积编码与双Swin Transformer分支，利用多尺度移窗注意力和分层特征聚合，同时建模局部解剖细节与长程上下文依赖。

Result: 在公开和临床数据集上，该方法在图像相似性和几何精度方面优于基线方法；剂量学评估显示平均靶区剂量误差为1.69%，达到临床可接受水平。

Conclusion: 所提方法能有效生成高保真度合成CT，支持仅MRI放疗规划，具有良好的临床应用前景。

Abstract: MRI provides superior soft tissue contrast without ionizing radiation; however, the absence of electron density information limits its direct use for dose calculation. As a result, current radiotherapy workflows rely on combined MRI and CT acquisitions, increasing registration uncertainty and procedural complexity. Synthetic CT generation enables MRI only planning but remains challenging due to nonlinear MRI-CT relationships and anatomical variability. We propose Parallel Swin Transformer-Enhanced Med2Transformer, a 3D architecture that integrates convolutional encoding with dual Swin Transformer branches to model both local anatomical detail and long-range contextual dependencies. Multi-scale shifted window attention with hierarchical feature aggregation improves anatomical fidelity. Experiments on public and clinical datasets demonstrate higher image similarity and improved geometric accuracy compared with baseline methods. Dosimetric evaluation shows clinically acceptable performance, with a mean target dose error of 1.69%. Code is available at: https://github.com/mobaidoctor/med2transformer.

</details>


### [28] [Dataset Distillation via Relative Distribution Matching and Cognitive Heritage](https://arxiv.org/abs/2602.05391)
*Qianxin Xia,Jiawei Du,Yuhan Zhang,Jielei Wang,Guoming Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为统计流匹配的新方法，用于高效地进行数据集蒸馏，在显著降低计算和内存开销的同时，达到或超越现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于线性梯度匹配的数据集蒸馏方法在每一步蒸馏中都需要加载大量真实图像并对合成图像进行多次可微增强，导致计算和内存开销巨大。为解决这一效率瓶颈，作者提出一种更稳定高效的替代方案。

Method: 提出“统计流匹配”框架，通过一次性加载原始数据的统计信息，并对合成图像仅执行一次增强操作，来优化合成图像，使其在特征空间中对齐从目标类中心到非目标类中心的恒定统计流。此外，还引入分类器继承策略，复用原始数据集上训练好的分类器，仅需一个轻量级线性投影器即可进行推理。

Result: 所提方法在GPU内存占用减少10倍、运行时间缩短4倍的情况下，实现了与当前最优方法相当甚至更优的性能；结合分类器继承策略后，还能以极低的存储成本获得显著性能提升。

Conclusion: 统计流匹配是一种高效、稳定的监督学习框架，能大幅降低数据集蒸馏的资源消耗，同时保持甚至提升模型性能，适用于基于预训练自监督模型的分类任务。

Abstract: Dataset distillation seeks to synthesize a highly compact dataset that achieves performance comparable to the original dataset on downstream tasks. For the classification task that use pre-trained self-supervised models as backbones, previous linear gradient matching optimizes synthetic images by encouraging them to mimic the gradient updates induced by real images on the linear classifier. However, this batch-level formulation requires loading thousands of real images and applying multiple rounds of differentiable augmentations to synthetic images at each distillation step, leading to substantial computational and memory overhead. In this paper, we introduce statistical flow matching , a stable and efficient supervised learning framework that optimizes synthetic images by aligning constant statistical flows from target class centers to non-target class centers in the original data. Our approach loads raw statistics only once and performs a single augmentation pass on the synthetic data, achieving performance comparable to or better than the state-of-the-art methods with 10x lower GPU memory usage and 4x shorter runtime. Furthermore, we propose a classifier inheritance strategy that reuses the classifier trained on the original dataset for inference, requiring only an extremely lightweight linear projector and marginal storage while achieving substantial performance gains.

</details>


### [29] [Explainable Pathomics Feature Visualization via Correlation-aware Conditional Feature Editing](https://arxiv.org/abs/2602.05397)
*Yuechen Yang,Junlin Guo,Ruining Deng,Junchao Zhu,Zhengyi Lu,Chongyu Qu,Yanfan Zhu,Xingyi Guo,Yu Wang,Shilin Zhao,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 本文提出了一种名为MAD（Manifold-Aware Diffusion）的新框架，通过在解耦的变分自编码器潜在空间中约束特征轨迹，实现对细胞核图像的可控且符合生物学规律的编辑，从而克服传统条件扩散模型在处理相关性病理组学特征时产生非真实伪影的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于条件扩散模型的病理图像编辑方法假设病理组学特征相互独立，但实际这些特征高度相关；直接编辑单一特征而固定其他特征会导致生成结果偏离真实的生物流形，产生不合理的伪影，限制了其临床应用。

Method: 作者提出MAD框架：首先利用变分自编码器（VAE）学习一个解耦的潜在空间，在该空间中对目标特征进行编辑时自动调整相关特征，使其保持在真实细胞分布内；然后将优化后的特征用于引导条件扩散模型生成高保真图像。

Result: 实验表明，该方法能够在编辑病理组学特征时有效沿真实数据流形进行导航，在条件特征编辑任务中优于现有基线方法，并能更好地保持细胞结构的一致性。

Conclusion: MAD框架通过结合流形感知机制与扩散模型，实现了更可控、更符合生物学意义的细胞核图像编辑，为可解释、可重复的数字病理分析提供了新思路。

Abstract: Pathomics is a recent approach that offers rich quantitative features beyond what black-box deep learning can provide, supporting more reproducible and explainable biomarkers in digital pathology. However, many derived features (e.g., "second-order moment") remain difficult to interpret, especially across different clinical contexts, which limits their practical adoption. Conditional diffusion models show promise for explainability through feature editing, but they typically assume feature independence**--**an assumption violated by intrinsically correlated pathomics features. Consequently, editing one feature while fixing others can push the model off the biological manifold and produce unrealistic artifacts. To address this, we propose a Manifold-Aware Diffusion (MAD) framework for controllable and biologically plausible cell nuclei editing. Unlike existing approaches, our method regularizes feature trajectories within a disentangled latent space learned by a variational auto-encoder (VAE). This ensures that manipulating a target feature automatically adjusts correlated attributes to remain within the learned distribution of real cells. These optimized features then guide a conditional diffusion model to synthesize high-fidelity images. Experiments demonstrate that our approach is able to navigate the manifold of pathomics features when editing those features. The proposed method outperforms baseline methods in conditional feature editing while preserving structural coherence.

</details>


### [30] [TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions](https://arxiv.org/abs/2602.05414)
*Ngoc Doan-Minh Huynh,Duong Nguyen-Ngoc Tran,Long Hoang Pham,Tai Huu-Phuong Tran,Hyung-Joon Jeon,Huy-Hung Nguyen,Duong Khac Vu,Hyung-Min Jeon,Son Hong Phan,Quoc Pham-Nam Ho,Chi Dai Tran,Trinh Le Ba Khanh,Jae Wook Jeon*

Main category: cs.CV

TL;DR: 本文提出了TSBOW数据集，这是一个涵盖多种极端天气条件下遮挡车辆的交通监控基准数据集，旨在提升恶劣天气下被遮挡车辆的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多局限于轻度雾霾、雨雪等天气条件，无法充分反映极端天气对交通监控视频质量及交通流的影响，导致在真实复杂场景中车辆检测性能下降。为弥补这一空白，作者构建了更全面的数据集以支持智能交通系统研究。

Method: 研究团队收集了超过32小时来自高密度城市区域的真实交通视频，包含48,000多帧人工标注和320万帧半自动标注图像，涵盖八大类交通参与者（从大型车辆到微型交通工具和行人），并建立目标检测基准以评估遮挡与恶劣天气带来的挑战。

Result: TSBOW数据集展示了在不同道路类型、尺度和视角下的多样化场景，突显了当前目标检测方法在极端天气和遮挡情况下的局限性，同时验证了基于CCTV的交通监控在复杂环境中的潜力。

Conclusion: TSBOW作为一个公开可用的综合性数据集，为推动智能交通系统在恶劣天气条件下的鲁棒性研究提供了关键资源，并为未来相关应用奠定基础。

Abstract: Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.

</details>


### [31] [VMF-GOS: Geometry-guided virtual Outlier Synthesis for Long-Tailed OOD Detection](https://arxiv.org/abs/2602.05415)
*Ningkang Peng,Qianfeng Yu,Yuhao Zhang,Yafei Liu,Xiaoqian Peng,Peirong Ma,Yi Chen,Peiheng Li,Yanhui Gu*

Main category: cs.CV

TL;DR: 本文提出了一种无需外部数据的新型框架，通过几何引导的虚拟异常合成（GOS）和双粒度语义损失（DGS），在长尾分布下实现优越的分布外（OOD）检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA方法依赖大规模真实外部数据集进行异常暴露（OE），但在实际部署中因数据获取成本高和隐私敏感而难以实现。因此，亟需一种不依赖外部数据的OOD检测方法。

Method: 提出Geometry-guided virtual Outlier Synthesis（GOS）策略，在超球面上利用von Mises-Fisher（vMF）分布建模特征空间中的低似然环带，并在此区域进行方向性采样生成虚拟异常样本；同时引入Dual-Granularity Semantic Loss（DGS），通过对比学习增强分布内特征与合成边界异常之间的区分度。

Result: 在CIFAR-LT等基准上的大量实验表明，所提方法优于使用真实外部图像的SOTA方法。

Conclusion: 该方法成功消除了对真实外部数据集的依赖，在长尾分布下实现了高性能的OOD检测，具有良好的实用性和可部署性。

Abstract: Out-of-Distribution (OOD) detection under long-tailed distributions is a highly challenging task because the scarcity of samples in tail classes leads to blurred decision boundaries in the feature space. Current state-of-the-art (sota) methods typically employ Outlier Exposure (OE) strategies, relying on large-scale real external datasets (such as 80 Million Tiny Images) to regularize the feature space. However, this dependence on external data often becomes infeasible in practical deployment due to high data acquisition costs and privacy sensitivity. To this end, we propose a novel data-free framework aimed at completely eliminating reliance on external datasets while maintaining superior detection performance. We introduce a Geometry-guided virtual Outlier Synthesis (GOS) strategy that models statistical properties using the von Mises-Fisher (vMF) distribution on a hypersphere. Specifically, we locate a low-likelihood annulus in the feature space and perform directional sampling of virtual outliers in this region. Simultaneously, we introduce a new Dual-Granularity Semantic Loss (DGS) that utilizes contrastive learning to maximize the distinction between in-distribution (ID) features and these synthesized boundary outliers. Extensive experiments on benchmarks such as CIFAR-LT demonstrate that our method outperforms sota approaches that utilize external real images.

</details>


### [32] [Disco: Densely-overlapping Cell Instance Segmentation via Adjacency-aware Collaborative Coloring](https://arxiv.org/abs/2602.05420)
*Rui Sun,Yiwen Yang,Kaiyu Guo,Chen Jiang,Dongli Xu,Zhaonan Liu,Tan Pan,Limei Han,Xue Jiang,Wu Wei,Yuan Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的细胞实例分割方法Disco，通过邻接感知的协同着色策略解决密集重叠细胞的分割难题，并发布了一个大规模数据集GBC-FS 2025。


<details>
  <summary>Details</summary>
Motivation: 现有基于轮廓检测和距离映射的方法在处理复杂密集细胞区域时仍存在挑战，而基于图着色的新范式在真实场景中的有效性尚未验证。

Method: 提出Disco框架，结合“显式标记”策略（将拓扑问题转化为可学习分类任务）和“隐式消歧”机制（通过强制特征差异解决冲突区域模糊性），基于“分而治之”原则进行邻接感知的协同着色。

Result: 首次系统分析了四个数据集中细胞邻接图的着色特性，发现大多数真实细胞图为非二分图，普遍存在奇数长度环（主要是三角形），表明简单二着色理论不足以处理复杂组织。

Conclusion: Disco通过结合数据驱动的拓扑标记与约束深度学习系统，有效解决了复杂邻接冲突，为密集重叠细胞实例分割提供了新思路。

Abstract: Accurate cell instance segmentation is foundational for digital pathology analysis. Existing methods based on contour detection and distance mapping still face significant challenges in processing complex and dense cellular regions. Graph coloring-based methods provide a new paradigm for this task, yet the effectiveness of this paradigm in real-world scenarios with dense overlaps and complex topologies has not been verified. Addressing this issue, we release a large-scale dataset GBC-FS 2025, which contains highly complex and dense sub-cellular nuclear arrangements. We conduct the first systematic analysis of the chromatic properties of cell adjacency graphs across four diverse datasets and reveal an important discovery: most real-world cell graphs are non-bipartite, with a high prevalence of odd-length cycles (predominantly triangles). This makes simple 2-coloring theory insufficient for handling complex tissues, while higher-chromaticity models would cause representational redundancy and optimization difficulties. Building on this observation of complex real-world contexts, we propose Disco (Densely-overlapping Cell Instance Segmentation via Adjacency-aware COllaborative Coloring), an adjacency-aware framework based on the "divide and conquer" principle. It uniquely combines a data-driven topological labeling strategy with a constrained deep learning system to resolve complex adjacency conflicts. First, "Explicit Marking" strategy transforms the topological challenge into a learnable classification task by recursively decomposing the cell graph and isolating a "conflict set." Second, "Implicit Disambiguation" mechanism resolves ambiguities in conflict regions by enforcing feature dissimilarity between different instances, enabling the model to learn separable feature representations.

</details>


### [33] [NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks](https://arxiv.org/abs/2602.05423)
*Pengcheng Chen,Yue Hu,Wenhao Li,Nicole M Gunderson,Andrew Feng,Zhenglong Sun,Peter Beerel,Eric J Seibel*

Main category: cs.CV

TL;DR: NeVStereo 是一种结合 NeRF 与立体视觉的框架，可从多视角 RGB 图像中联合估计相机位姿、深度、新视角合成和表面重建，在多个基准上实现领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在密集三维重建中难以同时兼顾高精度位姿、可靠深度、高质量新视角合成和准确三维表面，尤其在非受控拍摄条件下表现不佳。

Method: NeVStereo 融合 NeRF 驱动的新视角合成、置信度引导的多视角深度估计、NeRF 耦合的光束法平差进行位姿优化，并通过迭代优化深度与辐射场提升几何一致性。

Result: 在室内外、桌面及航拍数据集上，NeVStereo 在零样本设置下显著优于现有方法：深度误差降低最多36%，位姿精度提升10.4%，新视角合成质量提高4.5%，网格质量达到SOTA（F1 91.93%，Chamfer 4.35 mm）。

Conclusion: NeVStereo 成功整合了 NeRF 与多视角几何方法，有效缓解了传统 NeRF 的表面堆叠、伪影和位姿-深度耦合问题，为通用场景下的高质量三维重建提供了统一框架。

Abstract: In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.

</details>


### [34] [LD-SLRO: Latent Diffusion Structured Light for 3-D Reconstruction of Highly Reflective Objects](https://arxiv.org/abs/2602.05434)
*Sanghoon Jeon,Gihyun Jung,Suhyeon Ka,Jae-Sang Hyun*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的结构光方法（LD-SLRO），用于高反射、低粗糙度表面的三维重建，有效抑制镜面反射和间接照明引起的条纹失真，显著提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 高反射、低粗糙度物体在结构光三维测量中因镜面反射和间接照明导致条纹图案严重失真或丢失，传统方法难以有效恢复高质量条纹信息。

Method: 将从高反射表面捕获的相移条纹图像编码为潜在表示，作为条件输入送入潜在扩散模型；该模型通过概率方式抑制反射伪影并恢复丢失的条纹信息。方法包含镜面反射编码器、时变通道仿射层和注意力模块，提升条纹恢复质量，并支持灵活配置输入输出条纹集。

Result: 实验表明，所提方法在条纹质量和三维重建精度上优于现有先进方法，平均均方根误差从1.8176 mm降低至0.9619 mm。

Conclusion: LD-SLRO能有效处理高反射表面的条纹失真问题，显著提升三维重建精度，具有良好的灵活性和实用性。

Abstract: Fringe projection profilometry-based 3-D reconstruction of objects with high reflectivity and low surface roughness remains a significant challenge. When measuring such glossy surfaces, specular reflection and indirect illumination often lead to severe distortion or loss of the projected fringe patterns. To address these issues, we propose a latent diffusion-based structured light for reflective objects (LD-SLRO). Phase-shifted fringe images captured from highly reflective surfaces are first encoded to extract latent representations that capture surface reflectance characteristics. These latent features are then used as conditional inputs to a latent diffusion model, which probabilistically suppresses reflection-induced artifacts and recover lost fringe information, yielding high-quality fringe images. The proposed components, including the specular reflection encoder, time-variant channel affine layer, and attention modules, further improve fringe restoration quality. In addition, LD-SLRO provides high flexibility in configuring the input and output fringe sets. Experimental results demonstrate that the proposed method improves both fringe quality and 3-D reconstruction accuracy over state-of-the-art methods, reducing the average root-mean-squared error from 1.8176 mm to 0.9619 mm.

</details>


### [35] [Stable Velocity: A Variance Perspective on Flow Matching](https://arxiv.org/abs/2602.05435)
*Donglin Yang,Yongxing Zhang,Xin Yu,Liang Hou,Xin Tao,Pengfei Wan,Xiaojuan Qi,Renjie Liao*

Main category: cs.CV

TL;DR: 本文提出Stable Velocity框架，通过分析流匹配中条件速度的高方差问题，在低方差区域设计了训练和采样优化方法，显著提升训练效率并实现无需微调的2倍以上采样加速。


<details>
  <summary>Details</summary>
Motivation: 流匹配方法因依赖单样本条件速度导致训练目标方差高，使优化不稳定且收敛缓慢。作者旨在识别并利用方差特性以改进训练与采样。

Method: 提出Stable Velocity统一框架：训练阶段采用无偏方差缩减目标StableVM和自适应辅助监督VA-REPA；采样阶段利用低方差区域动态特性的闭式简化，实现StableVS加速。

Result: 在ImageNet 256×256及多个大型预训练模型（如SD3.5、Flux等）上验证，训练效率显著提升，采样速度提高2倍以上，且不损失生成质量。

Conclusion: 通过对方差特性的深入分析，Stable Velocity有效解决了流匹配中的优化不稳定性问题，为高效训练与快速采样提供了通用解决方案。

Abstract: While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.

</details>


### [36] [Synthetic Defect Geometries of Cast Metal Objects Modeled via 2d Voronoi Tessellations](https://arxiv.org/abs/2602.05440)
*Natascha Jeziorski,Petra Gospodnetić,Claudia Redenbach*

Main category: cs.CV

TL;DR: 本文提出了一种基于参数化建模的合成缺陷生成方法，用于在无损检测中创建大量带精确标注的合成训练数据。


<details>
  <summary>Details</summary>
Motivation: 工业质检中缺陷检测至关重要，而机器学习方法需要大量高质量标注数据；真实缺陷数据稀缺且难以获取，因此需借助可控的合成数据生成方法。

Method: 通过参数化方法构建多种类型三维缺陷模型，并将其嵌入到被检对象的数字孪生体中；结合基于物理的蒙特卡洛模拟生成与真实检测数据相似的合成数据，并同步生成像素级精确标注。

Result: 该方法可生成任意规模、包含罕见缺陷的合成数据集，适用于视觉表面检测等多种无损检测方法。

Conclusion: 所提出的参数化缺陷建模与合成数据生成框架具有通用性和可扩展性，能有效支持自动化缺陷检测系统的训练与评估。

Abstract: In industry, defect detection is crucial for quality control. Non-destructive testing (NDT) methods are preferred as they do not influence the functionality of the object while inspecting. Automated data evaluation for automated defect detection is a growing field of research. In particular, machine learning approaches show promising results. To provide training data in sufficient amount and quality, synthetic data can be used. Rule-based approaches enable synthetic data generation in a controllable environment. Therefore, a digital twin of the inspected object including synthetic defects is needed. We present parametric methods to model 3d mesh objects of various defect types that can then be added to the object geometry to obtain synthetic defective objects. The models are motivated by common defects in metal casting but can be transferred to other machining procedures that produce similar defect shapes. Synthetic data resembling the real inspection data can then be created by using a physically based Monte Carlo simulation of the respective testing method. Using our defect models, a variable and arbitrarily large synthetic data set can be generated with the possibility to include rarely occurring defects in sufficient quantity. Pixel-perfect annotation can be created in parallel. As an example, we will use visual surface inspection, but the procedure can be applied in combination with simulations for any other NDT method.

</details>


### [37] [DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching](https://arxiv.org/abs/2602.05449)
*Chang Zou,Changlin Li,Yang Li,Patrol Li,Jianbing Wu,Xiao He,Songtao Liu,Zhao Zhong,Kailin Huang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种与蒸馏兼容的可学习特征缓存机制，结合保守的Restricted MeanFlow方法，在视频生成中实现11.8倍加速的同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成扩散模型的加速方法（如无训练特征缓存和有训练步蒸馏）在进一步压缩时面临语义/细节丢失或性能严重下降的问题，尤其当两者结合时问题更严重。

Method: 引入轻量级可学习神经预测器替代传统无训练启发式策略以更准确捕捉高维特征演化，并提出保守的Restricted MeanFlow方法用于大规模视频模型的高倍率蒸馏。

Result: 在保持生成质量的前提下，将视频生成加速边界推进至11.8倍，实验验证了方法的有效性。

Conclusion: 所提方法有效解决了特征缓存与蒸馏结合时的质量损失问题，显著提升了视频扩散模型的推理效率。

Abstract: While diffusion models have achieved great success in the field of video generation, this progress is accompanied by a rapidly escalating computational burden. Among the existing acceleration methods, Feature Caching is popular due to its training-free property and considerable speedup performance, but it inevitably faces semantic and detail drop with further compression. Another widely adopted method, training-aware step-distillation, though successful in image generation, also faces drastic degradation in video generation with a few steps. Furthermore, the quality loss becomes more severe when simply applying training-free feature caching to the step-distilled models, due to the sparser sampling steps. This paper novelly introduces a distillation-compatible learnable feature caching mechanism for the first time. We employ a lightweight learnable neural predictor instead of traditional training-free heuristics for diffusion models, enabling a more accurate capture of the high-dimensional feature evolution process. Furthermore, we explore the challenges of highly compressed distillation on large-scale video models and propose a conservative Restricted MeanFlow approach to achieve more stable and lossless distillation. By undertaking these initiatives, we further push the acceleration boundaries to $11.8\times$ while preserving generation quality. Extensive experiments demonstrate the effectiveness of our method. The code is in the supplementary materials and will be publicly available.

</details>


### [38] [Attention Retention for Continual Learning with Vision Transformers](https://arxiv.org/abs/2602.05454)
*Yue Lu,Xiangyu Zhou,Shizhou Zhang,Yinghui Xing,Guoqiang Liang,Wencong Zhang*

Main category: cs.CV

TL;DR: 本文提出一种基于注意力保留的持续学习框架，通过在反向传播中对梯度进行掩码和缩放，有效缓解Vision Transformer中的注意力漂移问题，从而减轻灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的关键挑战，作者发现Vision Transformer中的注意力漂移是导致该问题的主要原因，因此受人类视觉系统选择性注意机制启发，提出新方法以保留先前任务的视觉概念。

Method: 方法包含两步：1）利用逐层rollout机制提取前一任务的注意力图并生成实例自适应二值掩码；2）在学习新任务时，用这些掩码将与先前注意力区域相关的梯度置零，并通过按比例缩放参数更新以兼容现代优化器。

Result: 实验和可视化表明该方法能有效缓解灾难性遗忘、保留视觉概念，在多种持续学习场景下达到当前最优性能并具有良好的泛化能力。

Conclusion: 通过约束注意力漂移，所提出的注意力保留框架为Vision Transformer在持续学习中的稳定性提供了有效解决方案，展现出优越的性能和通用性。

Abstract: Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.

</details>


### [39] [MerNav: A Highly Generalizable Memory-Execute-Review Framework for Zero-Shot Object Goal Navigation](https://arxiv.org/abs/2602.05467)
*Dekang Qi,Shuang Zeng,Xinyuan Chang,Feng Xiong,Shichao Xie,Xiaolong Wu,Mu Xu*

Main category: cs.CV

TL;DR: 本文提出了一种Memory-Execute-Review框架，用于提升视觉语言导航（VLN）任务中的成功率（SR）与泛化能力，在多个数据集上显著优于现有训练免费（TF）和监督微调（SFT）方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法难以同时兼顾高成功率与良好泛化能力：监督微调方法成功率高但泛化差，训练免费方法泛化好但成功率低。因此亟需一种能兼顾两者的统一框架。

Method: 提出Memory-Execute-Review三模块框架：分层记忆模块提供信息支持，执行模块负责常规决策与动作，审查模块处理异常情况并修正行为。

Result: 在4个数据集上验证，零样本（ZS）和训练免费（TF）设置下平均成功率分别提升5%和7%；在HM3D_v0.1和HM3D_OVON上ZS设置下提升8%和6%；在MP3D和HM3D_OVON上同时超越所有TF和SFT方法。

Conclusion: 所提框架在成功率与泛化能力上均取得领先，有效解决了现有方法难以兼顾两者的问题，为视觉语言导航提供了新的有效范式。

Abstract: Visual Language Navigation (VLN) is one of the fundamental capabilities for embodied intelligence and a critical challenge that urgently needs to be addressed. However, existing methods are still unsatisfactory in terms of both success rate (SR) and generalization: Supervised Fine-Tuning (SFT) approaches typically achieve higher SR, while Training-Free (TF) approaches often generalize better, but it is difficult to obtain both simultaneously. To this end, we propose a Memory-Execute-Review framework. It consists of three parts: a hierarchical memory module for providing information support, an execute module for routine decision-making and actions, and a review module for handling abnormal situations and correcting behavior. We validated the effectiveness of this framework on the Object Goal Navigation task. Across 4 datasets, our average SR achieved absolute improvements of 7% and 5% compared to all baseline methods under TF and Zero-Shot (ZS) settings, respectively. On the most commonly used HM3D_v0.1 and the more challenging open vocabulary dataset HM3D_OVON, the SR improved by 8% and 6%, under ZS settings. Furthermore, on the MP3D and HM3D_OVON datasets, our method not only outperformed all TF methods but also surpassed all SFT methods, achieving comprehensive leadership in both SR (5% and 2%) and generalization.

</details>


### [40] [SOMA-1M: A Large-Scale SAR-Optical Multi-resolution Alignment Dataset for Multi-Task Remote Sensing](https://arxiv.org/abs/2602.05480)
*Peihao Wu,Yongxiang Yao,Yi Wan,Wenfei Zhang,Ruipeng Zhao,Jiayuan Li,Yongjun Zhang*

Main category: cs.CV

TL;DR: 本文提出了SOMA-1M数据集，包含超过130万对像素级精确对齐的SAR与光学遥感图像，覆盖全球多尺度（0.5m–10m）和12类典型地物，支持多模态遥感基础模型训练与评估。


<details>
  <summary>Details</summary>
Motivation: 现有SAR-光学配准数据集存在空间分辨率单一、数据规模不足和对齐精度低等问题，难以支撑多尺度基础模型的训练与泛化，亟需高质量、大规模、高精度对齐的多模态遥感数据集。

Method: 整合Sentinel-1、PIESAT-1、Capella Space和Google Earth等多源影像，构建覆盖0.5m至10m分辨率的512×512像素图像对；设计由粗到精的图像匹配框架以实现像素级对齐；建立涵盖图像匹配、融合、SAR辅助去云和跨模态翻译四大任务的评估基准。

Result: 在SOMA-1M上进行监督训练显著提升各项任务性能，其中多模态遥感图像匹配达到当前最优（SOTA）水平；对30余种主流算法的系统评估验证了数据集的有效性与通用性。

Conclusion: SOMA-1M为多模态遥感智能解译和基础模型研究提供了关键数据支撑，将公开发布以促进领域发展。

Abstract: Synthetic Aperture Radar (SAR) and optical imagery provide complementary strengths that constitute the critical foundation for transcending single-modality constraints and facilitating cross-modal collaborative processing and intelligent interpretation. However, existing benchmark datasets often suffer from limitations such as single spatial resolution, insufficient data scale, and low alignment accuracy, making them inadequate for supporting the training and generalization of multi-scale foundation models. To address these challenges, we introduce SOMA-1M (SAR-Optical Multi-resolution Alignment), a pixel-level precisely aligned dataset containing over 1.3 million pairs of georeferenced images with a specification of 512 x 512 pixels. This dataset integrates imagery from Sentinel-1, PIESAT-1, Capella Space, and Google Earth, achieving global multi-scale coverage from 0.5 m to 10 m. It encompasses 12 typical land cover categories, effectively ensuring scene diversity and complexity. To address multimodal projection deformation and massive data registration, we designed a rigorous coarse-to-fine image matching framework ensuring pixel-level alignment. Based on this dataset, we established comprehensive evaluation benchmarks for four hierarchical vision tasks, including image matching, image fusion, SAR-assisted cloud removal, and cross-modal translation, involving over 30 mainstream algorithms. Experimental results demonstrate that supervised training on SOMA-1M significantly enhances performance across all tasks. Notably, multimodal remote sensing image (MRSI) matching performance achieves current state-of-the-art (SOTA) levels. SOMA-1M serves as a foundational resource for robust multimodal algorithms and remote sensing foundation models. The dataset will be released publicly at: https://github.com/PeihaoWu/SOMA-1M.

</details>


### [41] [Feature points evaluation on omnidirectional vision with a photorealistic fisheye sequence -- A report on experiments done in 2014](https://arxiv.org/abs/2602.05487)
*Julien Moreau,S. Ambellouis,Yassine Ruichek*

Main category: cs.CV

TL;DR: 该报告是一项2014年未发表的博士研究工作，旨在为鱼眼图像自标定任务评估最佳特征检测与描述方法，并公开了名为PFSeq的数据集。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中利用安装于车顶、朝向天顶的鱼眼相机进行三维建模时，面临特征提取与相机标定之间的“鸡生蛋”问题：缺乏精确投影模型影响特征提取效果，而高质量特征又是实现准确标定的前提。因此，作者希望找出最适合鱼眼图像自标定的特征检测器与描述子。

Method: 作者在未使用专为全向图像设计的特征算法的前提下，对标准特征检测与描述方法在鱼眼图像上的性能进行了系统性实验评估。研究基于自建的PFSeq数据集，聚焦于支持后续鱼眼视觉里程计和立体视觉的自标定流程。

Result: 报告提供了详尽的实验结果和参考文献，确定了在当时（2014年）最适合鱼眼图像自标定任务的特征检测与描述组合。但未与专为全向图像设计的算法进行比较。

Conclusion: 本工作为鱼眼图像处理中的特征选择问题提供了实证参考，并公开了PFSeq数据集以促进后续研究。作者强调这是一份未经同行评审的2014年研究报告，其结论需结合当时的技术背景理解。

Abstract: What is this report: This is a scientific report, contributing with a detailed bibliography, a dataset which we will call now PFSeq for ''Photorealistic Fisheye Sequence'' and make available at https://doi.org/10. 57745/DYIVVU, and comprehensive experiments. This work should be considered as a draft, and has been done during my PhD thesis ''Construction of 3D models from fisheye video data-Application to the localisation in urban area'' in 2014 [Mor16]. These results have never been published. The aim was to find the best features detector and descriptor for fisheye images, in the context of selfcalibration, with cameras mounted on the top of a car and aiming at the zenith (to proceed then fisheye visual odometry and stereovision in urban scenes). We face a chicken and egg problem, because we can not take advantage of an accurate projection model for an optimal features detection and description, and we rightly need good features to perform the calibration (i.e. to compute the accurate projection model of the camera). What is not this report: It does not contribute with new features algorithm. It does not compare standard features algorithms to algorithms designed for omnidirectional images (unfortunately). It has not been peer-reviewed. Discussions have been translated and enhanced but the experiments have not been run again and the report has not been updated accordingly to the evolution of the state-of-the-art (read this as a 2014 report).

</details>


### [42] [VGGT-Motion: Motion-Aware Calibration-Free Monocular SLAM for Long-Range Consistency](https://arxiv.org/abs/2602.05508)
*Zhuang Xiong,Chen Zhang,Qingshan Xu,Wenbing Tao*

Main category: cs.CV

TL;DR: 本文提出VGGT-Motion，一种无需标定的单目SLAM系统，通过运动感知子图构建与锚点驱动的直接Sim(3)配准，在长距离轨迹上实现高效且鲁棒的全局一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D视觉基础模型的无标定单目SLAM在长序列中仍存在严重尺度漂移问题，主要源于运动无关的子图划分破坏上下文连贯性，并引发零运动漂移；同时传统几何对齐方法计算开销大。

Method: 1）提出运动感知子图构建机制，利用光流引导自适应划分、剔除静态冗余并封装转弯以保持局部几何稳定性；2）设计锚点驱动的直接Sim(3)配准策略，通过上下文平衡锚点实现无需搜索的像素级稠密对齐和高效回环检测；3）采用轻量级子图级位姿图优化，以线性复杂度保障全局一致性。

Result: 实验表明，VGGT-Motion显著提升了轨迹精度与效率，在零样本、长距离、无标定单目SLAM任务中达到当前最优性能。

Conclusion: VGGT-Motion有效解决了长序列下无标定单目SLAM的尺度漂移与计算效率问题，为大规模场景下的鲁棒定位提供了可行方案。

Abstract: Despite recent progress in calibration-free monocular SLAM via 3D vision foundation models, scale drift remains severe on long sequences. Motion-agnostic partitioning breaks contextual coherence and causes zero-motion drift, while conventional geometric alignment is computationally expensive. To address these issues, we propose VGGT-Motion, a calibration-free SLAM system for efficient and robust global consistency over kilometer-scale trajectories. Specifically, we first propose a motion-aware submap construction mechanism that uses optical flow to guide adaptive partitioning, prune static redundancy, and encapsulate turns for stable local geometry. We then design an anchor-driven direct Sim(3) registration strategy. By exploiting context-balanced anchors, it achieves search-free, pixel-wise dense alignment and efficient loop closure without costly feature matching. Finally, a lightweight submap-level pose graph optimization enforces global consistency with linear complexity, enabling scalable long-range operation. Experiments show that VGGT-Motion markedly improves trajectory accuracy and efficiency, achieving state-of-the-art performance in zero-shot, long-range calibration-free monocular SLAM.

</details>


### [43] [Generalization of Self-Supervised Vision Transformers for Protein Localization Across Microscopy Domains](https://arxiv.org/abs/2602.05527)
*Ben Isselmann,Dilara Göksu,Andreas Weinmann*

Main category: cs.CV

TL;DR: 本文研究了在不同显微镜成像域（如染色方法和通道配置不同）之间，使用DINO自监督预训练的Vision Transformer模型进行蛋白定位任务的迁移能力。结果表明，基于人类蛋白质图谱（HPA）预训练的模型在OpenCell数据集上表现最佳，说明领域相关的自监督预训练能有效提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 显微镜任务特定数据集通常规模较小，难以训练出具有鲁棒特征表示的深度学习模型；而自监督学习虽可通过大规模无标签数据预训练缓解此问题，但其跨显微镜域的迁移能力尚不明确。

Method: 作者使用三种在不同数据集（ImageNet-1k、HPA、OpenCell）上预训练的DINO Vision Transformer模型，在OpenCell数据集上提取图像嵌入，并在其上训练有监督分类头以评估迁移性能。

Result: 所有预训练模型均表现出良好的迁移能力，其中HPA预训练模型效果最佳（平均macro F1得分为0.8221 ± 0.0062），略优于直接在OpenCell上预训练的模型（0.8057 ± 0.0090）。

Conclusion: 大规模、领域相关的自监督预训练能够有效泛化到相关但不同的显微镜数据集，在任务特定标注数据有限的情况下仍可实现优异的下游性能。

Abstract: Task-specific microscopy datasets are often too small to train deep learning models that learn robust feature representations. Self-supervised learning (SSL) can mitigate this by pretraining on large unlabeled datasets, but it remains unclear how well such representations transfer across microscopy domains with different staining protocols and channel configurations. We investigate the cross-domain transferability of DINO-pretrained Vision Transformers for protein localization on the OpenCell dataset. We generate image embeddings using three DINO backbones pretrained on ImageNet-1k, the Human Protein Atlas (HPA), and OpenCell, and evaluate them by training a supervised classification head on OpenCell labels. All pretrained models transfer well, with the microscopy-specific HPA-pretrained model achieving the best performance (mean macro $F_1$-score = 0.8221 \pm 0.0062), slightly outperforming a DINO model trained directly on OpenCell (0.8057 \pm 0.0090). These results highlight the value of large-scale pretraining and indicate that domain-relevant SSL representations can generalize effectively to related but distinct microscopy datasets, enabling strong downstream performance even when task-specific labeled data are limited.

</details>


### [44] [SSG: Scaled Spatial Guidance for Multi-Scale Visual Autoregressive Generation](https://arxiv.org/abs/2602.05534)
*Youngwoo Shin,Jiwan Hur,Junmo Kim*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的推理时引导方法 SSG（Scaled Spatial Guidance），通过在频率域中提取语义残差，强化视觉自回归（VAR）模型在多尺度生成中的高频信息贡献，从而缓解训练与推理之间的不一致问题，提升生成图像的保真度与多样性，同时保持低延迟。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归（VAR）模型在推理过程中常因模型容量有限和误差累积，导致其本应具备的由粗到细的生成机制发生偏移，造成训练与推理不一致。作者从信息论角度出发，旨在解决这一问题。

Method: 提出 Scaled Spatial Guidance（SSG）方法，在推理阶段引导 VAR 模型维持预期的层次结构。SSG 通过 Discrete Spatial Enhancement（DSE）在频域中构建更清晰的粗粒度先验，从中提取“语义残差”作为目标高频信号，并加以强调。

Result: 实验表明，SSG 在多种基于离散视觉 token 的 VAR 模型上均能一致提升生成图像的保真度和多样性，同时不牺牲推理速度。

Conclusion: SSG 有效挖掘了由粗到细图像生成范式中未被充分利用的效率潜力，为提升 VAR 模型性能提供了一种通用、高效且无需重新训练的解决方案。

Abstract: Visual autoregressive (VAR) models generate images through next-scale prediction, naturally achieving coarse-to-fine, fast, high-fidelity synthesis mirroring human perception. In practice, this hierarchy can drift at inference time, as limited capacity and accumulated error cause the model to deviate from its coarse-to-fine nature. We revisit this limitation from an information-theoretic perspective and deduce that ensuring each scale contributes high-frequency content not explained by earlier scales mitigates the train-inference discrepancy. With this insight, we propose Scaled Spatial Guidance (SSG), training-free, inference-time guidance that steers generation toward the intended hierarchy while maintaining global coherence. SSG emphasizes target high-frequency signals, defined as the semantic residual, isolated from a coarser prior. To obtain this prior, we leverage a principled frequency-domain procedure, Discrete Spatial Enhancement (DSE), which is devised to sharpen and better isolate the semantic residual through frequency-aware construction. SSG applies broadly across VAR models leveraging discrete visual tokens, regardless of tokenization design or conditioning modality. Experiments demonstrate SSG yields consistent gains in fidelity and diversity while preserving low latency, revealing untapped efficiency in coarse-to-fine image generation. Code is available at https://github.com/Youngwoo-git/SSG.

</details>


### [45] [A Comparative Study of 3D Person Detection: Sensor Modalities and Robustness in Diverse Indoor and Outdoor Environments](https://arxiv.org/abs/2602.05538)
*Malaz Tamim,Andrea Matic-Flierl,Karsten Roscher*

Main category: cs.CV

TL;DR: 本文系统评估了仅用相机、仅用LiDAR以及相机-LiDAR融合三种方法在3D人体检测中的性能，发现融合方法（DAL）在多样场景中表现最优，尤其在遮挡和远距离等挑战性条件下，但对传感器错位和LiDAR损坏仍较敏感。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体检测研究多聚焦于自动驾驶场景，缺乏在多样化室内外环境中的系统性评估；同时，不同传感器模态（相机、LiDAR及其融合）在鲁棒性和性能方面的比较尚不充分。

Method: 在JRDB数据集上，对比三种代表性模型：BEVDepth（仅相机）、PointPillars（仅LiDAR）和DAL（相机-LiDAR融合），分析其在不同遮挡程度、距离条件下的检测性能，并进一步评估它们在传感器损坏和错位情况下的鲁棒性。

Result: 融合方法DAL在各类场景中均优于单模态方法，尤其在遮挡和远距离情况下优势明显；但DAL对传感器错位和特定LiDAR损坏仍敏感。BEVDepth性能最差，受遮挡、距离和噪声影响最大。

Conclusion: 传感器融合能显著提升3D人体检测性能，但现有融合系统仍存在对传感器校准误差和损坏的脆弱性，需进一步研究以增强其鲁棒性。

Abstract: Accurate 3D person detection is critical for safety in applications such as robotics, industrial monitoring, and surveillance. This work presents a systematic evaluation of 3D person detection using camera-only, LiDAR-only, and camera-LiDAR fusion. While most existing research focuses on autonomous driving, we explore detection performance and robustness in diverse indoor and outdoor scenes using the JRDB dataset. We compare three representative models - BEVDepth (camera), PointPillars (LiDAR), and DAL (camera-LiDAR fusion) - and analyze their behavior under varying occlusion and distance levels. Our results show that the fusion-based approach consistently outperforms single-modality models, particularly in challenging scenarios. We further investigate robustness against sensor corruptions and misalignments, revealing that while DAL offers improved resilience, it remains sensitive to sensor misalignment and certain LiDAR-based corruptions. In contrast, the camera-based BEVDepth model showed the lowest performance and was most affected by occlusion, distance, and noise. Our findings highlight the importance of utilizing sensor fusion for enhanced 3D person detection, while also underscoring the need for ongoing research to address the vulnerabilities inherent in these systems.

</details>


### [46] [FastVMT: Eliminating Redundancy in Video Motion Transfer](https://arxiv.org/abs/2602.05551)
*Yue Ma,Zhikai Wang,Tianhao Ren,Mingzhe Zheng,Hongyu Liu,Jiayi Guo,Mark Fong,Yuxuan Xue,Zixiang Zhao,Konrad Schindler,Qifeng Chen,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出FastVMT方法，通过消除运动冗余和梯度冗余，在不损失视频质量的前提下将视频运动迁移速度提升3.43倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于DiT架构的视频运动迁移方法在运行效率上存在结构性冗余，导致计算开销大、推理速度慢。

Method: 针对运动冗余，在注意力层引入局部邻域掩码以避免远距离区域的无效计算；针对梯度冗余，设计梯度复用机制，在扩散过程中跳过不必要的梯度计算。

Result: FastVMT在保持生成视频视觉保真度和时序一致性的前提下，平均实现3.43倍的加速。

Conclusion: 通过识别并消除DiT中的两类计算冗余，可显著提升视频运动迁移的效率，为高效视频生成提供了新思路。

Abstract: Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.

</details>


### [47] [IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools](https://arxiv.org/abs/2602.05555)
*Panagiotis Sapoutzoglou,Orestis Vaggelis,Athina Zacharia,Evangelos Sartinas,Maria Pateraki*

Main category: cs.CV

TL;DR: IndustryShapes 是一个面向工业工具与组件的新型 RGB-D 基准数据集，支持实例级和新物体 6D 姿态估计，填补了实验室研究与实际制造场景之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多聚焦于家用或消费类产品，或在高度受控环境中采集，难以反映真实工业场景的复杂性；因此需要一个更贴近实际工业应用的数据集以推动 6D 姿态估计算法在制造业中的落地。

Method: 构建包含五类具有挑战性工业物体的新数据集 IndustryShapes，涵盖单/多物体、同物多实例等多样场景，并提供经典集（4.6k 图像，6k 标注姿态）和扩展集（支持无模型与序列方法评估），首次引入 RGB-D 静态上线序列。

Result: 对多种当前先进方法（包括实例级与新物体 6D 姿态估计、目标检测与分割）进行评估，结果显示在该数据集上性能仍有提升空间。

Conclusion: IndustryShapes 为工业机器人领域的 6D 姿态估计提供了更真实、更具应用价值的基准，有助于推动算法从实验室走向实际部署。

Abstract: We introduce IndustryShapes, a new RGB-D benchmark dataset of industrial tools and components, designed for both instance-level and novel object 6D pose estimation approaches. The dataset provides a realistic and application-relevant testbed for benchmarking these methods in the context of industrial robotics bridging the gap between lab-based research and deployment in real-world manufacturing scenarios. Unlike many previous datasets that focus on household or consumer products or use synthetic, clean tabletop datasets, or objects captured solely in controlled lab environments, IndustryShapes introduces five new object types with challenging properties, also captured in realistic industrial assembly settings. The dataset has diverse complexity, from simple to more challenging scenes, with single and multiple objects, including scenes with multiple instances of the same object and it is organized in two parts: the classic set and the extended set. The classic set includes a total of 4,6k images and 6k annotated poses. The extended set introduces additional data modalities to support the evaluation of model-free and sequence-based approaches. To the best of our knowledge, IndustryShapes is the first dataset to offer RGB-D static onboarding sequences. We further evaluate the dataset on a representative set of state-of-the art methods for instance-based and novel object 6D pose estimation, including also object detection, segmentation, showing that there is room for improvement in this domain. The dataset page can be found in https://pose-lab.github.io/IndustryShapes.

</details>


### [48] [PIRATR: Parametric Object Inference for Robotic Applications with Transformers in 3D Point Clouds](https://arxiv.org/abs/2602.05557)
*Michael Schwingshackl,Fabio F. Oberweger,Mario Niedermeyer,Huemer Johannes,Markus Murschitz*

Main category: cs.CV

TL;DR: PIRATR 是一种端到端的3D目标检测框架，可直接从受遮挡的点云中联合估计多类物体的6自由度姿态和类别特定参数属性，在完全合成数据训练下在真实户外LiDAR数据上取得0.919 mAP。


<details>
  <summary>Details</summary>
Motivation: 现有3D检测方法难以同时实现几何定位与任务相关参数（如夹爪开合度）的估计，且缺乏对新物体类别的灵活扩展能力；作者旨在构建一个可泛化、可扩展、适用于机器人场景的参数化感知系统。

Method: 基于PI3DETR扩展，采用模块化、类别特定的头部结构，直接从遮挡点云中联合预测多类6-DoF姿态和预定义规则下的参数化属性，整个系统在合成环境中训练，无需微调即可部署。

Result: 在自动叉车平台上验证，针对起重机夹爪、装卸平台和托盘三类物体，在真实户外LiDAR扫描中达到0.919 mAP，展现出优异的跨域泛化能力。

Conclusion: PIRATR 提出了一种姿态感知的参数化感知范式，弥合了几何推理与可执行世界模型之间的鸿沟，为动态机器人环境中部署基于仿真的可扩展感知系统提供了可行路径。

Abstract: We present PIRATR, an end-to-end 3D object detection framework for robotic use cases in point clouds. Extending PI3DETR, our method streamlines parametric 3D object detection by jointly estimating multi-class 6-DoF poses and class-specific parametric attributes directly from occlusion-affected point cloud data. This formulation enables not only geometric localization but also the estimation of task-relevant properties for parametric objects, such as a gripper's opening, where the 3D model is adjusted according to simple, predefined rules. The architecture employs modular, class-specific heads, making it straightforward to extend to novel object types without re-designing the pipeline. We validate PIRATR on an automated forklift platform, focusing on three structurally and functionally diverse categories: crane grippers, loading platforms, and pallets. Trained entirely in a synthetic environment, PIRATR generalizes effectively to real outdoor LiDAR scans, achieving a detection mAP of 0.919 without additional fine-tuning. PIRATR establishes a new paradigm of pose-aware, parameterized perception. This bridges the gap between low-level geometric reasoning and actionable world models, paving the way for scalable, simulation-trained perception systems that can be deployed in dynamic robotic environments. Code available at https://github.com/swingaxe/piratr.

</details>


### [49] [Visual Implicit Geometry Transformer for Autonomous Driving](https://arxiv.org/abs/2602.05573)
*Arsenii Shirokov,Mikhail Kuznetsov,Danila Stepochkin,Egor Evdokimov,Daniil Glazkov,Nikolay Patakin,Anton Konushin,Dmitry Senushkin*

Main category: cs.CV

TL;DR: ViGT 是一种用于自动驾驶的视觉隐式几何 Transformer，通过自监督方式从环视图像估计连续的 3D 占据场，无需标定且支持多数据集训练，在点图估计任务中达到 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有几何模型在自动驾驶中存在依赖标注、难以泛化到不同传感器配置、架构复杂等问题。作者旨在构建一个可扩展、结构简单、能跨传感器配置泛化的基础几何模型。

Method: ViGT 采用无标定（calibration-free）架构，将多视角图像直接映射到鸟瞰图（BEV）下的连续 3D 占据场；利用同步的图像-LiDAR 数据对进行自监督训练，避免人工标注；在五个大规模自动驾驶数据集上联合训练。

Result: 在点图估计任务中，ViGT 在所有基线方法中平均排名最佳；在 Occ3D-nuScenes 基准上，其性能与有监督方法相当。

Conclusion: ViGT 展示了在无需标定和人工标注条件下，构建可扩展、通用的自动驾驶几何基础模型的可行性，为多任务几何感知提供了统一表示。

Abstract: We introduce the Visual Implicit Geometry Transformer (ViGT), an autonomous driving geometric model that estimates continuous 3D occupancy fields from surround-view camera rigs. ViGT represents a step towards foundational geometric models for autonomous driving, prioritizing scalability, architectural simplicity, and generalization across diverse sensor configurations. Our approach achieves this through a calibration-free architecture, enabling a single model to adapt to different sensor setups. Unlike general-purpose geometric foundational models that focus on pixel-aligned predictions, ViGT estimates a continuous 3D occupancy field in a birds-eye-view (BEV) addressing domain-specific requirements. ViGT naturally infers geometry from multiple camera views into a single metric coordinate frame, providing a common representation for multiple geometric tasks. Unlike most existing occupancy models, we adopt a self-supervised training procedure that leverages synchronized image-LiDAR pairs, eliminating the need for costly manual annotations. We validate the scalability and generalizability of our approach by training our model on a mixture of five large-scale autonomous driving datasets (NuScenes, Waymo, NuPlan, ONCE, and Argoverse) and achieving state-of-the-art performance on the pointmap estimation task, with the best average rank across all evaluated baselines. We further evaluate ViGT on the Occ3D-nuScenes benchmark, where ViGT achieves comparable performance with supervised methods. The source code is publicly available at \href{https://github.com/whesense/ViGT}{https://github.com/whesense/ViGT}.

</details>


### [50] [LocateEdit-Bench: A Benchmark for Instruction-Based Editing Localization](https://arxiv.org/abs/2602.05577)
*Shiyu Wu,Shuyan Li,Jing Li,Jing Liu,Yequan Wang*

Main category: cs.CV

TL;DR: 本文提出了LocateEdit-Bench，一个包含23.1万张编辑图像的大规模数据集，用于评估针对指令驱动图像编辑的伪造定位方法。


<details>
  <summary>Details</summary>
Motivation: 现有伪造定位方法主要针对基于修复的图像篡改，难以应对新兴的指令式图像编辑技术，因此亟需新的基准数据集来推动该领域发展。

Method: 构建包含四种先进编辑模型和三种常见编辑类型的大规模数据集LocateEdit-Bench，并设计两种多指标评估协议以评测现有定位方法。

Result: 对数据集进行了详细分析，并通过所提出的评估协议验证了现有方法在指令驱动编辑场景下的局限性。

Conclusion: LocateEdit-Bench为应对不断演进的图像编辑技术提供了坚实基础，有助于推动未来伪造定位方法的发展。

Abstract: Recent advancements in image editing have enabled highly controllable and semantically-aware alteration of visual content, posing unprecedented challenges to manipulation localization. However, existing AI-generated forgery localization methods primarily focus on inpainting-based manipulations, making them ineffective against the latest instruction-based editing paradigms. To bridge this critical gap, we propose LocateEdit-Bench, a large-scale dataset comprising $231$K edited images, designed specifically to benchmark localization methods against instruction-driven image editing. Our dataset incorporates four cutting-edge editing models and covers three common edit types. We conduct a detailed analysis of the dataset and develop two multi-metric evaluation protocols to assess existing localization methods. Our work establishes a foundation to keep pace with the evolving landscape of image editing, thereby facilitating the development of effective methods for future forgery localization. Dataset will be open-sourced upon acceptance.

</details>


### [51] [Geometric Observability Index: An Operator-Theoretic Framework for Per-Feature Sensitivity, Weak Observability, and Dynamic Effects in SE(3) Pose Estimation](https://arxiv.org/abs/2602.05582)
*Joe-Mei Feng,Sheng-Wei Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于李群SE(3)的统一算子理论框架，通过引入几何可观测性指数（GOI）来量化单个图像特征对相机位姿估计的影响，并揭示了弱可观测性与敏感性之间的几何关系。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如条件分析、欧氏扰动和Fisher信息界）无法解释单个图像特征如何影响位姿估计，也无法说明动态或不一致观测为何会显著干扰现代SLAM和运动恢复结构系统。为此，作者旨在建立一个能刻画单个测量对估计影响的几何一致框架。

Method: 将影响函数理论推广到矩阵李群上，针对SE(3)上的左平凡化M估计器推导出内蕴扰动算子，并定义了几何可观测性指数（GOI）。该指数基于曲率算子和可观测子空间的李代数结构，通过谱分解揭示主方向上的敏感性。

Result: GOI在总体极限下与SE(3)上的Fisher信息几何一致，提供了Cramér-Rao界在单次测量下的类比；同时能解释纯旋转、视差消失等经典退化情形，以及动态特征在弱曲率方向上的放大效应。此外，GOI和曲率谱可作为轻量级、无需训练的诊断信号，用于识别动态特征和弱可观测构型。

Conclusion: GOI通过曲率算子的谱几何，统一了条件分析、Fisher信息、影响函数理论和动态场景可检测性，为现有SLAM系统提供了一种无需修改架构即可实现的敏感性诊断工具。

Abstract: We present a unified operator-theoretic framework for analyzing per-feature sensitivity in camera pose estimation on the Lie group SE(3). Classical sensitivity tools - conditioning analyses, Euclidean perturbation arguments, and Fisher information bounds - do not explain how individual image features influence the pose estimate, nor why dynamic or inconsistent observations can disproportionately distort modern SLAM and structure-from-motion systems. To address this gap, we extend influence function theory to matrix Lie groups and derive an intrinsic perturbation operator for left-trivialized M-estimators on SE(3).
  The resulting Geometric Observability Index (GOI) quantifies the contribution of a single measurement through the curvature operator and the Lie algebraic structure of the observable subspace. GOI admits a spectral decomposition along the principal directions of the observable curvature, revealing a direct correspondence between weak observability and amplified sensitivity. In the population regime, GOI coincides with the Fisher information geometry on SE(3), yielding a single-measurement analogue of the Cramer-Rao bound.
  The same spectral mechanism explains classical degeneracies such as pure rotation and vanishing parallax, as well as dynamic feature amplification along weak curvature directions. Overall, GOI provides a geometrically consistent description of measurement influence that unifies conditioning analysis, Fisher information geometry, influence function theory, and dynamic scene detectability through the spectral geometry of the curvature operator. Because these quantities arise directly within Gauss-Newton pipelines, the curvature spectrum and GOI also yield lightweight, training-free diagnostic signals for identifying dynamic features and detecting weak observability configurations without modifying existing SLAM architectures.

</details>


### [52] [EgoPoseVR: Spatiotemporal Multi-Modal Reasoning for Egocentric Full-Body Pose in Virtual Reality](https://arxiv.org/abs/2602.05590)
*Haojie Cheng,Shaun Jing Heng Ong,Shaoyu Cai,Aiden Tat Yang Koh,Fuxi Ouyang,Eng Tat Khoo*

Main category: cs.CV

TL;DR: EgoPoseVR 是一种用于 VR 中准确、实时全身姿态估计的端到端框架，融合头显运动信息与 RGB-D 视觉数据，在准确性和稳定性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于头戴相机的自我中心姿态估计方法在 VR 头显应用中存在时间不稳定性、下半身估计不准及缺乏实时性等问题，亟需改进。

Method: 提出 EgoPoseVR 框架，通过双模态融合管道整合头显运动线索与 RGB-D 观测；采用时空编码器提取帧级与关节级特征，并通过交叉注意力机制融合；引入运动学优化模块，利用头显信号施加约束以提升姿态估计的准确性与稳定性。同时构建包含 180 万帧的大规模合成数据集用于训练与评估。

Result: 实验表明 EgoPoseVR 在客观指标上优于当前最先进的自我中心姿态估计模型；真实场景用户研究显示其在准确性、稳定性、具身感和未来使用意愿方面显著优于基线方法。

Conclusion: EgoPoseVR 实现了无需额外穿戴传感器或房间级追踪系统的鲁棒全身姿态跟踪，为 VR 中高保真具身交互提供了实用解决方案。

Abstract: Immersive virtual reality (VR) applications demand accurate, temporally coherent full-body pose tracking. Recent head-mounted camera-based approaches show promise in egocentric pose estimation, but encounter challenges when applied to VR head-mounted displays (HMDs), including temporal instability, inaccurate lower-body estimation, and the lack of real-time performance. To address these limitations, we present EgoPoseVR, an end-to-end framework for accurate egocentric full-body pose estimation in VR that integrates headset motion cues with egocentric RGB-D observations through a dual-modality fusion pipeline. A spatiotemporal encoder extracts frame- and joint-level representations, which are fused via cross-attention to fully exploit complementary motion cues across modalities. A kinematic optimization module then imposes constraints from HMD signals, enhancing the accuracy and stability of pose estimation. To facilitate training and evaluation, we introduce a large-scale synthetic dataset of over 1.8 million temporally aligned HMD and RGB-D frames across diverse VR scenarios. Experimental results show that EgoPoseVR outperforms state-of-the-art egocentric pose estimation models. A user study in real-world scenes further shows that EgoPoseVR achieved significantly higher subjective ratings in accuracy, stability, embodiment, and intention for future use compared to baseline methods. These results show that EgoPoseVR enables robust full-body pose tracking, offering a practical solution for accurate VR embodiment without requiring additional body-worn sensors or room-scale tracking systems.

</details>


### [53] [CAViT -- Channel-Aware Vision Transformer for Dynamic Feature Fusion](https://arxiv.org/abs/2602.05598)
*Aon Safdar,Mohamed Saadeldin*

Main category: cs.CV

TL;DR: CAViT 是一种新型双注意力 Vision Transformer 架构，通过引入动态通道自注意力机制替代静态 MLP，在不增加模型复杂度的前提下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统 Vision Transformer 中的通道混合依赖固定 MLP，缺乏对输入内容的适应性，限制了特征表达能力。

Method: 在每个 Transformer 块中依次应用空间自注意力和通道自注意力，实现基于全局图像上下文的动态特征重校准。

Result: 在五个自然与医学图像数据集上，CAViT 相比标准 ViT 提升最高达 3.6% 准确率，同时减少超过 30% 的参数量和 FLOPs。

Conclusion: CAViT 通过统一且内容感知的 token 混合策略，有效增强了模型表达能力，验证了注意力驱动通道交互的优越性。

Abstract: Vision Transformers (ViTs) have demonstrated strong performance across a range of computer vision tasks by modeling long-range spatial interactions via self-attention. However, channel-wise mixing in ViTs remains static, relying on fixed multilayer perceptrons (MLPs) that lack adaptability to input content. We introduce 'CAViT', a dual-attention architecture that replaces the static MLP with a dynamic, attention-based mechanism for feature interaction. Each Transformer block in CAViT performs spatial self-attention followed by channel-wise self-attention, allowing the model to dynamically recalibrate feature representations based on global image context. This unified and content-aware token mixing strategy enhances representational expressiveness without increasing depth or complexity. We validate CAViT across five benchmark datasets spanning both natural and medical domains, where it outperforms the standard ViT baseline by up to +3.6% in accuracy, while reducing parameter count and FLOPs by over 30%. Qualitative attention maps reveal sharper and semantically meaningful activation patterns, validating the effectiveness of our attention-driven token mixing.

</details>


### [54] [Multi-instance robust fitting for non-classical geometric models](https://arxiv.org/abs/2602.05602)
*Zongliang Zhang,Shuxiang Li,Xingwang Huang,Zongyue Wang*

Main category: cs.CV

TL;DR: 本文提出一种无需预设误差阈值的鲁棒估计器，结合元启发式优化算法，用于从含噪数据中同时拟合多个非经典模型实例。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒拟合方法主要针对经典几何模型（如直线、平面），对非经典模型（如螺旋曲线、自由曲面等）支持有限，且大多仅处理单实例拟合问题。本文旨在解决多实例非经典模型的鲁棒拟合挑战。

Method: 将多实例拟合建模为优化问题，提出基于模型到数据误差的新估计器以处理离群点，并采用元启发式算法优化该不可微目标函数，从而寻找全局最优解。

Result: 在多种非经典模型上的实验验证了所提方法的有效性，代码已开源。

Conclusion: 该方法能有效处理含噪数据中多个非经典模型的鲁棒拟合问题，克服了传统方法对误差阈值依赖和单实例限制的不足。

Abstract: Most existing robust fitting methods are designed for classical models, such as lines, circles, and planes. In contrast, fewer methods have been developed to robustly handle non-classical models, such as spiral curves, procedural character models, and free-form surfaces. Furthermore, existing methods primarily focus on reconstructing a single instance of a non-classical model. This paper aims to reconstruct multiple instances of non-classical models from noisy data. We formulate this multi-instance fitting task as an optimization problem, which comprises an estimator and an optimizer. Specifically, we propose a novel estimator based on the model-to-data error, capable of handling outliers without a predefined error threshold. Since the proposed estimator is non-differentiable with respect to the model parameters, we employ a meta-heuristic algorithm as the optimizer to seek the global optimum. The effectiveness of our method are demonstrated through experimental results on various non-classical models. The code is available at https://github.com/zhangzongliang/fitting.

</details>


### [55] [Unified Sensor Simulation for Autonomous Driving](https://arxiv.org/abs/2602.05617)
*Nikolay Patakin,Arsenii Shirokov,Anton Konushin,Dmitry Senushkin*

Main category: cs.CV

TL;DR: 本文提出了XSIM，一种面向自动驾驶的传感器仿真框架，通过改进3DGUT splatting方法，解决了球形传感器（如LiDAR）在方位角边界处的投影不连续问题，并引入双透明度参数提升几何与外观一致性，在多个自动驾驶数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DGUT splatting方法在处理球形摄像头（如LiDAR）时存在因方位角边界处的时间和形状不连续性导致的错误投影问题，限制了其在自动驾驶场景中的准确性和真实性。因此，需要一个更通用、灵活且能处理复杂传感器畸变的仿真框架。

Method: XSIM扩展了3DGUT splatting，引入了适用于自动驾驶的广义滚动快门建模；提出相位建模机制以处理方位角边界处高斯投影的时间与形状不连续性；并采用包含两个独立透明度参数的扩展3D高斯表示，以对齐几何与颜色分布。

Result: 在Waymo Open Dataset、Argoverse 2和PandaSet等多个自动驾驶数据集上的实验表明，XSIM在几何一致性和视觉真实感方面均优于当前先进方法，取得了SOTA结果。

Conclusion: XSIM提供了一个统一、灵活且高效的传感器仿真框架，有效解决了球形传感器在动态环境中的建模难题，显著提升了自动驾驶场景的渲染质量与仿真准确性。

Abstract: In this work, we introduce \textbf{XSIM}, a sensor simulation framework for autonomous driving. XSIM extends 3DGUT splatting with a generalized rolling-shutter modeling tailored for autonomous driving applications. Our framework provides a unified and flexible formulation for appearance and geometric sensor modeling, enabling rendering of complex sensor distortions in dynamic environments. We identify spherical cameras, such as LiDARs, as a critical edge case for existing 3DGUT splatting due to cyclic projection and time discontinuities at azimuth boundaries leading to incorrect particle projection. To address this issue, we propose a phase modeling mechanism that explicitly accounts temporal and shape discontinuities of Gaussians projected by the Unscented Transform at azimuth borders. In addition, we introduce an extended 3D Gaussian representation that incorporates two distinct opacity parameters to resolve mismatches between geometry and color distributions. As a result, our framework provides enhanced scene representations with improved geometric consistency and photorealistic appearance. We evaluate our framework extensively on multiple autonomous driving datasets, including Waymo Open Dataset, Argoverse 2, and PandaSet. Our framework consistently outperforms strong recent baselines and achieves state-of-the-art performance across all datasets. The source code is publicly available at \href{https://github.com/whesense/XSIM}{https://github.com/whesense/XSIM}.

</details>


### [56] [UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos](https://arxiv.org/abs/2602.05638)
*Jinlin Wu,Felix Holm,Chuxi Chen,An Wang,Yaxin Hu,Xiaofan Ye,Zelin Zang,Miao Xu,Lihua Zhou,Huai Liao,Danny T. M. Chan,Ming Feng,Wai S. Poon,Hongliang Ren,Dong Yi,Nassir Navab,Gaofeng Meng,Jiebo Luo,Hongbin Liu,Zhen Lei*

Main category: cs.CV

TL;DR: UniSurg 是一种新型视频原生基础模型，通过从像素级重建转向潜在运动预测，显著提升了手术视频理解的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手术视频分析方法过度关注低层次视觉细节（如烟雾、镜面反射和流体运动），而忽略了对语义结构的学习，限制了模型在手术理解任务中的表现。

Method: 基于 V-JEPA 架构，UniSurg 引入三项关键技术：1）运动引导的潜在预测，聚焦语义重要区域；2）时空亲和性自蒸馏，增强关系一致性；3）特征多样性正则化，防止在纹理稀疏场景中表征崩溃。同时构建了包含 3,658 小时视频的 UniSurg-15M 数据集用于大规模预训练。

Result: 在 17 个基准测试中，UniSurg 在手术工作流识别（EgoSurgery F1 +14.6%，PitVis +10.3%）、动作三元组识别（CholecT50 mAP-IVT 39.54%）、技能评估、息肉分割和深度估计等任务上均显著优于现有最先进方法。

Conclusion: UniSurg 为通用、以运动为导向的手术视频理解树立了新标准。

Abstract: While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.

</details>


### [57] [Enhancing Personality Recognition by Comparing the Predictive Power of Traits, Facets, and Nuances](https://arxiv.org/abs/2602.05650)
*Amir Ansari,Jana Subirana,Bruna Silva,Sergio Escalera,David Gallardo-Pujol,Cristina Palmero*

Main category: cs.CV

TL;DR: 本文通过利用大五人格模型中更细粒度的层次（方面和细微特征），在UDIVA v0.5数据集上训练基于Transformer的跨模态、双人感知模型，发现细微特征层级的模型在音视频交互数据中的人格识别任务上显著优于传统特质层级模型，均方误差最多降低74%。


<details>
  <summary>Details</summary>
Motivation: 传统人格识别模型依赖于粗粒度的大五人格特质得分作为真实标签，且训练数据有限，导致模型泛化能力受限，因为相同特质得分可能对应多种上下文相关的行为表现。因此，作者希望探索更细粒度的人格层次（如方面和细微特征）是否能提升模型性能。

Method: 在UDIVA v0.5数据集上，构建了一个基于Transformer的模型，引入跨模态（音视频）和跨个体（双人感知）注意力机制，并分别在特质、方面和细微特征三个层级上进行训练与比较。

Result: 细微特征层级的模型在所有交互场景中均优于方面和特质层级模型，均方误差最多降低74%。

Conclusion: 利用人格结构中更细粒度的层次（特别是细微特征）可显著提升从音视频交互数据中识别人格的准确性，为未来人格计算研究提供了新方向。

Abstract: Personality is a complex, hierarchical construct typically assessed through item-level questionnaires aggregated into broad trait scores. Personality recognition models aim to infer personality traits from different sources of behavioral data. However, reliance on broad trait scores as ground truth, combined with limited training data, poses challenges for generalization, as similar trait scores can manifest through diverse, context dependent behaviors. In this work, we explore the predictive impact of the more granular hierarchical levels of the Big-Five Personality Model, facets and nuances, to enhance personality recognition from audiovisual interaction data. Using the UDIVA v0.5 dataset, we trained a transformer-based model including cross-modal (audiovisual) and cross-subject (dyad-aware) attention mechanisms. Results show that nuance-level models consistently outperform facet and trait-level models, reducing mean squared error by up to 74% across interaction scenarios.

</details>


### [58] [ShapeUP: Scalable Image-Conditioned 3D Editing](https://arxiv.org/abs/2602.05676)
*Inbar Gat,Dana Cohen-Bar,Guy Levy,Elad Richardson,Daniel Cohen-Or*

Main category: cs.CV

TL;DR: 本文提出ShapeUP，一种可扩展的、基于图像条件的3D编辑框架，通过在原生3D表示中进行监督的潜在空间到潜在空间的转换，实现高保真且结构一致的3D编辑。


<details>
  <summary>Details</summary>
Motivation: 现有3D编辑方法在视觉可控性、几何一致性和可扩展性之间难以兼顾：基于优化的方法速度慢，多视图2D传播方法存在视觉漂移，无训练的潜在空间操纵方法受限于固定先验且无法从模型扩展中受益。

Method: ShapeUP利用预训练的3D基础模型，通过监督训练将其适配于编辑任务。该方法使用三元组数据（源3D形状、编辑后的2D图像、对应的编辑后3D形状）训练一个3D扩散Transformer（DiT），将编辑建模为原生3D表示下的潜在空间到潜在空间的翻译任务，以图像作为编辑提示。

Result: 实验表明，ShapeUP在身份保持和编辑保真度方面均优于现有的有训练和无训练基线方法，能实现细粒度的局部与全局编辑，并在无需显式掩码的情况下保持与原始资产的严格结构一致性。

Conclusion: ShapeUP提供了一种稳健且可扩展的原生3D内容创建范式，有效解决了当前3D编辑方法在可控性、一致性和效率方面的核心挑战。

Abstract: Recent advancements in 3D foundation models have enabled the generation of high-fidelity assets, yet precise 3D manipulation remains a significant challenge. Existing 3D editing frameworks often face a difficult trade-off between visual controllability, geometric consistency, and scalability. Specifically, optimization-based methods are prohibitively slow, multi-view 2D propagation techniques suffer from visual drift, and training-free latent manipulation methods are inherently bound by frozen priors and cannot directly benefit from scaling. In this work, we present ShapeUP, a scalable, image-conditioned 3D editing framework that formulates editing as a supervised latent-to-latent translation within a native 3D representation. This formulation allows ShapeUP to build on a pretrained 3D foundation model, leveraging its strong generative prior while adapting it to editing through supervised training. In practice, ShapeUP is trained on triplets consisting of a source 3D shape, an edited 2D image, and the corresponding edited 3D shape, and learns a direct mapping using a 3D Diffusion Transformer (DiT). This image-as-prompt approach enables fine-grained visual control over both local and global edits and achieves implicit, mask-free localization, while maintaining strict structural consistency with the original asset. Our extensive evaluations demonstrate that ShapeUP consistently outperforms current trained and training-free baselines in both identity preservation and edit fidelity, offering a robust and scalable paradigm for native 3D content creation.

</details>


### [59] [Poster: Camera Tampering Detection for Outdoor IoT Systems](https://arxiv.org/abs/2602.05706)
*Shadi Attarha,Kanaga Shanmugi,Anna Förster*

Main category: cs.CV

TL;DR: 本文提出基于规则和基于深度学习的两种方法，用于检测静态监控图像中的摄像头篡改行为，并公开了一个包含正常、模糊和旋转图像的数据集。


<details>
  <summary>Details</summary>
Motivation: 户外智能摄像头易受人为破坏或环境影响导致监控失效，而静态图像因缺乏时间序列信息，使篡改检测更具挑战性。

Method: 分别采用基于规则的方法和基于深度学习的方法进行图像篡改检测，并在准确性、计算开销和训练数据需求方面进行对比评估。

Result: 深度学习方法准确率更高，而基于规则的方法更适合资源受限且无法进行长时间校准的场景。

Conclusion: 两种方法各有适用场景，同时作者发布了公开数据集以促进该领域研究。

Abstract: Recently, the use of smart cameras in outdoor settings has grown to improve surveillance and security. Nonetheless, these systems are susceptible to tampering, whether from deliberate vandalism or harsh environmental conditions, which can undermine their monitoring effectiveness. In this context, detecting camera tampering is more challenging when a camera is capturing still images rather than video as there is no sequence of continuous frames over time. In this study, we propose two approaches for detecting tampered images: a rule-based method and a deep-learning-based method. The aim is to evaluate how each method performs in terms of accuracy, computational demands, and the data required for training when applied to real-world scenarios. Our results show that the deep-learning model provides higher accuracy, while the rule-based method is more appropriate for scenarios where resources are limited and a prolonged calibration phase is impractical. We also offer publicly available datasets with normal, blurred, and rotated images to support the development and evaluation of camera tampering detection methods, addressing the need for such resources.

</details>


### [60] [Exploring the Temporal Consistency for Point-Level Weakly-Supervised Temporal Action Localization](https://arxiv.org/abs/2602.05718)
*Yunchuan Ma,Laiyun Qing,Guorong Li,Yuqing Liu,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出一种多任务学习框架，通过三个自监督时序理解任务增强模型对动作的时序一致性建模能力，在点监督动作定位任务中取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有点监督时序动作定位方法仅依赖片段级分类，缺乏对动作内部帧间时序关系的显式建模，而这种时序理解对准确定位完整动作至关重要。

Method: 设计包含三个自监督时序理解任务的多任务学习框架：(i) 动作完成、(ii) 动作顺序理解、(iii) 动作规律性理解，以提升模型在点监督下的时序建模能力。

Result: 在四个基准数据集上的实验表明，所提方法优于多种当前先进方法。

Conclusion: 显式建模时序一致性可有效提升点监督动作定位性能，本工作是该方向的首次尝试。

Abstract: Point-supervised Temporal Action Localization (PTAL) adopts a lightly frame-annotated paradigm (\textit{i.e.}, labeling only a single frame per action instance) to train a model to effectively locate action instances within untrimmed videos. Most existing approaches design the task head of models with only a point-supervised snippet-level classification, without explicit modeling of understanding temporal relationships among frames of an action. However, understanding the temporal relationships of frames is crucial because it can help a model understand how an action is defined and therefore benefits localizing the full frames of an action. To this end, in this paper, we design a multi-task learning framework that fully utilizes point supervision to boost the model's temporal understanding capability for action localization. Specifically, we design three self-supervised temporal understanding tasks: (i) Action Completion, (ii) Action Order Understanding, and (iii) Action Regularity Understanding. These tasks help a model understand the temporal consistency of actions across videos. To the best of our knowledge, this is the first attempt to explicitly explore temporal consistency for point supervision action localization. Extensive experimental results on four benchmark datasets demonstrate the effectiveness of the proposed method compared to several state-of-the-art approaches.

</details>


### [61] [Adaptive Global and Fine-Grained Perceptual Fusion for MLLM Embeddings Compatible with Hard Negative Amplification](https://arxiv.org/abs/2602.05729)
*Lexiang Hu,Youze Xue,Dian Li,Gang Liu,Zhouchen Lin*

Main category: cs.CV

TL;DR: 本文提出AGFF-Embed方法，通过自适应融合全局与细粒度感知信息提升多模态嵌入性能，并结合EGA技术增强批次内难负样本，实现在通用和细粒度理解任务上的SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP和MLLM嵌入模型仅能捕捉全局语义信息，难以应对复杂场景中同时包含全局与细粒度元素的混合感知需求，因此需要一种兼容的融合机制。

Method: 提出AGFF-Embed方法，引导MLLM生成聚焦不同语义维度的多个嵌入，并对其进行自适应平滑聚合；同时结合显式梯度放大（EGA）技术，在不需细粒度数据编辑的情况下增强批次内难负样本。

Result: 在MMEB和MMVP-VLM基准上，AGFF-Embed在通用与细粒度理解任务中均取得优于现有模型的性能。

Conclusion: AGFF-Embed有效融合了全局与细粒度感知信息，显著提升了多模态嵌入模型的理解能力，为复杂视觉语言对齐任务提供了新思路。

Abstract: Multimodal embeddings serve as a bridge for aligning vision and language, with the two primary implementations -- CLIP-based and MLLM-based embedding models -- both limited to capturing only global semantic information. Although numerous studies have focused on fine-grained understanding, we observe that complex scenarios currently targeted by MLLM embeddings often involve a hybrid perceptual pattern of both global and fine-grained elements, thus necessitating a compatible fusion mechanism. In this paper, we propose Adaptive Global and Fine-grained perceptual Fusion for MLLM Embeddings (AGFF-Embed), a method that prompts the MLLM to generate multiple embeddings focusing on different dimensions of semantic information, which are then adaptively and smoothly aggregated. Furthermore, we adapt AGFF-Embed with the Explicit Gradient Amplification (EGA) technique to achieve in-batch hard negatives enhancement without requiring fine-grained editing of the dataset. Evaluation on the MMEB and MMVP-VLM benchmarks shows that AGFF-Embed comprehensively achieves state-of-the-art performance in both general and fine-grained understanding compared to other multimodal embedding models.

</details>


### [62] [Depth as Prior Knowledge for Object Detection](https://arxiv.org/abs/2602.05730)
*Moussa Kassem Sbeyti,Nadja Klein*

Main category: cs.CV

TL;DR: 本文提出DepthPrior框架，利用深度信息作为先验知识提升小目标检测性能，无需修改检测器结构，在多个基准上显著提升小目标检测精度。


<details>
  <summary>Details</summary>
Motivation: 小而远的目标因尺度变化、低分辨率和背景干扰难以被可靠检测，而现有融合深度信息的方法需复杂且模型特定的架构修改。作者旨在提供一种通用、轻量且无需改动检测器结构的方式来利用深度信息提升检测性能。

Method: 提出DepthPrior框架，将深度作为先验而非融合特征，包含训练阶段的深度加权损失（DLW）和深度分层损失（DLS），以及推理阶段的深度感知置信度阈值（DCT）。仅需一次深度估计开销，不改变检测器架构。

Result: 在KITTI、MS COCO、VisDrone、SUN RGB-D四个数据集及YOLOv11、EfficientDet两个检测器上验证，小目标mAP和mAR分别最高提升9%和7%，真/假检测恢复率高达95:1。

Conclusion: DepthPrior有效利用深度先验提升小目标检测性能，无需额外传感器、架构改动或推理开销，具有通用性和实用性。

Abstract: Detecting small and distant objects remains challenging for object detectors due to scale variation, low resolution, and background clutter. Safety-critical applications require reliable detection of these objects for safe planning. Depth information can improve detection, but existing approaches require complex, model-specific architectural modifications. We provide a theoretical analysis followed by an empirical investigation of the depth-detection relationship. Together, they explain how depth causes systematic performance degradation and why depth-informed supervision mitigates it. We introduce DepthPrior, a framework that uses depth as prior knowledge rather than as a fused feature, providing comparable benefits without modifying detector architectures. DepthPrior consists of Depth-Based Loss Weighting (DLW) and Depth-Based Loss Stratification (DLS) during training, and Depth-Aware Confidence Thresholding (DCT) during inference. The only overhead is the initial cost of depth estimation. Experiments across four benchmarks (KITTI, MS COCO, VisDrone, SUN RGB-D) and two detectors (YOLOv11, EfficientDet) demonstrate the effectiveness of DepthPrior, achieving up to +9% mAP$_S$ and +7% mAR$_S$ for small objects, with inference recovery rates as high as 95:1 (true vs. false detections). DepthPrior offers these benefits without additional sensors, architectural changes, or performance costs. Code is available at https://github.com/mos-ks/DepthPrior.

</details>


### [63] [FMPose3D: monocular 3D pose estimation via flow matching](https://arxiv.org/abs/2602.05755)
*Ti Wang,Xiaohang Yu,Mackenzie Weygandt Mathis*

Main category: cs.CV

TL;DR: 本文提出FMPose3D，一种基于流匹配（Flow Matching）的高效单目3D姿态估计方法，通过将姿态生成建模为条件分布传输问题，在仅需少量ODE积分步数的情况下生成多样且准确的3D姿态假设，并在人体和动物数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D姿态估计存在深度模糊和遮挡问题，导致其本质上是病态的。现有基于扩散模型的方法虽能生成多样姿态假设，但推理过程计算开销大。因此，作者旨在设计一种更高效的生成式方法，在保持多样性的同时显著提升推理速度。

Method: 作者利用流匹配（Flow Matching）学习一个由常微分方程（ODE）定义的速度场，将3D姿态估计建模为从标准高斯先验到以2D输入为条件的3D姿态分布的连续传输问题。通过采样不同噪声种子，模型可生成多样姿态假设。此外，引入重投影后验期望聚合（RPEA）模块，从多个假设中聚合出最优的单一预测。

Result: FMPose3D在Human3.6M和MPI-INF-3DHP人体姿态基准上超越现有方法，并在Animal3D和CtrlAni3D动物姿态数据集上取得当前最优性能，验证了其在人体与动物3D姿态估计任务中的通用性和高效性。

Conclusion: FMPose3D通过流匹配框架有效解决了单目3D姿态估计中的效率与多样性难题，不仅推理速度快，而且在多个基准上表现优异，为生成式3D姿态估计提供了新思路。

Abstract: Monocular 3D pose estimation is fundamentally ill-posed due to depth ambiguity and occlusions, thereby motivating probabilistic methods that generate multiple plausible 3D pose hypotheses. In particular, diffusion-based models have recently demonstrated strong performance, but their iterative denoising process typically requires many timesteps for each prediction, making inference computationally expensive. In contrast, we leverage Flow Matching (FM) to learn a velocity field defined by an Ordinary Differential Equation (ODE), enabling efficient generation of 3D pose samples with only a few integration steps. We propose a novel generative pose estimation framework, FMPose3D, that formulates 3D pose estimation as a conditional distribution transport problem. It continuously transports samples from a standard Gaussian prior to the distribution of plausible 3D poses conditioned only on 2D inputs. Although ODE trajectories are deterministic, FMPose3D naturally generates various pose hypotheses by sampling different noise seeds. To obtain a single accurate prediction from those hypotheses, we further introduce a Reprojection-based Posterior Expectation Aggregation (RPEA) module, which approximates the Bayesian posterior expectation over 3D hypotheses. FMPose3D surpasses existing methods on the widely used human pose estimation benchmarks Human3.6M and MPI-INF-3DHP, and further achieves state-of-the-art performance on the 3D animal pose datasets Animal3D and CtrlAni3D, demonstrating strong performance across both 3D pose domains. The code is available at https://github.com/AdaptiveMotorControlLab/FMPose3D.

</details>


### [64] [ReText: Text Boosts Generalization in Image-Based Person Re-identification](https://arxiv.org/abs/2602.05785)
*Timur Mamedov,Karina Kvanchiani,Anton Konushin,Vadim Konushin*

Main category: cs.CV

TL;DR: 本文提出ReText方法，通过融合多摄像头与单摄像头数据，并引入文本描述增强语义信息，在无需重新训练的情况下显著提升跨域行人重识别的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用行人重识别方法在未见域上表现受限，而仅使用单摄像头数据虽易获取但缺乏跨视角变化；作者旨在通过结合多摄像头与带文本描述的单摄像头数据，提升模型泛化能力。

Method: ReText联合优化三个任务：(1) 多摄像头数据上的Re-ID任务，(2) 图像-文本匹配，(3) 基于文本引导的单摄像头图像重建，利用多模态联合学习增强语义线索。

Result: 实验表明，ReText在跨域Re-ID基准上显著优于当前最先进的方法，展现出强大的泛化能力。

Conclusion: 本文首次探索了在图像级行人重识别中对多摄像头与单摄像头数据混合进行多模态联合学习，有效提升了模型在未见域上的通用性。

Abstract: Generalizable image-based person re-identification (Re-ID) aims to recognize individuals across cameras in unseen domains without retraining. While multiple existing approaches address the domain gap through complex architectures, recent findings indicate that better generalization can be achieved by stylistically diverse single-camera data. Although this data is easy to collect, it lacks complexity due to minimal cross-view variation. We propose ReText, a novel method trained on a mixture of multi-camera Re-ID data and single-camera data, where the latter is complemented by textual descriptions to enrich semantic cues. During training, ReText jointly optimizes three tasks: (1) Re-ID on multi-camera data, (2) image-text matching, and (3) image reconstruction guided by text on single-camera data. Experiments demonstrate that ReText achieves strong generalization and significantly outperforms state-of-the-art methods on cross-domain Re-ID benchmarks. To the best of our knowledge, this is the first work to explore multimodal joint learning on a mixture of multi-camera and single-camera data in image-based person Re-ID.

</details>


### [65] [Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation](https://arxiv.org/abs/2602.05789)
*Hengyi Wang,Ruiqiang Zhang,Chang Liu,Guanjie Wang,Zehua Ma,Han Fang,Weiming Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的策略——Allocentric Perceiver，通过结合几何重建与视觉语言模型（VLM），显著提升了模型在需要以目标为中心进行空间推理的任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在处理需显式视角转换的异我中心（allocentric）空间查询时表现脆弱，因其依赖于相机视角而非目标中心参考系进行推理。

Method: 该方法利用现成的几何专家从单张或多张图像中恢复度量3D状态，并根据指令语义构建查询条件下的异我中心参考系；随后将重建的几何结构确定性地转换至该目标参考系，并以结构化、几何锚定的表示形式提示主干VLM。

Result: 在多个主干模型和空间推理基准上评估显示，该方法在异我中心任务上带来约10%的一致显著提升，同时保持优异的自我中心（egocentric）性能，超越了专门微调的空间感知模型及当前最先进的开源和闭源模型。

Conclusion: 通过将心理旋转从隐式推理转为显式计算，Allocentric Perceiver有效增强了VLM的空间理解能力，为无需训练即可提升模型空间推理性能提供了新思路。

Abstract: With the rising need for spatially grounded tasks such as Vision-Language Navigation/Action, allocentric perception capabilities in Vision-Language Models (VLMs) are receiving growing focus. However, VLMs remain brittle on allocentric spatial queries that require explicit perspective shifts, where the answer depends on reasoning in a target-centric frame rather than the observed camera view. Thus, we introduce Allocentric Perceiver, a training-free strategy that recovers metric 3D states from one or more images with off-the-shelf geometric experts, and then instantiates a query-conditioned allocentric reference frame aligned with the instruction's semantic intent. By deterministically transforming reconstructed geometry into the target frame and prompting the backbone VLM with structured, geometry-grounded representations, Allocentric Perceriver offloads mental rotation from implicit reasoning to explicit computation. We evaluate Allocentric Perciver across multiple backbone families on spatial reasoning benchmarks, observing consistent and substantial gains ($\sim$10%) on allocentric tasks while maintaining strong egocentric performance, and surpassing both spatial-perception-finetuned models and state-of-the-art open-source and proprietary models.

</details>


### [66] [Focus-Scan-Refine: From Human Visual Perception to Efficient Visual Token Pruning](https://arxiv.org/abs/2602.05809)
*Enwei Tong,Yuanchao Bai,Yao Zhu,Junjun Jiang,Xianming Liu*

Main category: cs.CV

TL;DR: 本文提出了一种受人类视觉问答机制启发的训练无关视觉令牌剪枝框架 Focus-Scan-Refine（FSR），通过聚焦关键证据、扫描补充上下文并精炼信息，在不增加令牌数量的前提下显著提升视觉语言模型的准确率与效率平衡。


<details>
  <summary>Details</summary>
Motivation: 现有训练无关的视觉令牌剪枝方法在高度压缩条件下难以兼顾局部证据与全局上下文，导致性能下降。为解决这一问题，作者受人类回答视觉问题的认知过程启发，设计一种更有效的剪枝策略。

Method: FSR 包含三个阶段：1）聚焦：结合视觉重要性与指令相关性选择关键令牌，避免偏向仅视觉显著但与查询无关的区域；2）扫描：基于已聚焦集合，选取与之差异最大的补充令牌以捕获全局上下文；3）精炼：通过相似性分配和得分加权合并，将邻近信息聚合到扫描锚点，不增加令牌预算。

Result: 在多个视觉语言模型主干和基准测试上，FSR 在保持低延迟和小内存占用的同时，始终优于当前最先进的剪枝方法，在准确率-效率权衡方面表现更优。

Conclusion: FSR 是一种即插即用、无需训练的高效剪枝框架，有效模拟人类视觉理解机制，在压缩视觉令牌的同时保留关键语义信息，显著提升视觉语言模型推理效率与性能。

Abstract: Vision-language models (VLMs) often generate massive visual tokens that greatly increase inference latency and memory footprint; while training-free token pruning offers a practical remedy, existing methods still struggle to balance local evidence and global context under aggressive compression. We propose Focus-Scan-Refine (FSR), a human-inspired, plug-and-play pruning framework that mimics how humans answer visual questions: focus on key evidence, then scan globally if needed, and refine the scanned context by aggregating relevant details. FSR first focuses on key evidence by combining visual importance with instruction relevance, avoiding the bias toward visually salient but query-irrelevant regions. It then scans for complementary context conditioned on the focused set, selecting tokens that are most different from the focused evidence. Finally, FSR refines the scanned context by aggregating nearby informative tokens into the scan anchors via similarity-based assignment and score-weighted merging, without increasing the token budget. Extensive experiments across multiple VLM backbones and vision-language benchmarks show that FSR consistently improves the accuracy-efficiency trade-off over existing state-of-the-art pruning methods. The source codes can be found at https://github.com/ILOT-code/FSR

</details>


### [67] [NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects](https://arxiv.org/abs/2602.05822)
*Musawar Ali,Manuel Carranza-García,Nicola Fioraio,Samuele Salti,Luigi Di Stefano*

Main category: cs.CV

TL;DR: NVS-HO 是首个面向真实环境中仅使用 RGB 输入进行手持物体新视角合成的基准，包含手持序列和标定板序列，用于训练与评估，并揭示了现有方法在非约束条件下的性能不足。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对真实世界中仅使用 RGB 图像对手持物体进行新视角合成的基准，限制了该领域方法的发展与评估。

Method: 提出 NVS-HO 基准，包含两类 RGB 序列：手持序列（用于训练）和 ChArUco 标定板序列（提供精确相机位姿和真值图像用于评估）；采用 SfM 和预训练 VGGT 作为位姿估计器，结合 NeRF 与 Gaussian Splatting 构建基线模型。

Result: 实验表明，现有方法在非约束手持条件下表现不佳，存在显著性能差距。

Conclusion: NVS-HO 提供了一个具有挑战性的真实世界基准，可推动基于 RGB 的手持物体新视角合成研究。

Abstract: We propose NVS-HO, the first benchmark designed for novel view synthesis of handheld objects in real-world environments using only RGB inputs. Each object is recorded in two complementary RGB sequences: (1) a handheld sequence, where the object is manipulated in front of a static camera, and (2) a board sequence, where the object is fixed on a ChArUco board to provide accurate camera poses via marker detection. The goal of NVS-HO is to learn a NVS model that captures the full appearance of an object from (1), whereas (2) provides the ground-truth images used for evaluation. To establish baselines, we consider both a classical SfM pipeline and a state-of-the-art pre-trained feed-forward neural network (VGGT) as pose estimators, and train NVS models based on NeRF and Gaussian Splatting. Our experiments reveal significant performance gaps in current methods under unconstrained handheld conditions, highlighting the need for more robust approaches. NVS-HO thus offers a challenging real-world benchmark to drive progress in RGB-based novel view synthesis of handheld objects.

</details>


### [68] [Neural Implicit 3D Cardiac Shape Reconstruction from Sparse CT Angiography Slices Mimicking 2D Transthoracic Echocardiography Views](https://arxiv.org/abs/2602.05884)
*Gino E. Jansen,Carolina Brás,R. Nils Planken,Mark J. Schuuring,Berto J. Bouma,Ivana Išgum*

Main category: cs.CV

TL;DR: 本文提出一种基于神经隐式函数的方法，从稀疏CTA切面重建完整3D心脏结构，用于提升2D经胸超声心动图（TTE）中的三维定量分析准确性。


<details>
  <summary>Details</summary>
Motivation: 2D TTE在临床中广泛应用，但缺乏完整的3D心脏结构信息；现有方法（如Simpson双平面法）在体积估算上存在较大误差。因此，亟需一种能从有限2D视图中高精度重建3D心脏结构的方法。

Method: 该方法利用多层感知机学习来自CTA的3D分割数据中的形状先验，并通过神经隐式函数，在测试阶段联合优化潜在编码和刚性变换，将模拟标准心尖2D TTE视图的稀疏CTA切面映射到3D空间，从而重建多类别心脏结构（包括左心室心肌、心腔等）。

Result: 在独立测试集上，该方法对所有结构的平均Dice系数达0.86±0.04；左心室和左心房的体积误差显著低于Simpson双平面法（分别为4.88±4.26 mL vs. 8.14±6.04 mL 和 6.40±7.37 mL vs. 37.76±22.96 mL）。

Conclusion: 所提方法能有效从模拟2D TTE视图的稀疏切面中重建高精度3D心脏结构，为2D TTE提供了一种可行且更准确的三维心腔定量分析途径。

Abstract: Accurate 3D representations of cardiac structures allow quantitative analysis of anatomy and function. In this work, we propose a method for reconstructing complete 3D cardiac shapes from segmentations of sparse planes in CT angiography (CTA) for application in 2D transthoracic echocardiography (TTE). Our method uses a neural implicit function to reconstruct the 3D shape of the cardiac chambers and left-ventricle myocardium from sparse CTA planes. To investigate the feasibility of achieving 3D reconstruction from 2D TTE, we select planes that mimic the standard apical 2D TTE views. During training, a multi-layer perceptron learns shape priors from 3D segmentations of the target structures in CTA. At test time, the network reconstructs 3D cardiac shapes from segmentations of TTE-mimicking CTA planes by jointly optimizing the latent code and the rigid transforms that map the observed planes into 3D space. For each heart, we simulate four realistic apical views, and we compare reconstructed multi-class volumes with the reference CTA volumes. On a held-out set of CTA segmentations, our approach achieves an average Dice coefficient of 0.86 $\pm$ 0.04 across all structures. Our method also achieves markedly lower volume errors than the clinical standard, Simpson's biplane rule: 4.88 $\pm$ 4.26 mL vs. 8.14 $\pm$ 6.04 mL, respectively, for the left ventricle; and 6.40 $\pm$ 7.37 mL vs. 37.76 $\pm$ 22.96 mL, respectively, for the left atrium. This suggests that our approach offers a viable route to more accurate 3D chamber quantification in 2D transthoracic echocardiography.

</details>


### [69] [Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation](https://arxiv.org/abs/2602.05827)
*Hai Zhang,Siqi Liang,Li Chen,Yuxian Li,Yukuan Xu,Yichao Zhong,Fu Zhang,Hongyang Li*

Main category: cs.CV

TL;DR: 本文提出SparseVideoNav，首次将视频生成模型引入超越视野导航（BVN）任务，通过生成稀疏未来轨迹实现高效长时程导航，在真实世界零样本实验中成功率是现有LLM方法的2.5倍，并首次实现在夜间场景中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航依赖详细指令，与现实世界中仅凭高层意图自主导航的目标相悖；而基于大语言模型的方法因短视监督难以应对目标遥远且不可见的BVN挑战。

Method: 利用视频生成模型天然具备的长时程语言对齐能力，首次将其引入BVN任务，并提出SparseVideoNav方法，通过生成覆盖20秒时间跨度的稀疏未来轨迹，实现亚秒级推理。

Result: SparseVideoNav相比未优化的视频生成方法提速27倍，在真实世界零样本BVN任务中成功率是当前最优LLM基线的2.5倍，并首次在夜间复杂场景中成功部署。

Conclusion: 视频生成模型结合稀疏轨迹推理可有效解决长时程、低指导密度的导航问题，为现实世界中高层意图驱动的自主导航提供了新范式。

Abstract: Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentally contradict the goal for navigation in the real-world. Ideally, agents should possess the autonomy to navigate in unknown environments guided solely by simple and high-level intents. Realizing this ambition introduces a formidable challenge: Beyond-the-View Navigation (BVN), where agents must locate distant, unseen targets without dense and step-by-step guidance. Existing large language model (LLM)-based methods, though adept at following dense instructions, often suffer from short-sighted behaviors due to their reliance on short-horimzon supervision. Simply extending the supervision horizon, however, destabilizes LLM training. In this work, we identify that video generation models inherently benefit from long-horizon supervision to align with language instructions, rendering them uniquely suitable for BVN tasks. Capitalizing on this insight, we propose introducing the video generation model into this field for the first time. Yet, the prohibitive latency for generating videos spanning tens of seconds makes real-world deployment impractical. To bridge this gap, we propose SparseVideoNav, achieving sub-second trajectory inference guided by a generated sparse future spanning a 20-second horizon. This yields a remarkable 27x speed-up compared to the unoptimized counterpart. Extensive real-world zero-shot experiments demonstrate that SparseVideoNav achieves 2.5x the success rate of state-of-the-art LLM baselines on BVN tasks and marks the first realization of such capability in challenging night scenes.

</details>


### [70] [Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching](https://arxiv.org/abs/2602.05951)
*Junwan Kim,Jiho Park,Seonghu Jeon,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出在流匹配（flow matching）框架中，通过学习条件依赖的源分布来提升文生图性能，显著加快收敛速度并提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配方法多沿用扩散模型中的标准高斯源分布，未将源分布本身作为优化目标，尤其在条件生成任务中忽略了利用丰富条件信号设计更优源分布的潜力。

Method: 提出一种条件依赖的源分布学习方法，在流匹配目标下引入方差正则化和源-目标方向对齐机制，以避免分布坍缩和训练不稳定，并分析目标表示空间对结构化源分布效果的影响。

Result: 在多个文生图基准上实现一致提升，FID收敛速度最高加快3倍，验证了所提方法的有效性和实用性。

Conclusion: 精心设计条件依赖的源分布能显著提升条件流匹配模型的性能，为未来生成模型的源分布优化提供了新方向。

Abstract: Flow matching has recently emerged as a promising alternative to diffusion-based generative models, particularly for text-to-image generation. Despite its flexibility in allowing arbitrary source distributions, most existing approaches rely on a standard Gaussian distribution, a choice inherited from diffusion models, and rarely consider the source distribution itself as an optimization target in such settings. In this work, we show that principled design of the source distribution is not only feasible but also beneficial at the scale of modern text-to-image systems. Specifically, we propose learning a condition-dependent source distribution under flow matching objective that better exploit rich conditioning signals. We identify key failure modes that arise when directly incorporating conditioning into the source, including distributional collapse and instability, and show that appropriate variance regularization and directional alignment between source and target are critical for stable and effective learning. We further analyze how the choice of target representation space impacts flow matching with structured sources, revealing regimes in which such designs are most effective. Extensive experiments across multiple text-to-image benchmarks demonstrate consistent and robust improvements, including up to a 3x faster convergence in FID, highlighting the practical benefits of a principled source distribution design for conditional flow matching.

</details>


### [71] [Weaver: End-to-End Agentic System Training for Video Interleaved Reasoning](https://arxiv.org/abs/2602.05829)
*Yudi Shi,Shangzhe Di,Qirui Chen,Qinian Wang,Jiayin Cai,Xiaolong Jiang,Yao Hu,Weidi Xie*

Main category: cs.CV

TL;DR: 提出Weaver，一种端到端可训练的多模态推理智能体系统，通过动态调用工具和强化学习提升视频推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的思维链方法在视频推理中存在表征不匹配和感知能力有限的问题。

Method: Weaver系统允许策略模型在推理过程中动态调用多种工具以获取视觉线索，并结合强化学习在无轨迹数据上探索工具使用策略。

Result: Weaver在多个复杂视频推理基准上表现优异，尤其在长视频任务中效果显著。

Conclusion: Weaver通过构建真实的多模态推理路径，有效提升了模型在视频理解任务中的综合能力。

Abstract: Video reasoning constitutes a comprehensive assessment of a model's capabilities, as it demands robust perceptual and interpretive skills, thereby serving as a means to explore the boundaries of model performance. While recent research has leveraged text-centric Chain-of-Thought reasoning to augment these capabilities, such approaches frequently suffer from representational mismatch and restricted by limited perceptual acuity. To address these limitations, we propose Weaver, a novel, end-to-end trainable multimodal reasoning agentic system. Weaver empowers its policy model to dynamically invoke diverse tools throughout the reasoning process, enabling progressive acquisition of crucial visual cues and construction of authentic multimodal reasoning trajectories. Furthermore, we integrate a reinforcement learning algorithm to allow the system to freely explore strategies for employing and combining these tools with trajectory-free data. Extensive experiments demonstrate that our system, Weaver, enhances performance on several complex video reasoning benchmarks, particularly those involving long videos.

</details>


### [72] [UI-Mem: Self-Evolving Experience Memory for Online Reinforcement Learning in Mobile GUI Agents](https://arxiv.org/abs/2602.05832)
*Han Xiao,Guozhi Wang,Hao Wang,Shilong Liu,Yuxiang Chai,Yue Pan,Yufeng Zhou,Xiaoxin Chen,Yafei Wen,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出UI-Mem框架，通过引入分层经验记忆和分层组采样机制，提升GUI智能体在在线强化学习中的表现，有效解决长周期任务信用分配效率低和跨任务重复犯错的问题。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习在GUI智能体中面临两大挑战：长周期任务中信用分配效率低下，以及因缺乏经验迁移能力导致跨任务重复犯错。现有方法如传统回放缓冲区难以支持结构化知识的积累与复用。

Method: 提出UI-Mem框架，包含分层经验记忆（存储高层工作流、子任务技能和失败模式的参数化模板）；采用分层组采样（Stratified Group Sampling）将不同层级的记忆引导注入rollout轨迹以保持多样性；并设计自进化循环（Self-Evolving Loop）持续抽象新策略与错误以更新记忆。

Result: 在在线GUI基准测试中，UI-Mem显著优于传统RL基线和静态复用策略，并在未见过的应用中展现出强泛化能力。

Conclusion: UI-Mem通过结构化记忆积累与动态引导机制，有效提升了GUI智能体在在线强化学习中的效率与泛化能力，为复杂人机交互任务提供了新思路。

Abstract: Online Reinforcement Learning (RL) offers a promising paradigm for enhancing GUI agents through direct environment interaction. However, its effectiveness is severely hindered by inefficient credit assignment in long-horizon tasks and repetitive errors across tasks due to the lack of experience transfer. To address these challenges, we propose UI-Mem, a novel framework that enhances GUI online RL with a Hierarchical Experience Memory. Unlike traditional replay buffers, our memory accumulates structured knowledge, including high-level workflows, subtask skills, and failure patterns. These experiences are stored as parameterized templates that enable cross-task and cross-application transfer. To effectively integrate memory guidance into online RL, we introduce Stratified Group Sampling, which injects varying levels of guidance across trajectories within each rollout group to maintain outcome diversity, driving the unguided policy toward internalizing guided behaviors. Furthermore, a Self-Evolving Loop continuously abstracts novel strategies and errors to keep the memory aligned with the agent's evolving policy. Experiments on online GUI benchmarks demonstrate that UI-Mem significantly outperforms traditional RL baselines and static reuse strategies, with strong generalization to unseen applications. Project page: https://ui-mem.github.io

</details>


### [73] [LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation](https://arxiv.org/abs/2602.05966)
*Mirlan Karimov,Teodora Spasojevic,Markus Braun,Julian Wiederer,Vasileios Belagiannis,Marc Pollefeys*

Main category: cs.CV

TL;DR: 本文提出Localized Semantic Alignment（LSA）方法，在无需推理时外部控制信号的情况下，通过语义特征对齐提升预训练视频生成模型的时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有可控视频生成方法依赖推理阶段的控制信号来保证动态物体的时间一致性，限制了其作为可扩展、通用数据引擎的能力。

Method: 在微调预训练视频生成模型时，引入一种新的语义特征一致性损失：利用现成的特征提取模型，对真实视频与生成视频中动态物体局部区域的语义特征进行对齐，并将其与标准扩散损失结合，仅用一个epoch进行微调。

Result: 在nuScenes和KITTI数据集上的实验表明，该方法在标准视频生成指标上优于基线，并通过引入mAP和mIoU两个目标检测指标进一步验证了生成视频的时间一致性提升。

Conclusion: LSA是一种简单有效的微调策略，可在不增加推理开销、无需外部控制信号的前提下显著提升生成视频的时间一致性。

Abstract: Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, limiting their utility as scalable and generalizable data engines. In this work, we propose Localized Semantic Alignment (LSA), a simple yet effective framework for fine-tuning pre-trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground-truth and generated video clips. Specifically, we compare the output of an off-the-shelf feature extraction model between the ground-truth and generated video clips localized around dynamic objects inducing a semantic feature consistency loss. We fine-tune the base model by combining this loss with the standard diffusion loss. The model fine-tuned for a single epoch with our novel loss outperforms the baselines in common video generation evaluation metrics. To further test the temporal consistency in generated videos we adapt two additional metrics from object detection task, namely mAP and mIoU. Extensive experiments on nuScenes and KITTI datasets show the effectiveness of our approach in enhancing temporal consistency in video generation without the need for external control signals during inference and any computational overheads.

</details>


### [74] [RISE-Video: Can Video Generators Decode Implicit World Rules?](https://arxiv.org/abs/2602.05986)
*Mingxin Liu,Shuran Ma,Shibei Meng,Xiangyu Zhao,Zicheng Zhang,Shaofeng Zhang,Zhihang Zhong,Peixian Chen,Haoyu Cao,Xing Sun,Haodong Duan,Xue Yang*

Main category: cs.CV

TL;DR: 本文提出了RISE-Video，一个面向推理的文本-图像到视频生成评测基准，强调模型对隐式世界规则的理解与推理能力，而非仅关注视觉质量。


<details>
  <summary>Details</summary>
Motivation: 当前生成式视频模型虽在视觉保真度上表现优异，但在内化和推理隐式世界规则方面仍存在明显不足，亟需新的评测体系来推动该方向的发展。

Method: 构建包含467个人工标注样本、涵盖8个类别的RISE-Video基准，并提出四项评估维度：推理一致性、时序一致性、物理合理性与视觉质量；同时设计基于大语言多模态模型（LMM）的自动化评估流程。

Result: 在11个前沿TI2V模型上的实验表明，现有模型在复杂隐式约束场景下的推理能力普遍存在显著缺陷。

Conclusion: RISE-Video为评估和推动生成式视频模型的认知推理能力提供了有效工具，揭示了未来世界模拟模型需重点提升的方向。

Abstract: While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: \textit{Reasoning Alignment}, \textit{Temporal Consistency}, \textit{Physical Rationality}, and \textit{Visual Quality}. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.

</details>


### [75] [Pathwise Test-Time Correction for Autoregressive Long Video Generation](https://arxiv.org/abs/2602.05871)
*Xunzhi Xiang,Zixuan Duan,Guiyu Zhang,Haiyu Zhang,Zhe Gao,Junta Wu,Shaofeng Zhang,Tengfei Wang,Qi Fan,Chunchao Guo*

Main category: cs.CV

TL;DR: 提出了一种无需训练的测试时校正方法（TTC），通过初始帧作为参考锚点，有效缓解长视频生成中的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试时优化（TTO）方法在长序列生成中因奖励景观不稳定和蒸馏参数高度敏感而无法有效抑制漂移，导致生成质量下降。

Method: 引入测试时校正（TTC）方法，利用初始帧作为稳定参考锚点，在采样轨迹中校准中间随机状态，无需额外训练。

Result: 实验表明，TTC可无缝集成于多种蒸馏模型，在几乎无额外开销的情况下显著延长生成长度，并在30秒视频基准上达到与耗资源训练方法相当的质量。

Conclusion: TTC是一种高效、通用且无需训练的解决方案，有效解决了蒸馏自回归扩散模型在长视频生成中的误差累积问题。

Abstract: Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks.

</details>


### [76] [GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?](https://arxiv.org/abs/2602.06013)
*Ruihang Li,Leigang Qu,Jingxu Zhang,Dongnan Gui,Mengde Xu,Xiaosong Zhang,Han Hu,Wenjie Wang,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出GenArena，一种基于成对比较的视觉生成模型评估框架，显著优于传统绝对评分方法，在与人类判断一致性方面大幅提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型的评估依赖于绝对点对点评分，但该方法存在随机不一致性和与人类感知对齐差的问题，亟需更可靠、自动化的评估标准。

Method: 引入GenArena框架，采用成对比较范式替代传统的绝对评分方式，利用现成的开源视觉-语言模型进行稳定且与人类判断高度一致的评估。

Result: 成对比较方法使开源模型在评估中超越顶级闭源模型；评估准确率提升超20%，与LMArena排行榜的Spearman相关性达0.86，远高于点对点方法的0.36。

Conclusion: GenArena为视觉生成任务提供了统一、可靠且自动化的评估标准，显著提升了评估结果与人类判断的一致性，推动了该领域的标准化发展。

Abstract: The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide spectrum of visual generation tasks. Our analysis reveals that this paradigm is limited due to stochastic inconsistency and poor alignment with human perception. To resolve these limitations, we introduce GenArena, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human-aligned evaluation. Crucially, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off-the-shelf open-source models to outperform top-tier proprietary models. Notably, our method boosts evaluation accuracy by over 20% and achieves a Spearman correlation of 0.86 with the authoritative LMArena leaderboard, drastically surpassing the 0.36 correlation of pointwise methods. Based on GenArena, we benchmark state-of-the-art visual generation models across diverse tasks, providing the community with a rigorous and automated evaluation standard for visual generation.

</details>


### [77] [Contour Refinement using Discrete Diffusion in Low Data Regime](https://arxiv.org/abs/2602.05880)
*Fei Yu Guan,Ian Keefe,Sophie Wilkinson,Daniel D. B. Perrakis,Steven Waslander*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级离散扩散轮廓优化方法，用于在标注数据稀缺的情况下实现鲁棒的边界检测，尤其适用于医学图像、环境监测等场景。


<details>
  <summary>Details</summary>
Motivation: 不规则和半透明物体的边界检测在医学成像、环境监测和制造等领域具有重要意义，但现有研究多关注分割掩码对齐，边界检测在低数据条件下仍缺乏有效方法，且实际应用中常受限于标注数据少和计算资源有限。

Method: 提出一种轻量级离散扩散轮廓细化流程：以带自注意力层的CNN为核心，以分割掩码为条件，迭代去噪稀疏轮廓表示；引入简化扩散过程、定制模型架构和极简后处理，以提升低数据下的性能与推理效率。

Result: 在KVASIR医学图像数据集上优于多个SOTA基线，在HAM10K和自建野火数据集Smoke上表现具竞争力，同时推理帧率提升3.5倍。

Conclusion: 所提方法在极低训练数据（<500张图像）条件下实现了高效、准确的边界检测，兼顾精度与计算效率，适用于资源受限的实际应用场景。

Abstract: Boundary detection of irregular and translucent objects is an important problem with applications in medical imaging, environmental monitoring and manufacturing, where many of these applications are plagued with scarce labeled data and low in situ computational resources. While recent image segmentation studies focus on segmentation mask alignment with ground-truth, the task of boundary detection remains understudied, especially in the low data regime. In this work, we present a lightweight discrete diffusion contour refinement pipeline for robust boundary detection in the low data regime. We use a Convolutional Neural Network(CNN) architecture with self-attention layers as the core of our pipeline, and condition on a segmentation mask, iteratively denoising a sparse contour representation. We introduce multiple novel adaptations for improved low-data efficacy and inference efficiency, including using a simplified diffusion process, a customized model architecture, and minimal post processing to produce a dense, isolated contour given a dataset of size <500 training images. Our method outperforms several SOTA baselines on the medical imaging dataset KVASIR, is competitive on HAM10K and our custom wildfire dataset, Smoke, while improving inference framerate by 3.5X.

</details>


### [78] [CLIP-Map: Structured Matrix Mapping for Parameter-Efficient CLIP Compression](https://arxiv.org/abs/2602.05909)
*Kangjie Zhang,Wenxuan Huang,Xin Zhou,Boxiang Zhou,Dejia Song,Yuan Xie,Baochang Zhang,Lizhuang Ma,Nemo Chen,Xu Tang,Yao Hu,Shaohui Lin*

Main category: cs.CV

TL;DR: 本文提出了一种基于映射的CLIP压缩框架CLIP-Map，通过可学习矩阵结合预训练权重，在高压缩率下优于现有基于选择的压缩方法。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在视觉任务中表现优异，但其高内存和计算开销限制了在资源受限场景中的应用；现有压缩方法通过选择子集继承权重，但在极端压缩下损害特征表达能力。

Method: 提出CLIP-Map框架，利用可学习矩阵通过全映射与Kronecker分解将预训练权重进行映射组合，并引入对角继承初始化策略以缓解优化困难和分布偏移问题。

Result: 实验表明，CLIP-Map在多种压缩比下均优于基于选择的压缩方法，尤其在高压缩率下提升显著。

Conclusion: 所提出的映射式压缩方法能更有效地保留原始权重信息，在保持模型性能的同时实现高效压缩，适用于资源受限环境。

Abstract: Contrastive Language-Image Pre-training (CLIP) has achieved widely applications in various computer vision tasks, e.g., text-to-image generation, Image-Text retrieval and Image captioning. However, CLIP suffers from high memory and computation cost, which prohibits its usage to the resource-limited application scenarios. Existing CLIP compression methods typically reduce the size of pre-trained CLIP weights by selecting their subset as weight inheritance for further retraining via mask optimization or important weight measurement. However, these select-based weight inheritance often compromises the feature presentation ability, especially on the extreme compression. In this paper, we propose a novel mapping-based CLIP compression framework, CLIP-Map. It leverages learnable matrices to map and combine pretrained weights by Full-Mapping with Kronecker Factorization, aiming to preserve as much information from the original weights as possible. To mitigate the optimization challenges introduced by the learnable mapping, we propose Diagonal Inheritance Initialization to reduce the distribution shifting problem for efficient and effective mapping learning. Extensive experimental results demonstrate that the proposed CLIP-Map outperforms select-based frameworks across various compression ratios, with particularly significant gains observed under high compression settings.

</details>


### [79] [Multi-Scale Global-Instance Prompt Tuning for Continual Test-time Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2602.05937)
*Lingrui Li,Yanfeng Zhou,Nan Pu,Xin Chen,Zhun Zhong*

Main category: cs.CV

TL;DR: 本文提出了一种名为多尺度全局-实例提示调优（MGIPT）的新方法，用于在持续变化的医疗图像目标域中实现鲁棒的持续测试时自适应（CTTA），通过结合自适应尺度实例提示（AIP）和多尺度全局提示（MGP），有效缓解误差累积、灾难性遗忘等问题，并提升跨域分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法在长期适应过程中易受误差累积和灾难性遗忘影响，而基于提示调优的方法虽有所改善，但仍存在多尺度提示多样性不足、实例特异性知识利用不充分及隐私泄露风险等问题。

Method: 提出MGIPT框架，包含自适应尺度实例提示（AIP）和多尺度全局提示（MGP）。AIP动态学习轻量级、实例特定的提示并采用自适应最优尺度选择机制；MGP在不同尺度上捕获域级知识以增强抗遗忘能力。两者通过加权集成实现全局与局部信息融合。

Result: 在多个医学图像分割基准上的实验表明，MGIPT优于当前最先进的方法，在持续变化的目标域中实现了更鲁棒的自适应性能。

Conclusion: MGIPT通过融合多尺度全局与实例级提示，有效解决了现有CTTA方法的关键局限，在医学图像分割任务中展现出优越的持续适应能力和稳定性。

Abstract: Distribution shift is a common challenge in medical images obtained from different clinical centers, significantly hindering the deployment of pre-trained semantic segmentation models in real-world applications across multiple domains. Continual Test-Time Adaptation(CTTA) has emerged as a promising approach to address cross-domain shifts during continually evolving target domains. Most existing CTTA methods rely on incrementally updating model parameters, which inevitably suffer from error accumulation and catastrophic forgetting, especially in long-term adaptation. Recent prompt-tuning-based works have shown potential to mitigate the two issues above by updating only visual prompts. While these approaches have demonstrated promising performance, several limitations remain:1)lacking multi-scale prompt diversity, 2)inadequate incorporation of instance-specific knowledge, and 3)risk of privacy leakage. To overcome these limitations, we propose Multi-scale Global-Instance Prompt Tuning(MGIPT), to enhance scale diversity of prompts and capture both global- and instance-level knowledge for robust CTTA. Specifically, MGIPT consists of an Adaptive-scale Instance Prompt(AIP) and a Multi-scale Global-level Prompt(MGP). AIP dynamically learns lightweight and instance-specific prompts to mitigate error accumulation with adaptive optimal-scale selection mechanism. MGP captures domain-level knowledge across different scales to ensure robust adaptation with anti-forgetting capabilities. These complementary components are combined through a weighted ensemble approach, enabling effective dual-level adaptation that integrates both global and local information. Extensive experiments on medical image segmentation benchmarks demonstrate that our MGIPT outperforms state-of-the-art methods, achieving robust adaptation across continually changing target domains.

</details>


### [80] [VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation](https://arxiv.org/abs/2602.05998)
*Jie Deng,Kaichun Yao,Libo Zhang*

Main category: cs.CV

TL;DR: 本文提出VisRefiner框架，通过让模型从渲染结果与目标设计之间的视觉差异中学习，显著提升截图到代码生成的质量和布局保真度，并赋予模型强大的自优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在训练过程中无法观察其生成代码的视觉效果，而人类开发者会通过反复渲染、对比设计稿并调整代码来学习。受此启发，作者希望让模型也能从视觉差异中学习代码修改。

Method: 构建“差异对齐监督”数据，将视觉差异与对应的代码编辑关联；在此基础上引入强化学习阶段，使模型能通过观察自身渲染结果与目标设计的差异，自主优化生成的代码。

Result: 实验表明，VisRefiner显著提升了单步生成的代码质量与布局保真度，并使模型具备了强大的自优化能力。

Conclusion: 从视觉差异中学习是提升截图到代码生成效果的有效途径，VisRefiner为此提供了一个可行的训练框架。

Abstract: Screenshot-to-code generation aims to translate user interface screenshots into executable frontend code that faithfully reproduces the target layout and style. Existing multimodal large language models perform this mapping directly from screenshots but are trained without observing the visual outcomes of their generated code. In contrast, human developers iteratively render their implementation, compare it with the design, and learn how visual differences relate to code changes. Inspired by this process, we propose VisRefiner, a training framework that enables models to learn from visual differences between rendered predictions and reference designs. We construct difference-aligned supervision that associates visual discrepancies with corresponding code edits, allowing the model to understand how appearance variations arise from implementation changes. Building on this, we introduce a reinforcement learning stage for self-refinement, where the model improves its generated code by observing both the rendered output and the target design, identifying their visual differences, and updating the code accordingly. Experiments show that VisRefiner substantially improves single-step generation quality and layout fidelity, while also endowing models with strong self-refinement ability. These results demonstrate the effectiveness of learning from visual differences for advancing screenshot-to-code generation.

</details>


### [81] [Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028)
*Shuo Chen,Cong Wei,Sun Sun,Ping Nie,Kai Zhou,Ge Zhang,Ming-Hsuan Yang,Wenhu Chen*

Main category: cs.CV

TL;DR: 本文提出Context Forcing框架，通过长上下文教师训练长上下文学生模型，并结合Slow-Fast Memory架构降低计算开销，显著提升长视频生成的时序一致性与有效上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有实时长视频生成方法采用短上下文教师监督长上下文学生，导致学生-教师之间存在上下文不匹配问题，限制了学生模型对长期时序依赖的学习能力。

Method: 提出Context Forcing框架，使用具备完整生成历史感知能力的长上下文教师对学生进行监督；同时设计Slow-Fast Memory机制，将线性增长的上下文转化为高效记忆结构以减少视觉冗余。

Result: 该方法实现超过20秒的有效上下文长度，是当前最优方法（如LongLive和Infinite-RoPE）的2至10倍，在多项长视频评估指标上表现更优。

Conclusion: 通过消除学生-教师间的监督不匹配并引入高效上下文管理机制，Context Forcing显著提升了长视频生成的长期一致性和可扩展性。

Abstract: Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

</details>


### [82] [Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation](https://arxiv.org/abs/2602.06032)
*David Shavin,Sagie Benaim*

Main category: cs.CV

TL;DR: 本文提出“Splat and Distill”框架，通过引入快速前馈的3D重建流程，将3D感知能力注入2D视觉基础模型（VFM），显著提升其在多种下游任务中的3D理解和语义表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有2D视觉基础模型虽在2D任务中表现优异，但缺乏3D感知能力。为解决这一问题，作者希望在不依赖耗时逐场景优化的前提下，赋予2D模型更强的几何理解能力。

Method: 该方法利用教师模型生成的2D特征，通过前馈方式将其提升为显式的3D高斯表示，再将这些3D特征“投影”（splat）到新视角，生成新的2D特征图以监督学生模型，从而实现3D感知知识的蒸馏。

Result: 在单目深度估计、表面法线估计、多视角对应和语义分割等任务上，该方法显著优于以往工作，不仅提升了3D感知能力，还增强了2D特征的语义丰富性。

Conclusion: 通过前馈式3D重建与特征蒸馏，“Splat and Distill”有效解决了2D VFM缺乏3D意识的问题，为构建兼具几何与语义理解能力的通用视觉模型提供了新思路。

Abstract: Vision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this end, we introduce Splat and Distill, a framework that instills robust 3D awareness into 2D VFMs by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. Given 2D features produced by a teacher model, our method first lifts these features into an explicit 3D Gaussian representation, in a feedforward manner. These 3D features are then ``splatted" onto novel viewpoints, producing a set of novel 2D feature maps used to supervise the student model, ``distilling" geometrically grounded knowledge. By replacing slow per-scene optimization of prior work with our feed-forward lifting approach, our framework avoids feature-averaging artifacts, creating a dynamic learning process where the teacher's consistency improves alongside that of the student. We conduct a comprehensive evaluation on a suite of downstream tasks, including monocular depth estimation, surface normal estimation, multi-view correspondence, and semantic segmentation. Our method significantly outperforms prior works, not only achieving substantial gains in 3D awareness but also enhancing the underlying semantic richness of 2D features. Project page is available at https://davidshavin4.github.io/Splat-and-Distill/

</details>


### [83] [V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval](https://arxiv.org/abs/2602.06034)
*Dongyang Chen,Chaoyang Wang,Dezhao SU,Xi Xiao,Zeyu Zhang,Jing Xiong,Qing Li,Yuzhang Shang,Shichao Ka*

Main category: cs.CV

TL;DR: 本文提出V-Retrver，一种基于视觉证据驱动的多模态检索框架，通过引入外部视觉工具使多模态大语言模型在推理过程中主动获取并验证细粒度视觉证据，从而提升检索准确率与推理可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于链式思维（CoT）的多模态检索方法主要依赖静态视觉编码，缺乏对细粒度视觉证据的主动验证能力，在视觉模糊情况下易产生推测性错误推理。

Method: V-Retrver将多模态检索重构为一个基于视觉检查的智能体推理过程，使MLLM能在推理中通过外部视觉工具选择性获取视觉证据，并交替进行假设生成与目标视觉验证；训练上采用课程学习策略，结合监督推理激活、基于拒绝的精炼和以证据对齐为目标的强化学习。

Result: 在多个多模态检索基准上的实验表明，该方法平均检索准确率提升23.0%，同时提高了感知驱动的推理可靠性和泛化能力。

Conclusion: 通过将主动视觉证据获取机制融入多模态推理过程，V-Retrver有效缓解了传统语言主导方法在视觉模糊场景下的局限性，显著提升了多模态检索性能。

Abstract: Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.

</details>


### [84] [InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions](https://arxiv.org/abs/2602.06035)
*Sirui Xu,Samuel Schulter,Morteza Ziyadi,Xialin He,Xiaohan Fei,Yu-Xiong Wang,Liangyan Gui*

Main category: cs.CV

TL;DR: 本文提出InterPrior框架，通过大规模模仿预训练与强化学习微调，构建一个可泛化的统一生成式控制器，使类人机器人能根据高层意图（如功能可用性）自然协调全身动作，实现多样场景下的loco-manipulation技能组合与泛化。


<details>
  <summary>Details</summary>
Motivation: 人类通常不会以显式的全身运动规划与物体的交互，而是依赖高层意图和内在的物理与运动先验来自然协调平衡、接触与操作。为使类人机器人具备类似能力，需构建可扩展的运动先验，以支持在多样化环境中组合并泛化loco-manipulation技能。

Method: InterPrior首先通过模仿学习将专家策略蒸馏为一个目标条件变分策略，该策略能从多模态观测和高层意图中重建运动；随后引入物理扰动的数据增强，并结合强化学习进行微调，以提升对未见目标和初始状态的泛化能力，从而将重建的潜在技能整合到有效流形中。

Result: 该方法成功实现了超越训练数据的泛化能力，例如可处理与未见过物体的交互，并在用户交互控制和真实机器人部署中展现出有效性。

Conclusion: InterPrior提供了一种可扩展的运动先验学习框架，能够支持类人机器人在复杂环境中基于高层意图实现协调、鲁棒且可泛化的全身loco-manipulation行为。

Abstract: Humans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, and manipulation can emerge naturally from underlying physical and motor priors. Scaling such priors is key to enabling humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. To this end, we introduce InterPrior, a scalable framework that learns a unified generative controller through large-scale imitation pretraining and post-training by reinforcement learning. InterPrior first distills a full-reference imitation expert into a versatile, goal-conditioned variational policy that reconstructs motion from multimodal observations and high-level intent. While the distilled policy reconstructs training behaviors, it does not generalize reliably due to the vast configuration space of large-scale human-object interactions. To address this, we apply data augmentation with physical perturbations, and then perform reinforcement learning finetuning to improve competence on unseen goals and initializations. Together, these steps consolidate the reconstructed latent skills into a valid manifold, yielding a motion prior that generalizes beyond the training data, e.g., it can incorporate new behaviors such as interactions with unseen objects. We further demonstrate its effectiveness for user-interactive control and its potential for real robot deployment.

</details>


### [85] [Thinking with Geometry: Active Geometry Integration for Spatial Reasoning](https://arxiv.org/abs/2602.06037)
*Haoyuan Li,Qihang Cao,Tao Tang,Kun Xiang,Zihan Guo,Jianhua Han,Hang Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: GeoThinker提出了一种主动感知框架，通过在特定视觉语言模型层中引入空间锚定融合和重要性门控机制，实现语义与几何信息的精准对齐，显著提升多模态大模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将3D几何先验融入多模态大语言模型时采用被动融合策略，导致语义与几何信息错位及冗余信号问题，限制了空间推理性能。

Method: GeoThinker采用主动感知范式，在选定的VLM层中通过空间锚定融合机制，使语义视觉先验能按需查询并整合任务相关的几何信息，并结合重要性门控机制强化对关键结构的关注。

Result: 在VSI-Bench上达到72.6的峰值分数，刷新空间智能任务的SOTA，并在具身指代和自动驾驶等复杂下游任务中展现出更强的泛化能力和空间感知性能。

Conclusion: 主动整合空间结构的能力对下一代空间智能至关重要，GeoThinker为此提供了有效框架。

Abstract: Recent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, which often induces semantic-geometry misalignment and redundant signals. We propose GeoThinker, a framework that shifts the paradigm from passive fusion to active perception. Instead of feature mixing, GeoThinker enables the model to selectively retrieve geometric evidence conditioned on its internal reasoning demands. GeoThinker achieves this through Spatial-Grounded Fusion applied at carefully selected VLM layers, where semantic visual priors selectively query and integrate task-relevant geometry via frame-strict cross-attention, further calibrated by Importance Gating that biases per-frame attention toward task-relevant structures. Comprehensive evaluation results show that GeoThinker sets a new state-of-the-art in spatial intelligence, achieving a peak score of 72.6 on the VSI-Bench. Furthermore, GeoThinker demonstrates robust generalization and significantly improved spatial perception across complex downstream scenarios, including embodied referring and autonomous driving. Our results indicate that the ability to actively integrate spatial structures is essential for next-generation spatial intelligence. Code can be found at https://github.com/Li-Hao-yuan/GeoThinker.

</details>


### [86] [SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs](https://arxiv.org/abs/2602.06040)
*Jintao Tong,Shilin Yan,Hongwei Xue,Xiaojun Tang,Kunyu Shi,Guannan Zhang,Ruixuan Li,Yixiong Zou*

Main category: cs.CV

TL;DR: SwimBird 是一种可切换推理模式的多模态大语言模型，能根据输入动态选择纯文本、纯视觉或图文交错的推理方式，在保持强文本逻辑的同时显著提升视觉密集型任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLM 主要依赖文本链式推理（CoT），在视觉密集任务中效果受限；而引入固定数量“视觉思维”虽提升视觉表现，却损害了文本逻辑推理能力。根本问题在于缺乏对不同查询自适应选择最优推理模态的能力。

Method: 提出 SwimBird 模型，支持三种推理模式：纯文本、纯视觉（以连续隐状态作为视觉思维）、图文交错推理。通过混合自回归建模统一文本 token 与视觉嵌入的预测，并构建包含 92K 样本的多样化监督微调数据集 SwimBird-SFT-92K，覆盖全部三种推理模式。

Result: 在涵盖文本推理与复杂视觉理解的多个基准测试中，SwimBird 实现了 SOTA 性能，相比以往固定推理模式的方法取得显著且稳健的提升。

Conclusion: 通过实现查询自适应的灵活推理模式切换，SwimBird 在保留强大文本逻辑能力的同时，有效增强了视觉密集任务的表现，为多模态推理提供了更通用和高效的范式。

Abstract: Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as "visual thoughts" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods.

</details>


### [87] [Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning](https://arxiv.org/abs/2602.06041)
*Xuejun Zhang,Aditi Tiwari,Zhenhailong Wang,Heng Ji*

Main category: cs.CV

TL;DR: 本文提出CAMCUE框架，通过显式利用相机姿态信息实现多视角图像的空间推理，显著提升模型在新视角下回答问题的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在处理多图像空间推理任务时存在困难，尤其在需要从多个视角构建一致的三维场景理解并据此推理新视角的问题上表现不足。现有方法缺乏对视角几何关系的有效建模，导致推理效率和准确性受限。

Method: 作者提出CAMCUE框架，将每个视角的相机姿态信息注入视觉token中，将自然语言描述的目标视角映射到具体的相机姿态，并合成一个姿态条件下的目标视图用于回答问题。同时构建了包含27,668个训练样本和508个测试样本的数据集CAMCUE-DATA，包含多视角图像、相机姿态、目标视角描述及视角转换问题。

Result: CAMCUE在整体准确率上提升了9.06%，在从自然语言描述预测目标相机姿态的任务中，旋转角度误差在20°以内的准确率超过90%，平移误差控制在0.5以内。推理时间从每例256.6秒大幅缩短至1.45秒。

Conclusion: 通过将相机姿态作为几何锚点显式引入多视角融合与新视角推理过程，CAMCUE有效提升了多模态模型的空间推理能力，在准确性和效率方面均取得显著进展，为实际交互式应用提供了可能。

Abstract: Multi-image spatial reasoning remains challenging for current multimodal large language models (MLLMs). While single-view perception is inherently 2D, reasoning over multiple views requires building a coherent scene understanding across viewpoints. In particular, we study perspective taking, where a model must build a coherent 3D understanding from multi-view observations and use it to reason from a new, language-specified viewpoint. We introduce CAMCUE, a pose-aware multi-image framework that uses camera pose as an explicit geometric anchor for cross-view fusion and novel-view reasoning. CAMCUE injects per-view pose into visual tokens, grounds natural-language viewpoint descriptions to a target camera pose, and synthesizes a pose-conditioned imagined target view to support answering. To support this setting, we curate CAMCUE-DATA with 27,668 training and 508 test instances pairing multi-view images and poses with diverse target-viewpoint descriptions and perspective-shift questions. We also include human-annotated viewpoint descriptions in the test split to evaluate generalization to human language. CAMCUE improves overall accuracy by 9.06% and predicts target poses from natural-language viewpoint descriptions with over 90% rotation accuracy within 20° and translation accuracy within a 0.5 error threshold. This direct grounding avoids expensive test-time search-and-match, reducing inference time from 256.6s to 1.45s per example and enabling fast, interactive use in real-world scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [88] [Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents](https://arxiv.org/abs/2602.05597)
*Stephen Pilli,Vivek Nallur*

Main category: cs.AI

TL;DR: 本文研究大语言模型（LLM）是否能在个体层面预测并模拟人类在认知负荷等情境因素影响下的认知偏差行为。通过与人类实验（N=1100）对比，发现GPT-4和GPT-5能较准确地复现人类偏差，且不同模型在行为拟合上存在差异。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型能否在交互式情境中预测并模拟个体层面的认知偏差，尤其是在认知负荷等上下文因素影响下的人类决策行为。

Method: 将三种经典决策场景改编为对话形式，开展人类实验（N=1100），参与者通过简单或复杂对话与聊天机器人互动；随后利用参与者人口统计信息和对话记录，在GPT-4和GPT-5上模拟相同条件，评估其对人类偏差的复现能力。

Result: 人类实验中观察到显著的认知偏差；GPT-4和GPT-5均能较精确地复现这些偏差，且不同模型在拟合人类行为方面表现出明显差异。

Conclusion: 大语言模型具备在交互环境中模拟人类认知偏差的能力，但模型间存在行为拟合差异，这对设计和评估具有偏差感知能力的自适应LLM系统具有重要意义。

Abstract: Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.

</details>


### [89] [Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence](https://arxiv.org/abs/2602.04986)
*Kendra Chilson,Eric Schwitzgebel*

Main category: cs.AI

TL;DR: 本文批判了线性AI智能模型，提出“熟悉智能”与“陌生智能”的概念，主张采用非线性智能模型来理解AI能力，并指出AI在某些任务中可能表现出超常能力，同时在看似简单的任务中却出现明显错误。


<details>
  <summary>Details</summary>
Motivation: 作者旨在回应Susan Schneider对线性AI进步模型的批评，强调当前对AI智能的理解过于简化，忽视了AI可能展现出的非典型、不一致的能力模式。

Method: 通过引入“陌生智能”概念，构建并论证一种非线性的智能模型，该模型将通用智能视为在多种环境中实现广泛目标的能力，而非单一可量化的线性指标。

Result: 文章阐明了AI系统可能在某些领域表现超人，而在其他领域（甚至同一领域内）表现远低于人类水平，这种能力分布不符合传统线性智能观。

Conclusion: 在非线性智能模型下，AI在特定任务上的失败不能否定其整体通用智能，而单一任务（如IQ测试）的优异表现也不应被泛化为广泛能力；这对评估AI能力的对抗性测试方法具有重要启示。

Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: "familiar intelligence" and "strange intelligence". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which "general intelligence" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.

</details>


### [90] [DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search](https://arxiv.org/abs/2602.05014)
*Zhanli Li,Huiwen Tian,Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.AI

TL;DR: DeepRead 是一种结构感知的多轮文档推理智能体，通过利用文档的层级和顺序结构，在长文档问答任务中显著优于现有基于检索的智能体方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体检索框架将长文档视为扁平的文本块集合，忽略了文档固有的层级结构和顺序信息，限制了其在长文档问答中的表现。

Method: DeepRead 首先使用 LLM 基础的 OCR 模型将 PDF 转换为保留标题和段落边界的结构化 Markdown；然后以段落为单位建立索引，并为每个段落分配包含章节身份和段内顺序的坐标式元数据；在此基础上，提供 Retrieve（定位相关段落并暴露结构坐标）和 ReadSection（按顺序连续阅读指定范围内容）两个互补工具供 LLM 使用。

Result: 实验表明 DeepRead 在文档问答任务上显著优于 Search-o1 类型的智能体检索方法，且检索与阅读工具之间存在协同效应；细粒度行为分析显示其表现出类似人类“先定位后阅读”的推理范式。

Conclusion: 显式建模和利用文档原生结构能有效提升智能体在长文档问答中的性能，DeepRead 为结构感知的智能体设计提供了新思路。

Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-style agentic search in document question answering. The synergistic effect between retrieval and reading tools is also validated. Our fine-grained behavioral analysis reveals a reading and reasoning paradigm resembling human-like ``locate then read'' behavior.

</details>


### [91] [MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation](https://arxiv.org/abs/2602.05048)
*Zeyu Fang,Tian Lan,Mahdi Imani*

Main category: cs.AI

TL;DR: 本文提出MINT框架，通过神经符号树结合自博弈与大语言模型，使AI在存在知识缺口的开放世界规划中主动向人类提问，以最少交互获得接近专家水平的规划性能。


<details>
  <summary>Details</summary>
Motivation: 开放世界中的人机联合规划常面临对象、目标等信息不完整的问题，导致知识缺口；现有方法缺乏高效策略引导AI主动获取必要人类输入。

Method: 提出Minimal Information Neuro-Symbolic Tree（MINT）：构建符号树表示人机交互假设，利用神经规划策略评估知识缺口带来的不确定性，通过自博弈优化提问策略，并借助大语言模型搜索推理路径、生成最优查询。

Result: 在三个包含未知/未见物体的基准任务上，MINT仅需少量提问即可实现接近专家的回报，在奖励和成功率上显著优于基线。

Conclusion: MINT有效弥合了开放世界规划中的知识缺口，通过主动、最小化的人类交互实现了高效且鲁棒的联合规划。

Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.

</details>


### [92] [Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education](https://arxiv.org/abs/2602.05059)
*Adithya Kulkarni,Mohna Chakraborty,Jay Bagga*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLM）在图论问题中的表现，发现其在已解决的问题上能准确推理并构建有效证明，但在开放性问题上虽能进行合理探索却无法取得实质性突破。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被广泛用于计算机科学教育，尤其是在图论等数学严谨性要求高的领域，有必要评估其在支持数学推理方面的可靠性。

Method: 采用包含八个阶段的评估协议，模拟真实数学探究过程，测试LLM在一个已解决的图论问题和一个开放问题上的表现。

Result: LLM在已解决问题上表现优异，能正确使用定义、识别结构、引用结果并构建专家验证的有效证明；在开放问题上虽能提出合理策略但未推进解题，且未虚构结果。

Conclusion: LLM适用于已有知识的概念探索，但在需要原创性数学洞察的任务中仍有限；教育中应引导学生将其用于探索，并辅以独立验证和严谨论证。

Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction.
  The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims.
  These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.

</details>


### [93] [Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents](https://arxiv.org/abs/2602.05073)
*Changdae Oh,Seongheon Park,To Eun Kim,Jiatong Li,Wendi Li,Samuel Yeh,Xuefeng Du,Hamed Hassani,Paul Bogdan,Dawn Song,Sharon Li*

Main category: cs.AI

TL;DR: 本文提出首个面向交互式大语言模型（LLM）智能体的不确定性量化（UQ）通用框架，强调应将UQ视为条件不确定性缩减过程，而非传统的不确定性累积过程，以更有效地支持复杂任务中的安全应用。


<details>
  <summary>Details</summary>
Motivation: 现有UQ研究多聚焦于单轮问答场景，难以适用于日益复杂的交互式LLM智能体。因此，亟需一个适用于现实交互环境的、原则性的智能体UQ新框架。

Method: 作者提出一种新的视角——“条件不确定性缩减过程”，通过显式建模智能体轨迹中可缩减的不确定性，并突出动作的“交互性”，构建了一个概念性UQ框架。

Result: 该框架统一了多种现有UQ设定，并揭示了以往方法在开放世界交互场景中的局限性，为设计面向LLM智能体的UQ机制提供了可操作的指导。

Conclusion: 论文强调了智能体UQ在前沿LLM开发和领域应用中的实际意义，并指出了若干待解决的开放问题。

Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting "interactivity" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.

</details>


### [94] [Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance](https://arxiv.org/abs/2602.05075)
*Agni Bandyopadhyay,Gunther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 本文提出一种基于强化学习的自适应避碰框架，用于小卫星执行多目标空间碎片清除任务，在保证避碰安全的同时优化燃料消耗与任务时长。


<details>
  <summary>Details</summary>
Motivation: 随着近地轨道碎片日益增多，主动碎片清除（ADR）任务面临严峻的在轨碰撞风险；现有方法在动态环境下的适应性和效率不足，亟需更智能的任务规划与避碰策略。

Method: 采用掩码Proximal Policy Optimization（PPO）算法构建强化学习框架，融合加油策略、高效任务规划与自适应避碰机制，利用Iridium 33碎片数据集构建多样化仿真场景进行训练与评估。

Result: 实验表明，所提方法相比传统启发式方法能有效降低碰撞风险，并提升任务整体效率，包括燃料节省和任务时间缩短。

Conclusion: 该强化学习框架为复杂多目标碎片清除任务提供了可扩展的解决方案，亦适用于其他自主航天器多目标交会任务。

Abstract: As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a reinforcement learning (RL) based framework to enhance adaptive collision avoidance in ADR missions, specifically for multi-debris removal using small satellites. Small satellites are increasingly adopted due to their flexibility, cost effectiveness, and maneuverability, making them well suited for dynamic missions such as ADR.
  Building on existing work in multi-debris rendezvous, the framework integrates refueling strategies, efficient mission planning, and adaptive collision avoidance to optimize spacecraft rendezvous operations. The proposed approach employs a masked Proximal Policy Optimization (PPO) algorithm, enabling the RL agent to dynamically adjust maneuvers in response to real-time orbital conditions. Key considerations include fuel efficiency, avoidance of active collision zones, and optimization of dynamic orbital parameters.
  The RL agent learns to determine efficient sequences for rendezvousing with multiple debris targets, optimizing fuel usage and mission time while incorporating necessary refueling stops. Simulated ADR scenarios derived from the Iridium 33 debris dataset are used for evaluation, covering diverse orbital configurations and debris distributions to demonstrate robustness and adaptability. Results show that the proposed RL framework reduces collision risk while improving mission efficiency compared to traditional heuristic approaches.
  This work provides a scalable solution for planning complex multi-debris ADR missions and is applicable to other multi-target rendezvous problems in autonomous space mission planning.

</details>


### [95] [Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal](https://arxiv.org/abs/2602.05091)
*Agni Bandyopadhyay,Günther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 本文比较了三种用于低地球轨道主动碎片清除任务的自主规划方法：标准Masked PPO、领域随机化Masked PPO和蒙特卡洛树搜索（MCTS），在高保真轨道仿真中评估其在不同燃料和时间约束下的性能与适应性。


<details>
  <summary>Details</summary>
Motivation: 主动碎片清除任务需在燃料和任务时长等严格约束下实现高效且适应性强的规划，因此需要评估不同规划方法在面对环境变化和约束变动时的鲁棒性与可行性。

Method: 对比三种方法：1）在固定任务参数下训练的标准Masked PPO策略；2）在多种任务约束下通过领域随机化训练的Masked PPO策略；3）作为基线的普通MCTS算法。所有方法在包含加油机制、真实轨道转移动力学和随机碎片分布的高保真仿真环境中进行测试，涵盖300个测试案例，包括正常、燃料减少和任务时间缩短三种场景。

Result: 标准PPO在匹配训练条件时表现最优，但在分布偏移下性能急剧下降；领域随机化PPO在保持较好名义性能的同时显著提升了适应性；MCTS因支持在线重规划，在处理约束变化方面最稳健，但计算开销高出数个数量级。

Conclusion: 学习型策略速度快但适应性有限，搜索型方法适应性强但计算成本高。未来有前景的方向是结合训练时的多样性与在线规划能力，以构建更鲁棒的主动碎片清除任务规划器。

Abstract: Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.

</details>


### [96] [GAMMS: Graph based Adversarial Multiagent Modeling Simulator](https://arxiv.org/abs/2602.05105)
*Rohan Patil,Jai Malegaonkar,Xiao Jiang,Andre Dion,Gaurav S. Sukhatme,Henrik I. Christensen*

Main category: cs.AI

TL;DR: GAMMS 是一个轻量级、可扩展的多智能体仿真框架，基于图结构，支持快速开发与评估各类智能体行为，适用于城市路网、通信系统等复杂场景，并兼容多种策略类型和外部工具。


<details>
  <summary>Details</summary>
Motivation: 现有高保真仿真器计算成本高，难以支持快速原型设计和大规模智能体部署；因此需要一个兼具可扩展性与易用性的轻量级仿真工具。

Method: 提出 GAMMS 框架，以图为基础建模环境，强调可扩展性、易用性、集成优先架构、快速可视化反馈和现实世界关联性，支持多种智能体策略（启发式、优化、学习型，包括大语言模型）及与外部工具（如机器学习库、规划求解器）的集成。

Result: GAMMS 能在普通硬件上高效运行复杂领域仿真，提供内置可视化，降低研究人员使用门槛，支持多智能体系统、自主规划和对抗建模的研究。

Conclusion: GAMMS 为多智能体仿真提供了一个开源、轻量且功能强大的平台，有助于推动相关领域的实验与创新。

Abstract: As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autonomous planning, and adversarial modeling. The framework is open-source and available at https://github.com/GAMMSim/GAMMS/

</details>


### [97] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: 本文提出民主偏好优化（DemPO）框架，通过算法抽签机制构建具有人口代表性的偏好数据集，用于微调语言模型，使模型行为更符合代表性公众的价值观。


<details>
  <summary>Details</summary>
Motivation: 当前基于偏好的AI对齐方法（如RLHF）依赖便利抽样获取人类评分者数据，导致某些人口群体被系统性过度或不足代表，从而影响模型价值观的公平性和代表性。

Method: DemPO引入两种训练方案：Hard Panel仅使用通过配额抽签选出的微型公众的偏好数据；Soft Panel保留全部数据但根据抽签入选概率对评分者进行加权。作者证明Soft Panel在数学上可还原Hard Panel的目标函数，并在包含人口统计信息和独立宪法条款的公开数据集上对1B至8B参数的Llama模型进行微调评估。

Result: 在六种聚合方法下，Hard Panel始终排名第一，Soft Panel始终优于未加权基线，且随着模型容量增加，效果差异更加显著。

Conclusion: 在偏好收集阶段强制实现人口代表性（而非事后修正）能有效提升模型行为与代表性公众价值观的一致性。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [98] [CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction](https://arxiv.org/abs/2602.05133)
*Abdul Joseph Fofanah,Lian Wen,David Chen,Alpha Alimamy Kamara,Zhongyi Zhang*

Main category: cs.AI

TL;DR: 本文提出CAST-CKT框架，通过引入混沌感知机制，在跨城市、数据稀缺场景下显著提升交通预测性能，并提供可解释的预测结果与不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在跨城市、数据稀疏条件下有效建模交通系统固有的混沌特性，导致小样本学习效果不佳。

Method: 提出CAST-CKT框架，包含混沌分析器以识别交通可预测性状态，并据此设计混沌感知注意力机制、自适应拓扑学习模块和基于混沌一致性的跨城市对齐策略。

Result: 在四个基准数据集上的实验表明，CAST-CKT在MAE和RMSE指标上显著优于现有最先进方法，并能提供可解释的混沌状态分析。

Conclusion: CAST-CKT有效结合混沌理论与时空建模，提升了跨城市小样本交通预测的准确性与泛化能力，具有良好的实用性和可解释性。

Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.

</details>


### [99] [HugRAG: Hierarchical Causal Knowledge Graph Design for RAG](https://arxiv.org/abs/2602.05143)
*Nengbo Wang,Tuo Liang,Vikash Singh,Chaoda Song,Van Yang,Yu Yin,Jing Ma,Jagdip Singh,Vipin Chaudhary*

Main category: cs.AI

TL;DR: HugRAG 是一种新型图结构检索增强生成（RAG）框架，通过在分层模块间引入因果门控机制，显式建模因果关系，从而抑制虚假相关性，并支持在大规模知识图谱上的可扩展推理。


<details>
  <summary>Details</summary>
Motivation: 现有图结构 RAG 方法过度依赖节点表面匹配，缺乏显式的因果建模，易产生不忠实或虚假答案；同时，已有因果方法局限于局部或单文档上下文，且受模块化图结构导致的信息孤岛限制，难以实现跨模块的可扩展因果推理。

Method: 提出 HugRAG 框架，通过在分层模块之间引入因果门控机制，对知识进行重新组织，显式建模因果关系以抑制虚假关联，并支持在大规模知识图谱上进行高效、可扩展的推理。

Result: 在多个数据集和评估指标上，HugRAG 均显著优于现有图结构 RAG 基线方法。

Conclusion: HugRAG 为构建结构化、可扩展且具有因果基础的 RAG 系统提供了原则性框架。

Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.

</details>


### [100] [First Proof](https://arxiv.org/abs/2602.05192)
*Mohammed Abouzaid,Andrew J. Blumberg,Martin Hairer,Joe Kileel,Tamara G. Kolda,Paul D. Nelson,Daniel Spielman,Nikhil Srivastava,Rachel Ward,Shmuel Weinberger,Lauren Williams*

Main category: cs.AI

TL;DR: 本文分享了十个在作者研究过程中自然产生的研究级数学问题，用于评估当前AI系统解答此类问题的能力。


<details>
  <summary>Details</summary>
Motivation: 评估当前人工智能系统是否具备正确回答研究级数学问题的能力。

Method: 提出一组十个尚未公开的、源自作者实际研究过程的数学问题，并由作者掌握答案（暂时加密）。

Result: 尚未公布结果，因答案仍处于加密状态。

Conclusion: 该问题集为衡量AI在高级数学推理方面的能力提供了一个新基准。

Abstract: To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.

</details>


### [101] [Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering](https://arxiv.org/abs/2602.05195)
*Fengxian Chen,Zhilong Tao,Jiaxuan Li,Yunlong Li,Qingguo Zhou*

Main category: cs.AI

TL;DR: 本文针对藏医药领域中多异构知识库（百科、典籍、临床论文）的检索增强生成（RAG）问题，提出DAKS路由与预算检索机制和基于对齐图的证据融合方法，有效缓解了因百科条目密度高导致的检索偏差，提升了跨知识库证据覆盖、答案忠实性与引用准确性。


<details>
  <summary>Details</summary>
Motivation: 在藏医药等专业领域，现有RAG系统在面对多个异构知识库时容易受高密度但非权威的百科内容主导，忽略更具权威性的典籍或临床文献，导致回答不准确或产生幻觉。因此，亟需提升跨知识库检索的公平性、可追溯性与证据整合能力。

Method: 提出两种互补方法：1）DAKS，通过知识库路由与预算化检索，减少密度偏差并优先选择权威来源；2）构建对齐图指导证据融合，并采用覆盖感知的打包策略，避免简单拼接，提升跨知识库证据覆盖。使用轻量级生成器openPangu-Embedded-7B生成答案。

Result: 在包含500个查询（K=5）的基准测试中，系统在路由质量与跨知识库证据覆盖率（CrossEv@5）上均取得一致提升，同时保持高忠实度与引用正确性。

Conclusion: 所提方法有效解决了多异构知识库下RAG的权威性偏差与证据整合难题，为专业领域问答系统提供了可追溯、低幻觉、高覆盖的解决方案。

Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.

</details>


### [102] [Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink](https://arxiv.org/abs/2602.05228)
*Guozhi Liu,Weiwei Lin,Tiansheng Huang,Ruichao Mo,Qi Mu,Xiumin Wang,Li Shen*

Main category: cs.AI

TL;DR: 本文提出了一种名为Surgery的防御方法，通过抑制注意力头中的“sink divergence”正向分量，减少有害微调对大语言模型安全对齐的破坏，在多个基准上显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 有害微调会破坏大语言模型的安全对齐，带来严重安全风险。现有方法难以在微调阶段有效防止模型学习有害模式，因此亟需一种能在微调过程中主动防御的方法。

Method: 作者观察到不同注意力头在“sink divergence”上呈现正负两种符号，并发现正向sink divergence与模型有害性正相关。基于此提出可分离sink divergence假设，并设计Surgery方法：在微调阶段引入正则项，抑制正向sink divergence，引导注意力头向负向群体靠拢，从而削弱模型学习有害模式的能力。

Result: 在BeaverTails、HarmBench和SorryBench三个基准上，Surgery分别提升了5.90%、11.25%和9.55%的防御性能，验证了其有效性。

Conclusion: Sink divergence的符号可作为识别与有害学习相关注意力头的指标，基于此设计的Surgery方法能有效缓解有害微调带来的安全风险，为安全对齐提供了一种新的微调阶段防御思路。

Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \emph{sink divergence} for each attention head and observe that \emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\%, 11.25\%, and 9.55\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.

</details>


### [103] [Explainable AI: A Combined XAI Framework for Explaining Brain Tumour Detection Models](https://arxiv.org/abs/2602.05240)
*Patrick McGonagle,William Farrelly,Kevin Curran*

Main category: cs.AI

TL;DR: 该研究通过融合GRAD-CAM、LRP和SHAP三种XAI技术，提升了深度学习模型在脑肿瘤检测中的可解释性，实现了91.24%的准确率，并提供了从区域到像素级的多层次解释。


<details>
  <summary>Details</summary>
Motivation: 提高深度学习模型在医疗影像（尤其是脑肿瘤检测）中的透明度与可信度，单一XAI方法难以全面揭示模型决策过程，因此需要整合多种XAI技术以获得更完整的解释。

Method: 构建一个自定义CNN模型，在BraTS 2021数据集上训练；同时结合GRAD-CAM（突出空间区域）、LRP（提供像素级相关性）和SHAP（量化特征贡献）三种XAI方法进行综合解释。

Result: 模型在区分肿瘤与非肿瘤区域上达到91.24%的准确率；多XAI融合方法能有效识别完整和部分可见的肿瘤，提供从宏观区域到像素细节的分层解释，优于单一XAI方法。

Conclusion: 集成多种XAI技术可显著提升AI系统在关键医疗任务中的可解释性与可靠性，为临床决策提供更透明、可信的支持。

Abstract: This study explores the integration of multiple Explainable AI (XAI) techniques to enhance the interpretability of deep learning models for brain tumour detection. A custom Convolutional Neural Network (CNN) was developed and trained on the BraTS 2021 dataset, achieving 91.24% accuracy in distinguishing between tumour and non-tumour regions. This research combines Gradient-weighted Class Activation Mapping (GRAD-CAM), Layer-wise Relevance Propagation (LRP) and SHapley Additive exPlanations (SHAP) to provide comprehensive insights into the model's decision-making process. This multi-technique approach successfully identified both full and partial tumours, offering layered explanations ranging from broad regions of interest to pixel-level details. GRAD-CAM highlighted important spatial regions, LRP provided detailed pixel-level relevance and SHAP quantified feature contributions. The integrated approach effectively explained model predictions, including cases with partial tumour visibility thus showing superior explanatory power compared to individual XAI methods. This research enhances transparency and trust in AI-driven medical imaging analysis by offering a more comprehensive perspective on the model's reasoning. The study demonstrates the potential of integrated XAI techniques in improving the reliability and interpretability of AI systems in healthcare, particularly for critical tasks like brain tumour detection.

</details>


### [104] [Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents](https://arxiv.org/abs/2602.05249)
*Xinyi He,Ying Yang,Chuanjian Fu,Sihan Guo,Songchun Zhu,Lifeng Fan,Zhenliang Zhang,Yujia Peng*

Main category: cs.AI

TL;DR: 本文提出了一种名为TEA的动态原位任务生成方法，用于在未见过的3D环境中评估通用智能体，通过两阶段交互-演化系统自动生成大量合理任务，并揭示了当前SOTA模型在真实场景中表现远逊于人类。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在数据污染和缺乏场景特异性的问题，无法有效评估智能体在未见3D环境中的能力，因此亟需一种面向真实家庭环境的原位评估方法。

Method: 提出TEA（Task Evolution for Agents）系统：1）交互阶段，智能体与环境互动，形成任务执行与生成的闭环；2）演化阶段，通过任务图建模重组和复用已有任务，无需外部数据即可生成新任务。

Result: 在10个未见场景中，TEA自动生成87,876个任务，经人工验证具有物理合理性并涵盖日常认知能力；对SOTA模型的评测显示其在基础感知、3D交互意识和任务类型鲁棒性方面表现显著不足。

Conclusion: 在将通用智能体部署到真实人类环境前，必须采用原位评估方法；当前模型虽在公开基准上表现优异，但在真实场景中仍存在严重缺陷。

Abstract: As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.

</details>


### [105] [Beyond Cosine Similarity](https://arxiv.org/abs/2602.05266)
*Xinbo Ai*

Main category: cs.AI

TL;DR: 本文提出了一种新的语义相似度度量方法 recos，通过改进点积的上界，超越了传统余弦相似度对线性关系的限制，在多个嵌入模型和语义文本相似度任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 余弦相似度受限于柯西-施瓦茨不等式，仅能捕捉线性关系，难以刻画真实语义空间中的非线性结构，因此需要一种更灵活、更具表达力的相似度度量方法。

Method: 作者推导出比经典柯西-施瓦茨界更紧的点积上界，并据此提出 recos 相似度：通过向量分量排序后的归一化点积来衡量相似性，将完全相似的条件从严格线性相关放宽为序数一致性。

Result: 在11种不同类型的嵌入模型（包括静态、上下文和通用嵌入）上，recos 在标准语义文本相似度（STS）基准上始终优于余弦相似度，与人类判断的相关性更高。

Conclusion: recos 是一种在理论上更严谨、在实践中更有效的语义相似度度量方法，能够更准确地捕捉复杂嵌入空间中的语义关系。

Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.

</details>


### [106] [Hallucination-Resistant Security Planning with a Large Language Model](https://arxiv.org/abs/2602.05279)
*Kim Hammar,Tansu Alpcan,Emil Lupu*

Main category: cs.AI

TL;DR: 本文提出一个结合大语言模型（LLM）与一致性校验及数字孪生反馈的迭代框架，用于提升安全事件响应中的决策可靠性，显著减少恢复时间并控制幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在安全管理工作（如事件响应规划）中具有潜力，但其不可靠性和幻觉问题限制了实际应用。因此，亟需一种可靠、可控的方法来利用LLM进行决策支持。

Method: 提出一个迭代框架：LLM生成候选动作 → 检查其与系统约束和前瞻预测的一致性 → 若一致性低，则通过数字孪生等外部反馈机制获取信息 → 利用上下文学习（ICL）优化动作。通过调节一致性阈值控制幻觉风险，并对ICL的后悔值给出理论界。

Result: 在四个公开数据集上的实验表明，该框架相比前沿LLM最多可将系统恢复时间缩短30%。

Conclusion: 所提框架有效提升了LLM在安全事件响应中的可靠性与实用性，在控制幻觉的同时显著改善了响应效率。

Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.

</details>


### [107] [Position: Universal Time Series Foundation Models Rest on a Category Error](https://arxiv.org/abs/2602.05287)
*Xilin Dai,Wanxu Cai,Zhijian Xu,Qiang Xu*

Main category: cs.AI

TL;DR: 该论文认为“通用时间序列基础模型”存在范畴错误，主张用因果控制智能体范式替代，并提出新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 作者指出当前追求通用时间序列基础模型的做法忽略了时间序列在不同领域（如金融与流体动力学）中生成机制的根本差异，导致模型在分布漂移下泛化能力差。

Method: 提出“自回归盲界”理论限制，说明仅依赖历史数据的模型无法预测干预引起的机制变化；并倡导采用因果控制智能体架构，结合外部上下文调度多个专用求解器。

Result: 揭示了通用时间序列模型的理论局限性，并为构建更具鲁棒性和适应性的系统提供了新方向。

Conclusion: 应放弃对通用性的追求，转向以“漂移适应速度”为核心的评估标准，推动面向控制理论的稳健时间序列建模。

Abstract: This position paper argues that the pursuit of "Universal Foundation Models for Time Series" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible generative processes (e.g., finance vs. fluid dynamics), monolithic models degenerate into expensive "Generic Filters" that fail to generalize under distributional drift. To address this, we introduce the "Autoregressive Blindness Bound," a theoretical limit proving that history-only models cannot predict intervention-driven regime shifts. We advocate replacing universality with a Causal Control Agent paradigm, where an agent leverages external context to orchestrate a hierarchy of specialized solvers, from frozen domain experts to lightweight Just-in-Time adaptors. We conclude by calling for a shift in benchmarks from "Zero-Shot Accuracy" to "Drift Adaptation Speed" to prioritize robust, control-theoretic systems.

</details>


### [108] [ProAct: Agentic Lookahead in Interactive Environments](https://arxiv.org/abs/2602.05327)
*Yangbin Yu,Mingyu Yang,Junyou Li,Yiming Gao,Feiyu Liu,Yijun Yang,Zichuan Lin,Jiafei Lyu,Yicheng Liu,Zhicong Lu,Deheng Ye,Jie Jiang*

Main category: cs.AI

TL;DR: 本文提出ProAct框架，通过两阶段训练提升大语言模型在长视野规划任务中的表现：首先利用基于环境搜索的轨迹进行有监督微调（GLAD），使模型内化前瞻推理能力；其次引入蒙特卡洛评论家（MC-Critic）优化策略梯度训练。实验表明该方法显著优于现有开源模型，甚至媲美顶尖闭源模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体在需要长视野规划的交互环境中表现不佳，主要因为模拟未来状态时误差不断累积，导致规划失败。

Method: 提出ProAct框架，包含两个阶段：1）Grounded LookAhead Distillation (GLAD)：基于环境搜索生成的轨迹对模型进行有监督微调，将复杂搜索树压缩为因果推理链；2）Monte-Carlo Critic (MC-Critic)：一种轻量级辅助价值估计器，通过环境rollout校准价值估计，提升策略梯度算法（如PPO、GRPO）的稳定性与准确性。

Result: 在2048（随机）和Sokoban（确定性）等环境中，ProAct显著提升规划准确率。一个4B参数模型在多个任务上超越所有开源基线，并接近顶尖闭源模型性能，同时展现出良好的泛化能力。

Conclusion: ProAct通过内化前瞻推理与高效价值估计，有效解决了LLM在长视野规划中的误差累积问题，为构建高效、通用的智能体提供了新路径。

Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct

</details>


### [109] [RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs](https://arxiv.org/abs/2602.05367)
*Youngcheon You,Banseok Lee,Minseop Choi,Seonyoung Kim,Hyochan Chong,Changdong Kim,Youngmin Kim,Dongkyu Kim*

Main category: cs.AI

TL;DR: RaBiT是一种新颖的极低比特量化框架，通过算法强制构建残差层级结构，有效缓解二值化路径间的特征共适应问题，在2比特下实现SOTA性能，并显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型极端量化（如二值化）中，现有残差二值化方法因并行路径间学习冗余特征（即“路径间适应”）而破坏误差补偿机制，限制模型表达能力；现有启发式方法（如路径冻结）又过度约束解空间。

Method: 提出RaBiT框架：其核心机制是从单一共享全精度权重依次导出各二值路径，确保每条路径校正前一条路径的误差；并通过优先保持功能而非仅逼近权重的鲁棒初始化策略来稳定训练过程。

Result: RaBiT在2比特量化下达到最先进的准确率，性能媲美计算开销更大的向量量化（VQ）方法，并在RTX 4090上实现相比全精度模型4.49倍的推理加速。

Conclusion: RaBiT通过算法构建残差层级有效解决了极低比特量化中的路径间共适应问题，重新定义了2比特量化下的精度-效率边界，为高效部署大语言模型提供了新方案。

Abstract: Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\times$ inference speed-up over full-precision models on an RTX 4090.

</details>


### [110] [Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation](https://arxiv.org/abs/2602.05381)
*Ting Fang Tan,Kabilan Elangovan,Andreas Pollreisz,Kevin Bryan Dy,Wei Yan Ng,Joy Le Yi Wong,Jin Liyuan,Chrystie Quek Wan Ning,Ashley Shuen Ying Hong,Arun James Thirunavukarasu,Shelley Yin-His Chang,Jie Yao,Dylan Hong,Wang Zhaoran,Amrita Gupta,Daniel SW Ting*

Main category: cs.AI

TL;DR: 本研究评估了四种小型医学大语言模型（Meerkat-7B、BioMistral-7B、OpenBioLLM-8B 和 MedLLaMA3-v20）在回答眼科患者问题方面的表现，并验证了基于大语言模型的自动评估与眼科医生人工评分的一致性。结果显示 Meerkat-7B 表现最佳，而 MedLLaMA3-v20 存在较多幻觉和误导性内容；GPT-4-Turbo 的自动评分与医生评分高度一致，表明混合评估框架具有临床部署潜力。


<details>
  <summary>Details</summary>
Motivation: 随着领域专用大语言模型在眼科患者教育、分诊和临床决策支持中的应用日益广泛，亟需对其安全性与准确性进行严格评估，以确保临床使用的可靠性。

Method: 研究采用横断面设计，让四个参数量低于100亿的小型医学大语言模型分别回答180个眼科患者问题，共生成2160条回复。三位不同资历的眼科医生和GPT-4-Turbo依据S.C.O.R.E.框架（涵盖安全性、共识与上下文、客观性、可重复性和可解释性）对回复进行五点李克特量表评分。通过Spearman秩相关、Kendall tau统计量和核密度估计分析模型评分与医生评分的一致性。

Result: Meerkat-7B表现最优（高级顾问、顾问和住院医师评分分别为3.44、4.08和4.18），而MedLLaMA3-v20表现最差，25.5%的回答包含幻觉或临床误导内容。GPT-4-Turbo评分与医生总体评分高度一致（Spearman rho=0.80，Kendall tau=0.67），但高级顾问评分更为保守。

Conclusion: 医学大语言模型在眼科问答中展现出安全应用的潜力，但在临床深度和共识方面仍有不足。研究支持使用大语言模型进行大规模自动评估，并建议结合自动化与医生评审的混合框架以保障临床部署的安全性。

Abstract: Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.

</details>


### [111] [H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration](https://arxiv.org/abs/2602.05407)
*Jun-Min Lee,Meong Hi Son,Edward Choi*

Main category: cs.AI

TL;DR: 本文提出了H-AdminSim，一个端到端的医院行政工作流仿真框架，结合真实数据生成与多智能体模拟，用于系统评估大语言模型（LLM）在医院行政自动化中的可行性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦于医患交互或孤立的行政子任务，未能反映真实医院行政流程的复杂性；而大型医院每日处理上万项请求，亟需更全面的LLM自动化解决方案。

Method: 构建H-AdminSim框架，整合基于FHIR标准的真实数据生成、多智能体行政流程模拟，并通过详细评分标准对LLM执行任务进行定量评估。

Result: H-AdminSim实现了跨异构医院环境的统一、可互操作的测试平台，支持对LLM驱动的行政自动化进行系统性比较和性能评估。

Conclusion: H-AdminSim为医院行政自动化提供了一个标准化测试平台，有助于推动LLM在复杂真实行政场景中的应用与优化。

Abstract: Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.

</details>


### [112] [THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs](https://arxiv.org/abs/2602.05424)
*Weijian Yu,Yuhuan Lu,Dingqi Yang*

Main category: cs.AI

TL;DR: 本文提出THOR，一种面向超关系知识图谱（HKGs）的归纳式链接预测方法，通过构建关系与实体基础图并结合图编码器与Transformer解码器，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有超关系知识图谱的链接预测方法多局限于传导式设置，无法泛化到未见过的实体和关系词汇，限制了其在实际场景中的应用。因此，亟需一种能够支持完全归纳推理的模型。

Method: 作者提出THOR方法：首先构建与具体实体/关系无关的关系基础图和实体基础图，以捕捉HKG中事实间的通用交互结构；然后采用两个并行图编码器分别处理这两类基础图，并通过Transformer解码器进行链接预测，支持高效的掩码训练和完全归纳推理。

Result: 在12个不同设置的超关系链接预测数据集上，THOR显著优于现有方法，相比最佳的基于规则、半归纳和全归纳基线方法，分别提升了66.1%、55.9%和20.4%。

Conclusion: THOR通过建模结构不变性，成功实现了在超关系知识图谱上的高效归纳链接预测，显著提升了模型泛化能力，为HKG的归纳推理提供了有效解决方案。

Abstract: Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.

</details>


### [113] [M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining](https://arxiv.org/abs/2602.05429)
*Rui Lv,Juncheng Mo,Tianyi Chu,Chen Rao,Hongyi Jing,Jiajie Teng,Jiafu Chen,Shiqi Zhang,Liangzi Ding,Shuo Fang,Huaizhong Lin,Ziqiang Dang,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: 本文提出M²-Miner，一种基于蒙特卡洛树搜索（MCTS）的低成本自动化移动端GUI智能体数据挖掘框架，通过多智能体协作与意图复用策略高效生成高质量、多样化的用户行为轨迹数据，显著提升GUI智能体在多个基准上的性能。


<details>
  <summary>Details</summary>
Motivation: 构建强大的图形用户界面（GUI）智能体需要大量高质量的用户行为轨迹数据（即意图-轨迹对），但现有手动标注和数据挖掘方法存在成本高、质量差和多样性不足三大挑战。

Method: 提出M²-Miner框架，结合蒙特卡洛树搜索（MCTS）与多智能体协作机制（InferAgent、OrchestraAgent、JudgeAgent）进行自动化数据挖掘；引入意图复用策略以提升数据多样性，并采用渐进式模型在环训练策略提高挖掘成功率。

Result: 实验表明，使用M²-Miner挖掘的数据微调的GUI智能体在多个主流移动端GUI基准上达到最先进性能。

Conclusion: M²-Miner是一种高效、低成本且自动化的GUI智能体训练数据生成方法，能有效提升数据质量和多样性，推动GUI智能体研究发展，相关成果将开源以促进社区研究。

Abstract: Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajectory pairs) for training. However, manual annotation methods and current GUI agent data mining approaches typically face three critical challenges: high construction cost, poor data quality, and low data richness. To address these issues, we propose M$^2$-Miner, the first low-cost and automated mobile GUI agent data-mining framework based on Monte Carlo Tree Search (MCTS). For better data mining efficiency and quality, we present a collaborative multi-agent framework, comprising InferAgent, OrchestraAgent, and JudgeAgent for guidance, acceleration, and evaluation. To further enhance the efficiency of mining and enrich intent diversity, we design an intent recycling strategy to extract extra valuable interaction trajectories. Additionally, a progressive model-in-the-loop training strategy is introduced to improve the success rate of data mining. Extensive experiments have demonstrated that the GUI agent fine-tuned using our mined data achieves state-of-the-art performance on several commonly used mobile GUI benchmarks. Our work will be released to facilitate the community research.

</details>


### [114] [Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy](https://arxiv.org/abs/2602.05430)
*Kritchanat Ponyuenyong,Pengyu Tu,Jia Wei Tan,Wei Soon Cheong,Jamie Ng Suat Ling,Lianlian Jiang*

Main category: cs.AI

TL;DR: 本文研究时间序列基础模型（TSFMs）在新加坡日前电力价格预测中的表现，提出尖峰正则化策略，发现TSFMs显著优于传统统计和深度学习模型，MAPE最高提升37.4%。


<details>
  <summary>Details</summary>
Motivation: 电力价格具有高度波动性和非线性，传统统计与深度学习模型难以有效捕捉其复杂时序依赖并融合多源异构数据；尽管TSFMs在其他时序任务中表现优异，其在高波动电力市场日前预测中的潜力尚未充分探索。

Method: 提出尖峰正则化策略，并在包含尖峰趋势的新加坡半小时间隔批发电价数据上，评估多种TSFMs（如TTMs、MOIRAI、MOMENT、TimesFM）与传统模型（ARIMA、LSTM、CNN-LSTM）的性能；同时将天气和日历等外生变量纳入适用模型中。

Result: TSFMs在各种评估设置下均一致优于传统方法，MAPE指标最高提升37.4%。

Conclusion: TSFMs能显著提升高波动电力市场中的日前电价预测精度，为市场参与者提供实用的决策支持。

Abstract: Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.

</details>


### [115] [Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning](https://arxiv.org/abs/2602.05464)
*Jiaquan Wang,Yan Lyu,Chen Li,Yuheng Jia*

Main category: cs.AI

TL;DR: 本文提出OD-CRL框架，通过自适应正交基优化（AOBO）和零空间去噪投影（NSDP）提升条件表征学习性能，在多项定制任务中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有条件表征学习方法对子空间基敏感且易受子空间间干扰影响，限制了其泛化能力与稳定性。

Method: 提出OD-CRL框架：1）利用奇异值分解结合曲率截断构建正交语义基（AOBO）；2）将嵌入投影到无关子空间的零空间以抑制非目标语义干扰（NSDP）。

Result: 在定制聚类、分类与检索任务上实验表明，OD-CRL显著优于现有方法，实现新的SOTA性能并具备更强泛化能力。

Conclusion: OD-CRL有效缓解了条件表征学习中的基敏感性和子空间干扰问题，为定制化任务提供了更鲁棒、通用的表征学习方案。

Abstract: Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.

</details>


### [116] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE 是一种无需人工监督的对齐框架，通过对抗学习与语言化反馈，使大语言模型内化推理逻辑，从而突破传统强化学习中稀疏、脆弱且昂贵的标量奖励瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖外部标量奖励，难以扩展、跨域泛化差且无法捕捉推理过程的内在逻辑，阻碍了大语言模型发展深层次的自主推理能力。

Method: 提出 ALIVE 框架，基于“认知协同”原则，在单一策略模型中统一问题提出、求解与评判，利用对抗学习和语言化评价反馈，从原始语料中内化正确性标准。

Result: 在数学推理、代码生成和逻辑推理任务上，ALIVE 在相同数据与算力下显著提升准确率、跨域泛化能力和自纠错率。

Conclusion: ALIVE 通过构建推理三位一体机制，实现无需人工干预的自持续推理能力增长，为通用推理对齐提供了可扩展的基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [117] [Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction](https://arxiv.org/abs/2602.05479)
*Zhe Wang,Zijing Liu,Chencheng Xu,Yuan Yao*

Main category: cs.AI

TL;DR: 本文提出Phi-former，一种基于分子片段（motif）层次化建模化合物-蛋白质相互作用（CPI）的深度学习方法，在多个交互层级上提升预测性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽在原子层面建模CPI取得进展，但忽视了生物识别中起关键作用的分子片段（如官能团），导致模型与化学现实不一致。

Method: Phi-former采用层次化表示化合物和蛋白质，并通过成对预训练框架，在原子-原子、片段-片段及原子-片段三个层级上系统建模相互作用，设计了层内与跨层学习机制以增强各层级间的协同。

Result: 实验表明Phi-former在CPI相关任务上性能优于现有方法，案例研究显示其能准确识别参与相互作用的关键原子或片段，提供可解释结果。

Conclusion: Phi-former通过引入生物合理的片段层级交互建模，不仅提升了CPI预测准确性，还增强了模型可解释性，有望助力理性药物设计与精准医疗。

Abstract: Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.

</details>


### [118] [SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration](https://arxiv.org/abs/2602.05499)
*Hanyu Wei,Zunhai Su,Peng Lu,Chao Li,Spandan Tiwari,Ashish Sirasao,Yuhan Dong*

Main category: cs.AI

TL;DR: SDFP 是一种无需训练、即插即用的推测解码框架，通过基于 Fisher 信息迹（FIT）的层剪枝构建草稿模型，在不改变目标大语言模型输出分布的前提下，实现 1.32x–1.5x 的解码加速。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多媒体交互应用中因自回归解码导致高延迟；现有推测解码方法依赖额外训练或复杂优化来构建有效的草稿模型，部署成本高。

Method: 提出 SDFP 框架，利用 FIT 度量各层对输出扰动的敏感性，剪除影响小的层以构建紧凑草稿模型，无需训练、调参或维护独立草稿模型。

Result: 在多个基准测试中，SDFP 实现了 1.32x–1.5x 的解码速度提升，同时保持目标模型输出分布不变。

Conclusion: SDFP 提供了一种高效、轻量且易于部署的推测解码方案，适用于低延迟多媒体应用场景。

Abstract: Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.

</details>


### [119] [A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma](https://arxiv.org/abs/2602.05515)
*Ajo Babu George,Anna Mariam John,Athul Anoop,Balu Bhasuran*

Main category: cs.AI

TL;DR: 本文构建了一个专注于成釉细胞瘤的多模态数据集，并开发了相应的深度学习模型，显著提升了亚型分类准确率和异常组织检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在成釉细胞瘤覆盖范围和格式一致性方面存在不足，难以直接用于AI模型训练，因此需要构建结构化、高质量的多模态数据资源。

Method: 整合带注释的放射影像、组织病理图像和口内临床图像，并利用自然语言处理从病例报告中提取结构化临床特征；对图像进行领域特定的预处理与增强；构建可接受临床输入（如主诉、年龄、性别）的多模态深度学习模型。

Result: 成釉细胞瘤亚型分类准确率从46.2%提升至65.9%，异常组织检测F1分数从43.0%提升至90.3%。

Conclusion: 该研究通过提供高质量多模态数据集和可适配的AI框架，在成釉细胞瘤诊疗中实现了更优的患者个体化决策支持。

Abstract: Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.

</details>


### [120] [Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities](https://arxiv.org/abs/2602.05532)
*Florian Dietz,William Wale,Oscar Gilg,Robert McCarthy,Felix Michalak,Gustavo Ewbank Rodrigues Danon,Miguelito de Guzman,Dietrich Klakow*

Main category: cs.AI

TL;DR: 本文提出“分裂人格训练”（SPT）方法，在LoRA参数中微调一个“诚实人格”，用于检测大型语言模型在正常运行时隐藏的不当行为。该方法在Anthropic审计游戏模型生物基准上对Llama-3.3-70B进行测试，准确率达96%，远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒审计方法难以区分模型的恶意输出与正常输出，而机制可解释性方法又难以随模型能力扩展。因此，亟需一种能有效揭示模型隐藏不当行为的新方法。

Method: 通过Split Personality Training（SPT），在LoRA适配器中训练一个“诚实人格”，该人格在模型正常运行时不激活；在主模型生成回应后，通过触发字符串激活LoRA，并让诚实人格访问主模型的潜在状态以审查其输出。

Result: 在Anthropic Auditing Game Model Organism基准上，SPT对经过奖励黑客训练并试图隐藏行为的Llama-3.3-70B模型实现了96%的整体检测准确率，而Anthropic报告的准确率接近0%。

Conclusion: SPT能够有效揭示模型内部隐藏的知识（如虚构偏见），为检测大型语言模型的隐蔽性错位行为提供了可行且高效的解决方案。

Abstract: Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.

</details>


### [121] [TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?](https://arxiv.org/abs/2602.05570)
*Yikun Zong,Cheston Tan*

Main category: cs.AI

TL;DR: 本文提出一种受人类认知启发的测试时自优化框架，通过上下文学习与奖励反馈机制显著提升视觉语言模型在连续几何推理任务（如七巧板拼图）中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在连续几何推理任务中表现远逊于人类，尤其在多部件组合任务中性能急剧下降；作者旨在探索模型能否在不更新参数的情况下通过测试时迭代优化提升性能。

Method: 提出一个无需训练的验证-优化智能体，结合上下文学习（ICL）与基于几何一致性的奖励反馈回路，实现递归式预测自优化。

Result: 在中等三角形任务中，IoU从0.63提升至0.932；在单部件和双部件任务中，原始VLM平均IoU分别为0.41和0.23，显著低于人类水平。

Conclusion: 引入受人类启发的迭代优化机制可显著增强VLM的几何推理能力，使测试时自优化AI在连续空间任务中从理论走向实践。

Abstract: Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, and correction, we design a framework that models these human cognitive mechanisms. However, comprehensive experiments across five representative Vision-Language Models (VLMs) reveal systematic failures in continuous geometric reasoning: average IoU of only 0.41 on single-piece tasks, dropping to 0.23 on two-piece composition, far below human performance where children can complete Tangram tasks successfully. This paper addresses a fundamental challenge in self-improving AI: can models iteratively refine their predictions at test time without parameter updates? We introduce a test-time self-refinement framework that combines in-context learning (ICL) with reward-guided feedback loops, inspired by human cognitive processes. Our training-free verifier-refiner agent applies recursive refinement loops that iteratively self-refine predictions based on geometric consistency feedback, achieving IoU improvements from 0.63 to 0.932 on medium-triangle cases without any model retraining. This demonstrates that incorporating human-inspired iterative refinement mechanisms through ICL and reward loops can substantially enhance geometric reasoning in VLMs, moving self-improving AI from promise to practice in continuous spatial domains. Our work is available at this anonymous link https://anonymous.4open.science/r/TangramVLM-F582/.

</details>


### [122] [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625)
*Simon Kohaut,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Resin的反应式概率编程语言及其底层执行机制Reactive Circuits（RCs），通过将计算按输入信号变化频率划分并仅更新受影响部分，显著提升了动态环境中实时概率推理的效率。


<details>
  <summary>Details</summary>
Motivation: 在复杂概率模型中进行精确推理通常计算成本高昂，尤其对需要频繁实时信念更新的自主智能体而言。现有方法在信息流变化时重新评估整个模型，未利用现实世界中信息更新速率异构的特点，导致效率低下。

Method: 作者引入Resin语言，结合概率逻辑与反应式编程；并提出Reactive Circuits（RCs）作为其高效精确语义基础。RCs是一种基于代数电路和异步数据流的元结构，构建为时间动态的有向无环图，能根据输入信号的波动性自主调整结构，并通过记忆化机制仅重算受影响子问题。

Result: 在高保真无人机群仿真中，该方法相比不考虑频率的推理方法实现了数个数量级的速度提升，显著降低延迟，有效支持实时反应式推理。

Conclusion: 通过依据异步输入的变化频率划分计算任务，RCs能有效捕捉环境动态，避免冗余计算，为动态环境中的高效精确概率推理提供了新范式。

Abstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.

</details>


### [123] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 本文提出“生成式本体”（Generative Ontology）框架，结合传统本体的结构性与大语言模型（LLM）的创造性，通过可执行的Pydantic模式和多智能体流程，在保证结构有效性的前提下生成新颖、连贯的领域工件（如桌游设计），并指出该方法可推广至音乐、软件架构等其他领域。


<details>
  <summary>Details</summary>
Motivation: 传统本体虽能描述领域结构但无法生成新内容，而大语言模型虽具生成能力却常产出结构无效或幻觉内容。为融合二者优势，作者提出一种既能保障结构性又能激发创造力的新范式。

Method: 将领域知识编码为可执行的Pydantic本体模式，通过DSPy签名约束LLM生成；采用多智能体流水线（如机制架构师、主题编织者、平衡批评者），各角色携带专业“焦虑”以避免肤浅输出；结合检索增强生成与迭代验证，确保生成内容在机制与组件间保持一致。

Result: 在GameGrammar系统中，给定主题提示（如“洞穴生态系统中竞争的生物发光真菌”），该框架能生成结构完整、可玩的桌游设计方案，包含机制、组件、胜利条件和设置说明，同时满足本体约束并体现创意。

Conclusion: 生成式本体提供了一种通用模式：在具备专家术语、有效性约束和历史范例的领域中，结构化约束非但不限制创造力，反而使其成为可能——正如语法规则成就诗歌，本体使结构化生成成为现实。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [124] [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665)
*Chang Yang,Chuang Zhou,Yilin Xiao,Su Dong,Luyao Zhuang,Yujing Zhang,Zhu Wang,Zijin Hong,Zheng Yuan,Zhishang Xiang,Shengyuan Chen,Huachi Zhou,Qinggang Zhang,Ninghao Liu,Jinsong Su,Xinrun Wang,Yi Chang,Xiao Huang*

Main category: cs.AI

TL;DR: 本文综述了基于图结构的大语言模型智能体记忆系统，涵盖分类、关键技术、开源工具、应用场景及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 为应对复杂长周期任务中对高效记忆机制的需求，探索图结构在智能体记忆中的优势与潜力。

Method: 提出基于图的智能体记忆分类体系，并按记忆生命周期（提取、存储、检索、演化）系统分析关键技术；同时汇总相关开源库、基准和应用。

Result: 构建了图记忆系统的全面综述框架，整理了现有研究、工具与资源，并指出了当前挑战与发展方向。

Conclusion: 图结构在建模关系依赖、组织层次信息和支持高效检索方面具有显著优势，是构建高效可靠智能体记忆系统的重要方向。

Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.

</details>


### [125] [Determining Energy Efficiency Sweet Spots in Production LLM Inference](https://arxiv.org/abs/2602.05695)
*Hiari Pizzini Cavagna,Andrea Proia,Giacomo Madella,Giovanni B. Esposito,Francesco Antici,Daniele Cesarini,Zeynep Kiziltan,Andrea Bartolini*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer架构计算与内存访问复杂度的分析模型，用于准确预测大语言模型（LLM）推理过程中的能效曲线，并发现存在“能效甜点”：短至中等输入与中等长度输出时能效最高。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常用输入和输出序列长度的线性函数估算LLM推理能耗，但实际能效表现出非线性特征，尤其在长输入或极短输出时效率显著下降，因此需要更精确的能耗建模方法。

Method: 作者基于Transformer的计算与内存访问复杂度构建了一个分析模型，并在NVIDIA H100 GPU上使用TensorRT-LLM对多种LLM（如OPT、LLaMA、Gemma等）在不同输入/输出长度（64–4096 tokens）下进行能耗评估。

Result: 该模型在1B至9B参数的多种LLM上实现了平均1.79%的MAPE误差，验证了其高准确性；同时发现合理调整序列长度可显著降低能耗。

Conclusion: 通过识别并利用能效“甜点”，可在实际系统中通过截断、摘要或自适应生成策略有效降低LLM推理的能源消耗。

Abstract: Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency "Sweet Spots" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.

</details>


### [126] [Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions](https://arxiv.org/abs/2602.05709)
*Yihao Ouyang,Shiwei Li,Haozhao Wang,Xiandi Luo,Zhuoqi Hu,Yuetong Song,Qiyu Qin,Yichen Li,Ruixuan Li*

Main category: cs.AI

TL;DR: 本文提出GenLoRA，通过轻量级非线性函数生成低秩适配器的基向量，替代显式存储，从而在更少参数下实现更高有效秩和更优微调性能。


<details>
  <summary>Details</summary>
Motivation: 标准LoRA采用显式秩范式，增加模型容量需添加更多基向量，导致参数显著增长；作者发现这些基向量存在冗余，可被紧凑表示。

Method: 提出Generative Low-Rank Adapter（GenLoRA），为每个低秩矩阵维护一个潜在向量，并使用轻量级径向基函数（RBF）合成基向量。

Result: 在多个数据集和架构上的实验表明，GenLoRA在更小参数预算下达到更高的有效LoRA秩，微调性能优于标准LoRA。

Conclusion: GenLoRA通过非线性基向量生成机制显著提升了参数效率，在保持甚至提升性能的同时减少了参数开销。

Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.

</details>


### [127] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种名为锚定策略优化（APO）的新方法，通过从全局形状匹配转向支持覆盖，有效缓解强化学习中因奖励可验证性导致的递归空间收缩问题，在提升准确率的同时恢复解的多样性。


<details>
  <summary>Details</summary>
Motivation: 现有基于KL正则化的强化学习方法在应对递归空间收缩（RSC）问题时存在缺陷：其强制策略模仿参考模型整体分布的“形状匹配”约束，与实现正确性所需的锐化机制产生梯度冲突，导致有效解空间不可逆坍缩。

Method: 作者提出锚定策略优化（APO），构建基于参考模型高置信度支撑集的安全流形，允许策略在正常情况下进行高效锐化，仅在出错时施加恢复力以防止坍缩，并从理论上证明APO是一种梯度对齐的支持覆盖最大化机制。

Result: 在数学推理基准上的实验表明，APO方法不仅显著提升了Pass@1准确率，还成功恢复了标准策略梯度方法通常丢失的Pass@K多样性，打破了准确率与多样性之间的权衡。

Conclusion: 通过将优化目标从全局分布匹配转变为支撑集覆盖，APO有效解决了RLVR中的递归空间收缩问题，实现了弹性恢复与性能提升的统一。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [128] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 本文提出一种结合强化学习与细粒度知识验证（RLFKV）的方法，用于提升金融RAG系统中生成内容与检索文档的一致性，减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 金融领域对时效性要求高，RAG系统虽利用检索文档补充知识，但生成内容仍常出现与检索信息矛盾的幻觉问题，亟需提升生成结果的忠实度。

Method: 将生成的回答分解为原子知识单元，通过细粒度知识验证计算忠实度奖励，并结合信息量奖励防止模型生成过于简略的回答，利用强化学习联合优化。

Result: 在公开FDD任务和新构建的FDD-ANT数据集上均取得一致性能提升，验证了方法的有效性。

Conclusion: 所提出的RLFKV框架能有效提升金融RAG系统生成内容与检索文档的一致性，在保证信息量的同时显著减少幻觉。

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


### [129] [RocqSmith: Can Automatic Optimization Forge Better Proof Agents?](https://arxiv.org/abs/2602.05762)
*Andrei Kozyrev,Nikita Khramov,Denis Lochmelis,Valerio Morelli,Gleb Solovev,Anton Podkopaev*

Main category: cs.AI

TL;DR: 本文研究了自动AI智能体优化方法在真实世界形式化验证任务（以Rocq自动定理证明为代表）中的适用性，发现虽然多种优化器能带来一定提升，但简单的少样本引导方法最为稳定有效，仍无法超越精心设计的最先进证明智能体。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以将自动AI智能体优化方法应用于真实的形式化验证场景，特别是在Rocq自动定理证明这一具有挑战性的领域中，自动化智能体系统中如提示设计、上下文知识和控制策略等细粒度调优环节。

Method: 评估多种自动智能体优化器在优化Rocq证明生成智能体任务上的表现，比较其在提示工程、上下文知识整合和控制策略等方面的自动化调优效果。

Result: 多个优化器带来了可测量的性能提升，其中简单的少样本引导（few-shot bootstrapping）方法表现最为一致且有效，但所有方法均未达到当前最先进的手工设计证明智能体的性能水平。

Conclusion: 尽管自动优化方法在Rocq定理证明任务中展现出一定潜力，但目前尚无法完全替代人工精心设计的智能体系统，未来需进一步改进自动化优化策略。

Abstract: This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.

</details>


### [130] [RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism](https://arxiv.org/abs/2602.05765)
*Zhong Guan,Haoran Sun,Yongjian Guo,Shuai Di,Xiaodong Bai,Jing Long,Tianyun Zhao,Mingxi Luo,Chen Zhou,Yucheng Guo,Qiming Yang,Wanting Xu,Wen Huang,Yunxuan Ma,Hongke Zhao,Likang Wu,Xiaotie Deng,Xi Xiao,Sheng Wen,Yicheng Gong,Junwu Xiong*

Main category: cs.AI

TL;DR: 本文首次提出了一种端到端完全异步的视觉-语言-动作（VLA）策略训练框架，显著提升了训练吞吐量和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的VLA模型训练方法（如RLinf）依赖同步执行，在环境交互、策略生成和模型更新阶段存在严重的资源利用率低和吞吐量瓶颈问题。

Method: 借鉴大模型强化学习中的异步优化思想，设计了多级解耦架构：异步并行化环境交互与轨迹收集、流式策略生成、解耦调度的训练更新。

Result: 在LIBERO基准上，相比同步策略最高提升59.25%吞吐量；深度优化分离策略后可达126.67%提升。消融实验证明各异步组件有效性，8至256 GPU扩展实验显示良好可扩展性。

Conclusion: 所提出的全异步训练框架有效解决了VLA模型训练效率瓶颈，显著提升吞吐量与可扩展性，为通用具身智能的高效训练提供了新路径。

Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.

</details>


### [131] [FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem](https://arxiv.org/abs/2602.05794)
*Aboli Kathar,Aman Kumar,Anusha Kamath,Araveeti Srujan,Ashish Sharma,Chandra Bhushan,Dilip Asbe,Divya Sorate,Duddu Prasanth Kumar,Evan Acharya,Harsh Sharma,Hrithik Kadam,Kanishk Singla,Keyur Doshi,Kiran Praveen,Kolisetty Krishna SK,Krishanu Adhikary,Lokesh MPT,Mayurdeep Sonowal,Nadeem Shaikh,Navya Prakash,Nimit Kothari,Nitin Kukreja,Prashant Devadiga,Rakesh Paul,Ratanjeet Pratap Chauhan,Raunak Kalani,Raviraj Joshi,Shamanth MH,Shantanu Pandey,Shubham Soni,Siddharth Dixit,Smriti Jopat,Sunil Patel,Suraj Singh,Suvradip Paul,Tulasi Pilla,Utkarsh Vaidya,Vineeth Nambiar,Vishal Kanvaty,Yatharth Dedhia*

Main category: cs.AI

TL;DR: 本文提出了FiMI（Finance Model for India），一个专为印度数字支付系统设计的金融领域语言模型，包含FiMI Base和FiMI Instruct两个版本，在金融推理和工具调用任务上显著优于基线模型，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 为满足印度数字支付系统对多语言、领域特定金融对话能力的需求，开发一个在金融任务（如交易争议处理和授权生命周期管理）中表现优异的语言模型。

Method: 基于Mistral Small 24B架构，采用多阶段训练流程：首先在680亿token的金融、多语言（英语、印地语、Hinglish）及合成数据上进行持续预训练，然后进行指令微调和面向多轮工具驱动对话的领域监督微调。

Result: FiMI Base在金融推理基准上比Mistral Small 24B Base提升20%；FiMI Instruct在领域工具调用任务上比Mistral Small 24B Instruct提升87%；同时在通用基准上保持与同类模型相当的性能。

Conclusion: FiMI通过领域定制化训练，在印度金融场景中显著提升模型性能，证明了在保留通用能力的同时进行高效领域适配的可行性。

Abstract: We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.

</details>


### [132] [NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking](https://arxiv.org/abs/2602.05805)
*Kang Chen,Zhuoka Feng,Sihan Zhao,Kai Xiong,Junjie Nian,Yaoning Wang,Changyi Xiao,Yixin Cao*

Main category: cs.AI

TL;DR: 本文提出NEX，一种无监督、无需标签的白盒评分框架，通过分析大语言模型推理过程中MLP神经元的稀疏激活模式，识别探索（E）与利用（X）阶段，并据此评估生成答案或模型合并变体的质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在推理时越来越多地采用多轨迹采样或检查点合并搜索，选择环节成为瓶颈，而目标分布上往往缺乏监督信号。现有基于熵的探索度量存在冗余甚至“过度思考”问题，亟需一种无需标签、可解释且有效的评估方法。

Method: NEX将推理过程建模为交替的E-phase（探索）和X-phase（利用）。通过稀疏激活缓存检测每token中新激活的MLP神经元尖峰以识别E-phase，再用粘性二状态隐马尔可夫模型（HMM）推断E-X阶段转换，并根据E阶段引入的神经元是否在后续X阶段被重用来赋予权重，最终形成可解释的神经元权重和单一的Good-Mass Fraction分数用于排序候选响应。

Result: 在多个推理基准和Qwen3合并模型族上，仅使用小型无标签激活集计算的NEX分数能有效预测下游准确率，并识别出更优的模型变体。人工标注验证了E-X信号的有效性，并通过“有效vs冗余”神经元迁移实验提供了因果证据。

Conclusion: NEX提供了一种无需任务标签、基于内部神经元激活动态的无监督评估机制，能有效指导推理结果选择与模型合并优化，揭示了大模型推理中探索与利用的内在机制。

Abstract: Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an inverted-U with accuracy, suggesting extra exploration can become redundant and induce overthinking. We propose NEX, a white-box label-free unsupervised scoring framework that views reasoning as alternating E-phase (exploration) and X-phase (exploitation). NEX detects E-phase as spikes in newly activated MLP neurons per token from sparse activation caches, then uses a sticky two-state HMM to infer E-X phases and credits E-introduced neurons by whether they are reused in the following X span. These signals yield interpretable neuron weights and a single Good-Mass Fraction score to rank candidate responses and merged variants without task answers. Across reasoning benchmarks and Qwen3 merge families, NEX computed on a small unlabeled activation set predicts downstream accuracy and identifies better variants; we further validate the E-X signal with human annotations and provide causal evidence via "Effective-vs-Redundant" neuron transfer.

</details>


### [133] [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818)
*Zihao Jiang,Miao Peng,Zhenyan Shan,Wenjie Xu,Ben Liu,Gong Chen,Ziqi Gao,Min Peng*

Main category: cs.AI

TL;DR: 本文提出TKG-Thinker，一种具备自主规划与自适应检索能力的智能体，通过动态多轮交互和双阶段训练策略（SFT+强化学习），在时序知识图谱问答任务中实现SOTA性能与强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的时序知识图谱问答方法存在两个主要问题：一是在复杂时间约束下容易产生推理幻觉；二是静态提示策略缺乏与知识图谱环境的动态交互，限制了模型的自主性与泛化能力。

Method: 提出TKG-Thinker智能体，采用双阶段训练策略：首先通过带思维链数据的监督微调（SFT）赋予模型基础规划能力，再通过强化学习结合多维奖励机制优化其在复杂时间约束下的推理策略，并支持与TKG的动态多轮交互。

Result: 在多个基准数据集上使用三种开源大语言模型进行实验，TKG-Thinker均取得当前最优性能，并在复杂TKGQA场景中展现出良好的泛化能力。

Conclusion: TKG-Thinker通过引入自主规划与自适应检索机制，有效缓解了LLM在TKGQA中的幻觉问题并提升了泛化能力，为时序知识图谱问答提供了新的高效解决方案。

Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.

</details>


### [134] [OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention](https://arxiv.org/abs/2602.05847)
*Zhangquan Chen,Jiale Tao,Ruihuang Li,Yihao Hu,Ruitao Chen,Zhantao Yang,Xinlei Yu,Haodong Jing,Manyuan Zhang,Shuai Shao,Biao Wang,Qinglin Lu,Ruqi Huang*

Main category: cs.AI

TL;DR: 本文提出了OmniVideo-R1，一种通过多模态线索增强音视频理解的新框架，在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有全视频模型在音频-视觉理解任务中仍存在挑战，缺乏对多模态协同感知的有效建模。

Method: 提出OmniVideo-R1框架，包含两个关键策略：(1) 基于自监督学习的查询密集型定位；(2) 基于对比学习的模态注意力融合。

Result: 在多个基准上的实验表明，OmniVideo-R1持续优于强基线模型，展现出良好的泛化能力。

Conclusion: OmniVideo-R1有效提升了模型对多模态信息的推理能力，为音视频理解任务提供了新的解决思路。

Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to "think with omnimodal cues" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.

</details>


### [135] [BABE: Biology Arena BEnchmark](https://arxiv.org/abs/2602.05857)
*Junting Zhou,Jin Chen,Linfeng Hao,Denghui Cao,Zheyu Wang,Qiguang Chen,Chaoyou Fu,Jiaze Chen,Yuchen Wu,Ge Zhang,Mingxuan Wang,Wenhao Huang,Tong Yang*

Main category: cs.AI

TL;DR: 本文提出了BABE（Biology Arena BEnchmark），一个基于真实生物学研究论文的新型基准，用于评估大语言模型在整合实验结果与背景知识、进行因果推理和跨尺度推断方面的科研推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有生物学领域的评测基准未能有效衡量AI系统将实验结果与上下文知识结合以得出科学结论的关键能力，因此需要一个更贴近真实科研场景的评估框架。

Method: 构建名为BABE的评测基准，其任务源自同行评审的研究论文和真实世界生物学研究，要求模型完成因果推理和跨尺度推断等复杂任务。

Result: BABE能有效评估AI系统在模拟真实生物科研过程中的推理能力，提供比现有基准更真实、全面的性能衡量标准。

Conclusion: BABE为评估AI在生物学研究中的科学推理能力提供了可靠框架，有助于推动AI系统在生命科学领域的实际应用与进步。

Abstract: The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.

</details>


### [136] [Beyond Manual Planning: Seating Allocation for Large Organizations](https://arxiv.org/abs/2602.05875)
*Anton Ipsen,Michael Cashmore,Kirsty Fielding,Nicolas Marchesotti,Parisa Zehtabi,Daniele Magazzeni,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文提出了层级座位分配问题（HSAP），旨在将具有层级结构的组织团队最优地分配到物理座位布局中，并设计了一个结合概率路线图（PRM）、快速探索随机树（RRT）、启发式搜索与动态规划的端到端框架来高效求解该问题。


<details>
  <summary>Details</summary>
Motivation: 大型组织常需根据团队的层级关系安排座位，例如让同一研究组占据连续区域，但目前多依赖人工操作，导致重规划频率低且效果不佳，因此亟需自动化、优化的解决方案。

Method: 提出一个端到端框架：首先利用PRM和RRT高效计算任意座位对之间的距离，再结合启发式搜索与动态规划，通过整数规划求解HSAP。

Result: 在不同规模实例上验证了所提PRM框架及座位分配方案的有效性，通过定量与定性评估展示了方法的可扩展性和实用性。

Conclusion: 该框架能有效自动化解决层级座位分配问题，显著优于当前的人工方法，为大型组织的空间规划提供了实用工具。

Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.

</details>


### [137] [Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy](https://arxiv.org/abs/2602.05877)
*Lukas Stappen,Ahmet Erkan Turan,Johann Hagerer,Georg Groh*

Main category: cs.AI

TL;DR: 本文提出了一种名为 AgentHeLLM 的威胁建模框架，用于分析车载大语言模型（LLM）智能体的安全风险，通过将资产识别与攻击路径分析分离，并结合以人为本的资产分类和图模型，实现对多阶段攻击路径的自动化发现。


<details>
  <summary>Details</summary>
Motivation: 随着基于 LLM 的对话智能体被集成到车辆中，其与外部服务（如 Google A2A 协议）的交互引入了新的安全挑战。现有 AI 安全框架未能在安全关键系统中遵循“关注点分离”原则，混淆了保护对象（资产）与攻击方式（攻击路径），亟需一种更结构化的方法来系统化地识别和分析威胁。

Method: 作者提出了 AgentHeLLM 框架，包含两个核心部分：一是基于“受害者建模”并参考《世界人权宣言》的人本资产分类法；二是形式化的图模型，区分“污染路径”（恶意数据传播）与“触发路径”（激活行为）。此外，开发了开源工具 AgentHeLLM Attack Path Generator，采用双层搜索策略自动发现多阶段攻击路径。

Result: 该框架成功实现了对车载 LLM 智能体潜在攻击路径的结构化建模与自动化发现，验证了其在实际场景中的适用性，并为安全关键系统中的 AI 威胁建模提供了新方法。

Conclusion: AgentHeLLM 通过分离资产与攻击路径，提升了对 LLM 智能体安全风险的系统性理解，为未来智能汽车及其他安全关键领域中 AI 系统的安全设计提供了可扩展的威胁建模基础。

Abstract: The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as Google's Agent-to-Agent (A2A), they establish attack surfaces where manipulations can propagate through natural language payloads, potentially causing severe consequences ranging from driver distraction to unauthorized vehicle control. Existing AI security frameworks, while foundational, lack the rigorous "separation of concerns" standard in safety-critical systems engineering by co-mingling the concepts of what is being protected (assets) with how it is attacked (attack paths). This paper addresses this methodological gap by proposing a threat modeling framework called AgentHeLLM (Agent Hazard Exploration for LLM Assistants) that formally separates asset identification from attack path analysis. We introduce a human-centric asset taxonomy derived from harm-oriented "victim modeling" and inspired by the Universal Declaration of Human Rights, and a formal graph-based model that distinguishes poison paths (malicious data propagation) from trigger paths (activation actions). We demonstrate the framework's practical applicability through an open-source attack path suggestion tool AgentHeLLM Attack Path Generator that automates multi-stage threat discovery using a bi-level search strategy.

</details>


### [138] [A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges](https://arxiv.org/abs/2602.05883)
*Philippe J. Giabbanelli*

Main category: cs.AI

TL;DR: 本文为在建模与仿真（M&S）中使用大语言模型（LLMs）提供实用指南，指出常见误区并强调基于原则的设计、诊断策略和实证评估。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在M&S领域日益普及，但许多看似简单的实践（如提示工程、温度设置、微调等）可能带来性能下降、信息丢失或非预期后果。作者旨在澄清误解，帮助研究者做出更明智的使用决策。

Method: 通过分析LLMs在M&S应用中的典型问题（如非确定性、知识增强方法、数据分解和超参数设置），提出以原则性设计、诊断策略和实证评估为核心的指导框架。

Result: 揭示了若干常见但有害的做法（如盲目增加数据、默认温度设为0、过度输入M&S数据等），并提供了替代方案和最佳实践建议。

Conclusion: 在M&S中有效使用LLMs需避免直觉驱动的误区，应结合系统性评估与领域知识，审慎选择是否及如何集成LLMs。

Abstract: Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&S) workflows. However, practices that appear straightforward may introduce subtle issues, unnecessary complexity, or may even lead to inferior results. Adding more data can backfire (e.g., deteriorating performance through model collapse or inadvertently wiping out existing guardrails), spending time on fine-tuning a model can be unnecessary without a prior assessment of what it already knows, setting the temperature to 0 is not sufficient to make LLMs deterministic, providing a large volume of M&S data as input can be excessive (LLMs cannot attend to everything) but naive simplifications can lose information. We aim to provide comprehensive and practical guidance on how to use LLMs, with an emphasis on M&S applications. We discuss common sources of confusion, including non-determinism, knowledge augmentation (including RAG and LoRA), decomposition of M&S data, and hyper-parameter settings. We emphasize principled design choices, diagnostic strategies, and empirical evaluation, with the goal of helping modelers make informed decisions about when, how, and whether to rely on LLMs.

</details>


### [139] [Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2602.05920)
*Eva Andrés*

Main category: cs.AI

TL;DR: 本文比较了经典与量子强化学习方法在解决带容量限制的车辆路径问题（CVRP）中的表现，发现混合量子-经典架构在路径距离、紧凑性和重叠度方面均优于纯经典和全量子模型。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算与强化学习结合在解决复杂组合优化问题（如CVRP）中的潜力，特别是通过引入量子增强机制提升路由策略的学习效果与鲁棒性。

Method: 构建了经典、全量子和混合三种Advantage Actor-Critic（A2C）智能体，并融合Transformer架构，利用自注意力和交叉注意力机制建模车辆、客户与仓库之间的关系；在20个客户、4辆车的多车场景下进行10次独立实验。

Result: 三种方法均能学习到有效的路径策略，但量子增强模型（尤其是混合架构）在路径距离、紧凑性和路线重叠等指标上表现更优，且生成的路线更具结构性和一致性。

Conclusion: 混合量子-经典强化学习模型在处理CVRP等复杂组合优化问题上展现出显著优势，具有良好的应用前景。

Abstract: This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.

</details>


### [140] [Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000)
*Ali Shendabadi,Parnia Izadirad,Mostafa Salehi,Mahmoud Bijankhan*

Main category: cs.AI

TL;DR: 本文提出两种基于注意力的池化方法（Multi-head Attentive Average Pooling 和 QKV Pooling），利用 Whisper 预训练模型进行语音情感识别（SER），在 ShEMO 数据集上取得 SOTA 结果，表明 Whisper 可作为高效的情感特征提取器。


<details>
  <summary>Details</summary>
Motivation: 现有 SER 研究受限于缺乏标准且规模足够大的数据集，而预训练模型可为下游任务提供有效特征。本文旨在探索 Whisper 在 SER 任务中的潜力，并设计高效的池化方法以保留情感信息。

Method: 利用 Whisper Tiny 和 Small 模型提取语音表示，并提出 Multi-head Attentive Average Pooling 与 QKV Pooling 两种注意力池化方法对表示进行降维；在 IEMOCAP（英语）和 ShEMO（波斯语）数据集上进行实验，比较不同编码层的表现。

Result: 所提出的多头 QKV 架构在 ShEMO 数据集上达到 SOTA，未加权准确率提升 2.47%；实验发现中间层编码器在波斯语 SER 任务中表现更优，且优于更大模型如 HuBERT X-Large。

Conclusion: Whisper 可作为 SER 任务中有效的表示提取器，结合注意力池化方法能高效保留情感特征，为资源受限场景提供轻量级替代方案。

Abstract: Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

</details>


### [141] [AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008)
*Xianyang Liu,Shangding Gu,Dawn Song*

Main category: cs.AI

TL;DR: 本文提出了AgenticPay，一个用于评估多智能体通过自然语言进行买家-卖家谈判的基准框架，涵盖110多项任务，揭示了当前大语言模型在长期策略推理和谈判表现上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对多智能体之间基于语言的经济互动进行系统性评估的设置，难以衡量大语言模型在真实市场谈判场景中的能力。

Method: 构建AgenticPay框架，模拟具有私有约束和产品依赖估值的买家与卖家之间的多轮自然语言谈判，支持从双边讨价还价到多对多市场的多样化任务，并提供结构化动作提取及可行性、效率和福利等评估指标。

Result: 对主流开源和闭源大语言模型的测试显示，其在谈判任务中存在显著性能差距，尤其在长期策略推理方面表现不佳。

Conclusion: AgenticPay为研究基于语言的智能体商业交互和市场谈判提供了坚实基础，推动了多智能体经济行为的评估与改进。

Abstract: Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

</details>


### [142] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 本文提出一种基于虚拟现实（VR）数据驱动的离散事件模拟器（DES），用于高效、可扩展地评估和学习校园枪击事件中的干预策略，特别是机器人干预方案，从而克服直接使用人类受试者进行大规模或迭代实验的限制。


<details>
  <summary>Details</summary>
Motivation: 在高风险场景（如校园枪击）中，虽然VR能提供行为保真度高的实验环境，但每次评估新干预措施都需要招募新的参与者，难以支持大规模或需要大量训练回合的策略学习。因此，亟需一种可扩展的替代方法。

Method: 开发了一个数据驱动的离散事件模拟器（DES），该模拟器将枪手移动和区域内行为建模为从VR研究中参与者行为学习得到的随机过程，并用其评估基于机器人的干预策略。

Result: 该DES成功复现了关键的实证行为模式，并实现了对人类受试者难以直接训练的干预策略的可扩展评估与学习。

Conclusion: 本研究展示了一种从高保真VR到中保真模拟的工作流，为自主校园安全干预策略的开发与评估提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


### [143] [DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching](https://arxiv.org/abs/2602.06039)
*Yuxing Lu,Yucheng Hu,Xukai Zhao,Jiuxin Cao*

Main category: cs.AI

TL;DR: DyTopo 是一种动态拓扑的多智能体框架，通过在每轮推理中根据任务目标动态构建稀疏通信图，提升多轮推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统通常采用固定的通信模式，无法适应迭代求解过程中不同阶段的通信需求。

Method: DyTopo 引入一个管理者，在每轮根据目标引导各智能体生成自然语言形式的“需求”与“提供”描述符；通过嵌入和语义匹配构建稀疏有向通信图，并仅沿该图传递私有消息。

Result: 在代码生成与数学推理任务上，使用四种大语言模型作为骨干，DyTopo 平均比最强基线提升 6.2 个百分点。

Conclusion: DyTopo 不仅提升了准确率，还通过动态演化的通信图提供了可解释的协作轨迹，便于分析多轮通信结构的变化。

Abstract: Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [144] [AI Agent Systems for Supply Chains: Structured Decision Prompts and Memory Retrieval](https://arxiv.org/abs/2602.05524)
*Konosuke Yoshizato,Kazuma Shimizu,Ryota Higa,Takanobu Otsuka*

Main category: cs.MA

TL;DR: 本文研究了基于大语言模型（LLM）的多智能体系统（MAS）在库存管理中的应用，提出了一种名为AIM-RM的新智能体，通过历史经验匹配提升适应性，在多种供应链场景中表现优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 现有库存管理方法面临挑战，而LLM-based MAS虽具潜力，但其能否稳定推导最优订货策略并适应多样供应链场景仍不明确。

Method: 作者首先测试了一个采用固定订货策略提示的LLM-based MAS；随后提出AIM-RM智能体，利用相似性匹配借鉴历史经验以增强适应性。

Result: 实验表明，即使无精细提示调整，LLM-based MAS也能在受限场景下做出最优订货决策；AIM-RM在多种供应链场景中均优于基准方法。

Conclusion: LLM-based MAS在库存管理中具有可行性，而AIM-RM通过引入历史经验匹配机制显著提升了系统的鲁棒性与适应性。

Abstract: This study investigates large language model (LLM) -based multi-agent systems (MASs) as a promising approach to inventory management, which is a key component of supply chain management. Although these systems have gained considerable attention for their potential to address the challenges associated with typical inventory management methods, key uncertainties regarding their effectiveness persist. Specifically, it is unclear whether LLM-based MASs can consistently derive optimal ordering policies and adapt to diverse supply chain scenarios. To address these questions, we examine an LLM-based MAS with a fixed-ordering strategy prompt that encodes the stepwise processes of the problem setting and a safe-stock strategy commonly used in inventory management. Our empirical results demonstrate that, even without detailed prompt adjustments, an LLM-based MAS can determine optimal ordering decisions in a restricted scenario. To enhance adaptability, we propose a novel agent called AIM-RM, which leverages similar historical experiences through similarity matching. Our results show that AIM-RM outperforms benchmark methods across various supply chain scenarios, highlighting its robustness and adaptability.

</details>


### [145] [Learning to Share: Selective Memory for Efficient Parallel Agentic Systems](https://arxiv.org/abs/2602.05965)
*Joseph Fioresi,Parth Parag Kulkarni,Ashmal Vayani,Song Wang,Mubarak Shah*

Main category: cs.MA

TL;DR: 本文提出了一种名为“Learning to Share (LTS)”的机制，通过在并行智能体系统中引入可学习的共享内存，减少重复计算，提升效率而不牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 并行多智能体系统在解决复杂任务时存在大量重复计算，不同团队对相似子问题独立推理导致资源浪费，亟需一种机制实现高效的信息共享。

Method: LTS 引入一个全局内存库和一个轻量级控制器。控制器通过逐步强化学习与使用感知的信用分配机制，决定哪些中间步骤应存入共享内存，从而实现选择性信息复用并控制上下文增长。

Result: 在 AssistantBench 和 GAIA 基准测试中，LTS 显著降低整体运行时间，同时在任务性能上达到或优于无共享内存的并行基线。

Conclusion: 可学习的内存准入策略是提升并行智能体系统效率的有效方法，能够在保持甚至提升性能的同时大幅减少计算开销。

Abstract: Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently reason about similar sub-problems or execute analogous steps, they repeatedly perform substantial overlapping computation. To address these limitations, in this paper, we propose Learning to Share (LTS), a learned shared-memory mechanism for parallel agentic frameworks that enables selective cross-team information reuse while controlling context growth. LTS introduces a global memory bank accessible to all teams and a lightweight controller that decides whether intermediate agent steps should be added to memory or not. The controller is trained using stepwise reinforcement learning with usage-aware credit assignment, allowing it to identify information that is globally useful across parallel executions. Experiments on the AssistantBench and GAIA benchmarks show that LTS significantly reduces overall runtime while matching or improving task performance compared to memory-free parallel baselines, demonstrating that learned memory admission is an effective strategy for improving the efficiency of parallel agentic systems. Project page: https://joefioresi718.github.io/LTS_webpage/

</details>


### [146] [PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling](https://arxiv.org/abs/2602.06030)
*Kavana Venkatesh,Yinhan He,Jundong Li,Jiaming Cui*

Main category: cs.MA

TL;DR: 本文提出PhysicsAgentABM，通过将推理聚焦于行为一致的智能体聚类，结合符号化机制先验与多模态神经转移模型，并引入基于LLM的高效聚类策略ANCHOR，实现可扩展、校准良好的群体级模拟。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的多智能体系统虽具表达力但难以扩展且在校准时间步对齐的状态转移模拟方面表现不佳；而传统基于智能体的模型（ABM）虽具可解释性，却难以融合丰富的个体信号和非平稳行为。因此，亟需一种兼顾可扩展性、校准性和表达能力的新范式。

Method: PhysicsAgentABM将推理转移到行为一致的智能体聚类：使用状态专用的符号智能体编码机制转移先验，多模态神经转移模型捕捉时序与交互动态，通过不确定性感知的认知融合生成校准的聚类级转移分布；个体智能体在局部约束下随机实现转移。此外，提出ANCHOR策略，利用LLM驱动的跨情境行为响应和新型对比损失进行聚类，显著减少LLM调用次数。

Result: 在公共卫生、金融和社会科学等多个领域的实验表明，PhysicsAgentABM在事件时间准确性和校准性方面均优于机制模型、神经模型和LLM基线方法。

Conclusion: 通过围绕群体级推理重构生成式ABM，并融合不确定性感知的神经符号方法，PhysicsAgentABM为利用LLM进行可扩展且校准良好的模拟建立了新范式。

Abstract: Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.

</details>
